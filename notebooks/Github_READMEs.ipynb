{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bd1f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp github_readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37f32d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b45858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from github_search import paperswithcode_tasks\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d90f4d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_readme(repo):\n",
    "    url_pattern = \"https://raw.githubusercontent.com/{}/master/README.md\"\n",
    "    result = requests.get(url_pattern.format(repo))\n",
    "    if result.status_code == 200:\n",
    "        return result.content\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "046d4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_df, all_papers_df = paperswithcode_tasks.get_paperswithcode_dfs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367eaf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20d793ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8cf98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.86 s, sys: 684 ms, total: 3.55 s\n",
      "Wall time: 4min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readmes = list(pool.map(get_readme, paperswithcode_df[\"repo\"].iloc[:10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f7754eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "readmes = pd.Series(readmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d472f4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       b'# APE-NPI\\nSource code of paper \"Automatic P...\n",
       "1       b'# Deep Transferring Quantization\\n\\nWe provi...\n",
       "2       b'# README\\n\\n## About\\n\\nParallel bayesian op...\n",
       "3       b'# LaneNet lane detection in Pytorch\\n\\nLaneN...\n",
       "4       b'# Misbehaviour Prediction for Autonomous Dri...\n",
       "                              ...                        \n",
       "9995    b'# Structure and Isotropy of Lattice Pressure...\n",
       "9996    b'# ESPCN-PyTorch\\n\\n## Overview\\n\\nThis repos...\n",
       "9997                                                 None\n",
       "9998    b'# ESPCN-PyTorch\\n\\n## Overview\\n\\nThis repos...\n",
       "9999    b'# An End-to-End Architecture for Keyword Spo...\n",
       "Length: 10000, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8b967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def try_decode(s, codec=\"utf-8\"):\n",
    "    try:\n",
    "        return s.decode(codec)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_readmes(df, max_workers):\n",
    "    pool = concurrent.futures.ThreadPoolExecutor(max_workers=max_workers)\n",
    "    raw_readmes = list(pool.map(get_readme, df[\"repo\"]))\n",
    "    readmes = list(map(try_decode, raw_readmes))\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d54cd6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.12 s, sys: 94.2 ms, total: 2.22 s\n",
      "Wall time: 39.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readmes = paperswithcode_df[\"repo\"].iloc[:200].apply(get_readme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ffd51f2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "      <th>repo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>https://paperswithcode.com/paper/low-rank-matr...</td>\n",
       "      <td>Low-Rank Matrix Recovery from Row-and-Column A...</td>\n",
       "      <td>1505.06292</td>\n",
       "      <td>http://arxiv.org/abs/1505.06292v1</td>\n",
       "      <td>http://arxiv.org/pdf/1505.06292v1.pdf</td>\n",
       "      <td>https://github.com/avishaiwa/SVLS</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>avishaiwa/SVLS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>https://paperswithcode.com/paper/incorporating...</td>\n",
       "      <td>Incorporating long-range consistency in CNN-ba...</td>\n",
       "      <td>1606.01286</td>\n",
       "      <td>http://arxiv.org/abs/1606.01286v2</td>\n",
       "      <td>http://arxiv.org/pdf/1606.01286v2.pdf</td>\n",
       "      <td>https://github.com/guillaumebrg/texture_genera...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>guillaumebrg/texture_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>https://paperswithcode.com/paper/towards-k-mea...</td>\n",
       "      <td>Towards K-means-friendly Spaces: Simultaneous ...</td>\n",
       "      <td>1610.04794</td>\n",
       "      <td>http://arxiv.org/abs/1610.04794v2</td>\n",
       "      <td>http://arxiv.org/pdf/1610.04794v2.pdf</td>\n",
       "      <td>https://github.com/boyangumn/DCN</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>boyangumn/DCN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>https://paperswithcode.com/paper/proximal-poli...</td>\n",
       "      <td>Proximal Policy Optimization Algorithms</td>\n",
       "      <td>1707.06347</td>\n",
       "      <td>http://arxiv.org/abs/1707.06347v2</td>\n",
       "      <td>http://arxiv.org/pdf/1707.06347v2.pdf</td>\n",
       "      <td>https://github.com/clwainwright/proximal_polic...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "      <td>clwainwright/proximal_policy_optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>https://paperswithcode.com/paper/unifying-regi...</td>\n",
       "      <td>Unifying Registration based Tracking: A Case S...</td>\n",
       "      <td>1607.04673</td>\n",
       "      <td>http://arxiv.org/abs/1607.04673v4</td>\n",
       "      <td>http://arxiv.org/pdf/1607.04673v4.pdf</td>\n",
       "      <td>https://github.com/abhineet123/MTF</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>abhineet123/MTF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>https://paperswithcode.com/paper/automated-cor...</td>\n",
       "      <td>Automated Coronal Hole Identification via Mult...</td>\n",
       "      <td>1711.11476</td>\n",
       "      <td>http://arxiv.org/abs/1711.11476v1</td>\n",
       "      <td>http://arxiv.org/pdf/1711.11476v1.pdf</td>\n",
       "      <td>https://github.com/GartontT/CHIMERA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "      <td>GartontT/CHIMERA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>https://paperswithcode.com/paper/cross-lingual...</td>\n",
       "      <td>Cross-Lingual Adaptation using Structural Corr...</td>\n",
       "      <td>1008.0716</td>\n",
       "      <td>http://arxiv.org/abs/1008.0716v2</td>\n",
       "      <td>http://arxiv.org/pdf/1008.0716v2.pdf</td>\n",
       "      <td>https://github.com/pprett/bolt</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "      <td>pprett/bolt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>https://paperswithcode.com/paper/lip-movements...</td>\n",
       "      <td>Lip Movements Generation at a Glance</td>\n",
       "      <td>1803.10404</td>\n",
       "      <td>http://arxiv.org/abs/1803.10404v3</td>\n",
       "      <td>http://arxiv.org/pdf/1803.10404v3.pdf</td>\n",
       "      <td>https://github.com/lelechen63/3d_gan</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>lelechen63/3d_gan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>https://paperswithcode.com/paper/mobilenets-ef...</td>\n",
       "      <td>MobileNets: Efficient Convolutional Neural Net...</td>\n",
       "      <td>1704.04861</td>\n",
       "      <td>http://arxiv.org/abs/1704.04861v1</td>\n",
       "      <td>http://arxiv.org/pdf/1704.04861v1.pdf</td>\n",
       "      <td>https://github.com/Tsejing/object_detection</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "      <td>Tsejing/object_detection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>https://paperswithcode.com/paper/recent-trends...</td>\n",
       "      <td>Recent Trends in Deep Learning Based Natural L...</td>\n",
       "      <td>1708.02709</td>\n",
       "      <td>http://arxiv.org/abs/1708.02709v8</td>\n",
       "      <td>http://arxiv.org/pdf/1708.02709v8.pdf</td>\n",
       "      <td>https://github.com/ridakadri14/AspectBasedSent...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "      <td>ridakadri14/AspectBasedSentimentAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>https://paperswithcode.com/paper/effective-lst...</td>\n",
       "      <td>Effective LSTMs for Target-Dependent Sentiment...</td>\n",
       "      <td>1512.01100</td>\n",
       "      <td>http://arxiv.org/abs/1512.01100v2</td>\n",
       "      <td>http://arxiv.org/pdf/1512.01100v2.pdf</td>\n",
       "      <td>https://github.com/ridakadri14/AspectBasedSent...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "      <td>ridakadri14/AspectBasedSentimentAnalysis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>https://paperswithcode.com/paper/a-deep-genera...</td>\n",
       "      <td>A Deep Generative Model for Semi-Supervised Cl...</td>\n",
       "      <td>1809.05957</td>\n",
       "      <td>http://arxiv.org/abs/1809.05957v1</td>\n",
       "      <td>http://arxiv.org/pdf/1809.05957v1.pdf</td>\n",
       "      <td>https://github.com/maxime1310/fuzzy_labeling_s...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>maxime1310/fuzzy_labeling_scRNA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>https://paperswithcode.com/paper/self-normaliz...</td>\n",
       "      <td>Self-Normalizing Neural Networks</td>\n",
       "      <td>1706.02515</td>\n",
       "      <td>http://arxiv.org/abs/1706.02515v5</td>\n",
       "      <td>http://arxiv.org/pdf/1706.02515v5.pdf</td>\n",
       "      <td>https://github.com/BioImageInformatics/tfmodels</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "      <td>BioImageInformatics/tfmodels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_url  \\\n",
       "56   https://paperswithcode.com/paper/low-rank-matr...   \n",
       "62   https://paperswithcode.com/paper/incorporating...   \n",
       "84   https://paperswithcode.com/paper/towards-k-mea...   \n",
       "99   https://paperswithcode.com/paper/proximal-poli...   \n",
       "118  https://paperswithcode.com/paper/unifying-regi...   \n",
       "150  https://paperswithcode.com/paper/automated-cor...   \n",
       "153  https://paperswithcode.com/paper/cross-lingual...   \n",
       "154  https://paperswithcode.com/paper/lip-movements...   \n",
       "155  https://paperswithcode.com/paper/mobilenets-ef...   \n",
       "168  https://paperswithcode.com/paper/recent-trends...   \n",
       "169  https://paperswithcode.com/paper/effective-lst...   \n",
       "190  https://paperswithcode.com/paper/a-deep-genera...   \n",
       "196  https://paperswithcode.com/paper/self-normaliz...   \n",
       "\n",
       "                                           paper_title paper_arxiv_id  \\\n",
       "56   Low-Rank Matrix Recovery from Row-and-Column A...     1505.06292   \n",
       "62   Incorporating long-range consistency in CNN-ba...     1606.01286   \n",
       "84   Towards K-means-friendly Spaces: Simultaneous ...     1610.04794   \n",
       "99             Proximal Policy Optimization Algorithms     1707.06347   \n",
       "118  Unifying Registration based Tracking: A Case S...     1607.04673   \n",
       "150  Automated Coronal Hole Identification via Mult...     1711.11476   \n",
       "153  Cross-Lingual Adaptation using Structural Corr...      1008.0716   \n",
       "154               Lip Movements Generation at a Glance     1803.10404   \n",
       "155  MobileNets: Efficient Convolutional Neural Net...     1704.04861   \n",
       "168  Recent Trends in Deep Learning Based Natural L...     1708.02709   \n",
       "169  Effective LSTMs for Target-Dependent Sentiment...     1512.01100   \n",
       "190  A Deep Generative Model for Semi-Supervised Cl...     1809.05957   \n",
       "196                   Self-Normalizing Neural Networks     1706.02515   \n",
       "\n",
       "                         paper_url_abs                          paper_url_pdf  \\\n",
       "56   http://arxiv.org/abs/1505.06292v1  http://arxiv.org/pdf/1505.06292v1.pdf   \n",
       "62   http://arxiv.org/abs/1606.01286v2  http://arxiv.org/pdf/1606.01286v2.pdf   \n",
       "84   http://arxiv.org/abs/1610.04794v2  http://arxiv.org/pdf/1610.04794v2.pdf   \n",
       "99   http://arxiv.org/abs/1707.06347v2  http://arxiv.org/pdf/1707.06347v2.pdf   \n",
       "118  http://arxiv.org/abs/1607.04673v4  http://arxiv.org/pdf/1607.04673v4.pdf   \n",
       "150  http://arxiv.org/abs/1711.11476v1  http://arxiv.org/pdf/1711.11476v1.pdf   \n",
       "153   http://arxiv.org/abs/1008.0716v2   http://arxiv.org/pdf/1008.0716v2.pdf   \n",
       "154  http://arxiv.org/abs/1803.10404v3  http://arxiv.org/pdf/1803.10404v3.pdf   \n",
       "155  http://arxiv.org/abs/1704.04861v1  http://arxiv.org/pdf/1704.04861v1.pdf   \n",
       "168  http://arxiv.org/abs/1708.02709v8  http://arxiv.org/pdf/1708.02709v8.pdf   \n",
       "169  http://arxiv.org/abs/1512.01100v2  http://arxiv.org/pdf/1512.01100v2.pdf   \n",
       "190  http://arxiv.org/abs/1809.05957v1  http://arxiv.org/pdf/1809.05957v1.pdf   \n",
       "196  http://arxiv.org/abs/1706.02515v5  http://arxiv.org/pdf/1706.02515v5.pdf   \n",
       "\n",
       "                                              repo_url  mentioned_in_paper  \\\n",
       "56                   https://github.com/avishaiwa/SVLS                True   \n",
       "62   https://github.com/guillaumebrg/texture_genera...                True   \n",
       "84                    https://github.com/boyangumn/DCN                True   \n",
       "99   https://github.com/clwainwright/proximal_polic...               False   \n",
       "118                 https://github.com/abhineet123/MTF               False   \n",
       "150                https://github.com/GartontT/CHIMERA               False   \n",
       "153                     https://github.com/pprett/bolt                True   \n",
       "154               https://github.com/lelechen63/3d_gan               False   \n",
       "155        https://github.com/Tsejing/object_detection               False   \n",
       "168  https://github.com/ridakadri14/AspectBasedSent...               False   \n",
       "169  https://github.com/ridakadri14/AspectBasedSent...               False   \n",
       "190  https://github.com/maxime1310/fuzzy_labeling_s...                True   \n",
       "196    https://github.com/BioImageInformatics/tfmodels               False   \n",
       "\n",
       "     mentioned_in_github framework                                       repo  \n",
       "56                 False      none                             avishaiwa/SVLS  \n",
       "62                 False      none            guillaumebrg/texture_generation  \n",
       "84                  True      none                              boyangumn/DCN  \n",
       "99                  True        tf  clwainwright/proximal_policy_optimization  \n",
       "118                 True      none                            abhineet123/MTF  \n",
       "150                 True      none                           GartontT/CHIMERA  \n",
       "153                False      none                                pprett/bolt  \n",
       "154                 True   pytorch                          lelechen63/3d_gan  \n",
       "155                 True        tf                   Tsejing/object_detection  \n",
       "168                 True        tf   ridakadri14/AspectBasedSentimentAnalysis  \n",
       "169                 True        tf   ridakadri14/AspectBasedSentimentAnalysis  \n",
       "190                False   pytorch            maxime1310/fuzzy_labeling_scRNA  \n",
       "196                 True        tf               BioImageInformatics/tfmodels  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df.iloc[:200][readmes.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cabd5d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_readme(paperswithcode_df.iloc[100][\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1441edb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This repo implements DP-GAN (https://arxiv.org/abs/1802.01345) and SeqGAN for Neural Dialogue generation (https://arxiv.org/abs/1701.06547). Additionally, we propose a new Actor Critic framework for DP-GAN which we call DPAC-GAN. This project is done for the course Information Retrieval 2 as part of the Masters in Artificial Intelligence. \\n\\nWe based code for the generator on seq2seq models from IBM (https://github.com/IBM/pytorch-seq2seq) and use NLG-Eval from (https://github.com/Maluuba/nlg-eval).\\n'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "646ab8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# LaneNet lane detection in Pytorch\n",
      "\n",
      "LaneNet is a segmentation-tasked lane detection algorithm, described in [1] \"[Towards end-to-end lane detection: an instance segmentation approach](https://arxiv.org/pdf/1802.05591.pdf)\" . The key idea of instance segmentation should be referred to [2] \"[Semantic instance segmentation with a discriminative loss function](https://arxiv.org/pdf/1708.02551.pdf)\". This repository contains a re-implementation in Pytorch.\n",
      "\n",
      "### News\n",
      "- Codebase would be updated these days. There are many bugs currently in this repo. Sorry for the late response. \n",
      "\n",
      "\n",
      "\n",
      "## Data preparation\n",
      "\n",
      "### CULane\n",
      "\n",
      "The dataset is available in [CULane](https://xingangpan.github.io/projects/CULane.html). Please download and unzip the files in one folder, which later is represented as `CULane_path`.  Then modify the path of `CULane_path` in `config.py`.\n",
      "```\n",
      "CULane_path\n",
      "├── driver_100_30frame\n",
      "├── driver_161_90frame\n",
      "├── driver_182_30frame\n",
      "├── driver_193_90frame\n",
      "├── driver_23_30frame\n",
      "├── driver_37_30frame\n",
      "├── laneseg_label_w16\n",
      "├── laneseg_label_w16_test\n",
      "└── list\n",
      "```\n",
      "\n",
      "**Note: absolute path is encouraged.**\n",
      "\n",
      "\n",
      "\n",
      "### Tusimple\n",
      "The dataset is available in [here](https://github.com/TuSimple/tusimple-benchmark/issues/3). Please download and unzip the files in one folder, which later is represented as `Tusimple_path`. Then modify the path of `Tusimple_path` in `config.py`.\n",
      "```\n",
      "Tusimple_path\n",
      "├── clips\n",
      "├── label_data_0313.json\n",
      "├── label_data_0531.json\n",
      "├── label_data_0601.json\n",
      "└── test_label.json\n",
      "```\n",
      "\n",
      "**Note:  seg\\_label images and gt.txt, as in CULane dataset format,  will be generated the first time `Tusimple` object is instantiated. It may take time.**\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Demo Test\n",
      "\n",
      "For single image demo test:\n",
      "\n",
      "```Bash\n",
      "python demo_test.py -i demo/demo.jpg \n",
      "                    -w path/to/weight\n",
      "                    -b 1.5\n",
      "                    [--visualize / -v]\n",
      "```\n",
      "\n",
      "An untested model can be downloaded [here].  (It will be uploaded soon.)\n",
      "![](demo/demo_result.jpg \"demo_result\")\n",
      "\n",
      "\n",
      "\n",
      "## Train \n",
      "\n",
      "1. Specify an experiment directory, e.g. `experiments/exp0`.  Assign the path to variable `exp_dir` in `train.py`.\n",
      "\n",
      "2. Modify the hyperparameters in `experiments/exp0/cfg.json`.\n",
      "\n",
      "3. Start training:\n",
      "\n",
      "   ```python\n",
      "   python train.py [-r]\n",
      "   ```\n",
      "\n",
      "4. Monitor on tensorboard:\n",
      "\n",
      "   ```\n",
      "   tensorboard --logdir='experiments/exp0' > experiments/exp0/board.log 2>&1 &\n",
      "   ```\n",
      "\n",
      "**Note**\n",
      "\n",
      "\n",
      "- My model is trained with `torch.nn.DataParallel`. Modify it according to your hardware configuration.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "## Reference\n",
      "\n",
      "[1]. Neven, Davy, et al. \"[Towards end-to-end lane detection: an instance segmentation approach.](https://arxiv.org/pdf/1802.05591.pdf)\" *2018 IEEE Intelligent Vehicles Symposium (IV)*. IEEE, 2018.\n",
      "\n",
      "[2]. De Brabandere, Bert, Davy Neven, and Luc Van Gool. \"[Semantic instance segmentation with a discriminative loss function.](https://arxiv.org/pdf/1708.02551.pdf)\" *arXiv preprint arXiv:1708.02551* (2017).\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(readmes.head().iloc[3].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99e230b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
