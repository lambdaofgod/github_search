{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb550aad-3451-4d0a-aa61-7de90b16976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ba5088-ffd7-464e-982c-1f617097906c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 128)\n",
    "\n",
    "from pathlib import Path\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d74e80ff-5ea4-4bdb-a001-137570c203af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.cache/pypoetry/virtualenvs/github-search-hM2r__Rf-py3.10/lib/python3.10/site-packages/beir/util.py:2: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from github_search.beir_evaluation import EvaluateRetrievalCustom as EvaluateRetrieval\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "\n",
    "\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from beir.retrieval.models import SPLADE, SentenceBERT, UniCOIL\n",
    "from beir.retrieval.search.sparse import SparseSearch\n",
    "\n",
    "#from github_search.ir.evaluate_bm25 import load_ir_data, load_generation_metrics_df, RetrievalConfig, get_retriever\n",
    "#from github_search.pipelines.get_zenml_results import ArtifactLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15253dbf-a922-4223-a87e-ce76d0ff5283",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dependency and librarian signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de5ebae9-cab6-4e40-9c98-de0826d77948",
   "metadata": {},
   "outputs": [],
   "source": [
    "librarian_signatures_df = pd.read_parquet(\"/home/kuba/Projects/uhackathons/fastrag_util/data/librarian_signatures.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08e79241-6506-40a9-b4db-3ee189626a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load import2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2fb2e9f-2022-4fc0-bd93-0279423b99e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26f3283e-3602-46ff-8d86-61f3242b70db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "import ast\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CorpusDataLoader(BaseModel):\n",
    "    repos_df_path: Union[str, Path]\n",
    "    generated_readmes_df_path: Union[str, Path]\n",
    "    code_df_path: Union[str, Path]\n",
    "\n",
    "    @classmethod\n",
    "    def from_dir(cls, dir):\n",
    "        dir = Path(dir)\n",
    "        return CorpusDataLoader(\n",
    "            repos_df_path=dir / \"sampled_repos.jsonl\",\n",
    "            generated_readmes_df_path=dir / \"generated_readmes.jsonl\",\n",
    "            code_df_path=dir.parent.parent / \"code\" / \"python_files_with_selected_code.feather\"\n",
    "        )\n",
    "\n",
    "    def load_repos_df(self):\n",
    "        assert self.repos_df_path.exists()\n",
    "        df = pd.read_json(self.repos_df_path, orient=\"records\", lines=True)\n",
    "        if type(df[\"tasks\"].iloc[0]) is str:\n",
    "            df[\"tasks\"] = df[\"tasks\"].apply(ast.literal_eval)\n",
    "        for col in [\"repo\", \"tasks\", \"readme\"]:\n",
    "            assert col in df.columns\n",
    "        return df\n",
    "\n",
    "    def load_generated_readmes_df(self):\n",
    "        assert self.generated_readmes_df_path.exists()\n",
    "        if \".json\" in str(self.generated_readmes_df_path):\n",
    "            return self.load_generated_readmes_from_json()\n",
    "        else:\n",
    "            return self.load_generated_readmes_from_phoenix(self.generated_readmes_df_path)\n",
    "            \n",
    "    def load_generated_readmes_from_json(self):\n",
    "        df = pd.read_json(self.generated_readmes_df_path, orient=\"records\", lines=True)\n",
    "        for col in ['rationale', 'answer', 'context_history', 'repo_name']:\n",
    "            assert col in df.columns\n",
    "        return df\n",
    "    \n",
    "    def load_python_code_df(self):\n",
    "        assert self.code_df_path.exists()\n",
    "        df = pd.read_feather(self.code_df_path)\n",
    "        for col in ['content', 'path', 'repo_name', 'tasks', 'selected_code']:\n",
    "            assert col in df.columns\n",
    "        return df\n",
    "\n",
    "    def load_corpus_dfs(self, selected_repos=None):\n",
    "        readme_df = self.load_repos_df()\n",
    "        generated_readme_df = self.load_generated_readmes_df()\n",
    "        selected_python_code_df = self.load_python_code_df()\n",
    "        repos = set(readme_df[\"repo\"]).intersection(set(generated_readme_df[\"repo_name\"]))\n",
    "        if selected_repos is not None:\n",
    "            repos = repos.intersection(set(selected_repos))\n",
    "        readme_df = readme_df[readme_df[\"repo\"].isin(repos)].reset_index()\n",
    "        generated_readme_df = generated_readme_df.set_index(\"repo_name\").loc[readme_df[\"repo\"]].reset_index()\n",
    "        selected_python_code_df = selected_python_code_df[selected_python_code_df[\"repo_name\"].isin(repos)]\n",
    "        return readme_df, generated_readme_df, selected_python_code_df\n",
    "\n",
    "    @classmethod\n",
    "    def load_generated_readmes_from_phoenix(cls, path):\n",
    "        phoenix_trace_df = pd.read_parquet(path)\n",
    "        phoenix_trace_df = phoenix_trace_df[(phoenix_trace_df[\"status_code\"] == \"OK\") & (phoenix_trace_df[\"name\"] == \"Code2Documentation.forward\")] \n",
    "        trace_generated_readmes_df = pd.json_normalize(phoenix_trace_df[phoenix_trace_df[\"name\"] == \"Code2Documentation.forward\"][\"attributes.output.value\"].apply(json.loads))\n",
    "        generated_readmes_df = pd.concat(\n",
    "            [\n",
    "                pd.json_normalize(phoenix_trace_df[\"attributes.input.value\"].apply(json.loads)),\n",
    "                trace_generated_readmes_df\n",
    "            ],\n",
    "            axis=1\n",
    "        )\n",
    "        return generated_readmes_df\n",
    "\n",
    "\n",
    "data_path = Path(\"../output\").expanduser()\n",
    "\n",
    "small_sample_loader = CorpusDataLoader(\n",
    "    repos_df_path= data_path / \"code2doc/sample2k/sampled_repos.jsonl\",\n",
    "    generated_readmes_df_path=Path(\"~/Projects\").expanduser() / \"torch_example/phoenix/sample_2k/trace_dataset-353a22a7-b529-4d9d-a4ec-75f442aa3eb7.parquet\",\n",
    "    code_df_path=data_path / \"code\" / \"python_files_with_selected_code.feather\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf37fd6e-9efd-480f-86d8-871eddd8f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentParams:\n",
    "    sampled_repos_per_task = 20\n",
    "    min_repos_per_task = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95e550ff-ab1b-45e8-8c32-9034462371e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_repos_df, sampled_generated_readmes_df, sample_python_code_df = small_sample_loader.load_corpus_dfs(librarian_signatures_df[\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b83f185-304f-45bd-a2d3-a76b0d1a6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_dfs_by_cols_in(dfs, col_values, colnames=[\"repo\", \"repo_name\"]):\n",
    "    out_dfs = []\n",
    "    for df in dfs:\n",
    "        df_cols = [c for c in colnames if c in df.columns]\n",
    "        col = df_cols[0]\n",
    "        filtered_df = df[df[col].isin(col_values)]\n",
    "        out_dfs.append(filtered_df)\n",
    "    return out_dfs\n",
    "\n",
    "\n",
    "def align_dfs(dfs, colname=\"repo\"):\n",
    "    df0 = dfs[0].reset_index()\n",
    "    df_index = df0[colname]\n",
    "    new_dfs = [\n",
    "        df.set_index(colname).loc[df_index].reset_index()\n",
    "        for df in dfs[1:]\n",
    "    ]\n",
    "    return [df0] + new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d929310a-e62c-4f63-9b9c-7025da8f4aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3998391-cfaa-41e4-9863-6656951d7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigger_sample_path = f\"../output/code2doc/sample_per_task_5_repos/sampled_repos{ExperimentParams.sampled_repos_per_task}.jsonl\"\n",
    "sample_path = bigger_sample_path#\"../output/code2doc/sample_small/sampled_repos_min10.jsonl\"\n",
    "sampled_repos_df = pd.read_json(sample_path, orient=\"records\", lines=True)\n",
    "sample_python_code_df = pd.read_feather(Path(data_path) / \"code\" / \"python_files_with_selected_code.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4060be4-5b00-4e14-8d74-21502fee7f3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6375, 9)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_repos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9232302a-b2d2-434c-9e3a-0249ff2723c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_with_all_data = (\n",
    "    set(sampled_repos_df[\"repo\"]) &\n",
    "    set(librarian_signatures_df[\"repo\"]) &\n",
    "    set(sample_python_code_df[\"repo_name\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db38845a-a524-4475-96f7-f363c46a1b10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2982"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_with_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "505c7170-9443-49d7-a434-f5858b121f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "librarian_signatures_df = librarian_signatures_df[librarian_signatures_df[\"generation\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75d9f34-ceb8-4011-a6cf-5922d0eb433a",
   "metadata": {},
   "source": [
    "Select only repos with signatures that were in sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f8d10d4-fd6e-4112-ba21-0cc8fb2b2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df, sample_python_code_df, sampled_librarian_signatures_df = filter_dfs_by_cols_in([sampled_repos_df, sample_python_code_df, librarian_signatures_df], repos_with_all_data)\n",
    "sampled_repos_df, sampled_librarian_signatures_df = align_dfs([sampled_repos_df, sampled_librarian_signatures_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19698961-c529-4039-9c20-bfc0a84c816f",
   "metadata": {},
   "source": [
    "## Sample with generated READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e69c139-2439-44ee-8ab9-7e45123bede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"codellama\"\n",
    "sample_prefix = \"sample_per_task_5_repos\"\n",
    "\n",
    "sample_loader = CorpusDataLoader(\n",
    "    repos_df_path= data_path / f\"code2doc/{sample_prefix}/sampled_repos5.jsonl\",\n",
    "    generated_readmes_df_path=data_path / f\"code2doc/{sample_prefix}/{model_name}_generated_readmes5.jsonl\",\n",
    "    code_df_path=data_path / \"code\" / \"python_files_with_selected_code.feather\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "99b187db-8c95-4242-a4f2-c5b113aae479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../output/code2doc/sample_per_task_5_repos/codellama_generated_readmes5.jsonl')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_loader.generated_readmes_df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd0c1194-3c54-457f-9efc-d1623ee62296",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df, sampled_generated_readmes_df, sample_python_code_df = sample_loader.load_corpus_dfs(librarian_signatures_df[\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54c9b94b-7070-4199-90e4-80fb4cb3930c",
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_with_all_data = set(sampled_repos_df[\"repo\"]).intersection(librarian_signatures_df[\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "958b9176-539d-4735-97a6-b5e2c39aa2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df, sample_python_code_df, sampled_librarian_signatures_df = filter_dfs_by_cols_in([sampled_repos_df, sample_python_code_df, librarian_signatures_df], repos_with_all_data)\n",
    "sampled_repos_df, sampled_librarian_signatures_df = align_dfs([sampled_repos_df, sampled_librarian_signatures_df[sampled_librarian_signatures_df[\"generation\"] == 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de791df-88cf-4280-97cf-7f8b3e33802e",
   "metadata": {},
   "source": [
    "## Example BEIR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d76d7fa-163f-492a-937f-99d047164fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "dataset = \"scifact\"\n",
    "url = \"https://public.ukp.informatik.tu-darmstadt.de/thakur/BEIR/datasets/{}.zip\".format(dataset)\n",
    "out_dir = os.path.join(pathlib.Path(\"..\").parent.absolute(), \"datasets\")\n",
    "beir_data_path = util.download_and_unzip(url, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ae4b85ec-0210-482a-84aa-bd89310cfbb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5183/5183 [00:00<00:00, 37880.68it/s]\n"
     ]
    }
   ],
   "source": [
    "_corpus, _queries, _qrels = GenericDataLoader(beir_data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0bd00916-1d08-43f1-8016-a6f2088b1a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'title'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.',\n",
       " 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(_corpus['4983'].keys())\n",
    "_corpus['4983']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce0034c-dd46-4b46-9974-9e69535ae64c",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "62889fe9-48ba-4d89-a39c-1ff8fd59b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repos_for_query(query, repos_df):\n",
    "    return repos_df[repos_df[\"tasks\"].apply(lambda ts: query in ts)]\n",
    "\n",
    "\n",
    "def get_queries(repos_df, min_query_count):\n",
    "    all_queries = repos_df[\"query_tasks\"].explode()\n",
    "    qcounts = all_queries.value_counts()\n",
    "    return qcounts[qcounts >= min_query_count].index.to_list()\n",
    "\n",
    "def prepare_query_data(repos_df, min_query_count=5):\n",
    "    task_queries = {str(i): query for (i, query) in enumerate(get_queries(repos_df, min_query_count=min_query_count))}\n",
    "\n",
    "    task_qrels = {\n",
    "        qid: {str(corpus_id): 1 for corpus_id in get_repos_for_query(task_queries[qid], repos_df).index}\n",
    "        for qid in task_queries.keys()\n",
    "    }\n",
    "    return task_queries, task_qrels\n",
    "\n",
    "\n",
    "def prepare_readme_corpus(repos_df):\n",
    "    return {str(i): {\"text\": row[\"readme\"], \"title\": row[\"repo\"], 'tasks': row['tasks']} for (i, row) in repos_df.iterrows()}\n",
    "\n",
    "\n",
    "def prepare_generated_readme_corpus(repos_df, generated_readmes_df, columns=[\"answer\"]):\n",
    "    generated_readmes_df = generated_readmes_df.set_index(\"repo_name\").loc[repos_df[\"repo\"]].reset_index()\n",
    "    return {str(i): {\"text\": \"\\n\".join(row[columns]), \"title\": row[\"repo_name\"]} for (i, row) in generated_readmes_df.iterrows()}\n",
    "\n",
    "    \n",
    "def prepare_code_corpus(repos_df, selected_python_code_df):\n",
    "    per_repo_code_df = selected_python_code_df.groupby(\"repo_name\").apply(lambda df: \"\\n\\n\".join(df[\"selected_code\"].fillna(\"\")))\n",
    "    per_repo_code_df = per_repo_code_df.loc[repos_df[\"repo\"]].reset_index()\n",
    "    return {str(i): {\"text\": row[0], \"title\": row[\"repo_name\"]} for (i, row) in per_repo_code_df.iterrows()}\n",
    "\n",
    "\n",
    "# THIS IS FOR ONE GENERATION ONLY NOW\n",
    "def prepare_librarian_corpora(repos_df, sampled_librarian_signatures_df):\n",
    "    columns = [\"dependency_signature\", \"repository_signature\", \"generated_tasks\"]\n",
    "    sampled_librarian_signatures_df = sampled_librarian_signatures_df.set_index(\"repo\").loc[repos_df[\"repo\"]].reset_index()\n",
    "    return {\n",
    "        column: {str(i): {\"text\": row[column], \"title\": row[\"repo\"]} for (i, row) in sampled_librarian_signatures_df[[\"repo\", column]].iterrows()} \n",
    "        for column in columns\n",
    "    }\n",
    "\n",
    "\n",
    "def prepare_basic_corpora(repos_df, selected_python_code_df):\n",
    "    readme_corpus = prepare_readme_corpus(repos_df)\n",
    "    selected_python_code_corpus = prepare_code_corpus(repos_df, selected_python_code_df)\n",
    "    return {\"readme\": readme_corpus, \"selected_code\": selected_python_code_corpus}\n",
    "\n",
    "\n",
    "def prepare_corpora(repos_df, generated_readmes_df, selected_python_code_df):\n",
    "    basic_corpora = prepare_basic_corpora(repos_df, selected_python_code_df)\n",
    "    readme_corpus = basic_corpora[\"readme\"]\n",
    "    selected_python_code_corpus = basic_corpora[\"selected_code\"]\n",
    "    generated_readme_corpus = prepare_generated_readme_corpus(repos_df, sampled_generated_readmes_df)\n",
    "    generated_rationale_corpus = prepare_generated_readme_corpus(repos_df, sampled_generated_readmes_df, columns=[\"rationale\"])\n",
    "    generated_readme_rationale_corpus = prepare_generated_readme_corpus(repos_df, sampled_generated_readmes_df, columns=[\"answer\", \"rationale\"])\n",
    "    generated_readme_context_corpus = prepare_generated_readme_corpus(repos_df, sampled_generated_readmes_df, columns=[\"context_history\"])\n",
    "    \n",
    "\n",
    "    assert len(readme_corpus) == len(generated_readme_corpus)\n",
    "    assert len(selected_python_code_corpus) == len(readme_corpus)\n",
    "    \n",
    "    for k in readme_corpus.keys():\n",
    "        assert readme_corpus[k]['title'] == generated_readme_corpus[k]['title'], str((readme_corpus[k]['title'], generated_readme_corpus[k]['title']))\n",
    "        assert readme_corpus[k]['title'] == selected_python_code_corpus[k]['title']\n",
    "    return {\n",
    "        \"readme\": readme_corpus,\n",
    "        \"generated_readme\": generated_readme_corpus,\n",
    "        \"selected_code\": selected_python_code_corpus,\n",
    "        \"generated_rationale\": generated_rationale_corpus,\n",
    "        \"generation_context\": generated_readme_context_corpus,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "64dee229-d10c-45f8-a833-079b10e0feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_queries, task_qrels = prepare_query_data(sampled_repos_df, min_query_count=ExperimentParams.min_repos_per_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "532a42cb-1988-4958-887d-a8b7b97a23b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    831.000000\n",
       "mean      28.132371\n",
       "std       43.113013\n",
       "min       10.000000\n",
       "25%       11.000000\n",
       "50%       14.000000\n",
       "75%       26.000000\n",
       "max      383.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(task_qrels).apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3da35506-e561-4af7-bebe-191cffbebd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    831.000000\n",
       "mean      28.132371\n",
       "std       43.113013\n",
       "min       10.000000\n",
       "25%       11.000000\n",
       "50%       14.000000\n",
       "75%       26.000000\n",
       "max      383.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([len(qrl) for qrl in task_qrels.values()]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "577c979a-268c-41b7-a6ca-968087dbced7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpora = prepare_basic_corpora(sampled_repos_df, sample_python_code_df) |  #\n",
    "corpora =  prepare_corpora(sampled_repos_df, sampled_generated_readmes_df, sample_python_code_df) | prepare_librarian_corpora(sampled_repos_df, sampled_librarian_signatures_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cda62449-ba8b-4350-a1c3-fb018ea3baf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87cd42d2-99f5-4ced-830f-d9da36a6e841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7060, 7060, 7060, 7060, 7060, 7060, 7060, 7060]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(corpora[cname].keys()) for cname in corpora.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc5caf7e-5d2b-4283-acc3-9bcf03d432a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in corpora[\"readme\"].keys():\n",
    "    assert corpora[\"readme\"][cid][\"title\"] == corpora[\"readme\"][cid][\"title\"], f\"no match at {cid}\"\n",
    "    assert corpora[\"readme\"][cid][\"title\"] == corpora[\"dependency_signature\"][cid][\"title\"], f\"no match at {cid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "83edb572-ef27-470b-b16d-90a8621b9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bf282096-1c70-453a-a73e-219386ba86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "\n",
    "es_client = elasticsearch.Elasticsearch()\n",
    "def retrieve_repos_with_es(query, k=50, index=\"readme\", es_client=es_client):\n",
    "    es_result = es_client.search(index=index, body={\"query\": {\"match\": {\"txt\": query}}}, size=k)\n",
    "    return [\n",
    "        hit[\"_source\"][\"title\"]\n",
    "        for hit in es_result[\"hits\"][\"hits\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def get_elasticsearch_results():\n",
    "    retrieved_repo_tasks = {}\n",
    "\n",
    "    qcounts = sampled_repos_df[\"tasks\"].explode().value_counts()\n",
    "    used_queries = [\n",
    "        query\n",
    "        for query in sampled_repos_df[\"tasks\"].explode().drop_duplicates()\n",
    "        if qcounts.loc[query] > 5\n",
    "    ]\n",
    "    # [task_queries[qid] for qid in task_queries.keys()]\n",
    "    \n",
    "    index=\"selected_code\"\n",
    "    for query in used_queries:\n",
    "        retrieved_tasks = sampled_repos_df[sampled_repos_df[\"repo\"].isin(retrieve_repos_with_es(query, index=index))][\"tasks\"].to_list()\n",
    "        retrieved_repo_tasks[query] = retrieved_tasks\n",
    "    \n",
    "    k = 10\n",
    "    query_hits = pd.Series({\n",
    "        query: sum([query in tasks for tasks in retrieved_repo_tasks[query][:k]])\n",
    "        for query in retrieved_repo_tasks.keys()\n",
    "    })\n",
    "\n",
    "def show_elasticsearch_results(qid='10'):\n",
    "    query = task_queries[qid]\n",
    "    \n",
    "    print(query)\n",
    "    print(query_hits[query], \"hits\")\n",
    "    \n",
    "    for hit in es_client.search(index=index, body={\"query\": {\"match\": {\"txt\": task_queries[qid]}}}, size=k)[\"hits\"][\"hits\"]:\n",
    "        print(\"#\" * 100)\n",
    "        print(\"#\" * 100)\n",
    "        repo_name = hit[\"_source\"][\"title\"]\n",
    "        repo_record = sampled_repos_df[sampled_repos_df[\"repo\"] == repo_name].iloc[0]\n",
    "        is_hit = query in repo_record[\"tasks\"]\n",
    "        print(repo_name, \"HIT\" if is_hit else \"NO HIT\")\n",
    "        \n",
    "        if is_hit:\n",
    "            print(\"#\" * 100)\n",
    "            print(\"#\" * 100)\n",
    "            print(hit['_source']['txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604b8c5-a332-4213-b1c3-3101fd14e78f",
   "metadata": {},
   "source": [
    "## Evaluating with BEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29db4c1f-942f-4eab-afdd-8383454bee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v_sentence_transformer(w2v_model_path):\n",
    "    w2v_layer = sentence_transformers.models.WordEmbeddings.load(w2v_model_path)\n",
    "    return sentence_transformers.SentenceTransformer(modules=[w2v_layer, sentence_transformers.models.Pooling(200)])\n",
    "\n",
    "def get_w2v_retriever(w2v_model_path=\"../models/rnn_abstract_readme_w2v/0_WordEmbeddings\"):\n",
    "    w2v_model = load_w2v_sentence_transformer(w2v_model_path)\n",
    "    st_model = SentenceBERT(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    st_model.q_model = w2v_model\n",
    "    st_model.doc_model = w2v_model\n",
    "    return EvaluateRetrieval(DRES(st_model), score_function=\"cos_sim\")\n",
    "\n",
    "def get_splade_retriever(splade_model_path = \"splade/weights/distilsplade_max\", batch_size=128):\n",
    "    splade_model = DRES(SPLADE(splade_model_path), batch_size=128)\n",
    "    return EvaluateRetrieval(splade_model, score_function=\"dot\")\n",
    "\n",
    "def get_bm25_retrievers(corpora):\n",
    "        \n",
    "    bm25_retrievers = {}\n",
    "    for corpus_name, corpus in corpora.items():\n",
    "        model = BM25(index_name=corpus_name)\n",
    "        retriever = EvaluateRetrieval(model)\n",
    "        bm25_retrievers[corpus_name] = retriever\n",
    "    return bm25_retrievers\n",
    "\n",
    "\n",
    "sentence_transformer_model_names = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    \"flax-sentence-embeddings/st-codesearch-distilroberta-base\"\n",
    "]\n",
    "\n",
    "def get_sentence_transformer_retriever(model_name=\"sentence-transformers/all-mpnet-base-v2\", batch_size=256):\n",
    "    model = DRES(SentenceBERT(model_name), batch_size=batch_size)\n",
    "    return EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "def get_unicoil_retriever(model_name=\"castorini/unicoil-msmarco-passage\"):\n",
    "    \"\"\"\n",
    "    THERE IS A BUG WITH BEIR THAT MAKES THIS UNUSABLE\n",
    "    \"\"\"\n",
    "    model = SparseSearch(UniCOIL(model_path=model_name), batch_size=32)\n",
    "    return EvaluateRetrieval(model, score_function=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "132bae32-1332-4d52-b7c5-12ab6c4527bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retrievers = get_bm25_retrievers(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81ca835a-6dd8-4613-91da-8d6ac91fd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splade_retriever = get_splade_retriever()\n",
    "sentence_transformer_retrievers = {\n",
    "    model_name: get_sentence_transformer_retriever(model_name)\n",
    "    for model_name in sentence_transformer_model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eaac0ad8-cc25-4c49-a9ed-c9332fa0daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_retriever = get_w2v_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d0d2c2f9-ab24-4d28-8d20-458ae701c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.cache/pypoetry/virtualenvs/github-search-hM2r__Rf-py3.10/lib/python3.10/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_type\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "\n",
    "class RetrieverInput(BaseModel):\n",
    "    corpus: Dict[str, dict]\n",
    "    queries: Dict[str, str]\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    "\n",
    "\n",
    "class RetrievalEvaluationResults(BaseModel):\n",
    "    retrieval_results: Dict[str, Dict[str, float]]\n",
    "    metrics: dict\n",
    "    model_type: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_retriever(cls, retriever, retriever_input, metric_names=[\"accuracy@k\", \"hits@k\", \"r_cap@k\"]):\n",
    "        retrieval_results = retriever.retrieve(retriever_input.corpus, retriever_input.queries)\n",
    "        custom_metrics = retriever.evaluate_custom_multi(retriever_input.qrels, retrieval_results, retriever.k_values, metrics=metric_names)\n",
    "        other_metrics = retriever.evaluate(retriever_input.qrels, retrieval_results, retriever.k_values, ignore_identical_ids=False)\n",
    "        metrics = custom_metrics | cls.tuple_to_dict(other_metrics)\n",
    "        try:\n",
    "            model_type = str(retriever.retriever.model)\n",
    "        except:\n",
    "            model_type = \"bm25\"\n",
    "        return RetrievalEvaluationResults(metrics=metrics, model_type=model_type, retrieval_results=retrieval_results)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def tuple_to_dict(cls, dicts):\n",
    "        merged_dict = {}\n",
    "        for d in dicts:\n",
    "            merged_dict = d | merged_dict\n",
    "        return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb3a3bd3-4b79-463f-b909-fbbff6b9376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_inputs = {\n",
    "    corpus_name: RetrieverInput(corpus=corpus, queries=task_queries, qrels=task_qrels)\n",
    "    for (corpus_name, corpus) in corpora.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23297d95-c8d8-4c39-bd95-d5f40162c300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "77c1a0f1-f9c2-44fc-a6b8-0f45691c93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.62it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.62it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:04<00:00,  1.52it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.79it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:02<00:00,  2.77it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  8.44it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  3.72it/s]\n",
      "  0%|                                                                                                                                                                                 | 0/7060 [00:00<?, ?docs/s]\n",
      "que: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  5.00it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(bm25_retrievers[corpus_name], retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "090813b1-30db-47b4-b448-d4dea67c2e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 52.29it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:20<00:00, 10.56it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 186.36it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:12<00:00, 17.74it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 203.45it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:23<00:00,  9.58it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 200.27it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:14<00:00, 15.29it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 194.45it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:18<00:00, 11.85it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 192.84it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:11<00:00, 19.58it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 201.63it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:12<00:00, 17.58it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 197.20it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 221/221 [00:02<00:00, 85.81it/s]\n"
     ]
    }
   ],
   "source": [
    "splade_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(splade_retriever, retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b18db778-cfd3-4495-be41-755b5a48085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 575.49it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 38.54it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1912.09it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 301.10it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1949.54it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:01<00:00, 29.05it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1620.32it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 259.35it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1684.27it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 227.48it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1630.94it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 765.15it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1676.19it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 610.63it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 1726.66it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 56/56 [00:00<00:00, 1571.45it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(w2v_retriever, retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cfbbc87e-18a4-4492-af66-0851f1ae17b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 32.97it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:35<00:00,  1.27s/it]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 94.00it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  6.60it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 73.07it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  5.11it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 40.22it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:18<00:00,  1.50it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 94.75it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  8.56it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 83.12it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  6.02it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 40.03it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:36<00:00,  1.32s/it]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 94.55it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  5.33it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 84.38it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:05<00:00,  4.68it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 39.59it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:21<00:00,  1.29it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 100.50it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  7.94it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 84.75it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  5.70it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 39.41it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:30<00:00,  1.08s/it]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 98.56it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  7.99it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 77.85it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  5.65it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 41.16it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:14<00:00,  1.94it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 100.84it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  8.13it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 84.29it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  5.83it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 41.00it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:15<00:00,  1.76it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 94.89it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  7.86it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 80.59it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:04<00:00,  5.65it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 40.41it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:02<00:00,  9.76it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 98.74it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 27.06it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 84.38it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:01<00:00, 18.14it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer_results = {\n",
    "    (corpus_name, model_name.split(\"/\")[1]): RetrievalEvaluationResults.from_retriever(sentence_transformer_retrievers[model_name], retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "    for model_name in sentence_transformer_model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "168d970f-1613-40cd-bf39-ccc755c0f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": \"bm25\", **bm25_results[corpus_name].metrics}\n",
    "    for corpus_name in corpora.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b5ca892-7b81-4a1d-aef0-8d98a2b48be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": \"Python code word2vec\", **word2vec_results[corpus_name].metrics}\n",
    "    for corpus_name in corpora.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4bba502a-d4ba-401e-bf43-d553a755e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "splade_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": \"splade\", **splade_results[corpus_name].metrics}\n",
    "     for corpus_name in corpora.keys()\n",
    "]\n",
    " \n",
    "sentence_transformer_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": f\"{model_name} (sentence_transformer)\", **sentence_transformer_results[(corpus_name, model_name)].metrics}\n",
    "    for (corpus_name, model_name) in sentence_transformer_results.keys()\n",
    "]\n",
    "\n",
    "all_metrics_df = pd.DataFrame.from_records(bm25_metrics + word2vec_metrics + splade_metrics +  sentence_transformer_metrics).sort_values(\"Hits@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6bd3b84e-430e-4177-ab38-c1c29c7822d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../output/code2doc/sample_per_task_5_repos/beir_results_codellama.csv'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"../output/code2doc/{sample_prefix}/beir_results_{model_name}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c3e17de-6297-41f2-a031-6cc47d895d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.to_csv(f\"../output/code2doc/{sample_prefix}/beir_results_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380e81d-e1d5-4e3b-bbe4-c6842ade4eb2",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "By default we will use min_task_count=10 (as we used originally)\n",
    "\n",
    "We can switch to smaller task counts like 5 to incorporate the fact that we use sample of repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3834435-49fe-4530-b371-5b5e046a4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_cols = [\"corpus\", \"retriever\", \"Accuracy@10\", \"Hits@10\", \"R_cap@10\", \"NDCG@10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c057a-4e95-4faa-aa2b-392c521913fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[metric_df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84006df9-9b52-430b-8366-842b536e29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"corpus\").apply(lambda df: df.sort_values(\"Accuracy@10\", ascending=False).iloc[0])[metric_df_cols].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792258e0-5684-48af-852b-5a605d28d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\").apply(lambda df: df.sort_values(\"Accuracy@10\", ascending=False).iloc[0])[metric_df_cols].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe046c-2a0d-45f1-9312-2c3b946da92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[all_metrics_df[\"retriever\"] == \"bm25\"][metric_df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c9fac-7d0e-4435-ad1a-c19c399c1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(task_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d20918-117d-43d7-8f65-5dd9f8cb077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624352d5-f9be-4b0d-b4ae-383794166137",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca4f6d-9a5b-45d0-98ff-5d103203a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c7855-7279-4170-9fd5-1360e8fef5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f9993-0773-4de9-8dad-e55f5e458c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421d2ec-14b5-46e4-91ad-701e16a041f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9e80f-9263-4092-93df-c316df93f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2fe2e-b314-4bc4-b33b-4ee1048601fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"corpus\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56598d-9dc5-4804-8bf4-d3133832208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df[\"tasks\"].explode().value_counts().loc[list(task_queries.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72a823-c74f-45f3-ac25-9b4b0ab9be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd8ff1-3a58-44f1-bebf-fd4face2563a",
   "metadata": {},
   "source": [
    "## Does combining rationale with generated readme help?\n",
    "\n",
    "It seems that the best sentence transformer retrievers can only get worse when using any other information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12853e-cec3-4cca-a9fb-1644f172090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc79a75-9a8a-4d2b-b22a-e4ef0c42c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_generated_readme_results= sentence_transformer_results[('generated_readme', 'all-mpnet-base-v2')].retrieval_results\n",
    "st_rationale_results = sentence_transformer_results[('generated_rationale', 'all-mpnet-base-v2')].retrieval_results\n",
    "bm25_generated_readme_results = bm25_results[\"generated_readme\"].retrieval_results\n",
    "st_context_results = sentence_transformer_results[('generation_context', 'all-mpnet-base-v2')].retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5f56b-00cf-44b9-aeef-aee8bca3e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(bm25_generated_readme_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328808cf-3f7b-4fd6-927c-76d7f0f76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(st_generated_readme_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bec109-8530-48d7-a3cf-27d522a9b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_qrels(qrels1, qrels2):\n",
    "    merged_qrels = {}\n",
    "    for k in qrels1.keys():\n",
    "        tmp_rel = dict()\n",
    "        for rel_k in set(qrels1[k].keys()).union(qrels2[k]):\n",
    "            tmp_rel[rel_k] = qrels1[k].get(rel_k, 0) +  qrels2[k].get(rel_k, 0)\n",
    "        merged_qrels[k] = tmp_rel\n",
    "    return merged_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52804e89-a816-42b6-8f74-938ad36b5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_generation_results = merge_qrels(bm25_generated_readme_results, st_generated_readme_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dd17a8-a60c-4348-a509-4875c302190d",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_generation_results['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cbbaf-9966-4aee-8364-ea160f208ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_generation_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11896681-5362-49fe-abbc-c029c245dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_generated_readme_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891037fc-0580-4e20-90d7-7b4c7c94f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_rationale_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80909711-5f02-4854-97d0-6554f40d9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[all_metrics_df[\"retriever\"] == \"bm25\"][[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491390e-ee04-4559-b945-13dc91919c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting does not make much sense as the most of generated data is under the sentence-transformer context length (384 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992cd4f-32e3-4793-8e9f-b4c6e10c29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_corpus_by_lengths(corpus, chunk_length):\n",
    "    splitted_corpora = [dict() for _ in range(n_splits)]\n",
    "    for c_id in corpus.keys():\n",
    "        text = corpus[c_id][\"text\"]\n",
    "        chunk_length =  len(text) // n_splits\n",
    "        for i in range(0, n_splits):\n",
    "            splitted_corpora[i] = text[i*chunk_length:(i+1)*chunk_length]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfda84b-0d7d-427c-8feb-724c0521078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTextEvaluator(BaseModel):\n",
    "    \"\"\"\n",
    "    Evaluate a dataframe that has multiple texts for each query (multiple generation experiments)\n",
    "    iteration_col says which experiment it was\n",
    "    \"\"\"\n",
    "    iteration_col: str\n",
    "    text_cols: List[str]\n",
    "    k_values: List[int] = [1,5,10,25]\n",
    "\n",
    "    def get_ir_datas(self, df):\n",
    "        for iter in df[self.iteration_col].unique():\n",
    "            ir_data = load_ir_data(df[df[self.iteration_col] == iter], self.text_cols)\n",
    "            yield (iter, ir_data)\n",
    "\n",
    "    def evaluate(self, df, retriever):\n",
    "        ir_datas = dict(self.get_ir_datas(df))\n",
    "        dfs = []\n",
    "        for iter, ir_data in ir_datas.items():\n",
    "            per_query_evaluator = PerQueryIREvaluator(k_values=self.k_values)\n",
    "            df = per_query_evaluator.get_scores(ir_data, retriever)\n",
    "            df[self.iteration_col] = iter\n",
    "            dfs.append(df)\n",
    "        metrics_df = pd.concat(dfs)\n",
    "        metrics_df[\"query\"] = metrics_df.index\n",
    "        return metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_search",
   "language": "python",
   "name": "github_search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
