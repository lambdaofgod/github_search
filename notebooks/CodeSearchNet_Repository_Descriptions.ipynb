{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp repository_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/05/2021 20:45:36 - INFO - faiss -   Loading faiss with AVX2 support.\n",
      "03/05/2021 20:45:36 - INFO - faiss -   Loading faiss.\n",
      "03/05/2021 20:45:36 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import pypi_cli\n",
    "from sklearn import feature_extraction, metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "\n",
    "import mlutil.parallel\n",
    "\n",
    "import haystack.document_store.memory\n",
    "import haystack.document_store.elasticsearch\n",
    "from haystack import document_store\n",
    "\n",
    "import haystack.retriever.sparse\n",
    "from haystack import retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: ../data/python/train.jsonl: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '../data/python/train.jsonl' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head  -1 ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_all_codesearch_df(data_dir):\n",
    "    return pd.concat(\n",
    "        [\n",
    "            pd.read_json(os.path.join(data_dir, split), lines=True)\n",
    "            for split in [\"train.jsonl\", \"valid.jsonl\", \"test.jsonl\"]\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codesearch_df = get_all_codesearch_df(\"data/python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 280652 entries, 0 to 14917\n",
      "Data columns (total 12 columns):\n",
      "repo                280652 non-null object\n",
      "path                280652 non-null object\n",
      "func_name           280652 non-null object\n",
      "original_string     280652 non-null object\n",
      "language            280652 non-null object\n",
      "code                280652 non-null object\n",
      "code_tokens         280652 non-null object\n",
      "docstring           280652 non-null object\n",
      "docstring_tokens    280652 non-null object\n",
      "sha                 280652 non-null object\n",
      "url                 280652 non-null object\n",
      "partition           280652 non-null object\n",
      "dtypes: object(12)\n",
      "memory usage: 27.8+ MB\n"
     ]
    }
   ],
   "source": [
    "all_codesearch_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['saltstack/salt', 'mitsei/dlkit', 'google/grr', 'bcbio/bcbio-nextgen',\n",
       "       'materialsproject/pymatgen', 'tensorflow/tensor2tensor',\n",
       "       'iotile/coretools', 'pandas-dev/pandas', 'cloud9ers/gurumate',\n",
       "       'spyder-ide/spyder', 'pypa/pipenv', 'apple/turicreate', 'gem/oq-engine',\n",
       "       'pantsbuild/pants', 'log2timeline/plaso',\n",
       "       'googleapis/google-cloud-python', 'inasafe/inasafe', 'gwastro/pycbc',\n",
       "       'apache/incubator-mxnet', 'senaite/senaite.core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df[\"repo\"].value_counts().index[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github page project descriptions\n",
    "\n",
    "Most repositories have easily accesible descriptions on github.\n",
    "\n",
    "Github page HTML has description in 'title' tag.\n",
    "\n",
    "The problem with this approach is github's rate limit (we're not using API for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_html(url):\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "def get_short_description(repo):\n",
    "    url = \"http://www.github.com/{}\".format(repo)\n",
    "    html = get_html(url)\n",
    "    parsed_html = bs4.BeautifulSoup(html)\n",
    "    return parsed_html.find(\"title\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"allenai/allennlp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://www.github.com/{}?\".format(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    get_short_description(\"allenai/allennlp\")\n",
    "    == \"GitHub - allenai/allennlp: An open-source NLP research library, built on PyTorch.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.Series(all_codesearch_df[\"repo\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12361,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptions = []\n",
    "for repo in tqdm.tqdm(repos[:50]):\n",
    "    descriptions.append(get_short_description(repo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "descriptions_p = list(mlutil.parallel.mapp(get_short_description, repos[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptions_p.index('Rate limit Â· GitHub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPI project descriptions with pypi_cli\n",
    "\n",
    "Most of dataset repositories are registered in PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_pypi_package_description(package_name, part=2):\n",
    "    temp_out = StringIO()\n",
    "    sys.stdout = temp_out\n",
    "    try:\n",
    "        pypi_cli.info([package_name])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    stdout = sys.stdout.getvalue().split(\"\\n\")\n",
    "    if len(stdout) > part:\n",
    "        description = stdout[part]\n",
    "    else:\n",
    "        description = None\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensors and Dynamic neural networks in Python with strong GPU acceleration'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_package_description(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_pypi_repo_description(repo):\n",
    "    print(repo.split(\"/\"))\n",
    "    return get_pypi_package_description(repo.split(\"/\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An open-source NLP research library, built on PyTorch.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_repo_description(\"allenai/allennlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlutil.parallel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def load_pypi_repo_descriptions(\n",
    "    repos_descriptions_path=\"data/repo_pypi_descriptions.csv\",\n",
    "):\n",
    "    if not os.path.exists(repos_descriptions_path):\n",
    "        t_start = time.time()\n",
    "        pypi_descriptions_p = list(\n",
    "            mlutil.parallel.mapp(get_pypi_repo_description, repos)\n",
    "        )\n",
    "        t_end = time.time()\n",
    "\n",
    "        # repos_with_descriptions = [repo for (repo, n) in zip(repos, pypi_descriptions_p) if not n is None]\n",
    "        repos_descriptions = [\n",
    "            (repo, desc)\n",
    "            for (repo, desc) in zip(repos, pypi_descriptions_p)\n",
    "            if not (desc is None or desc == \"\")\n",
    "        ]\n",
    "        repos, descriptions = zip(*repos_descriptions)\n",
    "        repos_descriptions_df = pd.DataFrame(\n",
    "            {\"repo\": repos, \"pypi_description\": descriptions}\n",
    "        )\n",
    "        repos_descriptions_df.to_csv(repos_descriptions_path)\n",
    "        print(\"loaded descriptions in\", round((t_end - t_start) / 60, 2), \"minutes\")\n",
    "    else:\n",
    "        repos_descriptions_df = pd.read_csv(repos_descriptions_path, index_col=0)\n",
    "    return repos_descriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_descriptions_df = load_pypi_repo_descriptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long did it take to retrieve PyPI descriptions (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repos_with_no_pypi_description = len(repos) - len(repos_descriptions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repositories without pypi description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27.68%'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round(100 * n_repos_with_no_pypi_description / len(repos), 2)) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>pypi_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>Tools for phylogenetic data analysis including visualization and cluster-com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkouhei/bootstrap-py</td>\n",
       "      <td>Open-source algorithms for data-driven building analysis and control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elbow-jason/Uno-deprecated</td>\n",
       "      <td>Bootstrap Python package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disqus/nydus</td>\n",
       "      <td>Extremely fast and easy feature based HTML generator.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jay-johnson/network-pipeline</td>\n",
       "      <td>Connection utilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    repo  \\\n",
       "Unnamed: 0                                 \n",
       "0                   smdabdoub/phylotoast   \n",
       "1                   mkouhei/bootstrap-py   \n",
       "2             elbow-jason/Uno-deprecated   \n",
       "3                           disqus/nydus   \n",
       "4           jay-johnson/network-pipeline   \n",
       "\n",
       "                                                                           pypi_description  \n",
       "Unnamed: 0                                                                                   \n",
       "0           Tools for phylogenetic data analysis including visualization and cluster-com...  \n",
       "1                      Open-source algorithms for data-driven building analysis and control  \n",
       "2                                                                  Bootstrap Python package  \n",
       "3                                     Extremely fast and easy feature based HTML generator.  \n",
       "4                                                                      Connection utilities  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_descriptions_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
