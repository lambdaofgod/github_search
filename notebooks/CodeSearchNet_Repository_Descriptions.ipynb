{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "WARNING:root:tensorflow or tensorflow-hub not found, loading tfhub models won't work\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import mlutil.parallel\n",
    "from io import StringIO\n",
    "import sys\n",
    "import pypi_cli\n",
    "import time\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251820 ../data/python/train.jsonl\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"repo\": \"smdabdoub/phylotoast\", \"path\": \"phylotoast/util.py\", \"func_name\": \"split_phylogeny\", \"original_string\": \"def split_phylogeny(p, level=\\\"s\\\"):\\n    \\\"\\\"\\\"\\n    Return either the full or truncated version of a QIIME-formatted taxonomy string.\\n\\n    :type p: str\\n    :param p: A QIIME-formatted taxonomy string: k__Foo; p__Bar; ...\\n\\n    :type level: str\\n    :param level: The different level of identification are kingdom (k), phylum (p),\\n                  class (c),order (o), family (f), genus (g) and species (s). If level is\\n                  not provided, the default level of identification is species.\\n\\n    :rtype: str\\n    :return: A QIIME-formatted taxonomy string up to the classification given\\n            by param level.\\n    \\\"\\\"\\\"\\n    level = level+\\\"__\\\"\\n    result = p.split(level)\\n    return result[0]+level+result[1].split(\\\";\\\")[0]\", \"language\": \"python\", \"code\": \"def split_phylogeny(p, level=\\\"s\\\"):\\n    \\\"\\\"\\\"\\n    Return either the full or truncated version of a QIIME-formatted taxonomy string.\\n\\n    :type p: str\\n    :param p: A QIIME-formatted taxonomy string: k__Foo; p__Bar; ...\\n\\n    :type level: str\\n    :param level: The different level of identification are kingdom (k), phylum (p),\\n                  class (c),order (o), family (f), genus (g) and species (s). If level is\\n                  not provided, the default level of identification is species.\\n\\n    :rtype: str\\n    :return: A QIIME-formatted taxonomy string up to the classification given\\n            by param level.\\n    \\\"\\\"\\\"\\n    level = level+\\\"__\\\"\\n    result = p.split(level)\\n    return result[0]+level+result[1].split(\\\";\\\")[0]\", \"code_tokens\": [\"def\", \"split_phylogeny\", \"(\", \"p\", \",\", \"level\", \"=\", \"\\\"s\\\"\", \")\", \":\", \"level\", \"=\", \"level\", \"+\", \"\\\"__\\\"\", \"result\", \"=\", \"p\", \".\", \"split\", \"(\", \"level\", \")\", \"return\", \"result\", \"[\", \"0\", \"]\", \"+\", \"level\", \"+\", \"result\", \"[\", \"1\", \"]\", \".\", \"split\", \"(\", \"\\\";\\\"\", \")\", \"[\", \"0\", \"]\"], \"docstring\": \"Return either the full or truncated version of a QIIME-formatted taxonomy string.\\n\\n    :type p: str\\n    :param p: A QIIME-formatted taxonomy string: k__Foo; p__Bar; ...\\n\\n    :type level: str\\n    :param level: The different level of identification are kingdom (k), phylum (p),\\n                  class (c),order (o), family (f), genus (g) and species (s). If level is\\n                  not provided, the default level of identification is species.\\n\\n    :rtype: str\\n    :return: A QIIME-formatted taxonomy string up to the classification given\\n            by param level.\", \"docstring_tokens\": [\"Return\", \"either\", \"the\", \"full\", \"or\", \"truncated\", \"version\", \"of\", \"a\", \"QIIME\", \"-\", \"formatted\", \"taxonomy\", \"string\", \".\"], \"sha\": \"0b74ef171e6a84761710548501dfac71285a58a3\", \"url\": \"https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L159-L177\", \"partition\": \"train\"}\r\n",
      "{\"repo\": \"smdabdoub/phylotoast\", \"path\": \"phylotoast/util.py\", \"func_name\": \"ensure_dir\", \"original_string\": \"def ensure_dir(d):\\n    \\\"\\\"\\\"\\n    Check to make sure the supplied directory path does not exist, if so, create it. The\\n    method catches OSError exceptions and returns a descriptive message instead of\\n    re-raising the error.\\n\\n    :type d: str\\n    :param d: It is the full path to a directory.\\n\\n    :return: Does not return anything, but creates a directory path if it doesn't exist\\n             already.\\n    \\\"\\\"\\\"\\n    if not os.path.exists(d):\\n        try:\\n            os.makedirs(d)\\n        except OSError as oe:\\n            # should not happen with os.makedirs\\n            # ENOENT: No such file or directory\\n            if os.errno == errno.ENOENT:\\n                msg = twdd(\\\"\\\"\\\"One or more directories in the path ({}) do not exist. If\\n                           you are specifying a new directory for output, please ensure\\n                           all other directories in the path currently exist.\\\"\\\"\\\")\\n                return msg.format(d)\\n            else:\\n                msg = twdd(\\\"\\\"\\\"An error occurred trying to create the output directory\\n                           ({}) with message: {}\\\"\\\"\\\")\\n                return msg.format(d, oe.strerror)\", \"language\": \"python\", \"code\": \"def ensure_dir(d):\\n    \\\"\\\"\\\"\\n    Check to make sure the supplied directory path does not exist, if so, create it. The\\n    method catches OSError exceptions and returns a descriptive message instead of\\n    re-raising the error.\\n\\n    :type d: str\\n    :param d: It is the full path to a directory.\\n\\n    :return: Does not return anything, but creates a directory path if it doesn't exist\\n             already.\\n    \\\"\\\"\\\"\\n    if not os.path.exists(d):\\n        try:\\n            os.makedirs(d)\\n        except OSError as oe:\\n            # should not happen with os.makedirs\\n            # ENOENT: No such file or directory\\n            if os.errno == errno.ENOENT:\\n                msg = twdd(\\\"\\\"\\\"One or more directories in the path ({}) do not exist. If\\n                           you are specifying a new directory for output, please ensure\\n                           all other directories in the path currently exist.\\\"\\\"\\\")\\n                return msg.format(d)\\n            else:\\n                msg = twdd(\\\"\\\"\\\"An error occurred trying to create the output directory\\n                           ({}) with message: {}\\\"\\\"\\\")\\n                return msg.format(d, oe.strerror)\", \"code_tokens\": [\"def\", \"ensure_dir\", \"(\", \"d\", \")\", \":\", \"if\", \"not\", \"os\", \".\", \"path\", \".\", \"exists\", \"(\", \"d\", \")\", \":\", \"try\", \":\", \"os\", \".\", \"makedirs\", \"(\", \"d\", \")\", \"except\", \"OSError\", \"as\", \"oe\", \":\", \"# should not happen with os.makedirs\", \"# ENOENT: No such file or directory\", \"if\", \"os\", \".\", \"errno\", \"==\", \"errno\", \".\", \"ENOENT\", \":\", \"msg\", \"=\", \"twdd\", \"(\", \"\\\"\\\"\\\"One or more directories in the path ({}) do not exist. If\\n                           you are specifying a new directory for output, please ensure\\n                           all other directories in the path currently exist.\\\"\\\"\\\"\", \")\", \"return\", \"msg\", \".\", \"format\", \"(\", \"d\", \")\", \"else\", \":\", \"msg\", \"=\", \"twdd\", \"(\", \"\\\"\\\"\\\"An error occurred trying to create the output directory\\n                           ({}) with message: {}\\\"\\\"\\\"\", \")\", \"return\", \"msg\", \".\", \"format\", \"(\", \"d\", \",\", \"oe\", \".\", \"strerror\", \")\"], \"docstring\": \"Check to make sure the supplied directory path does not exist, if so, create it. The\\n    method catches OSError exceptions and returns a descriptive message instead of\\n    re-raising the error.\\n\\n    :type d: str\\n    :param d: It is the full path to a directory.\\n\\n    :return: Does not return anything, but creates a directory path if it doesn't exist\\n             already.\", \"docstring_tokens\": [\"Check\", \"to\", \"make\", \"sure\", \"the\", \"supplied\", \"directory\", \"path\", \"does\", \"not\", \"exist\", \"if\", \"so\", \"create\", \"it\", \".\", \"The\", \"method\", \"catches\", \"OSError\", \"exceptions\", \"and\", \"returns\", \"a\", \"descriptive\", \"message\", \"instead\", \"of\", \"re\", \"-\", \"raising\", \"the\", \"error\", \".\"], \"sha\": \"0b74ef171e6a84761710548501dfac71285a58a3\", \"url\": \"https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac71285a58a3/phylotoast/util.py#L180-L206\", \"partition\": \"train\"}\r\n"
     ]
    }
   ],
   "source": [
    "!head  -2 ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codesearch_df = pd.concat([\n",
    "    pd.read_json('../data/python/train.jsonl', lines=True),\n",
    "    pd.read_json('../data/python/valid.jsonl', lines=True),\n",
    "    pd.read_json('../data/python/test.jsonl', lines=True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['saltstack/salt', 'mitsei/dlkit', 'google/grr', 'bcbio/bcbio-nextgen',\n",
       "       'materialsproject/pymatgen', 'tensorflow/tensor2tensor',\n",
       "       'iotile/coretools', 'pandas-dev/pandas', 'cloud9ers/gurumate',\n",
       "       'spyder-ide/spyder', 'pypa/pipenv', 'apple/turicreate', 'gem/oq-engine',\n",
       "       'pantsbuild/pants', 'log2timeline/plaso',\n",
       "       'googleapis/google-cloud-python', 'inasafe/inasafe', 'gwastro/pycbc',\n",
       "       'apache/incubator-mxnet', 'senaite/senaite.core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df['repo'].value_counts().index[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github page project descriptions\n",
    "\n",
    "Most repositories have easily accesible descriptions on github.\n",
    "\n",
    "Github page HTML has description in 'title' tag.\n",
    "\n",
    "The problem with this approach is github's rate limit (we're not using API for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_html(url):\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "def get_short_description(repo):\n",
    "    url = 'http://www.github.com/{}'.format(repo)\n",
    "    html = get_html(url)\n",
    "    parsed_html = bs4.BeautifulSoup(html)\n",
    "    return parsed_html.find('title').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'allenai/allennlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.github.com/{}?'.format(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_short_description('allenai/allennlp') == 'GitHub - allenai/allennlp: An open-source NLP research library, built on PyTorch.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.Series(all_codesearch_df['repo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12361,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:38<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "descriptions = []\n",
    "for repo in tqdm.tqdm(repos[:50]):\n",
    "    descriptions.append(get_short_description(repo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 274 ms, sys: 562 ms, total: 836 ms\n",
      "Wall time: 14.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "descriptions_p = list(mlutil.parallel.mapp(get_short_description, repos[:1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptions_p.index('Rate limit · GitHub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPI project descriptions with pypi_cli\n",
    "\n",
    "Most of dataset repositories are registered in PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pypi_package_description(package_name):\n",
    "    temp_out = StringIO()\n",
    "    sys.stdout = temp_out\n",
    "    try:\n",
    "        pypi_cli.info([package_name])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    stdout = sys.stdout.getvalue().split('\\n')\n",
    "    if len(stdout) > 2:\n",
    "        description = stdout[2]\n",
    "    else:\n",
    "        description = None\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python plotting package'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_package_description('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pypi_repo_description(repo):\n",
    "    print(repo.split('/'))\n",
    "    return get_pypi_package_description(repo.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An open-source NLP research library, built on PyTorch.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_repo_description('allenai/allennlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "pypi_descriptions = []\n",
    "for repo in tqdm.tqdm(repos[:100]):\n",
    "    pypi_descriptions.append(get_pypi_package_description(repo.split('/')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlutil.parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "t_start = time.time()\n",
    "pypi_descriptions_p = list(mlutil.parallel.mapp(get_pypi_repo_description, repos))\n",
    "t_end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long did it take to retrieve PyPI descriptions (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.83"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round((t_end - t_start) / 60, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repos_with_no_pypi_description = len([n for n in pypi_descriptions_p if n is None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repositories without pypi description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14.03%'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round(100 * n_repos_with_no_pypi_description / len(pypi_descriptions_p), 2)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tools for phylogenetic data analysis including visualization and cluster-computing support.',\n",
       " None,\n",
       " 'Open-source algorithms for data-driven building analysis and control',\n",
       " 'Bootstrap Python package',\n",
       " 'Extremely fast and easy feature based HTML generator.',\n",
       " None,\n",
       " 'Connection utilities',\n",
       " 'Python library to work with Steam',\n",
       " 'Distributed Network Packet Analysis Pipeline for Layer 2, 3 and 4 Frames',\n",
       " 'Django Simple Multilingual Support for Models.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pypi_descriptions_p[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
