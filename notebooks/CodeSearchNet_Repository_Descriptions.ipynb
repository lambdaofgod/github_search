{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp repository_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import requests\n",
    "from io import StringIO\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import pypi_cli\n",
    "from sklearn import feature_extraction, metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "\n",
    "import mlutil.parallel\n",
    "\n",
    "import haystack.document_store.memory\n",
    "import haystack.document_store.elasticsearch\n",
    "from haystack import document_store\n",
    "\n",
    "import haystack.retriever.sparse \n",
    "from haystack import retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: ../data/python/train.jsonl: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '../data/python/train.jsonl' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head  -1 ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_all_codesearch_df(data_dir):\n",
    "    return pd.concat([\n",
    "        pd.read_json(os.path.join(data_dir, split), lines=True) for split in ['train.jsonl', 'valid.jsonl', 'test.jsonl']\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codesearch_df = get_all_codesearch_df('data/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['saltstack/salt', 'mitsei/dlkit', 'google/grr', 'bcbio/bcbio-nextgen',\n",
       "       'materialsproject/pymatgen', 'tensorflow/tensor2tensor',\n",
       "       'iotile/coretools', 'pandas-dev/pandas', 'cloud9ers/gurumate',\n",
       "       'spyder-ide/spyder', 'pypa/pipenv', 'apple/turicreate', 'gem/oq-engine',\n",
       "       'pantsbuild/pants', 'log2timeline/plaso',\n",
       "       'googleapis/google-cloud-python', 'inasafe/inasafe', 'gwastro/pycbc',\n",
       "       'apache/incubator-mxnet', 'senaite/senaite.core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df['repo'].value_counts().index[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github page project descriptions\n",
    "\n",
    "Most repositories have easily accesible descriptions on github.\n",
    "\n",
    "Github page HTML has description in 'title' tag.\n",
    "\n",
    "The problem with this approach is github's rate limit (we're not using API for this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_html(url):\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "def get_short_description(repo):\n",
    "    url = 'http://www.github.com/{}'.format(repo)\n",
    "    html = get_html(url)\n",
    "    parsed_html = bs4.BeautifulSoup(html)\n",
    "    return parsed_html.find('title').get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = 'allenai/allennlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.github.com/{}?'.format(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_short_description('allenai/allennlp') == 'GitHub - allenai/allennlp: An open-source NLP research library, built on PyTorch.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = pd.Series(all_codesearch_df['repo'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12361,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptions = []\n",
    "for repo in tqdm.tqdm(repos[:50]):\n",
    "    descriptions.append(get_short_description(repo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "descriptions_p = list(mlutil.parallel.mapp(get_short_description, repos[:1000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "descriptions_p.index('Rate limit Â· GitHub')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyPI project descriptions with pypi_cli\n",
    "\n",
    "Most of dataset repositories are registered in PyPI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_pypi_package_description(package_name, part=2):\n",
    "    temp_out = StringIO()\n",
    "    sys.stdout = temp_out\n",
    "    try:\n",
    "        pypi_cli.info([package_name])\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "    stdout = sys.stdout.getvalue().split('\\n')\n",
    "    if len(stdout) > part:\n",
    "        description = stdout[part]\n",
    "    else:\n",
    "        description = None\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensors and Dynamic neural networks in Python with strong GPU acceleration'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_package_description('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_pypi_repo_description(repo):\n",
    "    print(repo.split('/'))\n",
    "    return get_pypi_package_description(repo.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An open-source NLP research library, built on PyTorch.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pypi_repo_description('allenai/allennlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlutil.parallel\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def load_pypi_repo_descriptions(repos_descriptions_path='data/repo_pypi_descriptions.csv'):\n",
    "    if not os.path.exists(repos_descriptions_path):\n",
    "        t_start = time.time()\n",
    "        pypi_descriptions_p = list(mlutil.parallel.mapp(get_pypi_repo_description, repos))\n",
    "        t_end = time.time()\n",
    "\n",
    "        #repos_with_descriptions = [repo for (repo, n) in zip(repos, pypi_descriptions_p) if not n is None]\n",
    "        repos_descriptions = [(repo, desc) for (repo, desc) in zip(repos, pypi_descriptions_p) if not (desc is None or desc == '')]\n",
    "        repos, descriptions = zip(*repos_descriptions)\n",
    "        repos_descriptions_df = pd.DataFrame({\n",
    "            'repo': repos,\n",
    "            'pypi_description': descriptions\n",
    "        })\n",
    "        repos_descriptions_df.to_csv(repos_descriptions_path)\n",
    "        print('loaded descriptions in', round((t_end - t_start) / 60, 2), 'minutes')\n",
    "    else:\n",
    "        repos_descriptions_df = pd.read_csv(repos_descriptions_path, index_col=0)\n",
    "    return repos_descriptions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_descriptions_df = load_pypi_repo_descriptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long did it take to retrieve PyPI descriptions (minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_repos_with_no_pypi_description = len(repos) - len(repos_descriptions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repositories without pypi description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'27.68%'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(round(100 * n_repos_with_no_pypi_description / len(repos), 2)) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>pypi_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>Tools for phylogenetic data analysis including visualization and cluster-com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkouhei/bootstrap-py</td>\n",
       "      <td>Open-source algorithms for data-driven building analysis and control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elbow-jason/Uno-deprecated</td>\n",
       "      <td>Bootstrap Python package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disqus/nydus</td>\n",
       "      <td>Extremely fast and easy feature based HTML generator.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jay-johnson/network-pipeline</td>\n",
       "      <td>Connection utilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    repo  \\\n",
       "Unnamed: 0                                 \n",
       "0                   smdabdoub/phylotoast   \n",
       "1                   mkouhei/bootstrap-py   \n",
       "2             elbow-jason/Uno-deprecated   \n",
       "3                           disqus/nydus   \n",
       "4           jay-johnson/network-pipeline   \n",
       "\n",
       "                                                                           pypi_description  \n",
       "Unnamed: 0                                                                                   \n",
       "0           Tools for phylogenetic data analysis including visualization and cluster-com...  \n",
       "1                      Open-source algorithms for data-driven building analysis and control  \n",
       "2                                                                  Bootstrap Python package  \n",
       "3                                     Extremely fast and easy feature based HTML generator.  \n",
       "4                                                                      Connection utilities  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8940, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_descriptions_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
