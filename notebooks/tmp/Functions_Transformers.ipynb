{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2b4d1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rouge_score import rouge_scorer\n",
    "import pandas as pd\n",
    "\n",
    "import torch_scatter\n",
    "import transformers\n",
    "import findkit\n",
    "from sklearn import preprocessing\n",
    "import findkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b8dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f04d8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ff0596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list the defines the different programm codes\n",
    "code = [\"\"\"def sort_list(x):\n",
    "   return sorted(x)\"\"\",\n",
    "\"\"\"def count_above_threshold(elements, threshold=0):\n",
    "    counter = 0\n",
    "    for e in elements:\n",
    "        if e > threshold:\n",
    "            counter += 1\n",
    "    return counter\"\"\",\n",
    "\"\"\"def find_min_max(elements):\n",
    "    min_ele = 99999\n",
    "    max_ele = -99999\n",
    "    for e in elements:\n",
    "        if e < min_ele:\n",
    "            min_ele = e\n",
    "        if e > max_ele:\n",
    "            max_ele = e\n",
    "    return min_ele, max_ele\"\"\"]\n",
    "    \n",
    "\n",
    "# Encode our code into the vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8078edd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 181 ms, total: 1.33 s\n",
      "Wall time: 7.31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentence_model = SentenceTransformer(\"flax-sentence-embeddings/st-codesearch-distilroberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff0ce48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_model = sentence_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "602a3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_emb = sentence_model.encode(code, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b513e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wc -l ../../output/python_functions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4c5138e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 s, sys: 1.16 s, total: 43.7 s\n",
      "Wall time: 43.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "raw_functions_all = pd.read_csv(\"../../output/python_functions.csv\", nrows=1e7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "078e4ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_functions = raw_functions_all.iloc[::50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59b2f5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136029, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_functions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bea0196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_df = pd.read_csv(\"../../data/paperswithcode_with_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d0581d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_df['tasks'] = paperswithcode_df['tasks'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "304568f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = raw_functions.merge(paperswithcode_df[['repo', 'tasks']], left_on='repo_name', right_on='repo').drop(columns=[\"repo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12630768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "google-research/google-research                      21045\n",
       "osmr/imgclsmob                                       18787\n",
       "tensorflow/models                                    11582\n",
       "huggingface/transformers                              5861\n",
       "pytorch/fairseq                                       1160\n",
       "rwightman/pytorch-image-models                        1030\n",
       "tensorflow/tensor2tensor                              1029\n",
       "PaddlePaddle/Research                                  474\n",
       "joe-prog/https-github.com-facebookresearch-ParlAI      429\n",
       "pytorch/vision                                         413\n",
       "pytorch/pytorch                                        385\n",
       "VLOGroup/tensorflow-icg                                328\n",
       "yumoh/catboost_iter                                    317\n",
       "Daikenan/LTMU                                          316\n",
       "Saibo-creator/Text-Summrize-Project                    301\n",
       "dmlc/dgl                                               246\n",
       "open-mmlab/mmsegmentation                              224\n",
       "odlgroup/odl                                           211\n",
       "vj-thakur/catboost                                     209\n",
       "tensorflow/probability                                 205\n",
       "Name: repo_name, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions['repo_name'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4267f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = functions[~functions['repo_name'].isin([\"google-research/google-research\", \"osmr/imgclsmob\", \"tensorflow/models\", \"tensorflow/tensor2tensor\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1910d399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "      <th>repo</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tasks</th>\n",
       "      <th>least_common_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>21367</td>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>Unsupervised Learning of Object Structure and ...</td>\n",
       "      <td>1906.07889</td>\n",
       "      <td>https://arxiv.org/abs/1906.07889v3</td>\n",
       "      <td>https://arxiv.org/pdf/1906.07889v3.pdf</td>\n",
       "      <td>https://github.com/google-research/google-rese...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "      <td>google-research/google-research</td>\n",
       "      <td>Unsupervised Learning of Object Structure and ...</td>\n",
       "      <td>Extracting and predicting object structure and...</td>\n",
       "      <td>[action recognition, continuous control, objec...</td>\n",
       "      <td>action recognition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          paper_url  \\\n",
       "21367       21367  https://paperswithcode.com/paper/unsupervised-...   \n",
       "\n",
       "                                             paper_title paper_arxiv_id  \\\n",
       "21367  Unsupervised Learning of Object Structure and ...     1906.07889   \n",
       "\n",
       "                            paper_url_abs  \\\n",
       "21367  https://arxiv.org/abs/1906.07889v3   \n",
       "\n",
       "                                paper_url_pdf  \\\n",
       "21367  https://arxiv.org/pdf/1906.07889v3.pdf   \n",
       "\n",
       "                                                repo_url  mentioned_in_paper  \\\n",
       "21367  https://github.com/google-research/google-rese...               False   \n",
       "\n",
       "       mentioned_in_github framework                             repo  \\\n",
       "21367                False        tf  google-research/google-research   \n",
       "\n",
       "                                                   title  \\\n",
       "21367  Unsupervised Learning of Object Structure and ...   \n",
       "\n",
       "                                                abstract  \\\n",
       "21367  Extracting and predicting object structure and...   \n",
       "\n",
       "                                                   tasks   least_common_task  \n",
       "21367  [action recognition, continuous control, objec...  action recognition  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df[paperswithcode_df['repo'] == \"google-research/google-research\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "540157a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>repo</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>High-Performance Long-Term Tracking with Meta-...</td>\n",
       "      <td>Daikenan/LTMU</td>\n",
       "      <td>[visual tracking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>PLATO: Pre-trained Dialogue Generation Model w...</td>\n",
       "      <td>PaddlePaddle/Research</td>\n",
       "      <td>[dialogue generation, question answering, text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>MeanSum: A Neural Model for Unsupervised Multi...</td>\n",
       "      <td>Saibo-creator/Text-Summrize-Project</td>\n",
       "      <td>[abstractive text summarization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>On learning optimized reaction diffusion proce...</td>\n",
       "      <td>VLOGroup/tensorflow-icg</td>\n",
       "      <td>[image restoration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18605</th>\n",
       "      <td>Graph InfoClust: Leveraging cluster-level node...</td>\n",
       "      <td>dmlc/dgl</td>\n",
       "      <td>[graph representation learning, link predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>Exploring the Limits of Transfer Learning with...</td>\n",
       "      <td>huggingface/transformers</td>\n",
       "      <td>[abstractive text summarization, common sense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24653</th>\n",
       "      <td>Mask R-CNN</td>\n",
       "      <td>jiajunhua/facebookresearch-Detectron</td>\n",
       "      <td>[human part segmentation, instance segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The Ubuntu Dialogue Corpus: A Large Dataset fo...</td>\n",
       "      <td>joe-prog/https-github.com-facebookresearch-ParlAI</td>\n",
       "      <td>[answer selection, conversational response sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25854</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>kazeevn/catboost</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31472</th>\n",
       "      <td>Learned Primal-dual Reconstruction</td>\n",
       "      <td>odlgroup/odl</td>\n",
       "      <td>[ssim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31671</th>\n",
       "      <td>U-Net: Convolutional Networks for Biomedical I...</td>\n",
       "      <td>open-mmlab/mmsegmentation</td>\n",
       "      <td>[cell segmentation, data augmentation, electro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33010</th>\n",
       "      <td>RoBERTa: A Robustly Optimized BERT Pretraining...</td>\n",
       "      <td>pytorch/fairseq</td>\n",
       "      <td>[common sense reasoning, language modelling, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>Automatic Differentiation in PyTorch</td>\n",
       "      <td>pytorch/pytorch</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>pytorch/vision</td>\n",
       "      <td>[domain adaptation, domain generalization, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34407</th>\n",
       "      <td>Fast Graph Representation Learning with PyTorc...</td>\n",
       "      <td>rusty1s/pytorch_geometric</td>\n",
       "      <td>[graph classification, graph representation le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34434</th>\n",
       "      <td>Random Erasing Data Augmentation</td>\n",
       "      <td>rwightman/pytorch-image-models</td>\n",
       "      <td>[data augmentation, image augmentation, image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36833</th>\n",
       "      <td>Countdown Regression: Sharp and Calibrated Sur...</td>\n",
       "      <td>stanfordmlgroup/cdr-mimic</td>\n",
       "      <td>[decision making, mortality prediction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37895</th>\n",
       "      <td>TensorFlow Distributions</td>\n",
       "      <td>tensorflow/probability</td>\n",
       "      <td>[probabilistic programming]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39839</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>vj-thakur/catboost</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42222</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>yumoh/catboost_iter</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_title  \\\n",
       "2348   High-Performance Long-Term Tracking with Meta-...   \n",
       "7789   PLATO: Pre-trained Dialogue Generation Model w...   \n",
       "8876   MeanSum: A Neural Model for Unsupervised Multi...   \n",
       "10612  On learning optimized reaction diffusion proce...   \n",
       "18605  Graph InfoClust: Leveraging cluster-level node...   \n",
       "23130  Exploring the Limits of Transfer Learning with...   \n",
       "24653                                         Mask R-CNN   \n",
       "24999  The Ubuntu Dialogue Corpus: A Large Dataset fo...   \n",
       "25854  CatBoost: unbiased boosting with categorical f...   \n",
       "31472                 Learned Primal-dual Reconstruction   \n",
       "31671  U-Net: Convolutional Networks for Biomedical I...   \n",
       "33010  RoBERTa: A Robustly Optimized BERT Pretraining...   \n",
       "33022               Automatic Differentiation in PyTorch   \n",
       "33023       Deep Residual Learning for Image Recognition   \n",
       "34407  Fast Graph Representation Learning with PyTorc...   \n",
       "34434                   Random Erasing Data Augmentation   \n",
       "36833  Countdown Regression: Sharp and Calibrated Sur...   \n",
       "37895                           TensorFlow Distributions   \n",
       "39839  CatBoost: unbiased boosting with categorical f...   \n",
       "42222  CatBoost: unbiased boosting with categorical f...   \n",
       "\n",
       "                                                    repo  \\\n",
       "2348                                       Daikenan/LTMU   \n",
       "7789                               PaddlePaddle/Research   \n",
       "8876                 Saibo-creator/Text-Summrize-Project   \n",
       "10612                            VLOGroup/tensorflow-icg   \n",
       "18605                                           dmlc/dgl   \n",
       "23130                           huggingface/transformers   \n",
       "24653               jiajunhua/facebookresearch-Detectron   \n",
       "24999  joe-prog/https-github.com-facebookresearch-ParlAI   \n",
       "25854                                   kazeevn/catboost   \n",
       "31472                                       odlgroup/odl   \n",
       "31671                          open-mmlab/mmsegmentation   \n",
       "33010                                    pytorch/fairseq   \n",
       "33022                                    pytorch/pytorch   \n",
       "33023                                     pytorch/vision   \n",
       "34407                          rusty1s/pytorch_geometric   \n",
       "34434                     rwightman/pytorch-image-models   \n",
       "36833                          stanfordmlgroup/cdr-mimic   \n",
       "37895                             tensorflow/probability   \n",
       "39839                                 vj-thakur/catboost   \n",
       "42222                                yumoh/catboost_iter   \n",
       "\n",
       "                                                   tasks  \n",
       "2348                                   [visual tracking]  \n",
       "7789   [dialogue generation, question answering, text...  \n",
       "8876                    [abstractive text summarization]  \n",
       "10612                                [image restoration]  \n",
       "18605  [graph representation learning, link predictio...  \n",
       "23130  [abstractive text summarization, common sense ...  \n",
       "24653  [human part segmentation, instance segmentatio...  \n",
       "24999  [answer selection, conversational response sel...  \n",
       "25854                         [dimensionality reduction]  \n",
       "31472                                             [ssim]  \n",
       "31671  [cell segmentation, data augmentation, electro...  \n",
       "33010  [common sense reasoning, language modelling, l...  \n",
       "33022                         [dimensionality reduction]  \n",
       "33023  [domain adaptation, domain generalization, fin...  \n",
       "34407  [graph classification, graph representation le...  \n",
       "34434  [data augmentation, image augmentation, image ...  \n",
       "36833            [decision making, mortality prediction]  \n",
       "37895                        [probabilistic programming]  \n",
       "39839                         [dimensionality reduction]  \n",
       "42222                         [dimensionality reduction]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df[paperswithcode_df['repo'].isin(functions['repo_name'].value_counts().head(20).index)][['paper_title', 'repo', 'tasks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6cd2bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_title</th>\n",
       "      <th>repo</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>High-Performance Long-Term Tracking with Meta-...</td>\n",
       "      <td>Daikenan/LTMU</td>\n",
       "      <td>[visual tracking]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7789</th>\n",
       "      <td>PLATO: Pre-trained Dialogue Generation Model w...</td>\n",
       "      <td>PaddlePaddle/Research</td>\n",
       "      <td>[dialogue generation, question answering, text...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>MeanSum: A Neural Model for Unsupervised Multi...</td>\n",
       "      <td>Saibo-creator/Text-Summrize-Project</td>\n",
       "      <td>[abstractive text summarization]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10612</th>\n",
       "      <td>On learning optimized reaction diffusion proce...</td>\n",
       "      <td>VLOGroup/tensorflow-icg</td>\n",
       "      <td>[image restoration]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18605</th>\n",
       "      <td>Graph InfoClust: Leveraging cluster-level node...</td>\n",
       "      <td>dmlc/dgl</td>\n",
       "      <td>[graph representation learning, link predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23130</th>\n",
       "      <td>Exploring the Limits of Transfer Learning with...</td>\n",
       "      <td>huggingface/transformers</td>\n",
       "      <td>[abstractive text summarization, common sense ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24653</th>\n",
       "      <td>Mask R-CNN</td>\n",
       "      <td>jiajunhua/facebookresearch-Detectron</td>\n",
       "      <td>[human part segmentation, instance segmentatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24999</th>\n",
       "      <td>The Ubuntu Dialogue Corpus: A Large Dataset fo...</td>\n",
       "      <td>joe-prog/https-github.com-facebookresearch-ParlAI</td>\n",
       "      <td>[answer selection, conversational response sel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25854</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>kazeevn/catboost</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31472</th>\n",
       "      <td>Learned Primal-dual Reconstruction</td>\n",
       "      <td>odlgroup/odl</td>\n",
       "      <td>[ssim]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31671</th>\n",
       "      <td>U-Net: Convolutional Networks for Biomedical I...</td>\n",
       "      <td>open-mmlab/mmsegmentation</td>\n",
       "      <td>[cell segmentation, data augmentation, electro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33010</th>\n",
       "      <td>RoBERTa: A Robustly Optimized BERT Pretraining...</td>\n",
       "      <td>pytorch/fairseq</td>\n",
       "      <td>[common sense reasoning, language modelling, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33022</th>\n",
       "      <td>Automatic Differentiation in PyTorch</td>\n",
       "      <td>pytorch/pytorch</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33023</th>\n",
       "      <td>Deep Residual Learning for Image Recognition</td>\n",
       "      <td>pytorch/vision</td>\n",
       "      <td>[domain adaptation, domain generalization, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34407</th>\n",
       "      <td>Fast Graph Representation Learning with PyTorc...</td>\n",
       "      <td>rusty1s/pytorch_geometric</td>\n",
       "      <td>[graph classification, graph representation le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34434</th>\n",
       "      <td>Random Erasing Data Augmentation</td>\n",
       "      <td>rwightman/pytorch-image-models</td>\n",
       "      <td>[data augmentation, image augmentation, image ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36833</th>\n",
       "      <td>Countdown Regression: Sharp and Calibrated Sur...</td>\n",
       "      <td>stanfordmlgroup/cdr-mimic</td>\n",
       "      <td>[decision making, mortality prediction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37895</th>\n",
       "      <td>TensorFlow Distributions</td>\n",
       "      <td>tensorflow/probability</td>\n",
       "      <td>[probabilistic programming]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39839</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>vj-thakur/catboost</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42222</th>\n",
       "      <td>CatBoost: unbiased boosting with categorical f...</td>\n",
       "      <td>yumoh/catboost_iter</td>\n",
       "      <td>[dimensionality reduction]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paper_title  \\\n",
       "2348   High-Performance Long-Term Tracking with Meta-...   \n",
       "7789   PLATO: Pre-trained Dialogue Generation Model w...   \n",
       "8876   MeanSum: A Neural Model for Unsupervised Multi...   \n",
       "10612  On learning optimized reaction diffusion proce...   \n",
       "18605  Graph InfoClust: Leveraging cluster-level node...   \n",
       "23130  Exploring the Limits of Transfer Learning with...   \n",
       "24653                                         Mask R-CNN   \n",
       "24999  The Ubuntu Dialogue Corpus: A Large Dataset fo...   \n",
       "25854  CatBoost: unbiased boosting with categorical f...   \n",
       "31472                 Learned Primal-dual Reconstruction   \n",
       "31671  U-Net: Convolutional Networks for Biomedical I...   \n",
       "33010  RoBERTa: A Robustly Optimized BERT Pretraining...   \n",
       "33022               Automatic Differentiation in PyTorch   \n",
       "33023       Deep Residual Learning for Image Recognition   \n",
       "34407  Fast Graph Representation Learning with PyTorc...   \n",
       "34434                   Random Erasing Data Augmentation   \n",
       "36833  Countdown Regression: Sharp and Calibrated Sur...   \n",
       "37895                           TensorFlow Distributions   \n",
       "39839  CatBoost: unbiased boosting with categorical f...   \n",
       "42222  CatBoost: unbiased boosting with categorical f...   \n",
       "\n",
       "                                                    repo  \\\n",
       "2348                                       Daikenan/LTMU   \n",
       "7789                               PaddlePaddle/Research   \n",
       "8876                 Saibo-creator/Text-Summrize-Project   \n",
       "10612                            VLOGroup/tensorflow-icg   \n",
       "18605                                           dmlc/dgl   \n",
       "23130                           huggingface/transformers   \n",
       "24653               jiajunhua/facebookresearch-Detectron   \n",
       "24999  joe-prog/https-github.com-facebookresearch-ParlAI   \n",
       "25854                                   kazeevn/catboost   \n",
       "31472                                       odlgroup/odl   \n",
       "31671                          open-mmlab/mmsegmentation   \n",
       "33010                                    pytorch/fairseq   \n",
       "33022                                    pytorch/pytorch   \n",
       "33023                                     pytorch/vision   \n",
       "34407                          rusty1s/pytorch_geometric   \n",
       "34434                     rwightman/pytorch-image-models   \n",
       "36833                          stanfordmlgroup/cdr-mimic   \n",
       "37895                             tensorflow/probability   \n",
       "39839                                 vj-thakur/catboost   \n",
       "42222                                yumoh/catboost_iter   \n",
       "\n",
       "                                                   tasks  \n",
       "2348                                   [visual tracking]  \n",
       "7789   [dialogue generation, question answering, text...  \n",
       "8876                    [abstractive text summarization]  \n",
       "10612                                [image restoration]  \n",
       "18605  [graph representation learning, link predictio...  \n",
       "23130  [abstractive text summarization, common sense ...  \n",
       "24653  [human part segmentation, instance segmentatio...  \n",
       "24999  [answer selection, conversational response sel...  \n",
       "25854                         [dimensionality reduction]  \n",
       "31472                                             [ssim]  \n",
       "31671  [cell segmentation, data augmentation, electro...  \n",
       "33010  [common sense reasoning, language modelling, l...  \n",
       "33022                         [dimensionality reduction]  \n",
       "33023  [domain adaptation, domain generalization, fin...  \n",
       "34407  [graph classification, graph representation le...  \n",
       "34434  [data augmentation, image augmentation, image ...  \n",
       "36833            [decision making, mortality prediction]  \n",
       "37895                        [probabilistic programming]  \n",
       "39839                         [dimensionality reduction]  \n",
       "42222                         [dimensionality reduction]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df.merge(functions['repo_name'].value_counts().head(20), left_on=\"repo\", right_index=True)[['paper_title', 'repo', 'tasks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f539f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['abstractive text summarization', 'common sense reasoning', 'coreference resolution', 'document summarization', 'linguistic acceptability', 'machine translation', 'natural language inference', 'question answering', 'semantic textual similarity', 'sentiment analysis', 'text classification', 'transfer learning', 'word sense disambiguation'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df[paperswithcode_df['repo'] == \"huggingface/transformers\"]['tasks'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ddebd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['abstractive text summarization', 'common sense reasoning', 'coreference resolution', 'document summarization', 'linguistic acceptability', 'machine translation', 'natural language inference', 'question answering', 'semantic textual similarity', 'sentiment analysis', 'text classification', 'transfer learning', 'word sense disambiguation'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df[paperswithcode_df['repo'] == \"huggingface/transformers\"]['tasks'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b140a66",
   "metadata": {},
   "source": [
    "functions = functions.explode(\"tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "830152bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961c2f7ded9a43929959a5afd7b03447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/121 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "code_emb = sentence_model.encode(\n",
    "    functions['function_code'].reset_index(drop=True),\n",
    "    convert_to_tensor=True,\n",
    "    batch_size=512,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58f6ec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive demo: Enter queries, and the method returns the best function from the \n",
    "# 3 functions we defined\n",
    "query = \"\"#input(\"Query: \")\n",
    "query_emb = sentence_model.encode(query, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f510d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = pd.read_csv(\"../../data/paperswithcode_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7381aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "described_tasks = tasks.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5bc137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_record = tasks.dropna().iloc[120]\n",
    "query = query_record['task_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2918906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embeddings = sentence_model.encode(described_tasks['task_description'].reset_index(drop=True), convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed72855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions_exploded = functions.explode(\"tasks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c638e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96cde80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61482, 768])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf9b599d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1237, 768])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "201710ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "efd295d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_task_similarity = metrics.pairwise.cosine_similarity(code_emb.cpu().numpy(), task_embeddings.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fcf989d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13af097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61482/61482 [00:09<00:00, 6289.25it/s]\n"
     ]
    }
   ],
   "source": [
    "task_similarities = []\n",
    "i = 0\n",
    "for i in tqdm.tqdm(range(code_task_similarity.shape[0])):\n",
    "    repo_tasks = functions['tasks'].iloc[0]\n",
    "    indices = described_tasks[described_tasks['task'].isin(repo_tasks)].index\n",
    "    task_similarities.append((indices, code_task_similarity[i,indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "911c6700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([138, 857, 890], dtype='int64')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2ba4b4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(code_task_similarity.reshape(-1)).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c6b0ae72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    7.605323e+07\n",
       "mean     1.349400e-01\n",
       "std      1.127943e-01\n",
       "min     -3.442661e-01\n",
       "25%      5.589901e-02\n",
       "50%      1.303803e-01\n",
       "75%      2.095672e-01\n",
       "max      7.951401e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(code_task_similarity.reshape(-1)).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d6f16f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64Index([138, 857, 890], dtype='int64'),\n",
       " array([0.12210143, 0.12210143, 0.23171246], dtype=float32))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_similarities[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0d03211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "area                computer-vision\n",
       "task                brdf estimation\n",
       "task_description                NaN\n",
       "Name: 598, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks.iloc[code_task_similarity[0].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "920297bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882     0.230746\n",
       "925     0.230746\n",
       "595     0.232225\n",
       "606     0.234221\n",
       "1063    0.238678\n",
       "1229    0.242139\n",
       "138     0.243369\n",
       "857     0.243369\n",
       "1094    0.252715\n",
       "1001    0.257479\n",
       "2       0.258088\n",
       "991     0.263598\n",
       "679     0.275932\n",
       "1019    0.276297\n",
       "1112    0.277429\n",
       "605     0.293174\n",
       "635     0.304828\n",
       "1056    0.307086\n",
       "1089    0.320806\n",
       "598     0.341852\n",
       "dtype: float32"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(code_task_similarity[0]).sort_values()[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b40eba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Int64Index([138, 857, 890], dtype='int64'),\n",
       " array([ 0.05876533,  0.05876533, -0.04472627], dtype=float32))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 7 \n",
    "task_similarities[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "67db542c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(code_task_similarity[7]).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6d166e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.12047012,  0.1088477 ,  0.2580884 , ...,  0.07515857,\n",
       "         0.0770945 ,  0.13699791],\n",
       "       [ 0.21861146,  0.01043667,  0.19694343, ...,  0.05449983,\n",
       "        -0.01982843,  0.15897007],\n",
       "       [-0.06526994, -0.00577282,  0.06488507, ...,  0.0720339 ,\n",
       "        -0.07860072,  0.14993821],\n",
       "       ...,\n",
       "       [ 0.25663382,  0.17997906,  0.3631241 , ...,  0.23886147,\n",
       "         0.23127438,  0.17720753],\n",
       "       [ 0.19653183,  0.23862082,  0.492301  , ...,  0.18633887,\n",
       "         0.21899685,  0.30666316],\n",
       "       [ 0.00739896,  0.00855942,  0.07353381, ..., -0.08617901,\n",
       "         0.0100208 , -0.01266319]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_task_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60973b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6fd6f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "879b742e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 50s, sys: 1.2 s, total: 4min 51s\n",
      "Wall time: 9.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index = findkit.index.NMSLIBIndex.build(\n",
    "    code_emb.cpu().numpy(),\n",
    "    metadata=functions.reset_index(drop=True).drop(columns=[\"Unnamed: 0\"]),\n",
    "    metric=\"cosinesimil\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e857f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "described_tasks_sample = described_tasks[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79665c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.classes_ = functions['repo_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f14d3899",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_repo_labels = label_encoder.fit_transform(functions['repo_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "041edf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([61482, 768])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ae4bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_embeddings_mean = torch_scatter.scatter_mean(code_emb.T, torch.LongTensor(function_repo_labels).cuda()).T\n",
    "repo_embeddings_max = torch_scatter.scatter_max(code_emb.T, torch.LongTensor(function_repo_labels).cuda())[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b558696",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_embeddings = torch.column_stack([repo_embeddings_mean, repo_embeddings_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3059afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7883f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_metadata = functions[['repo_name', 'tasks']].drop_duplicates(subset=[\"repo_name\"])\n",
    "repo_labels = label_encoder.transform(repo_metadata['repo_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1380d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_index = findkit.index.NMSLIBIndex.build(repo_embeddings[repo_labels].cpu().numpy(), repo_metadata, metric=\"cosinesimil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464cdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_query_emb(query):\n",
    "    emb = sentence_model.encode(query)\n",
    "    return np.stack([emb, emb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa35020",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_metadata = functions[['repo_name', 'tasks']].drop_duplicates(subset=[\"repo_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a59889",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a3139",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_row = described_tasks_sample.iloc[5]\n",
    "query = query_row['task'] #+ \"\\n\" + query_row['task_description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af3db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aea8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_index.find_similar(get_query_emb(query), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac83ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at_rouge(rouge_scores, rouge_thresholds={\"rougeL\": 0.5}):\n",
    "    return [\n",
    "        rouge_score\n",
    "        for rouge_score in rouge_scores\n",
    "        if all(\n",
    "            [\n",
    "                (rouge_score[rouge_type].recall >= rouge_thresholds[rouge_type])\n",
    "                for rouge_type in rouge_thresholds.keys()\n",
    "            ]\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "\n",
    "queries = []\n",
    "n_hits = []\n",
    "for i in range(len(described_tasks_sample)):\n",
    "    query_row = described_tasks_sample.iloc[i]\n",
    "    query_id = query_row['task']\n",
    "    query = query_row['task'] + \"\\n\" + query_row['task_description']\n",
    "    query_emb = get_query_emb(query)\n",
    "    results = repo_index.find_similar(query_emb, 10)\n",
    "    queries.append(query_row['task'])\n",
    "    results_tasks = results['tasks'].explode()\n",
    "    rouge_scores = [scorer.score(task, query_id) for task in results_tasks.values] \n",
    "    n_hits.append(len(hits_at_rouge(rouge_scores)))\n",
    "    \n",
    "hits_df = pd.DataFrame(list(zip(queries, n_hits)), columns=[\"tasks\", \"n_hits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d92f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3e5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(queries, n_hits)), columns=[\"tasks\", \"n_hits\"]).plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d265c27",
   "metadata": {},
   "source": [
    "## TODO: a co jakby użyć dekodera do scoringu?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550a28b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d51db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(zip(queries, n_hits))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee3c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e2669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = \"speech to speech translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af462211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_at_rouge(rouge_scores, rouge_thresholds={\"rougeL\": 0.5}):\n",
    "    return [\n",
    "        rouge_score\n",
    "        for rouge_score in rouge_scores\n",
    "        if all(\n",
    "            [\n",
    "                (rouge_score[rouge_type].recall >= rouge_thresholds[rouge_type])\n",
    "                for rouge_type in rouge_thresholds.keys()\n",
    "            ]\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df4ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_rouge(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c20a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_rouge_res = scorer.score(ngram, hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107e7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "tex_spaces = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ecf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d193fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_scores = [\n",
    "    scorer.score(ngram, hypothesis)\n",
    "    for ngram in results['tasks'].explode()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01210b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits_at_rouge(rouge_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['tasks'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c51f750",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['tasks'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012add31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba38b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f0357",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['distance'] = results['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941d1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "isorted(code_task_similarity[i], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0603ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hnsw_index.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cc2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.find_similar(sentence_model.encode(\"similarity learning\"), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0d09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c31a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, T5ForConditionalGeneration\n",
    "\n",
    "t5_tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
    "t5_model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
    "\n",
    "text = \"\"\"def svg_to_image(string, size=None):\n",
    "if isinstance(string, unicode):\n",
    "    string = string.encode('utf-8')\n",
    "    renderer = QtSvg.QSvgRenderer(QtCore.QByteArray(string))\n",
    "if not renderer.isValid():\n",
    "    raise ValueError('Invalid SVG data.')\n",
    "if size is None:\n",
    "    size = renderer.defaultSize()\n",
    "    image = QtGui.QImage(size, QtGui.QImage.Format_ARGB32)\n",
    "    painter = QtGui.QPainter(image)\n",
    "    renderer.render(painter)\n",
    "return image\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "71e924e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "def test_update_from_traffic_sim(social_vehicle, provider_vehicle):\n",
    "    social_vehicle.control(pose=provider_vehicle.pose, speed=provider_vehicle.speed)\n",
    "    (sv_position, sv_heading) = social_vehicle.pose.as_sumo(social_vehicle.length, Heading(0))\n",
    "    (provider_position, provider_heading) = provider_vehicle.pose.as_sumo(social_vehicle.length, Heading(0))\n",
    "    assert np.isclose(sv_position, provider_position, rtol=0.01).all()\n",
    "    assert math.isclose(sv_heading, provider_heading, rel_tol=1e-05)\n",
    "    assert (social_vehicle.speed == provider_vehicle.speed)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a4e926f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sebis_model = \"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask\"\n",
    "code_trans_model=transformers.AutoModelForSeq2SeqLM.from_pretrained(sebis_model)\n",
    "code_trans_tokenizer=transformers.AutoTokenizer.from_pretrained(sebis_model, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b17a0fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = index.find_similar(sentence_model.encode(\"similarity learning\"), 5)['function_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1f42a908",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = code_trans_tokenizer(list(texts), return_tensors=\"pt\", padding=True).input_ids.cuda()\n",
    "code_trans_model = code_trans_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2cb66a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 365])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "084bf2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### CODE: \n",
      "class ModelSimilarity(SimilarityMeasure):\n",
      "    '\\n    Similarity defined by the model. The model parameters are given by the first element of the pair.\\n    The similarity is evaluated by doing the forward pass (inference) on the parametrized model with\\n    the second element of the pair as input.\\n    '\n",
      "\n",
      "    def __init__(self, model):\n",
      "        self.model = model\n",
      "\n",
      "    def forward(self, x):\n",
      "        model_parameters = x[0]\n",
      "        model_inputs = x[1]\n",
      "        cur_outputs = model_inputs\n",
      "        for (layer_model, parameter_map) in self.model:\n",
      "            param_dict = {}\n",
      "            for (param_name, param_slice_reshape) in parameter_map.items():\n",
      "                if isinstance(param_slice_reshape, SliceReshaper):\n",
      "                    val = param_slice_reshape(model_parameters)\n",
      "                else:\n",
      "                    val = param_slice_reshape\n",
      "                param_dict[param_name] = val\n",
      "            cur_outputs = layer_model(cur_outputs, **param_dict)\n",
      "        return cur_outputs\n",
      "### SUMMARY: \n",
      "Computes the similarity of a pair of layers. The similarity is defined by a SimilarityMeasure\n",
      "### CODE: \n",
      "class Similarity(nn.Module):\n",
      "\n",
      "    def __init__(self, mem_dim, hidden_dim, num_classes):\n",
      "        super(Similarity, self).__init__()\n",
      "        self.mem_dim = mem_dim\n",
      "        self.hidden_dim = hidden_dim\n",
      "        self.num_classes = num_classes\n",
      "        self.wh = nn.Linear((2 * self.mem_dim), self.hidden_dim)\n",
      "        self.wp = nn.Linear(self.hidden_dim, self.num_classes)\n",
      "\n",
      "    def forward(self, lvec, rvec):\n",
      "        mult_dist = torch.mul(lvec, rvec)\n",
      "        abs_dist = torch.abs(torch.add(lvec, (- rvec)))\n",
      "        vec_dist = torch.cat((mult_dist, abs_dist), 1)\n",
      "        out = F.sigmoid(self.wh(vec_dist))\n",
      "        out = F.log_softmax(self.wp(out))\n",
      "        return out\n",
      "### SUMMARY: \n",
      "Computes the log - softmax and the log - softmax of the Similarity Classifier\n",
      "### CODE: \n",
      "class Similarity(nn.Module):\n",
      "    'Base class for similarity functions.'\n",
      "\n",
      "    def forward(self, left: torch.FloatTensor, right: torch.FloatTensor) -> torch.FloatTensor:\n",
      "        '\\n        Compute pairwise similarity scores.\\n\\n        :param left: shape: (n, d)\\n            The left vectors.\\n        :param right: shape: (m, d)\\n            The right vectors.\\n\\n        :return shape: (m, n)\\n            The similarity matrix.\\n        '\n",
      "        return self.all_to_all(left=left, right=right)\n",
      "\n",
      "    @abstractmethod\n",
      "    def all_to_all(self, left: torch.FloatTensor, right: torch.FloatTensor) -> torch.FloatTensor:\n",
      "        '\\n        Compute pairwise similarity scores.\\n\\n        .. math::\\n\\n            out[i, j] = sim(left[i], right[j])\\n\\n        :param left: shape: (n, d)\\n            The left vectors.\\n        :param right: shape: (m, d)\\n            The right vectors.\\n\\n        :return shape: (m, n)\\n            sim_ij = sim(left_i, right_j)\\n        '\n",
      "        raise NotImplementedError\n",
      "\n",
      "    @abstractmethod\n",
      "    def one_to_one(self, left: torch.FloatTensor, right: torch.FloatTensor) -> torch.FloatTensor:\n",
      "        'Compute similarity scores.\\n\\n        .. math::\\n\\n            out[i] = sim(left[i], right[i])\\n\\n        :param left: shape: (n, d)\\n        :param right: shape: (n, d)\\n\\n        :return shape: (n,)\\n        '\n",
      "        raise NotImplementedError\n",
      "### SUMMARY: \n",
      "Compute pairwise similarity scores for one-to-one and one-to-one.\n",
      "### CODE: \n",
      "def cosine_similarity(encoding_a, encoding_b):\n",
      "    return F.cosine_similarity(encoding_a, encoding_b).item()\n",
      "### SUMMARY: \n",
      "Return the cosine similarity of two strings.\n",
      "### CODE: \n",
      "def similarity(x, y, x_lengths, y_lengths):\n",
      "    'calculate similarity with two 3d tensor.\\n\\n    Args:\\n        x: a tensor with shape [batch, time_x, dimension]\\n        y: a tensor with shape [batch, time_y, dimension]\\n\\n    Returns:\\n        a tensor with shape [batch, time_x, time_y]\\n\\n    Raises:\\n        ValueError: if\\n            the dimenisons of x and y are not equal.\\n    '\n",
      "    with tf.variable_scope('x_attend_y'):\n",
      "        try:\n",
      "            x_a_y = block(x, y, y, Q_lengths=x_lengths, K_lengths=y_lengths)\n",
      "        except ValueError:\n",
      "            tf.get_variable_scope().reuse_variables()\n",
      "            x_a_y = block(x, y, y, Q_lengths=x_lengths, K_lengths=y_lengths)\n",
      "    with tf.variable_scope('y_attend_x'):\n",
      "        try:\n",
      "            y_a_x = block(y, x, x, Q_lengths=y_lengths, K_lengths=x_lengths)\n",
      "        except ValueError:\n",
      "            tf.get_variable_scope().reuse_variables()\n",
      "            y_a_x = block(y, x, x, Q_lengths=y_lengths, K_lengths=x_lengths)\n",
      "    return tf.matmul((x + x_a_y), (y + y_a_x), transpose_b=True)\n",
      "### SUMMARY: \n",
      "calculate similarity with two 3d tensor.\\n\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(input_ids)):\n",
    "    print(\"### CODE: \")\n",
    "    print(texts.iloc[i])\n",
    "    ids = input_ids[i]\n",
    "    generated_ids = code_trans_model.generate(ids.reshape(1,-1), max_length=20, min_length=10, num_beams=10)\n",
    "    print(\"### SUMMARY: \")\n",
    "    print(code_trans_tokenizer.decode(generated_ids[0], skip_special_tokens=True))\n",
    "    # this prints: \"Convert a SVG string to a QImage.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4319f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_functions = raw_functions_all[raw_functions_all['repo_name'] == \"trangvu/ape-npi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a1bb1591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>function_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>failure</td>\n",
       "      <td>def failure(message):\\n    print('{}failure: {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>success</td>\n",
       "      <td>def success(message):\\n    print('{}success: {...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>get_best_score</td>\n",
       "      <td>def get_best_score(log_file):\\n    scores = []...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>run</td>\n",
       "      <td>def run(dir_, score=None):\\n    config_file = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>translate/import_graph.py</td>\n",
       "      <td>ImportGraph</td>\n",
       "      <td>class ImportGraph():\\n    '  Importing and run...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/speech/extract-audio-features.py</td>\n",
       "      <td>read_features</td>\n",
       "      <td>def read_features(filename):\\n    all_feats = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/well-formed.py</td>\n",
       "      <td>is_well_formed</td>\n",
       "      <td>def is_well_formed(line):\\n    if (len(line) &lt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/apply-edits.py</td>\n",
       "      <td>reverse_edits</td>\n",
       "      <td>def reverse_edits(source, edits, fix=True, str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/extract-edits.py</td>\n",
       "      <td>levenshtein_legacy</td>\n",
       "      <td>@functools.lru_cache(maxsize=1024)\\ndef levens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/extract-edits.py</td>\n",
       "      <td>levenshtein</td>\n",
       "      <td>def levenshtein(src, trg, sub_cost=1.0, del_co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        repo_name                                      path  \\\n",
       "0             0  trangvu/ape-npi                              run-tests.py   \n",
       "1             1  trangvu/ape-npi                              run-tests.py   \n",
       "2             2  trangvu/ape-npi                              run-tests.py   \n",
       "3             3  trangvu/ape-npi                              run-tests.py   \n",
       "4             4  trangvu/ape-npi                 translate/import_graph.py   \n",
       "..          ...              ...                                       ...   \n",
       "116         116  trangvu/ape-npi  scripts/speech/extract-audio-features.py   \n",
       "117         117  trangvu/ape-npi       scripts/post_editing/well-formed.py   \n",
       "118         118  trangvu/ape-npi       scripts/post_editing/apply-edits.py   \n",
       "119         119  trangvu/ape-npi     scripts/post_editing/extract-edits.py   \n",
       "120         120  trangvu/ape-npi     scripts/post_editing/extract-edits.py   \n",
       "\n",
       "          function_name                                      function_code  \n",
       "0               failure  def failure(message):\\n    print('{}failure: {...  \n",
       "1               success  def success(message):\\n    print('{}success: {...  \n",
       "2        get_best_score  def get_best_score(log_file):\\n    scores = []...  \n",
       "3                   run  def run(dir_, score=None):\\n    config_file = ...  \n",
       "4           ImportGraph  class ImportGraph():\\n    '  Importing and run...  \n",
       "..                  ...                                                ...  \n",
       "116       read_features  def read_features(filename):\\n    all_feats = ...  \n",
       "117      is_well_formed  def is_well_formed(line):\\n    if (len(line) <...  \n",
       "118       reverse_edits  def reverse_edits(source, edits, fix=True, str...  \n",
       "119  levenshtein_legacy  @functools.lru_cache(maxsize=1024)\\ndef levens...  \n",
       "120         levenshtein  def levenshtein(src, trg, sub_cost=1.0, del_co...  \n",
       "\n",
       "[121 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "5306cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#repo_functions = repo_functions.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "62e09c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225eff92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "762589aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "model_name = 'doc2query/stackexchange-title-body-t5-base-v1'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "96b9073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c7f7cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_trans_model = code_trans_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "1d74f516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def batched_generate(model, tokenizer, texts, batch_size=32, max_length=64, num_beams=5, **kwargs):\n",
    "    generated_sequences = []\n",
    "    for i in range(int(np.ceil(len(texts) / batch_size))):\n",
    "        batch_start = i * batch_size\n",
    "        batch_end = (i+1) * batch_size\n",
    "        text_chunk = texts[batch_start:batch_end]\n",
    "        input_ids = tokenizer.batch_encode_plus(text_chunk, max_length=320, padding=True, truncation=True, return_tensors='pt').to(model.device)\n",
    "        outputs = model.generate(\n",
    "            **input_ids,\n",
    "            max_length=max_length,\n",
    "            num_beams=num_beams,\n",
    "            num_return_sequences=1)\n",
    "\n",
    "        batch_generated_sequences = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        generated_sequences  += batch_generated_sequences \n",
    "    return generated_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1f280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "547bb757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 452 ms, sys: 4.45 ms, total: 456 ms\n",
      "Wall time: 429 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['How to format error message in python?',\n",
       " 'How to print success message in python?',\n",
       " 'Get the best score from a log file',\n",
       " 'Seq2seq.sh in Python',\n",
       " 'Importing and running isolated TF graph',\n",
       " 'How to use tf.train.save() in python?',\n",
       " \"tf.variable_scope() wrapper that automatically handles the reuse' parameter\",\n",
       " 'RNNCell wrapper class for LSTM',\n",
       " 'Multi-encoder in Keras',\n",
       " 'tf.nn.dropout is not working in python']"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "batched_generate(model, tokenizer, repo_functions['function_code'].iloc[:10].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "4a6dbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer.encode(input_texts, max_length=320, truncation=True, return_tensors='pt').to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "d540a901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# run-tests.py\\ndef failure(message):\\n    print('{}failure: {}{}'.format(FAIL, message, ENDC))\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "339671cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   20,    89,  3338,   599,  2687,     7,   545,    61,    10,  2281,\n",
       "           599,    31,     2,    89,     9,   173,  1462,    10,     3,     2,\n",
       "            31,     5,  8995,   599,   371, 22862,     6,  1569,     6,     3,\n",
       "         14920,   254,    61,    61,     1]], device='cuda:0')"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_texts = repo_functions['function_code'].iloc[:1]\n",
    "input_ids = tokenizer.batch_encode_plus(input_texts, max_length=320, truncation=True, padding=True, return_tensors='pt').to(model.device)\n",
    "input_ids['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3911cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model.generate(\n",
    "    **input_ids,\n",
    "    max_length=64,\n",
    "    num_beams=5,\n",
    "    num_return_sequences=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6a8132ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_query = tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d7692350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to format error message in python?']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2607bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3653195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "575c331f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:29<00:00,  4.15it/s]\n"
     ]
    }
   ],
   "source": [
    "function_summaries = get_summaries(model, tokenizer, repo_functions['function_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e9292248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:00<00:00, 425050.91it/s]\n",
      "100%|██████████| 121/121 [00:51<00:00,  2.36it/s]\n",
      "<ipython-input-160-126da3c4dbd5>:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  repo_functions['generated_queries'] = summaries\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = repo_functions['function_code']\n",
    "paths = repo_functions['path']\n",
    "names = repo_functions['function_name']\n",
    "\n",
    "generated_queries = []\n",
    "\n",
    "input_texts = [\n",
    "    \"# {}\\n{}\".format(path, text)\n",
    "    for path, function_name, text in tqdm.tqdm(zip(paths, names, texts), total=len(texts))\n",
    "]\n",
    "summaries = get_summaries(model, tokenizer, input_texts)\n",
    "\n",
    "repo_functions['generated_queries'] = summaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f3a9f5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_with_readmes_df = pd.read_csv(\"../../output/papers_with_readmes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5bd3177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_sample = papers_with_readmes_df['readme'].dropna().iloc[:100]\n",
    "title_sample = papers_with_readmes_df[['title', 'readme']].dropna().iloc[:100]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4336d8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"How to print error message in python using failure: '.format(FAIL, message, ENDC)?\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)?\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC) in python?\"],\n",
       " ['How to print success message in python?',\n",
       "  'How to format success message in python?',\n",
       "  'How to print success message in python using python?',\n",
       "  'How to print success message in python',\n",
       "  'How to print a success message in python?'],\n",
       " ['Getting the best score from a python python python python python python python python python python python',\n",
       "  'Getting the best score from a python python python python python python python python python python script',\n",
       "  'Getting the best score from a python python python python python python python python python python file',\n",
       "  'Getting the best score from a python python python python python python python python python python',\n",
       "  'Getting the best score from a python python python python python python python python python script'],\n",
       " ['What is wrong with my python code? (Seq2seq.sh)',\n",
       "  'What is wrong with my python code? (Seq2Seq.sh)',\n",
       "  'What is wrong with my python code? (Seq2Seq)',\n",
       "  'Is there a better way to write this python code?',\n",
       "  'What is wrong with my python code?'],\n",
       " ['Importing and running isolated TF graph',\n",
       "  'Importing and running isolated TF graph in python',\n",
       "  'Importing and running isolated TF graph in Tensorflow',\n",
       "  'Importing and running isolated TF graph using Tensorflow',\n",
       "  'Importing and running isolated TF graph in TensorFlow'],\n",
       " ['tf.train.Saver(variables.get_shape()) not working in python',\n",
       "  'tf.train.Saver(variables.get_shape()) is not working in python',\n",
       "  \"tf.train.Saver(variables.get_shape()) doesn't work in python\",\n",
       "  'tf.train.Saver(variables.get_shape()) in python',\n",
       "  'tf.train.Saver(variables.get_shape()) does not work in python'],\n",
       " ['tf.get_variable_scope() and tf.auto_reuse(fun)',\n",
       "  'tf.get_variable_scope() and tf.get_variable_scope()',\n",
       "  'tf.get_variable_scope() and tf.auto_reuse()',\n",
       "  'tf.get_variable_scope() and tf.auto_reuse',\n",
       "  'tf.get_variable_scope() and tf.get_variable_scope() in python'],\n",
       " ['How to wrap RNNCell with RNNCell in python?',\n",
       "  'How to wrap RNNCell with tf.split in python?',\n",
       "  'How to wrap RNNCell in python?',\n",
       "  'How to wrap RNNCell around RNNCell in python?',\n",
       "  'How to wrap RNNCell with tf.split() in python?'],\n",
       " ['What is wrong with my multi-encoder python code?',\n",
       "  'What is wrong with my multi-encoder code?',\n",
       "  'What is wrong with my multi-encoder model?',\n",
       "  'What is wrong with my multi-encoder keras code?',\n",
       "  'What is wrong with my multi-encoder implementation?'],\n",
       " ['tf.nn.dropout not working in python',\n",
       "  'tf.nn.dropout is not working in python',\n",
       "  'tf.nn.dropout() not working in python',\n",
       "  'tf.nn.dropout() is not working in python',\n",
       "  'tf.nn.dropout() does not work in python'],\n",
       " ['tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs])',\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) not working',\n",
       "  \"tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) doesn't work\",\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) does not work',\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) is not working'],\n",
       " ['tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) returns (weighted_average, weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weights)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average, weights)'],\n",
       " ['Why does tf.reduce_sum((hidden_states * args, **kwargs) return 0?',\n",
       "  'Why does tf.sequence_mask(encoder_input_length, *args, **kwargs) return 0?',\n",
       "  'Why does tf.sequence_mask(encoder_input_length, *args, **kwargs) not work?',\n",
       "  'Why does tf.reduce_sum((hidden_states * args, **kwargs)) return 0?',\n",
       "  'tf.sequence_mask(encoder_input_length, *args, **kwargs) not working'],\n",
       " ['tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((hidden_states), tf.expand_dims',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), tf.reduce_',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((hidden_states * args, **kwargs))',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), tf.reduce',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), kwargs)'],\n",
       " [\"tf.translate/models.py doesn't work for kwargs in python\",\n",
       "  \"tf.translate/models.py doesn't work in python\",\n",
       "  \"tf.translate/models.py doesn't work for kwargs\",\n",
       "  \"tf.translate/models.py doesn't work with kwargs\",\n",
       "  \"tf.translate/models.py doesn't seem to work in python\"],\n",
       " ['tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors)',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1))',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axi',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) in python'],\n",
       " ['What is wrong with my multi-attention model in python?',\n",
       "  'What is wrong with my multi-attention python code?',\n",
       "  'What is wrong with my multi-attention model?',\n",
       "  'What is wrong with my multi-attention keras code?',\n",
       "  'What is wrong with my multi-attention model in Keras?'],\n",
       " ['Keras attention decoder not working',\n",
       "  'Keras attention decoder',\n",
       "  'Keras attention decoder is not working',\n",
       "  'Keras attention decoder is not working as expected',\n",
       "  'keras attention decoder not working'],\n",
       " ['Keras attention_execution_decoder',\n",
       "  'keras attention_execution_decoder',\n",
       "  'keras attention_execution_decoder python',\n",
       "  'Keras attention_execution_decoder not working',\n",
       "  'keras attention_execution_decoder not working'],\n",
       " ['What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1)?',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1, axis=1)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1, axis=2)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1 and axis='],\n",
       " ['How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1, **kwargs)',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1))?',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1)) in pyth',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1) in python',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1)'],\n",
       " ['What is wrong with my chained encoder decoder?',\n",
       "  'What is wrong with my chained encoder decoder in python?',\n",
       "  'What is wrong with my chained encoder decoder python code?',\n",
       "  'What is wrong with my chained encoder decoder model?',\n",
       "  'What is wrong with my chained encoder decoder in Keras?'],\n",
       " ['What is wrong with my chained encoder decoder?',\n",
       "  'What is wrong with my kwargs model?',\n",
       "  'What is wrong with my chained encoder decoder code?',\n",
       "  'What is wrong with my chained encoder model?',\n",
       "  'What is wrong with my kwargs encoder?'],\n",
       " ['tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True)',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, axis=dim, keep_dim=True)',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True) not working',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True) is not working',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True)'],\n",
       " ['tf.nn.sparse_softmax_cross_entropy_with_logits',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits not working',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits does not work',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits is not working',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits returns 0'],\n",
       " ['tf.stop_gradient(decoder_states, reward_baseline) not working',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline)',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline) not working in python',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline) returns 0',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline, axis=2)'],\n",
       " ['tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True)',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=False, average_across_batch=True)',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) not working',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) returns 0',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) error'],\n",
       " ['Convolutional LSTM cell with tf.nn.tanh',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh in python',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh in python',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh.tanh'],\n",
       " ['Convolution of 4D tensors to a list of 4D tensors',\n",
       "  'Convolution of 4D tensors to a list of 4D tensors in python',\n",
       "  'Convolution of 4D tensors to a list of 4D tensors in Python',\n",
       "  'Convolutional neural network in python',\n",
       "  'Convolution of 4D tensors with a list of 4D tensors'],\n",
       " ['How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id, include_first_eos=True) and tf.shape(sequence,',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id)?',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id, eos_id) and tf.shape(sequence, eos',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id) in py',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id)'],\n",
       " ['tf.stack([(batch_size * beam_size) + shape(src, dst)[0])',\n",
       "  'tf.stack([(batch_size * beam_size)) + shape(src, dst)[0]',\n",
       "  'tf.stack([(batch_size * beam_size) + shape(src, dst)[0]) not working',\n",
       "  'tf.stack([(batch_size * beam_size) + shape(dst)[0])',\n",
       "  'tf.stack([(batch_size * beam_size)) + shape(src, dst)]'],\n",
       " ['tf.unstack(tf.shape(tensor)) not working in python',\n",
       "  'How to use tf.unstack(tf.shape(tensor)) in python?',\n",
       "  'How to use tf.unstack(tf.shape(tensor)) in beam search?',\n",
       "  'tf.unstack(tf.shape(tensor)) not working',\n",
       "  'tf.unstack(tf.shape(tensor, dynamic_shape))'],\n",
       " ['tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indice',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i]]',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i])',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i]',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i, indice'],\n",
       " ['How to solve this beam search problem in python using tf.reduce_max((x / T) - my_max = x - (tf.reduce_sum(((x / T - my_max) + my_',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum(((x / T - my_max)))',\n",
       "  'How to find the softmax of a beam search using tf.reduce_max((x / T) - my_max) and tf.reduce_sum(((x / T) - my_max)?',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum(((x / T - my_max) + my_max',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum((x / T - my_max) + my_max'],\n",
       " ['rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[0,1] and tf.shape(initial_',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(initial_states[',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[0,1]) and tf.shape(initial',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(seq_len)',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(initial_states]'],\n",
       " [\"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in python?\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn')?\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in python\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in rnn.py?\",\n",
       "  \"How to use tf.variable_scope((variable_scope or'stack_bidirectional_dynamic_rnn') in python?\"],\n",
       " ['Applying time pooling in rnn.py',\n",
       "  'Apply time pooling in rnn.py',\n",
       "  'Applying time pooling in rnn',\n",
       "  'Applying time pooling in rnn python',\n",
       "  'How to apply time pooling in rnn.py?'],\n",
       " ['Orthogonal initialization of recurrent connections, like in Bahdanau et al. 2015n',\n",
       "  'Orthogonal initialization of recurrent connections',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al. 2015',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al. (2015)',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al 2015n'],\n",
       " ['tf.nn.rnn.TensorShape(s).as_list() not working in python',\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() is not working in python',\n",
       "  \"tf.nn.rnn.TensorShape(s).as_list() doesn't work in python\",\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() not working',\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() does not work in python'],\n",
       " ['tf.nn.rnn_cell.RNNCell is not working in python',\n",
       "  'tf.nn.rnn_cell.RNNCell not working in python',\n",
       "  'tf.nn.rnn_cell.RNNCell is not working',\n",
       "  'tf.nn.rnn_cell.RNNCell not working',\n",
       "  'tf.nn.rnn_cell.RNNCell error'],\n",
       " ['Implementation of Projection-LSTM and Factorized-LSTM',\n",
       "  'Implementation of Projection-LSTM and Factorized-LSTM in python',\n",
       "  'Implementation of Projection-LSTM and Factorized-LSTM in Python',\n",
       "  'Implementation of Projection LSTM and Factorized LSTM',\n",
       "  'Implementation of Projection LSTM and Factorized LSTM in python'],\n",
       " ['How to use get_state_size() in rnn.py?',\n",
       "  'How to use get_state_size in rnn.py?',\n",
       "  'How to use get_state_size() in rnn.py',\n",
       "  'How to use get_state_size in rnn.py',\n",
       "  'How to use get_state_size() in rnn.py in python?'],\n",
       " ['How to debug a python class in python?',\n",
       "  'How to debug a python class in python using python/utils.py?',\n",
       "  'How do I debug a python class in python?',\n",
       "  'How to debug a python class in python using python?',\n",
       "  'How to debug a python class in a python class?'],\n",
       " ['How to pass a checkpoint exception in python?',\n",
       "  'How to pass a checkpoint exception to a function in python?',\n",
       "  'How do I pass a checkpoint exception in python?',\n",
       "  'How to pass a checkpoint exception in python using python?',\n",
       "  'How to pass a checkpoint exception to a function in python'],\n",
       " ['How to translate a python class to a python class?',\n",
       "  'How to translate a python class to a python class in python?',\n",
       "  'How to translate a python class to a python class using python?',\n",
       "  'EvalException(Exception): pass in python',\n",
       "  'How to translate a python class to python using python?'],\n",
       " ['Safely open a list of files in a context manager',\n",
       "  'Open a list of files in a context manager',\n",
       "  'Translate a list of files in a context manager',\n",
       "  'Safely open a list of files in a context manager in python',\n",
       "  'Open a list of files in a context manager using python'],\n",
       " ['Dictionary whose keys can be accessed as attributes',\n",
       "  'Translating a dictionary whose keys can be accessed as attributes',\n",
       "  'Dictionary whose keys can be accessed as attributes.n',\n",
       "  'Translating a dictionary into a dictionary whose keys can be accessed as attributes',\n",
       "  'Translating a dictionary whose keys can be accessed as attributes.n'],\n",
       " ['Reverse edits in python',\n",
       "  'Reverse edits in python using translate/utils.py',\n",
       "  'Reverse edits in python using python/translate/utils.py',\n",
       "  'Reverse edits in Python',\n",
       "  'Reverse-edits in Python'],\n",
       " ['Translating one-item-per-line vocabulary',\n",
       "  'Translating one-item-per-line vocabulary in Python',\n",
       "  'Translating one-item-per-line vocabulary in python',\n",
       "  'Translating one-item-per-line dictionary',\n",
       "  'Translating one-item-per-line dictionary in Python'],\n",
       " ['Convert a string to a list of integers representing token-ids',\n",
       "  'Convert a string to list of integers representing token-ids',\n",
       "  'Converting a string to a list of integers representing token-ids',\n",
       "  'Convert a string to a list of integers representing token-ids.nn',\n",
       "  'Converting a string to list of integers representing token-ids'],\n",
       " ['How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, dev_prefix, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)?'],\n",
       " ['Translate a text file into a python file using python/utils/python/translate/utils.py',\n",
       "  'Translate a text file into a python file using python and python/translate/utils.py',\n",
       "  'Translate a text file into a python file using python and python',\n",
       "  'Translating a sentence to a text file using python and translate/utils.py',\n",
       "  'Translate a text file into a text file using python and translate/utils.py'],\n",
       " ['How to make a random batch iterator in python?',\n",
       "  'How to write a random batch iterator in python?',\n",
       "  'How to make a random batch iterator in python',\n",
       "  'How to write a random batch iterator in python',\n",
       "  'How to make a random batch iterator with python?'],\n",
       " ['Is there a better way to write this batch iterator in python?',\n",
       "  'Is this batch iterator python or python?',\n",
       "  'Batch iterator in python',\n",
       "  'Is this batch iterator python or python or python or python?',\n",
       "  'Basic batch iterator in python'],\n",
       " ['Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)nn',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)n',\n",
       "  'Cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled)n at each new epoch',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffledn at each new epoch)n'],\n",
       " ['read_ahead_batch_iterator in python',\n",
       "  'read_ahead_batch_iterator',\n",
       "  'python read_ahead_batch_iterator',\n",
       "  'read_ahead_batch_iterator in Python',\n",
       "  'read_ahead_batch_iterator for python'],\n",
       " ['What is wrong with my python batch iterator?',\n",
       "  'What is wrong with this python batch iterator?',\n",
       "  'What is wrong with my batch iterator?',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with this batch iterator?'],\n",
       " ['Segmenting a dataset into fixed-size batches',\n",
       "  'Segmenting data into fixed-size batches',\n",
       "  'Segmenting a dataset into fixed-size fixed-size batches',\n",
       "  'Segment data into fixed-size batches',\n",
       "  'Segment a dataset into fixed-size batches'],\n",
       " ['Reading a binary file containing vector features (MFCCs) and extracting audio features (MFCCs)',\n",
       "  'Reading a binary file containing vector features and extracting audio (MFCCs)',\n",
       "  'Reading a binary file containing vector features (MFCCs) and creating a file for audio (MFCCs)',\n",
       "  'Extracting audio features from a binary file',\n",
       "  'Reading a binary file containing vector features (MFCCs) and extracting audio (MFCCs)'],\n",
       " ['python - read_binary_features(path, binary=None) and open(path, binary_) in zip(path, binary_) and open(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(path, binary=None) and open(path, binary_features(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(paths, binary=None) and open(path, binary_features(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(path, binary=None) and open(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(paths, binary=None) and open(path, binary_) in zip(path, binary_) and open(path, binary_) in zip(path, binary_)'],\n",
       " ['How to read text from a file in python?',\n",
       "  'How to read text from a file in python using translate/utils.py?',\n",
       "  'How to read text from a file in python using python?',\n",
       "  'How to read text from a file using python?',\n",
       "  'How to read text from a file in python using translate/utils.py'],\n",
       " ['python - python - python - python - python - python - python - python - python -',\n",
       "  'What is wrong with my python python python python python python python python python python python py',\n",
       "  'python - python - python - python - python - python - python - python - python',\n",
       "  'python - python - python - python - python - python - python - python - python :',\n",
       "  'What is wrong with my python python python python python python python python python python python?'],\n",
       " ['Logging to a file, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to a file, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to a standard output',\n",
       "  'Logging to a file, or to standard output, if the file is not None'],\n",
       " ['How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level, msg)?',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level, msg)',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level=logging.INFO)?',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level=logging.INFO)',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__.log(level, msg)?'],\n",
       " ['How to debug a python script in python?',\n",
       "  'How to debug a python script with python?',\n",
       "  'How to debug a python script?',\n",
       "  'How to debug a python script using python?',\n",
       "  'How do I debug a python script in python?'],\n",
       " ['How to write a python script to warn a user of a warning message in python?',\n",
       "  'How to write a python script to log a warning message in python?',\n",
       "  'How to write a python script to warn a user about a warning message in python?',\n",
       "  'How to write a python script to warn a user of a warning message?',\n",
       "  'How to write a python script to warn a user of a warning message in a python script?'],\n",
       " ['Heatmap showing the alignment between two sequences',\n",
       "  'How to draw a heatmap showing the alignment between two sequences?',\n",
       "  'How to draw a heatmap showing the alignment between two sequences in python?',\n",
       "  'How to draw a heatmap showing the alignment between two sequences',\n",
       "  'How to draw a heatmap showing the alignment between two sequences in python'],\n",
       " ['Translate text to svg using python',\n",
       "  'Translating text to svg using python',\n",
       "  'Alignment to text in python',\n",
       "  'Translate text to svg in python',\n",
       "  'Translate text to svg using python and python'],\n",
       " ['Levenshtein implementation in python',\n",
       "  'Levenshtein implementation in Python',\n",
       "  'Levenshtein in python',\n",
       "  'Levenshtein python implementation',\n",
       "  'Levenshtein implementation'],\n",
       " ['Sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'Calculate sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'Calculating sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'BLEU score between a translation hypothesis and a reference',\n",
       "  'Sentence level BLEU score between a translation hypothesis and a reference'],\n",
       " ['Reversed score function decorator in python',\n",
       "  'How can I get the score of a python function in python?',\n",
       "  'How do I get the score of a function in python?',\n",
       "  'How can I get the score of a function in python?',\n",
       "  'Reversed score decorator in python'],\n",
       " [\"python - divide x, y with np.errstate(divide='ignore', invalid='ignore') and z[( np.isfinite(z)) = 0\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore') and z[( np.isfinite(z\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore', return z[( np.isfinite(z\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore', z[( np.isfinite(z)\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore') and return z[( np.isfinite(\"],\n",
       " ['Compute BLEU score at the corpus-level between a list of translation hypotheses and references, smoothing=False, order=4, **kwargs',\n",
       "  'Compute BLEU score at the corpus-level between a list of translation hypotheses and references',\n",
       "  'Compute BLEU score at the corpus-level between a list of hypotheses and references, smoothing=False, order=4, **kwargs',\n",
       "  'Compute BLEU score at the corpus-level between a list of hypotheses and references',\n",
       "  'Compute BLEU score at the corpus-level between a list of translation hypotheses and references, with smoothing=False, order=4, **kwargs'],\n",
       " ['How to write a python code for a python code for a python code for a python code for a python code for a python code for a pyth',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code?',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code for python code',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code in a pyth',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code in python?'],\n",
       " ['What is wrong with my python code?',\n",
       "  'What is wrong with this python code? (Levenshtein)',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with my python code? (Levenshtein)',\n",
       "  'What is wrong with this python code? (Levenshtein, kwargs)'],\n",
       " ['How to translate a python code to a python code?',\n",
       "  'How to translate a python code into a python code?',\n",
       "  'How to translate a python script to a python script?',\n",
       "  'How to translate a python code in python?',\n",
       "  'How to translate a python script to python?'],\n",
       " ['python - python - python - python - python - python - python - python - python -',\n",
       "  'python - python - python - python - python - python - python - score_function_decorator(reversed',\n",
       "  'python - python - python - python - python - python - python - python - python',\n",
       "  'python - python - python - python - python - python - python - python - python :',\n",
       "  'python - python - python - python - python - python - python - python - score_function_'],\n",
       " ['Translate/evaluation.py',\n",
       "  'Translate/evaluation.py for python',\n",
       "  'Translate/evaluation python python python',\n",
       "  'Translate/evaluation.py with ordereddict',\n",
       "  'Translate/evaluation python python'],\n",
       " ['python corpus_scores_ter(*args, **kwargs)',\n",
       "  'python corpus_scores_ter(*arg, **kwargs)',\n",
       "  'python corpus_scores_ter(*args, **kwargs) not working in python',\n",
       "  'python corpus_scores_ter(*args, **kwargs) - python',\n",
       "  'python corpus_scores_ter(*args, **kwargs) not working'],\n",
       " ['python corpus_scores_wer(*args, **kwargs) - python - python - python - python - python - p',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python python - python - python - python - pyth',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python - python - python - python - translate/evaluation.py',\n",
       "  'python corpus_scores_wer(*args, **kwargs)',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python - python - python - python - python'],\n",
       " ['Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:]!= trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src, trg[1:], trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:], trg[1:], trg[1',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:], trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:]!= trg[1:]) -'],\n",
       " ['How to use tercom_statistics in python?',\n",
       "  'Error while running tercom-statistics in python',\n",
       "  'How to use tercom_statistics in python',\n",
       "  'How to use tercom_statistics.py in python?',\n",
       "  'How to use tercom_statistics in a python script?'],\n",
       " ['Multitask model in python',\n",
       "  'Multitask model implementation in python',\n",
       "  'Multitask model with kwargs and python',\n",
       "  'Multitask model in python with kwargs',\n",
       "  'Multitask model in python using kwargs'],\n",
       " ['What is wrong with my seq2seq model?',\n",
       "  'What is wrong with my seq2seq model in python?',\n",
       "  'Error in seq2seq_model.py',\n",
       "  'What is wrong with my seq2seq_model.py?',\n",
       "  'What is wrong with my seq2seq model python code?'],\n",
       " ['What is wrong with my python translation model?',\n",
       "  'What is wrong with my translation model in python?',\n",
       "  'What is wrong with my translation model?',\n",
       "  'What is wrong with this translation model in python?',\n",
       "  'What is wrong with my kwargs translation model?'],\n",
       " [\"tf.train.get_checkpoint_state(checkpoint_dir) doesn't work\",\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) not working',\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) is not working',\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) does not work',\n",
       "  \"tf.train.get_checkpoint_state(checkpoint_dir) doesn't work in python\"],\n",
       " ['tf.global_variables.write_meta_graph is not working in python',\n",
       "  'tf.global_variables.write_meta_graph is not working',\n",
       "  'tf.global_variables.write_meta_graph=False',\n",
       "  'tf.global_variables.write_meta_graph=False in python',\n",
       "  \"tf.global_variables.write_meta_graph doesn't work in python\"],\n",
       " ['What is wrong with my python code?',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with my python script?',\n",
       "  'What is wrong with my python code? Is it a python code?',\n",
       "  'What is wrong with my python code? Is there a better way to do this?'],\n",
       " ['tf.Summary.HistogramProto() not working in tensorflow',\n",
       "  'tf.Summary.HistogramProto() is not working in tensorflow',\n",
       "  \"tf.Summary.HistogramProto() doesn't work in tensorflow\",\n",
       "  'tf.Summary.HistogramProto() does not work in tensorflow',\n",
       "  'tf.Summary.HistogramProto() not working'],\n",
       " ['How to extract a word from a list of words in python using python scripts/vocab-stats.py?',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocab-stats.py',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocabulary-stats.py?',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocabulary-stats.py',\n",
       "  'How to extract a word from a list of words in python scripts/vocab-stats.py?'],\n",
       " ['Python script to get the best score for each step of a python python python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python python script',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python script'],\n",
       " ['Concat bpe pairs in python',\n",
       "  'Concatenate bpe_pairs in python',\n",
       "  'Concatenate bpe pairs in python',\n",
       "  'Concatenate bpe_pairs in Python',\n",
       "  'Concatenate bpe_pairs'],\n",
       " ['Encode word based on list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode a word based on list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode word based on list of BPE merge operations, which are applied consecutively',\n",
       "  'Encode a word based on a list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode a word based on list of BPE merge operations, which are applied consecutively'],\n",
       " ['How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python?',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter?'],\n",
       " ['How to get pairs of symbols in a word in python?',\n",
       "  'How to get all pairs of symbols in a word in python?',\n",
       "  'How to get a list of symbol pairs in a word in python?',\n",
       "  'How to get pairs of symbols in a word in python',\n",
       "  'How to get all pairs of symbols in a word in python'],\n",
       " ['How to boldify text in python?',\n",
       "  'How to boldify text in plot loss?',\n",
       "  'How to boldify text in python script?',\n",
       "  'How to boldify text in python',\n",
       "  'How to boldify text in a plot?'],\n",
       " ['Counting the number of unique items in a dict',\n",
       "  'Counting the number of unique items in a list',\n",
       "  'Counting the number of unique items in a list of dicts',\n",
       "  'Counting the number of items in an ordered dict',\n",
       "  'Counting the number of unique and average values in a dict'],\n",
       " ['What is wrong with my python scripts/stats.py?',\n",
       "  'What is wrong with my python stats.py code?',\n",
       "  'What is wrong with my python stats python script?',\n",
       "  'What is wrong with my python stats.py script?',\n",
       "  'What is wrong with my python stats.py?'],\n",
       " ['How to open a file in python using python codecs in python?',\n",
       "  'How to open a file in python using python and python?',\n",
       "  'How to open a file in python using python context manager?',\n",
       "  'How to open a file in python using python python context manager?',\n",
       "  'How to open a file in python using python and python'],\n",
       " ['How to open temporary files in python?',\n",
       "  'How to delete temporary files in python?',\n",
       "  'How to open temporary files in python using python context manager?',\n",
       "  'How to delete a temporary file in python?',\n",
       "  'How to delete a temporary file in python using python?'],\n",
       " ['How to enumerate words from a vocabulary file in python?',\n",
       "  'How to enumerate words from a vocabulary file using python?',\n",
       "  'How to enumerate words in a vocabulary file using python?',\n",
       "  'How to enumerate words in a vocabulary file in python?',\n",
       "  'How to enumerate words from a vocabulary file in python'],\n",
       " ['How to create a vocabulary from a text file in python?',\n",
       "  'Creating a vocabulary from a text file in python',\n",
       "  'Creating a vocabulary from a text file using python',\n",
       "  'How to create a vocabulary from a text file using python?',\n",
       "  'How to create a vocabulary from a text file in python'],\n",
       " ['Preparing data from a file using python',\n",
       "  'Preparing data from a file in python',\n",
       "  'Preparing data in python using python and python',\n",
       "  'Preparing data in python',\n",
       "  'Preparing data in python using python'],\n",
       " ['Filtering a corpus in python',\n",
       "  'Filtering data from a corpus in python',\n",
       "  'Filtering corpus in python',\n",
       "  'Filtering data from a corpus using python',\n",
       "  'Filtering data from a corpus in python using python'],\n",
       " ['Extracting data from a corpus using python',\n",
       "  'Extracting data from a corpus in python',\n",
       "  'Extracting data from a corpus',\n",
       "  'Preparing data from a corpus in python',\n",
       "  'Extracting data from a corpus in python using python'],\n",
       " ['Splitting a corpus into multiple files in python',\n",
       "  'Splitting a corpus into multiple files using python',\n",
       "  'Splitting a corpus into multiple files in python using python',\n",
       "  'How to split a corpus into multiple files in python?',\n",
       "  'Splitting a corpus into multiple files using python and python'],\n",
       " ['How to create subwords in python using bpe.py?',\n",
       "  'How to create subwords in python using python?',\n",
       "  'How to create subwords in python using python scripts?',\n",
       "  'How to create subwords using bpe.py in python?',\n",
       "  'How to create subwords in python using python script?'],\n",
       " ['How to apply subwords to a file using python?',\n",
       "  'How to apply subwords to a file in python?',\n",
       "  'How to apply subwords to a file in python using python?',\n",
       "  'How to apply subwords to a file using python',\n",
       "  'How to apply subwords to a file in python'],\n",
       " ['What is wrong with my python python python python python python python python python python python py',\n",
       "  'What is wrong with my python python python python python python python python python python python?',\n",
       "  'What is wrong with my python python python python python python python python python python python',\n",
       "  'What is wrong with my python python python python python python python python python python python script?',\n",
       "  'What is wrong with my python python python python python python python python python python script?'],\n",
       " ['python python python python python python python python python python python python py',\n",
       "  'python python python python python python python python python python python python',\n",
       "  'python python python python python python python python python python python',\n",
       "  'python python python python python python python python python python',\n",
       "  'python python python python python python python python python python python python rp'],\n",
       " ['How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter'],\n",
       " ['python scripts/learn_bpe.py get_vocabulary(fobj) return dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) returns dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj)',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) returns a dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) not working'],\n",
       " ['Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated.',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only those pairs that overlap with occurrencesn of this pair are affected, and need to be updated',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated. python'],\n",
       " ['Count frequency of all symbol pairs, and create index',\n",
       "  'Count frequency of all symbol pairs, and create index in python',\n",
       "  'Count Frequency of all symbol pairs, and create index',\n",
       "  'Count frequency of all symbol pairs and create index',\n",
       "  'Count frequency of all symbol pairs, and create index in Python'],\n",
       " [\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Replacing all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Python - Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol\",\n",
       "  \"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB' in Python\"],\n",
       " ['Is there a better way to prune bpe statistics in python?',\n",
       "  'Is there a better way to prune bpe stats in python?',\n",
       "  'Is there a better way to prune statistics in python?',\n",
       "  'Is there a better way to prune stats in python?',\n",
       "  'Is there a better way to prune stats in python than python?'],\n",
       " ['How to extract audio features from a text file in python?',\n",
       "  'How to extract audio features from a.rb file in python?',\n",
       "  'How to extract audio features from a video file in python?',\n",
       "  'How to extract audio features from a text file using python?',\n",
       "  'How to extract audio features from a text file in python'],\n",
       " ['Is this a good way to check if a line is well-formed?',\n",
       "  'Checking if a line is well-formed',\n",
       "  'Is this a good way to check if a line is well formed?',\n",
       "  'Check if a line is well-formed',\n",
       "  'Checking if a line is well formed'],\n",
       " ['Reverse edits in python',\n",
       "  'Applying edits to a post',\n",
       "  'Reverse edits in post-editing',\n",
       "  'Reverse edits in python script',\n",
       "  'Reverse edits for a post'],\n",
       " ['Extracting post edits with levenshtein_legacy',\n",
       "  'Extracting post edits with levenshtein_legacy in python',\n",
       "  'Extracting post edits with levenshtein_legacy in python using lru_cache',\n",
       "  'Extracting post edits in python using functools.lru_cache(maxsize=1024)',\n",
       "  'Extracting post edits in python using functools.lru_cache (maxsize=1024)'],\n",
       " ['Levenshtein in python',\n",
       "  'Levenshtein in Python',\n",
       "  'Levenshtein python implementation',\n",
       "  'Levenshtein python code',\n",
       "  'Levenshtein python script']]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8b836110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "benedekrozemberczki/karateclub       83\n",
       "facebookresearch/pythia              83\n",
       "KAIST-AILab/deeprl_practice_colab    77\n",
       "WING-NUS/scisumm-corpus              76\n",
       "GPflow/GPflow                        75\n",
       "                                     ..\n",
       "mkmenta/domain_adapt_segm             1\n",
       "dhlab-epfl/dhSegment-text-torch       1\n",
       "ckiplab/ckiptagger                    1\n",
       "gunooknam/Code_Study_Yolov3           1\n",
       "kongzhiyou/darknet-master             1\n",
       "Name: repo_name, Length: 11943, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions['repo_name'].value_counts()[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e6567ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:21<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "readme_summaries = get_summaries(code_trans_model, code_trans_tokenizer, readme_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5c1d2c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Unifying Generative Model for Graph Learning Algorithms: Label Propagation, Graph Convolutions, and Combinations\n",
      "['### Gaussian Markov Random Field Learning Algorithms', '### Gaussian Markov random field ( MRF )', '### Gaussian Markov Random Field ( Gaussian Markov Random Field ) ###', '### Gaussian Markov Random Field ( Gaussian Markov Random Field )', '### Gaussian Markov Random Field ( MRF ) ###']\n",
      "Graph-based Semi-Supervised & Active Learning for Edge Flows\n",
      "['### Semi-supervised Learning for Edge Flows in a network.', '### Semi-Supervised Learning for Edge Flows in a network.', '### Semi-Supervised Learning for Edge Flows ###', '### Semi-Supervised Learning for Edge Flows', '### Semi-supervised Learning for Edge Flows']\n",
      "Neural Ordinary Differential Equations\n",
      "['Using PyTorch to fit a spiral ODE', 'Using PyTorch to fit a spiral ODE to a spiral network.', 'Using PyTorch to fit a spiral ODE to a spiral network', 'Using PyTorch to fit a spiral ODE to a spiral ODE', 'Use PyTorch to fit a spiral ODE']\n",
      "Speaker Recognition from Raw Waveform with SincNet\n",
      "['Using TIMIT to create an image for SincNet', 'Using TIMIT to create a custom image for SincNet', 'Using TIMIT to create a custom image for use in speech recognition', 'Using TIMIT to create a custom image for use in speech recognition.', 'Using TIMIT to create an image for SincNet.']\n",
      "Towards real-time unsupervised monocular depth estimation on CPU\n",
      "['How to run pydnet on webcam stream', 'How to run pydnet on webcam stream using Tensorflow 1.8?', 'How to run pydnet on webcam stream in TensorFlow?', 'How to run pydnet on webcam stream?', 'How to run pydnet on webcam stream using TensorFlow 1.8?']\n",
      "Single Episode Policy Transfer in Reinforcement Learning\n",
      "['Python - TensorFlow - Single Episode Policy Transfer in Reinforcement Learning', 'Python 3.6 Single Episode Policy Transfer in Reinforcement Learning', 'Python - TensorFlow - Single Episode Policy Transfer ( SEPT )', 'Python 3.6 Single Episode Policy Transfer ( SEPT )', 'Python - TensorFlow - Single Episode Policy Transfer in Reinforcement Learning.']\n",
      "CM3: Cooperative Multi-goal Multi-stage Multi-agent Reinforcement Learning\n",
      "['SUMO - Markov Simulator - Simulation Markov Learning', 'SUMO - Markov algorithms and config files.', 'SUMO - Markov algorithms and configurations.', 'SUMO - SUMO - Markov Learning', 'SUMO Simulator - Markov algorithms and configuration files.']\n",
      "Hierarchical Cooperative Multi-Agent Reinforcement Learning with Skill Discovery\n",
      "['### Hierarchial Cooperative Multi-Agent Reinforcement Learning with Skill Discovery', '### Hierarchial Cooperative Multi-Agent Reinforcement Learning with Skill Discovery ( HSD ) - TensorFlow version < 3.5.2 - PyGame 1.9.4 - TensorFlow version < 3.5.2 - TensorFlow version < 3.5.2 - PyGame 1.', '### Hierarchial Cooperative Multi-Agent Reinforcement Learning with Skill Discovery ( HSD ) - TensorFlow version < 3.5.2 - PyGame 1.9.4 - TensorFlow version < 3.5.2 - PyGame 1.9.1 - TensorFlow version < 3.5.', '### Hierarchial Cooperative Multi-Agent Reinforcement Learning with Skill Discovery ( HSD ) - TensorFlow version >= 3.5.2 - PyGame 1. 2 - TensorFlow version < 3.5.2 - PyGame 2. 2 - TensorFlow version < 3.5.', '### Hierarchial Cooperative Multi-Agent Reinforcement Learning with Skill Discovery ( HSD ) - TensorFlow version < 3.5.2 - PyGame 1.9.4 - TensorFlow version < 3.5.2 - TensorFlow version < 3.5.2 - TensorFlow version']\n",
      "Learning to Incentivize Other Learning Agents\n",
      "['Baseline for Learning to Incentivize Other Learning Agents', 'Baseline for Learning to Incentivize Other Learning Agents.', 'Baseline for Learning to Incentivize Individual Learning Agents', 'Baseline for Learning to Incentivize Other Learning Agents in the paper.', 'Baseline for Learning to Incentivize Learning Agents']\n",
      "HOL(y)Hammer: Online ATP Service for HOL Light\n",
      "['Build a test program for HOL Light using OCaml.', 'Build a test program for HOL Light using OCaml and Cezary.', 'Testing OCaml bytecode for all HOL Light methods', 'Build a test program for HOL Light using OCaml', 'Build a test program for HOL Light using native code']\n",
      "Path-Based Reasoning over Heterogeneous Networks for Recommendation via Bidirectional Modeling\n",
      "[\"Implement Yue's library for Python 3.x and 3.x.\", 'Implement Yue library for Python 3.x and 3.x.', 'Implement Yue library for Python 3.x and 3.x.', 'Implement Yue library for Python 3. x and 3. x', 'Implement Yue library for Python 3. x and 3. x.']\n",
      "Densely Connected Convolutional Networks\n",
      "['的,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,', '数,数,数,数,数,数,数,数,数,数,数,数,数,数,数,数', '的,的,,,,,,,,,,,,,,,,,,,,,,,,,,,,', '数,数,数,数,数,数,数,数,数,数,数,数,数,数,,数,', '数,数,数,数,数,数,数,数,数,数,数,数,数,数,数,,']\n",
      "Image Super-Resolution Using Deep Convolutional Networks\n",
      "['================================================================', '----------------------------------------------------------------', '-------------------------------------------------', '------------------------------------------------------------', '##### # Image generation']\n",
      "FCOS: Fully Convolutional One-Stage Object Detection\n",
      "['FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. # FCOS : Fully Convolutional One-Stage Object Detection', 'FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. # FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. # FCOS : Fully Convolutional One-Stage Object Detection', 'Detectron2 with Fully Convolutional One-Stage Object Detection. # FCOS : Fully Convolutional One-Stage Object Detection', 'FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. # FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. # FCOS : Fully Convolutional One-Stage Object Detection with multiple anchor boxes', 'FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. * # FCOS : Fully Convolutional One-Stage Object Detection with ResNet-50. * # Faster R-CNN : Faster R-CNN with ResNet-']\n",
      "YOLOv4: Optimal Speed and Accuracy of Object Detection\n",
      "['Run onnx inference using PyTorch - Based on MIT Licensed Documentation : https : //github.com/darknet/yolo/blob/master/doc/developer-guide/onnx-python/blob/master/doc/developer/onnx-python/', 'Run onnx inference using PyTorch - Based on MIT Licensed Documentation : https : //github.com/darknet/yolo/blob/master/doc/developer-guide/onnx-python/blob/master/doc/developer-guide/onnx-', 'Run onnx inference using PyTorch - Based on MIT Licensed Documentation : https : //github.com/darknet/yolo/blob/master/doc/developer-guide/onnx-python/blob/master/doc/developer/onnx-python-', 'Run onnx inference using PyTorch - Based on MIT Licensed Documentation : https : //github.com/darknet/yolo/blob/master/doc/developer-guide/onnx-python/blob/master/doc/developer/yolo/yolo', 'Run onnx inference using PyTorch - Based on MIT Licensed Documentation : https : //github.com/darknet/yolo/blob/master/doc/developer-guide/onnx-python/blob/master/doc/developer/onnx/ onnx']\n",
      "Tacotron: Towards End-to-End Speech Synthesis\n",
      "['### Tacotron An implementation of speech synthesis in TensorFlow.', '### Tacotron A implementation of speech synthesis in TensorFlow', '### Tacotron An implementation of speech synthesis in TensorFlow.', '### Tacotron A implementation of speech synthesis in TensorFlow.', '### Tacotron An implementation of speech synthesis in TensorFlow']\n",
      "Accelerating Prototype-Based Drug Discovery using Conditional Diversity Networks\n",
      "['_Pytorch/blob/master//blob/master', '_Pytorch #_Pytorch', '_Pytorch -_Pytorch', '_Pytorch *_Pytorch', '/blob/master/CDN_Molecule#']\n",
      "Learning Deep Generative Models of Graphs\n",
      "['/blob/master/src/core', '/blob/master/src/main', '/blob/master/README.', '/issues/1 ##.git', '/blob/master/doc/']\n",
      "Scalable Bayesian Optimization Using Deep Neural Networks\n",
      "['Tensorflow ( 1.x ) Deep Bayes Optimization for Neural Network Search ## Requirements * tfcg * stellargraph', 'Tensorflow ( 1.x ) Deep Bayes Optimization for Neural Network Search. ## Requirements * tfcg * stellargraph * tfcg * tfcg * stellargraph', 'Tensorflow ( 1.x ) Deep Bayes Optimization for Neural Network Search. ## Requirements * tfcg * stellargraph * tfcg * tfcg * tfcg', 'Tensorflow - Deep Bayes Optimization for Neural Network Search. ## Requirements * tfcg * stellargraph * tfcg * tfcg * stellargraph', 'Tensorflow - Deep Bayes Optimization for Neural Network Search. ## Requirements * tfcg * stellargraph * tfcg * tfcg']\n",
      "Scalable Bayesian Optimization Using Deep Neural Networks\n",
      "['Pytorch Version Deep Bayes Optimization for Neural Network Search', 'Pytorch Version Deep Bayes Optimization', 'pytorch version deep Bayes Optimization', 'pytorch version Deep Bayes Optimization', 'Pytorch Version Deep Bayes Optimization for Neural Network Architecture Search']\n",
      "Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks\n",
      "['##########################################', '#####################################################', '##### # weight_normalization', '##### # Weight normalization', '# noinspection PyUnresolvedReferences #']\n",
      "ALBERT: A Lite BERT for Self-supervised Learning of Language Representations\n",
      "[\"Learn a model that can predict person's intent from the user's requests for speech asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for voice asistant from\", \"Learn a model that can predict person's intent from the user's requests for speech asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for voice asistant.\", \"Learn a model that can predict person's intent from the user's requests for speech asistant from user's requests for voice asistant from user's requests for speech asistant from user's requests for voice asistant from user's requests for voice asistant from\", \"Learn a model that can predict person's intent from the user's requests for speech asistant from user's requests for speech asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for voice asistant from\", \"Learn a model that can predict person's intent from the user's requests for speech asistant from user's requests for voice asistant from user's requests for voice asistant from user's requests for user's voice asistant from user's requests for voice as\"]\n",
      "Generalized Zero-Shot Learning Via Over-Complete Distribution\n",
      "['PDF reference : https : //arxiv.org/pdf/2004.00666.pdf', 'PDF Reference : https : //arxiv.org/pdf/2004.00666.pdf', 'PDF Reference : http : //arxiv.org/pdf/2004.00666.pdf', 'PDF reference : http : //arxiv.org/pdf/2004.00666.pdf', 'PDF document reference : https : //arxiv.org/pdf/2004.00666.pdf']\n",
      "Speech Denoising Convolutional Neural Network trained with Deep Feature Losses.\n",
      "['Speech-Denoising with Deep Feature Loss,,,,,,,,,,,,,,,,,,,,,,,,,', 'Speech-Denoising with Deep Feature Loss,的,,,,,,,,,,,,,,,,,,,,,,,', 'Speech-Denoising with Feature Loss,,,,,,,,,,,,,,,,,,,,,,,,,,', 'Speech Denoising with Feature Loss,的,,,,,,,,,,,,,,,,,,,,,,,,', 'Speech-Denoising with Deep Feature Loss 的,的,,,,,,,,,,,,,,,,,,,,,,']\n",
      "Handwriting Recognition of Historical Documents with few labeled data\n",
      "['### Handwriting Recognition System', 'Tensorflow handwriting recognition system image.', 'Images for Handwriting Recognition System in TensorFlow', 'Images for the Handwriting Recognition System', '# Handwriting Recognition System']\n",
      "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n",
      "['### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image #### #', '### # iOS 11 Project using Vision and CoreML ## preview image ################# ################# ################# ################# ################# ################# # iOS 11 Project using Vision and CoreML\"', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########################################################################################################################################## ########################################################### #', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########### ############################################## ########################################################### #', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########################################################################################################################################## ###########################################################']\n",
      "MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\n",
      "['### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image #### #', '### # iOS 11 Project using Vision and CoreML ## preview image ################# ################# ################# ################# ################# ################# # iOS 11 Project using Vision and CoreML\"', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########################################################################################################################################## ########################################################### #', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########### ############################################## ########################################################### #', '### # iOS 11 Project using Vision and CoreML ## preview image #### #Preview image #### #Preview image ########################################################################################################################################## ###########################################################']\n",
      "Pre-training on high-resource speech recognition improves low-resource speech-to-text translation\n",
      "['Python 3 : Automatically create a conda environment with Fisher data', 'Python 3 : Create a conda environment with Fisher data', 'Python 3 : Creating a conda environment with Fisher data', 'Python 3 : Automatically create a conda environment using the Fisher and Callhome Spanish Speech Transformation Model', 'Python 3 : Automatically create a conda environment with the Fisher and Callhome Spanish Speech-to-Text model']\n",
      "U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
      "['# Wnet-cGAN Architecture using depth and spectral information. ## # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet-cGAN', '# Wnet-cGAN Architecture using depth and spectral information. ## # Wnet-cGAN Architecture using depth and spectral information ## # # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet-cGAN', '# Wnet-cGAN Architecture using depth and spectral information. ## # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet-cGAN Architecture using depth and spectral information ## # # Wnet-cGAN', '# Wnet-cGAN Architecture using depth and spectral information for building outlines. ## # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet-cGAN Architecture using depth and spectral information ## ## # # Wnet', '# Wnet-cGAN Architecture using depth and spectral information. ## # Wnet-cGAN Architecture using depth and spectral information! [ Wnet-cGAN Architecture using depth and spectral information ] # # Wnet-cGAN Architecture using']\n",
      "Gating Revisited: Deep Multi-layer RNNs That Can Be Trained\n",
      "['TPAMI - Gating revisited - Tensorflow implementation', 'TPAMI - Gating revisited : Tensorflow implementation for Tensorflow Networks that can be trained.', 'TPAMI - Gating revisited : Tensorflow implementation for Tensorflow Networks that can be trained in TensorFlow', 'TPAMI - Gating revisited : Tensorflow implementation for a Tensorflow network.', 'TPAMI - Gating revisited : Tensorflow implementation for a TensorFlow network.']\n",
      "A Layer-Based Sequential Framework for Scene Generation with GANs\n",
      "['Generate Sequential Image Generation using GANs.', 'Generate a Sequential Framework for Scene Generation using GANs.', 'Generate a Sequential Framework for Scene generation using GANs.', 'Generate Sequential Image Generation using GANs in Turkoglu 2019.', 'Generate Sequential Image Generation using GANs in Turkoglu.']\n",
      "Synthesizer: Rethinking Self-Attention in Transformer Models\n",
      "['### 1 ) Create venv and move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move', '### 1 ) Create venv and move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move', '### 1 ) Create venv and move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 4 ) Move', '### 1 ) Create venv and move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Copy', '### 1 ) Create venv and move to the synth directory ##### 2 ) Move to the synth directory ##### 3 ) Move to the synth directory ##### 4 ) Move to the synth directory ##### 5 ) Move to the synth directory ##### 6 ) Move to the synth directory ##### 6 ) Move']\n",
      "A Neural Algorithm of Artistic Style\n",
      "['Neural-Style-Transfer Neural-Style-Transfer.gif - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 -', 'Neural-Style-Transfer Neural-Style-Transfer.gif - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19', 'Neural-Style-Transfer Neural-Style-Transfer.gif - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19', 'Neural-Style-Transfer Neural-Style-Transfer.gif - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19 - > VGG19.', 'Neural-Style-Transfer Neural-Style-Transfer.gif - > VGG19 - > VGG1 - > VG2 - > VG1 - > VG2 - > VG1 - > VG2 - > VG1 - > VG2 - >']\n",
      "Conditional BERT Contextual Augmentation\n",
      "['Contextual Augmentation # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data ) # cbert_aug ( aug_data,', 'Contextual Augmentation # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # cbert_aug (', 'Contextual Augmentation # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # aug_data ( aug_data ) # cbert_aug ( aug_data, st', 'Contextual Augmentation # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary )', 'Contextual Augmentation # cbert_aug ( aug_data, stsa.binary ) # cbert_aug ( aug_data, stsa.binary ) # aug_data ( aug_data ) # cbert_aug ( aug_data ) #']\n",
      "U-Net: Convolutional Networks for Biomedical Image Segmentation\n",
      "['                               ', '                             , ', '                            ,  ', '                           ,   ', '                              ,']\n",
      "Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks\n",
      "['Python : Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks', 'Python - Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks', 'Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks', 'Python : Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks *', 'Python - Cross-lingual Knowledge Graph Alignment via Graph Convolutional Networks *']\n",
      "XGBoost: A Scalable Tree Boosting System\n",
      "['### EC524 - Heart-disease classification                          ', '### EC524 - Heart-Disease classification                          ', '### EC524 - Heart-disease                           ', '### EC524 : Heart-disease classification                          ', '### EC524 - Heart-Disease                           ']\n",
      "SSD: Single Shot MultiBox Detector\n",
      "['### opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > opencv-ci - > open', '### opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubun', '### opencv-ci.org/weiliu/16.04, opencv-ci.org/weiliu/16.04, opencv-ci.org/weiliu/16.04, opencv-ci.org/weiliu/16.04, open', '### opencv - ubuntu 16.04, opencv - ubuntu 15.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubun', '### opencv - ubuntu 16.04, opencv - ubuntu 17.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubuntu 16.04, opencv - ubun']\n",
      "A Deep Sequential Model for Discourse Parsing on Multi-Party Dialogues\n",
      "['How to train the model with default settings in Python 3?', 'How to train a model with default settings in Python 3?', 'Python 3 : Train a model with default settings.', 'Python 3 : How to train the model with default settings?', 'How to train the model in Python 3?']\n",
      "Improved Baselines with Momentum Contrastive Learning\n",
      "['Momentum Contrast for Unsupervised Visual Representation Learning', 'Momentum Contrast for Unsupervised Visual Representation Learning in PyTorch', 'Momentum Contrast for Unsupervised Visual Representation Learning using PyTorch', 'Momentum Contrast with Unsupervised Visual Representation Learning in PyTorch', 'Momentum Contrast with Unsupervised Visual Representation Learning']\n",
      "Multi-branch and Multi-scale Attention Learning for Fine-Grained Visual Categorization\n",
      "['### TBMSL-Net ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '### TBMSL-Net ~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '### TBMSL-Net ~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '### TBMSL-Net ~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '### TBMSL-Net ~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~']\n",
      "EM-RBR: a reinforced framework for knowledge graph completion from reasoning perspective\n",
      "['Embedding method for better link prediction. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule and data set. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule', 'Embedding and Link Prediction. The data set should consist of three files, w.r.t entity2id relation2id train, test and rule. The data set should consist of three files, w.r.t entity2id relation2id train, test and rule. The data set', 'Embedding and Link Prediction. The data set should consist of three files, w.r.t entity2id relation2id train, test and rule. The data set should consist of three files, w.r.t entity2id relation2id train, test and rule. The embedding', 'Embedding method for better link prediction. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule. The data', 'Embedding and Link Prediction. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule. The data set should consist of three files, w.r.t entity2id relation2id train, test, rule, and link prediction']\n",
      "A Neural Algorithm of Artistic Style\n",
      "['NEural Style Transfer', '### Neural Style Transfer', 'NEURAL_STYLE_TRANSFER', 'NEURURUR', 'MIT License 2.']\n",
      "Using phase instead of optical flow for action recognition\n",
      "['Learning using phase instead of optical flow for action recognition.', 'Learning Phase-Based Descriptions for Action Recognition.', 'Learning phase-based descriptions for action recognition.', 'Learning Phase - Based Descriptions for Action Recognition.', 'Learning using phase instead of optical flow for Action Recognition.']\n",
      "Contextual Word Representations: A Contextual Introduction\n",
      "['### Project Name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TB', '### Project Name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Contextual Word Representation', '### Project Name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Natural Language Model - ', '### Project Name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Natural Language Processing with Deep Learning Techniques', '### Project Name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Project name_TBD - Natural Language Processing with Deep']\n",
      "StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks\n",
      "['Establece el proyecto de las imágenes de texto.', 'Establece el proyecto de las imágenes de texto en el cuadro de texto en tantas como sean necesarias. Si las imágenes de texto en tantas como sean necesarias', 'Establece el proyecto de las imágenes de texto en el cuadro de texto en tantas como sean necesarias. Si las imágenes de texto en el cuadro de texto en el cuadro', 'Establece el proyecto de las imágenes de texto en el cuadro de texto en tantas como sean necesarias. Si las imágenes de texto en el cuadro de texto en tantas com', 'Establece el proyecto de las imágenes de texto en el cuadro de texto en el cuadro de texto en tantas como sean necesarias']\n",
      "Progressive Bilateral-Context Driven Model for Post-Processing Person Re-Identification\n",
      "['Download the MAT-file for the baseline method and place it into the folder named baseline.', 'Download the MAT-file for the baseline method and place them into the folder named baseline.', 'Download the MAT-file for the baseline method from the repository and place it into the folder named baseline.', 'Download the MAT-file for the baseline method and place it into the folder named baseline', 'Download the MAT-file for the baseline method and place them into a folder named baseline.']\n",
      "word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding method\n",
      "['### Developing 1. Run `grunt serve` to start the development server. 2. Run `grunt serve` to start the development server. 3. Run `grunt serve` to start the development server. 4. Run `grunt serve` to start the development server. 5. Run `grunt serve', '### Developing 1. Run `grunt serve` to start the development server. 2. Run `grunt serve` to start the development server. 3. Run `grunt serve` to start the development server. 4. Run `grunt serve` to start the development server. 5. Start the development server', '### Developing 1. Run `grunt serve` to start the development server. 2. Run `grunt serve` to start the development server. 3. Run `grunt serve` to start the development server. 4. Run `grunt serve` to start the development server. 5. Serve the development server', '### Developing 1. Run `grunt serve` to start the development server. 2. Run `grunt serve` to start the development server. 3. Run `grunt serve` to start the development server. 4. Run `grunt serve` to start the development server. 5. Run `grunt serve', '### Developing 1. Run `grunt serve` to start the development server. 2. Run `grunt serve` to start the development server. 4. Run `grunt serve` to start the development server. 5. Run `grunt serve` to start the development server.']\n",
      "Generating Training Data for Denoising Real RGB Images via Camera Pipeline Simulation\n",
      "[\"Recommended version of PyTorch's Camera Simulation for Learning To-Do Modules. Recommended version of PyTorch's PyTorch's Camera Simulation for Learning To-Do Modules. Recommended version of PyTorch\", \"Recommended version of PyTorch's Camera Simulation for Learning To-Do Modules. Recommended version of PyTorch's PyTorch's Camera Simulation for Learning to-Do Modules. Recommended version of PyTorch\", \"Recommended version of PyTorch's Camera Simulation for Learning To-Do\", \"Recommended version of PyTorch's Camera Simulation for Learning To-Do. Recommended version of PyTorch's PyTorch's Dataset Class. Recommended version of PyTorch's PyTorch's PyTorch\", \"Recommended version of PyTorch's Camera Simulation for Learning To-Do Modules. Recommended version of PyTorch's PyTorch's Camera Simulation for Learning To-Do Modules\"]\n",
      "Gender Bias in Contextualized Word Embeddings\n",
      "['### NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters', '### NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project Code base for NLP', '### NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project Code base used for NL', '### NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project ## NLP_masters_project NLP_master', '### NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project NLP_masters_project # NLP_masters_project NLP_master']\n",
      "Transparent Classification with Multilayer Logical Perceptrons and Random Binarization\n",
      "['Learning CRS using PyTorch', 'Learning CRS in PyTorch', 'Learn CRS using PyTorch', 'How to create a CRS image in PyTorch?', 'How to create a CRS image in PyTorch']\n",
      "TPLinker: Single-stage Joint Extraction of Entities and Relations Through Token Pair Linking\n",
      "['TPLinker is a single-stage implementation of the TPLinker implementation. The TPLinker implementation is a single-stage implementation of the TPLinker implementation. The TPLinker implementation is a single-stage implementation of the TPLinker implementation. The TPLinker', 'TPLinker is a single-stage implementation of the TPLinker algorithm. The TPLinker implementation is a single-stage implementation of the TPLinker implementation. The TPLinker implementation is a single-stage implementation of the TPLinker implementation. The TPLinker', 'TPLinker is a single-stage implementation of the TPLinker algorithm. The TPLinker implementation is a single-stage implementation of the TPLinker algorithm. The TPLinker implementation is a single-stage implementation of the TPLinker implementation. The TPLinker', 'TPLinker is a single-stage implementation of the TPLinker algorithm. The TPLinker implementation is a single-stage implementation of the TPLinker algorithm. The TPLinker implementation is a single-stage implementation of the TPLinker algorithm. The TPLinker', 'TPLinker is a single-stage implementation of the TPLinker algorithm. The TPLinker is a single-stage implementation for the paper. The TPLinker is a single-stage implementation for the paper. The TPLinker is a single-stage implementation for the paper.']\n",
      "MMDetection: Open MMLab Detection Toolbox and Benchmark\n",
      "['MM Detection toolbox for PyTorch ( https : //www.pytorch.org/ ). See also https : //github.com/facebookresearch/mmdetection.io/blob/master/src/com/facebookresearch/mmdetection.', 'MM Detection toolbox for PyTorch ( https : //www.pytorch.org/ ). See also https : //github.com/facebookresearch/mmdetection.readthedocs.io/blob/master/doc/manual/mmdetection.', 'MM Detection toolbox for PyTorch ( https : //www.pytorch.org/ ). See also https : //github.com/facebookresearch/mmdetection.io/blob/master/src/com/facebookresearch/mmdetection/', 'MM Detection toolbox for PyTorch ( https : //www.pytorch.org/ ). See also https : //github.com/facebookresearch/mmdetection.io/blob/master/doc/master/doc/manual/mmdetection.', 'MM Detection toolbox for PyTorch ( https : //www.pytorch.org/ ). See also https : //github.com/facebookresearch/mmdetection.readthedocs.io/blob/master/doc/man/mmdetection/mm']\n",
      "News Session-Based Recommendations using Deep Neural Networks\n",
      "['Run ACR and NAR in a Jupyter Notebook', 'Run ACR and NAR in a Jupyter Notebook.', 'Run ACR and NAR in a Jupyter Notebook app', 'Run ACR and NAR in a Jupyter Runner', 'CHAMELEON - Run ACR and NAR in a journal of ACM RecSys.']\n",
      "MMDetection: Open MMLab Detection Toolbox and Benchmark\n",
      "['MM Detection with PyTorch. Recommended features : ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', 'MM Detection with PyTorch. Recommended features : ~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~', 'MM Detection with PyTorch. Recommended features : ~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~', 'MM Detection with PyTorch. Recommended features : ~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', 'MM Detection with PyTorch. Recommended features : ~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~~~~']\n",
      "MMDetection: Open MMLab Detection Toolbox and Benchmark\n",
      "['Prepare MSCOCO dataset for training and validation', 'Download MSCOCO dataset to your data path.', 'Prepare MSCOCO dataset for MLP training and validation', 'Prepare MSCOCO dataset for training, validation and validation', 'Download MSCOCO training and validation datasets.']\n",
      "MMDetection: Open MMLab Detection Toolbox and Benchmark\n",
      "['### Open MM Detection toolbox with PyTorch ( https : //github.com/Microsoft/OpenMMLab/blob/master/doc/developer-guide/mmdetection.html ) and [mask ] ( https : //github.com/Microsoft/OpenMMLab/', '### Open MM Detection toolbox with PyTorch ( https : //github.com/Microsoft/OpenMMLab/blob/master/doc/developer-guide/mmdetection.html ) and [maskmask ] ( https : //github.com/Microsoft/OpenMMLab', '### Open MM Detection toolbox with PyTorch ( https : //github.com/Microsoft/OpenMMLab/blob/master/doc/master/doc/developer-guide/mmdetection.html ) and [mask ] ( https : //github.com/Microsoft/', '### Open MM Detection toolbox with PyTorch ( https : //github.com/Microsoft/OpenMMLab/blob/master/doc/master/doc/developer_mm_detection.html ) and [mask ] ( https : //github.com/Microsoft/Open', '### Open MM Detection toolbox with PyTorch ( https : //github.com/Microsoft/OpenMMLab/blob/master/doc/developer-guide/mmdetection.html ) and [mask ] ( https : //github.com/Microsoft/OpenMML/']\n",
      "Attention Transfer Network for Aspect-level Sentiment Classification\n",
      "['### Attention Transfer Network for Aspect-Level Sentiment Classification', '### Attention Transfer Network for Aspect-level Sentiment Classification', '### Attention Transfer Network for Aspect-Level Sentiment Sentiment Classification', '### Attention Transfer Network for Aspect-Level Sentiment Classification?', '### Attention Transfer Network for Aspect-Level Sentiment Classification.']\n",
      "Latent Opinions Transfer Network for Target-Oriented Opinion Words Extraction\n",
      "['Python script to run LOTN on a pre-trained model. ### step1 : transfer - Softmax ``` # step2 : transfer - CRF ``` # # step3 : transfer - CRF ``` # # step4 : transfer - CRF ``` # # step4 : transfer', 'Python script to run LOTN on a pre-trained model. ### step1 : transfer - Softmax ``` # step2 : transfer - CRF ``` # # step3 : transfer - CRF ``` # # step4 : transfer - Softmax ``` # # step4 : transfer', 'Python script to run LOTN on a pre-trained model. ### step1 : transfer - Softmax ``` # step2 : transfer - CRF ``` # # step3 : transfer - Softmax ``` # # step4 : transfer - CRF ``` # # step4 : transfer', 'Python script to run LOTN on a pre-trained model. ### step1 : transfer - Softmax ``` # step2 : transfer - CRF ``` # # step3 : transfer - CRF ``` # # step4 : transfer - Softmax ``` # # # step4 :', 'Python script to run LOTN on a pre-trained model. ### step1 : transfer - Softmax ``` # step2 : transfer - CRF ``` # # step3 : transfer - Softmax ``` # # # step4 : transfer - CRF ``` # # step4 :']\n",
      "Deep Pyramidal Residual Networks\n",
      "[' # PyramidNet-Keras Keras  #  #  # PyramidNet-Keras Keras  #  #  #  #  # PyramidNet-Keras Keras  #  #', ' # PyramidNet-Keras Keras  #  #  # PyramidNet-Keras Keras  #  #  #  # PyramidNet-Keras Keras  #  #  #', ' # PyramidNet - Keras Keras  #  #  # PyramidNet - Keras Keras  #  #  #  #  #  # PyramidNet - Keras Keras  #  #', ' # PyramidNet-Keras Keras  #  #  # PyramidNet-Keras Keras  #  #  #  #  #  # PyramidNet-Keras Keras  #', ' # PyramidNet - Keras Keras  #  #  #  #  # PyramidNet - Keras Keras  #  #  #  #  # PyramidNet - Keras Keras  #']\n",
      "HHH: An Online Medical Chatbot System based on Knowledge Graph and Hierarchical Bi-Directional Attention\n",
      "['://hbda.com/://twitter.com/attentionLayer://://www.google.com/://://www.google.com/://://www.google.com/://://://www.google.com/://', '://hbda.com/://twitter.com/attentionLayer://://www.google.com/://://www.google.com/://://www.google.com/://://://://://www.google.com', '://hbda.com/://twitter.com/attentionLayer://://www.google.com/://://www.google.com/://://www.google.com/://://://://://twitter.com/at', '://hbda.com/://twitter.com/attentionLayer://://www.google.com/://://www.google.com/://://www.google.com/://://://://://www.attention', '://hbda.com/://twitter.com/attentionLayer://://www.google.com/://://www.google.com/://://www.google.com/://://://twitter.com/://://twitter']\n",
      "Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\n",
      "['Tensorflow implementation of fast RCNN with multi-gpu support.', 'Tensorflow implementation of fast RCNN with multi-gpu support by Xinlei Chen', 'Tensorflow implementation of fast RCNN with multi-gpu support', 'TensorFlow implementation of fast RCNN with multi-gpu support by Xinlei Chen', 'Tensorflow implementation of Faster RCNN with multi-gpu support by Xinlei Chen']\n",
      "Deep Back-Projection Networks For Super-Resolution\n",
      "['##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # ##### # DBPN-Keras # ##### # DBPN-Keras #', '##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # ##### # DBPN-', '##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### #', '##### # DBPN-Keras # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras', '##### # DBPN-Keras # DBPN-Keras # Observations # ##### # DBPN-Keras # Observations # ##### # DBPN-Keras # ##### # DBPN-Keras # ##### #']\n",
      "Mining Novel Multivariate Relationships in Time Series Data Using Correlation Networks\n",
      "['COMET_ADVANCED.py contains the code to obtain all multipoles in a given dataset. # Multipoles This repository contains the code to obtain all multipoles in a given dataset. # Multipoles This repository contains the code to obtain all multipoles in a given dataset', 'COMET_ADVANCED.py contains the code to obtain all multipoles in a given dataset. # Multipoles The repository contains the code to obtain all multipoles in a given dataset. # Multipoles The repository contains the code to obtain all multipoles in a given dataset', 'COMET_ADVANCED.py contains the code to obtain all multipoles in a given dataset. # Multipoles This repository contains the code to obtain all multipoles in a given dataset. # Multipoles The repository contains the code to obtain all multipoles in a given dataset', 'COMET_ADVANCED.py contains the code to obtain all multipoles in a given dataset. # Multipoles The repository contains the code to obtain all multipoles in a given dataset. # Multipoles The repository contains the module COMET_ADVANCED.py', 'COMET_ADVANCED.py contains the code to obtain all multipoles in a given dataset. # Multipoles This repository contains code to obtain all multipoles in a given dataset. # Multipoles This repository contains code to obtain all multipoles in a given dataset. #']\n",
      "YOLOv4: Optimal Speed and Accuracy of Object Detection\n",
      "['How to run onnx in pytorch?', 'How to run onnx and onnx inferences in parallel using onnx.py and onnx.py?', 'How to run pytorch and onnx inferences in parallel using onnx and onnx?', 'How to run pytorch and onnx inferences using onnx?', 'How to run onnx in pytorch using onnx.py?']\n",
      "Pyramid Scene Parsing Network\n",
      "['Images of semantic segmentation on MIT ADE20K dataset in PyTorch', 'Image encoding of semantic segmentation on MIT ADE20K dataset in PyTorch', 'Image encoding of semantic segmentation on MIT ADE20K dataset on PyTorch', 'Images of semantic segmentation on MIT ADE20K datasets in PyTorch', 'Images of semantic segmentation on MIT ADE20K dataset on PyTorch']\n",
      "UNet++: A Nested U-Net Architecture for Medical Image Segmentation\n",
      "['keras-unet 数 # ##### keras-unet- # ##### keras-unet- # ##### keras-unet- # ##### keras-unet- # ##### keras-unet', 'keras-unet 数 # ##### keras-unet  # ##### keras-unet  # ##### keras-unet  # ##### keras-unet  # ##### keras-unet', 'keras-unet 数 # ##### keras-unet- # ##### keras-unet- # ##### keras-unet- # ##### keras-unet  # ##### keras-unet', 'keras-unet 数 # ##### keras-unet- # ##### keras-unet- # ##### keras-unet  # ##### keras-unet- # ##### keras-unet', 'keras-unet 数 # ##### keras-unet- # ##### keras-unet- # ##### keras-unet  # ##### keras-unet  # ##### keras-unet']\n",
      "Dueling Network Architectures for Deep Reinforcement Learning\n",
      "['-----------------------------------------------------', 'Documentation URLs.', 'Refer to PDF.', 'Documentation Documentation.', 'Compose a PDF.']\n",
      "Proximal Policy Optimization Algorithms\n",
      "['                               ', '  cost function                             ', '   cost function                            ', '      .                        ', '        .                      ']\n",
      "Proximal Policy Optimization Algorithms\n",
      "['### MM Algorithm PPO  TRPO                          ', 'MM Algorithm                              ', '                               ', '### PPO  TRPO                            ', '##### MM Algorithm PPO  TRPO                          ']\n",
      "Graph Embedding on Biomedical Networks: Methods, Applications, and Evaluations\n",
      "['Bioinformatics : Graph Embedding Evaluation for Biomedical Networks', 'Bioinformatics : Graph Embedding Evaluation for a Biomedical Network ( Biomedical Networks )', 'Bioinformatics : Graph Embedding Evaluation for a Biomedical Network ( Biomedical Embedding Evaluation ).', 'Bioinformatics : Graph Embedding Evaluation for a Biomedical Network ( Biomedical Network )', 'Bioinformatics : Graph Embedding Evaluation for a Biomedical Network']\n",
      "Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models\n",
      "['Implementing Two Dimensional Local Attention Mechanisms for Generative Models', 'Two Dimensional Local Attention Mechanisms for Generative Models', 'Implementing Two Dimensional Attention Mechanisms for Generative Models', 'Creating Two Dimensional Local Attention Mechanisms for Generative Models', 'Implementing Two Dimensional Local Attention Mechanisms for Generative Models in Pytorch']\n",
      "FaceNet: A Unified Embedding for Face Recognition and Clustering\n",
      "['~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~']\n",
      "FaceNet: A Unified Embedding for Face Recognition and Clustering\n",
      "['~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~~~~', '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~~~~~~~~~~~~~~~']\n",
      "Competitive Policy Optimization\n",
      "['Install a multi-agent mirror Descent ( CGD ) package to a multi-agent setting', 'Install a multi-agent mirror Descent to a multi-agent setting', 'Install a multi-agent mirror Descent package to a multi-agent setting', 'Install a multi-agent mirror descent to a multi-agent setting', 'Install a multi-agent mirror descent package to a multi-agent setting']\n",
      "Affect Expression Behaviour Analysis in the Wild using Spatio-Channel Attention and Complementary Context Information\n",
      "[\"Figures out how to use FER in the expression track of ABAW 2020 competition. < p/ > Refer to https : //gist.github.com/fer/blob/master/src/main/java/com/fer/fer.png? title= ''\", 'Figures out how to use FER in the expression track of ABAW 2020 competition. < p/ > Refer to https : //gist.github.com/fer/blob/master/src/main/java/com/fer/fer.html # FER_', 'Figures out how to use FER in the expression track of ABAW 2020 competition. < p/ > Refer to https : //gist.github.com/fer/blob/master/src/main/java/com/fer/fer.html', 'Figures out how to use FER in the expression track of ABAW 2020 competition. < p/ > Refer to https : //gist.github.com/fer/blob/master/src/main/java/com/fer/fer_concepts.html', 'Figures out how to use FER in the expression track of ABAW 2020 competition. < p/ > Refer to https : //gist.github.com/fer/blob/master/src/main/java/com/fer/fer.png']\n",
      "Landmark Guidance Independent Spatio-channel Attention and Complementary Context Information based Facial Expression Recognition\n",
      "['Implement FER in-the-wild Behavior Analysis in-the-wild Behavior Analysis and Complementary Context Information Based Facial Expression Recognition for a Spatio-channel using Spatio-channel Attention and Complementary Context Information.', 'Implement FER in-the-wild Behavior Analysis in-the-wild Behavior Analysis and Complementary Context Information Based Facial Expression Recognition for a Spatio-channel using Spatio-channel attention and Complementary Context Information.', 'Implement FER in-the-wild Behavior Analysis in-the-wild Behavior Analysis and Complementary Context Information Based Facial Expression Recognition for a Spatio-channel using Spatio-Channel Attention and Complementary Context Information.', 'Implement FER in-the-wild Behavior Analysis in-the-wild Behavior Analysis and Complementary Context Information Based Facial Expression Recognition for a Spatio-channel using Spatio-channel Attention and Complementary Behavior Analysis in the Wild.', 'Implement FER in-the-wild Behavior Analysis in-the-wild Behavior Analysis and Complementary Context Information Based Facial Expression Recognition for a Spatio-channel using Spatio-channel Attention Analysis in the Wild.']\n",
      "A Fixed-Point Model for Pancreas Segmentation in Abdominal CT Scans\n",
      "['### # OrganSegC2F : a coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie, # Lingxi Xie, # Coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie,', '### # OrganSegC2F : a coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie, # Lingxi Xie, # Coarse-to-fine organ segmentation framework version 1.51, # Lingxi Xie,', '### # OrganSegC2F : a coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie, # Lingxi Xie, # Coarse-to-fine organ segmentation framework version 1.21, # Lingxi Xie,', '### # OrganSegC2F : a coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie, # Lingxi Xie, # Coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie #', '### # OrganSegC2F : a coarse-to-fine organ segmentation framework version 1.11, # Lingxi Xie, # Lingxi Xie, # Coarse-to-fine organ segmentation framework version 1.51, # Coarse-to-f']\n",
      "Recurrent Saliency Transformation Network: Incorporating Multi-Stage Visual Cues for Small Organ Segmentation\n",
      "['### # OrganSegRSTN : an end-to-end coarse-to-fine organ segmentation framework version 2.0 - Qihang Yu improved it to allow end-to-end training, and Qihang Zhou improved it to allow end-to-end training. #', '# OrganSegRSTN : an end-to-end coarse-to-fine organ segmentation framework version 2.0 - Qihang Yu, Yuyin Zhou improved it to allow end-to-end training, and Lingxi Xie improved it to allow end-to-', '# OrganSegRSTN : an end-to-end coarse-to-fine organ segmentation framework', '### # OrganSegRSTN : an end-to-end coarse-to-fine organ segmentation framework version 2.0 - Qihang Yu improved it to allow end-to-end training, and Lingxi Xie improved it to allow end-to-end training. #', '### # OrganSegRSTN : an end-to-end coarse-to-fine organ segmentation framework version 2.0 - Qihang Yu, Yuyin Zhou improved it to allow end-to-end training, and Lingxi Xie improved it to allow end-']\n",
      "Visual Semantic SLAM with Landmarks for Large-Scale Outdoor Environment\n",
      "['##![semantic SLAM...', '#![semantic SLAM...', '##![structure](graph.png)...', '##![semantic SLAM]...', '##![structure](graph.gif)...']\n",
      "Leveraging the Invariant Side of Generative Zero-Shot Learning\n",
      "['Implementing the LisGAN implementation of the \"\" zero-shot learning \"\" algorithm for AWA2 datasets.', 'Implementing Zero-Shot Learning for AWA2 datasets.', 'Implementing Zero-Shot Learning for AWA2 datasets. See \"\" LisGAN Using Torch \"\" paper.', 'Implementing Zero-Shot Learning for AWA2 datasets. See \"\" LisGAN - using-torch \"\" for more information.', 'Implementing Zero-Shot Learning for AWA2 datasets. See \"\" LisGAN - using-torch \"\" for more details.']\n",
      "ArcFace: Additive Angular Margin Loss for Deep Face Recognition\n",
      "['*** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** Arc', '*** ArcFace Demo * *** ArcFace Demo * *** *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * ', '*** ArcFace Demo * *** ArcFace Demo * *** *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *', '*** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * ', '*** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ArcFace Demo * *** ']\n",
      "RetinaFace: Single-stage Dense Face Localisation in the Wild\n",
      "['Reimplementation of retinaface in the Wild CVPR 2013 paper.', 'Reimplementation of retinaface in the Wild CVPR', 'Reimplementation of retinaface in the Wild CVPR 2013 paper', 'Reimplementation of retinaface in a Wild CVPR', 'Reimplementation of retinaface in the Wild CVPR 2010 paper.']\n",
      "Explaining and Harnessing Adversarial Examples\n",
      "['Train a MNIST classifier with the given name and generate a best_acc. tar file in the output directory. ### Usage 1. train a simple MNIST classifier and then see the best_acc. tar file in the output directory. ### Example 2. train a simple MNIST classifier', 'Train a MNIST classifier with the given name and generate the best_acc. tar file in the output directory. ### Usage 1. train a simple MNIST classifier and then see the best_acc. tar file in the output directory. ### Example 2. train a simple MNIST classifier', 'Train a MNIST classifier with the given name and generate a best_acc. tar with the best_acc. tar as output. ### Usage 1. train a simple MNIST classifier and then see the best_acc. tar as output. ### Example 2. train a simple MNIST', 'Train a MNIST classifier with the given name and generate a best_acc. tar with the best_acc. tar as output. ### Usage 1. train a simple MNIST classifier and then see the best_acc. tar as output. ### Example 2. train a simple MNIST', 'Train a MNIST classifier with the given name and generate a best_acc. tar with the best_acc. tar as output. ### Usage 1. train a simple MNIST classifier and then see the best_acc. tar as output. ### 2. generate a simple MNIST classifier']\n",
      "Revisiting Hierarchical Approach for Persistent Long-Term Video Prediction\n",
      "['Hierarchical Video Prediction using PyTorch', 'Hierarchical Video Prediction in PyTorch', 'Hierarchical Video Prediction and PyTorch', 'Hierarchical Video Prediction PyTorch implementation.', 'Hierarchical Video Prediction PyTorch implementation of Hierarchical Video Prediction']\n",
      "High-Fidelity Synthesis with Disentangled Representation\n",
      "['Synthesis) ##https://www.google.com/projects/ #https://www.google.com/projects/#https://www.google.com/projects/CelebA-HQ). #Synthes', 'Synthesis) ##https://www.google.com/projects/ #https://www.google.com/projects/#https://www.google.com/projects/CelebA-HQ) #Synthes', 'Synthesis) ##https://www.google.com/projects/ #https://www.google.com/projects/#https://www.google.com/projects/CelebA/', 'Synthesis) ##https://www.google.com/projects/ #https://www.google.com/projects/ #https://www.google.com/projects/CelebA/', 'Synthesis) ##https://www.google.com/projects/ #https://www.google.com/projects/#https://www.google.com/projects/CelebA-HQ). #GPL) ##']\n",
      "Identity Mappings in Deep Residual Networks\n",
      "['How to get a PDF of a Resnet18 Resnet18', 'How to get Resnet18 from Google Spreadsheets?', 'How to get a PDF of a Resnet18 Resnet18?', 'How to get a PDF of a Resnet18 project?', 'Getting a PDF of a Resnet18 Resnet18']\n",
      "Efficient Optimization of Echo State Networks for Time Series Datasets\n",
      "['Python : Train and Optimize Echo State Networks for Time Series Datasets', 'Efficient Optimization of Echo State Networks for Time Series Datasets', 'Efficient Optimization of Echo State Networks for Time Series Datasets in Python', 'Python : Train and Optimize Echo State Network for Time Series Datasets', 'Efficient Optimization of Echo State Networks for Time Series Datasets. Python']\n",
      "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)\n",
      "['Requiring the 3D facial landmarks in a 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D', 'Requiring the 3D facial landmarks in a 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN - Full version of the 3D', 'Requiring the 3D facial landmarks in a 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN -Full version of the 3D', 'Requiring the 3D facial landmarks in a 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN - Full version of the 3D-FAN - Full version of the 3D', 'Requiring the 3D facial landmarks in a 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN-Full version of the 3D-FAN - Full version of the 3D facial landmarks in a binary-face-alignment']\n",
      "Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources\n",
      "['### Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '### Binarize Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '### Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources in PyTorch', '### Binarized Convolutional Landmark Localizers for Human Pose Estimation with Limited Resources', '### Binarized Convolutional Landmark Localizers for Human Pose Estimation & Face Alignment with Limited Resources']\n",
      "Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources\n",
      "['### Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '### Binarize Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '# Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '## Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources', '##### Binarized Convolutional Landmark Localizers for Human Pose Estimation and Face Alignment with Limited Resources']\n",
      "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)\n",
      "['Face Recognition in Python', 'Face Recognition using a scikit-learn library.', 'Face Recognition using a scikit-learn GUI', 'Face Recognition Adabbreviation in Python', 'Face Recognition Adabbreviation for Python']\n",
      "How far are we from solving the 2D & 3D Face Alignment problem? (and a dataset of 230,000 3D facial landmarks)\n",
      "['### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-F', '### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ### Code for training 2D-FAN and 3D-', '### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 3D-FAN and 3D-F', '### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 4D-FAN and 3D-F', '### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ### Code for training 2D-FAN and 3D-FAN in a binary-face-alignment program. ## Code for training 2D-FAN and 3D-']\n",
      "Human pose estimation via Convolutional Part Heatmap Regression\n",
      "['### Torch packages - [ nn ] ( https : //github.com/torch/nn/blob/master/src/main/src/main/src/main/packages/ ) - [ xlua ] ( https : //github.com/torch/xlua ) - [', '### Torch packages - [ nn ] ( https : //github.com/torch/nn/blob/master/src/main/src/main/resources/src/main/packages/ ) - [ xlua ] ( https : //github.com/torch/xlua )', '### Torch packages - [ nn ] ( https : //github.com/torch/nn/blob/master/src/main/src/main/src/main/src/main/ ) - [ xlua ] ( https : //github.com/torch/xlua )', '### Torch packages - [ nn ] ( https : //github.com/torch/nn/blob/master/src/main/src/main/src/main/packages/ ) - [ XL ua ] ( https : //github.com/torch/xlua ) - [', '### Torch packages - [ nn ] ( https : //github.com/torch/nn-python/blob/master/src/main/src/main/resources/src/main/packages/ ) - [ xlua ] ( https : //github.com/torch/xl']\n",
      "Attention-Based Models for Text-Dependent Speaker Verification\n",
      "['How to use VGGish with Deep Learning?', 'How to use VGGish with Deep Learning', 'How to use VGGish with Deep Learning with VGGish?', 'Speech recognition with Deep Learning', 'How to get pretrained weights for speech recognition using VGGish?']\n",
      "An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection\n",
      "['ImageNet Classification with VOVNet ( https : //arxiv.org/abs/1904.09730 ).', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/ )', 'ImageNet Classification with VOVNet ( https : //en.wikipedia.org/wiki/VovNet_classification ).', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/vovnetnet/ )', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/vovnetnet )']\n",
      "An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection\n",
      "['ImageNet Classification with VOVNet ( https : //arxiv.org/abs/1904.09730 ).', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/ )', 'ImageNet Classification with VOVNet ( https : //en.wikipedia.org/wiki/VovNet_classification ).', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/vovnetnet/ )', 'ImageNet Classification with VOVNet ( https : //arxiv.org/arxiv/blob/master/src/vovnetnet/vovnetnet )']\n",
      "Tensor2Tensor for Neural Machine Translation\n",
      "['Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2', 'Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # TensorFlow # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor', 'Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # TensorFlow', 'Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # TensorFlow # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor', 'Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # TensorFlow # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor # Tensor2Tensor']\n",
      "Deep Reinforcement Learning with Double Q-learning\n",
      "['# Navigation using DQN The project uses DQN with prioritized experience replay. # Navigation using DQN The project uses DQN with prioritized experience replay. # Navigation using DQN The project uses DQN with prioritized experience replay. # Navigation using DQN', '# Navigation using DQN The project uses DQN with prioritized cummulative reward. # Navigation using DQN The project uses DQN with prioritized cummulative reward. # Navigation using DQN The project uses DQN with prioritized cummul', '# Navigation using DQN The project uses DQN with prioritized experience replay. # Navigation using DQN The project uses DQN with prioritized experience replay to train an agent. # Navigation using DQN The project uses DQN with prioritized experience replay to train an', '# Navigation using DQN The project uses DQN with prioritized experience replay. # Navigation using DQN The project uses DQN with prioritized experience replay for training the agent. # Navigation using DQN The project uses DQN with prioritized experience replay for training the', '# Navigation using DQN The project uses DQN with prioritized cummulative reward. # Navigation using DQN The project uses DQN with prioritized cummulative reward. # Navigation using DQN The project uses DQN with prioritized DQN']\n",
      "Deep Parallel MRI Reconstruction Network Without Coil Sensitivities\n",
      "['Implementing the Deep Parallel Reconstruction Network with Coil Sensitivities', 'Implementing the Deep Parallel Parallel Reconstruction Network with Coil Sensitivities', 'Implementing the Deep Parallel Reconstruction Network with Coil Sensitivity Masking', 'Implementing the Deep Parallel MR Reconstruction Network with Coil Sensitivities', 'Implementing the Deep Parallel MRI Reconstruction Network with Coil Sensitivities']\n"
     ]
    }
   ],
   "source": [
    "for title, summary in zip(title_sample, readme_summaries):\n",
    "    print(title)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b0f3557e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[\"How to print error message in python using failure: '.format(FAIL, message, ENDC)?\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)?\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC)\",\n",
       "  \"How to print error message in python using failure: '.format(FAIL, message, ENDC) in python?\"],\n",
       " ['How to print success message in python?',\n",
       "  'How to format success message in python?',\n",
       "  'How to print success message in python using python?',\n",
       "  'How to print success message in python',\n",
       "  'How to print a success message in python?'],\n",
       " ['Getting the best score from a python python python python python python python python python python python',\n",
       "  'Getting the best score from a python python python python python python python python python python script',\n",
       "  'Getting the best score from a python python python python python python python python python python file',\n",
       "  'Getting the best score from a python python python python python python python python python python',\n",
       "  'Getting the best score from a python python python python python python python python python script'],\n",
       " ['What is wrong with my python code? (Seq2seq.sh)',\n",
       "  'What is wrong with my python code? (Seq2Seq.sh)',\n",
       "  'What is wrong with my python code? (Seq2Seq)',\n",
       "  'Is there a better way to write this python code?',\n",
       "  'What is wrong with my python code?'],\n",
       " ['Importing and running isolated TF graph',\n",
       "  'Importing and running isolated TF graph in python',\n",
       "  'Importing and running isolated TF graph in Tensorflow',\n",
       "  'Importing and running isolated TF graph using Tensorflow',\n",
       "  'Importing and running isolated TF graph in TensorFlow'],\n",
       " ['tf.train.Saver(variables.get_shape()) not working in python',\n",
       "  'tf.train.Saver(variables.get_shape()) is not working in python',\n",
       "  \"tf.train.Saver(variables.get_shape()) doesn't work in python\",\n",
       "  'tf.train.Saver(variables.get_shape()) in python',\n",
       "  'tf.train.Saver(variables.get_shape()) does not work in python'],\n",
       " ['tf.get_variable_scope() and tf.auto_reuse(fun)',\n",
       "  'tf.get_variable_scope() and tf.get_variable_scope()',\n",
       "  'tf.get_variable_scope() and tf.auto_reuse()',\n",
       "  'tf.get_variable_scope() and tf.auto_reuse',\n",
       "  'tf.get_variable_scope() and tf.get_variable_scope() in python'],\n",
       " ['How to wrap RNNCell with RNNCell in python?',\n",
       "  'How to wrap RNNCell with tf.split in python?',\n",
       "  'How to wrap RNNCell in python?',\n",
       "  'How to wrap RNNCell around RNNCell in python?',\n",
       "  'How to wrap RNNCell with tf.split() in python?'],\n",
       " ['What is wrong with my multi-encoder python code?',\n",
       "  'What is wrong with my multi-encoder code?',\n",
       "  'What is wrong with my multi-encoder model?',\n",
       "  'What is wrong with my multi-encoder keras code?',\n",
       "  'What is wrong with my multi-encoder implementation?'],\n",
       " ['tf.nn.dropout not working in python',\n",
       "  'tf.nn.dropout is not working in python',\n",
       "  'tf.nn.dropout() not working in python',\n",
       "  'tf.nn.dropout() is not working in python',\n",
       "  'tf.nn.dropout() does not work in python'],\n",
       " ['tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs])',\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) not working',\n",
       "  \"tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) doesn't work\",\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) does not work',\n",
       "  'tf.sequence_mask([state, hidden_states, encoder_input_length, **kwargs]) is not working'],\n",
       " ['tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) returns (weighted_average, weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weights)',\n",
       "  'tf.stack([batch_size, 0; hidden_states, *args, **kwargs, **kwargs]) return (weighted_average, weighted_average, weights)'],\n",
       " ['Why does tf.reduce_sum((hidden_states * args, **kwargs) return 0?',\n",
       "  'Why does tf.sequence_mask(encoder_input_length, *args, **kwargs) return 0?',\n",
       "  'Why does tf.sequence_mask(encoder_input_length, *args, **kwargs) not work?',\n",
       "  'Why does tf.reduce_sum((hidden_states * args, **kwargs)) return 0?',\n",
       "  'tf.sequence_mask(encoder_input_length, *args, **kwargs) not working'],\n",
       " ['tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((hidden_states), tf.expand_dims',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), tf.reduce_',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((hidden_states * args, **kwargs))',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), tf.reduce',\n",
       "  'tf.one_hot((encoder_input_length - 1), *args, **kwargs), tf.reduce_sum((encoder_input_length - 1), kwargs)'],\n",
       " [\"tf.translate/models.py doesn't work for kwargs in python\",\n",
       "  \"tf.translate/models.py doesn't work in python\",\n",
       "  \"tf.translate/models.py doesn't work for kwargs\",\n",
       "  \"tf.translate/models.py doesn't work with kwargs\",\n",
       "  \"tf.translate/models.py doesn't seem to work in python\"],\n",
       " ['tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors)',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1))',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axi',\n",
       "  'tf.concat(context_vectors, axis=(-1)) and tf.concat(context_vectors, axis=(-1)) in python'],\n",
       " ['What is wrong with my multi-attention model in python?',\n",
       "  'What is wrong with my multi-attention python code?',\n",
       "  'What is wrong with my multi-attention model?',\n",
       "  'What is wrong with my multi-attention keras code?',\n",
       "  'What is wrong with my multi-attention model in Keras?'],\n",
       " ['Keras attention decoder not working',\n",
       "  'Keras attention decoder',\n",
       "  'Keras attention decoder is not working',\n",
       "  'Keras attention decoder is not working as expected',\n",
       "  'keras attention decoder not working'],\n",
       " ['Keras attention_execution_decoder',\n",
       "  'keras attention_execution_decoder',\n",
       "  'keras attention_execution_decoder python',\n",
       "  'Keras attention_execution_decoder not working',\n",
       "  'keras attention_execution_decoder not working'],\n",
       " ['What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1)?',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1, axis=1)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1, axis=2)',\n",
       "  'What is wrong with my tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1) and tf.reduce_sum(mask, axis=1 and axis='],\n",
       " ['How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1, **kwargs)',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1))?',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1)) in pyth',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1) in python',\n",
       "  'How to use tf.to_int32(tf.reduce_sum(weights, axis=1)) with tf.to_int32(tf.reduce_sum(weights, axis=1)'],\n",
       " ['What is wrong with my chained encoder decoder?',\n",
       "  'What is wrong with my chained encoder decoder in python?',\n",
       "  'What is wrong with my chained encoder decoder python code?',\n",
       "  'What is wrong with my chained encoder decoder model?',\n",
       "  'What is wrong with my chained encoder decoder in Keras?'],\n",
       " ['What is wrong with my chained encoder decoder?',\n",
       "  'What is wrong with my kwargs model?',\n",
       "  'What is wrong with my chained encoder decoder code?',\n",
       "  'What is wrong with my chained encoder model?',\n",
       "  'What is wrong with my kwargs encoder?'],\n",
       " ['tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True)',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, axis=dim, keep_dim=True)',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True) not working',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True, keep_dim=True) is not working',\n",
       "  'tf.reduce_sum(e, axis=dim, keep_dim=True)'],\n",
       " ['tf.nn.sparse_softmax_cross_entropy_with_logits',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits not working',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits does not work',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits is not working',\n",
       "  'tf.nn.sparse_softmax_cross_entropy_with_logits returns 0'],\n",
       " ['tf.stop_gradient(decoder_states, reward_baseline) not working',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline)',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline) not working in python',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline) returns 0',\n",
       "  'tf.stop_gradient(decoder_states, reward_baseline, axis=2)'],\n",
       " ['tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True)',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=False, average_across_batch=True)',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) not working',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) returns 0',\n",
       "  'tf.shape(rewards, weights, average_across_timesteps=True, average_across_batch=True) error'],\n",
       " ['Convolutional LSTM cell with tf.nn.tanh',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh in python',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh in python',\n",
       "  'Convolutional LSTM cell with tf.nn.tanh.tanh.tanh'],\n",
       " ['Convolution of 4D tensors to a list of 4D tensors',\n",
       "  'Convolution of 4D tensors to a list of 4D tensors in python',\n",
       "  'Convolution of 4D tensors to a list of 4D tensors in Python',\n",
       "  'Convolutional neural network in python',\n",
       "  'Convolution of 4D tensors with a list of 4D tensors'],\n",
       " ['How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id, include_first_eos=True) and tf.shape(sequence,',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id)?',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id, eos_id) and tf.shape(sequence, eos',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id) in py',\n",
       "  'How to get tf.stop_gradient(weights) from tf.shape(sequence, eos_id) and tf.shape(sequence, eos_id)'],\n",
       " ['tf.stack([(batch_size * beam_size) + shape(src, dst)[0])',\n",
       "  'tf.stack([(batch_size * beam_size)) + shape(src, dst)[0]',\n",
       "  'tf.stack([(batch_size * beam_size) + shape(src, dst)[0]) not working',\n",
       "  'tf.stack([(batch_size * beam_size) + shape(dst)[0])',\n",
       "  'tf.stack([(batch_size * beam_size)) + shape(src, dst)]'],\n",
       " ['tf.unstack(tf.shape(tensor)) not working in python',\n",
       "  'How to use tf.unstack(tf.shape(tensor)) in python?',\n",
       "  'How to use tf.unstack(tf.shape(tensor)) in beam search?',\n",
       "  'tf.unstack(tf.shape(tensor)) not working',\n",
       "  'tf.unstack(tf.shape(tensor, dynamic_shape))'],\n",
       " ['tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indice',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i]]',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i])',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i]',\n",
       "  'tf.gather(tensor[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i], indices[i, indice'],\n",
       " ['How to solve this beam search problem in python using tf.reduce_max((x / T) - my_max = x - (tf.reduce_sum(((x / T - my_max) + my_',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum(((x / T - my_max)))',\n",
       "  'How to find the softmax of a beam search using tf.reduce_max((x / T) - my_max) and tf.reduce_sum(((x / T) - my_max)?',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum(((x / T - my_max) + my_max',\n",
       "  'How to solve this beam search problem in python using tf.reduce_max((x / T - my_max) + my_max(tf.reduce_sum((x / T - my_max) + my_max'],\n",
       " ['rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[0,1] and tf.shape(initial_',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(initial_states[',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[0,1]) and tf.shape(initial',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(seq_len)',\n",
       "  'rnn_beam_search with tf.shape(initial_states[0,1]) and tf.shape(initial_states[1], tf.shape(initial_states]'],\n",
       " [\"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in python?\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn')?\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in python\",\n",
       "  \"How to use tf.variable_scope((scope or'stack_bidirectional_dynamic_rnn') in rnn.py?\",\n",
       "  \"How to use tf.variable_scope((variable_scope or'stack_bidirectional_dynamic_rnn') in python?\"],\n",
       " ['Applying time pooling in rnn.py',\n",
       "  'Apply time pooling in rnn.py',\n",
       "  'Applying time pooling in rnn',\n",
       "  'Applying time pooling in rnn python',\n",
       "  'How to apply time pooling in rnn.py?'],\n",
       " ['Orthogonal initialization of recurrent connections, like in Bahdanau et al. 2015n',\n",
       "  'Orthogonal initialization of recurrent connections',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al. 2015',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al. (2015)',\n",
       "  'Orthogonal initialization of recurrent connections, like in Bahdanau et al 2015n'],\n",
       " ['tf.nn.rnn.TensorShape(s).as_list() not working in python',\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() is not working in python',\n",
       "  \"tf.nn.rnn.TensorShape(s).as_list() doesn't work in python\",\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() not working',\n",
       "  'tf.nn.rnn.TensorShape(s).as_list() does not work in python'],\n",
       " ['tf.nn.rnn_cell.RNNCell is not working in python',\n",
       "  'tf.nn.rnn_cell.RNNCell not working in python',\n",
       "  'tf.nn.rnn_cell.RNNCell is not working',\n",
       "  'tf.nn.rnn_cell.RNNCell not working',\n",
       "  'tf.nn.rnn_cell.RNNCell error'],\n",
       " ['Implementation of Projection-LSTM and Factorized-LSTM',\n",
       "  'Implementation of Projection-LSTM and Factorized-LSTM in python',\n",
       "  'Implementation of Projection-LSTM and Factorized-LSTM in Python',\n",
       "  'Implementation of Projection LSTM and Factorized LSTM',\n",
       "  'Implementation of Projection LSTM and Factorized LSTM in python'],\n",
       " ['How to use get_state_size() in rnn.py?',\n",
       "  'How to use get_state_size in rnn.py?',\n",
       "  'How to use get_state_size() in rnn.py',\n",
       "  'How to use get_state_size in rnn.py',\n",
       "  'How to use get_state_size() in rnn.py in python?'],\n",
       " ['How to debug a python class in python?',\n",
       "  'How to debug a python class in python using python/utils.py?',\n",
       "  'How do I debug a python class in python?',\n",
       "  'How to debug a python class in python using python?',\n",
       "  'How to debug a python class in a python class?'],\n",
       " ['How to pass a checkpoint exception in python?',\n",
       "  'How to pass a checkpoint exception to a function in python?',\n",
       "  'How do I pass a checkpoint exception in python?',\n",
       "  'How to pass a checkpoint exception in python using python?',\n",
       "  'How to pass a checkpoint exception to a function in python'],\n",
       " ['How to translate a python class to a python class?',\n",
       "  'How to translate a python class to a python class in python?',\n",
       "  'How to translate a python class to a python class using python?',\n",
       "  'EvalException(Exception): pass in python',\n",
       "  'How to translate a python class to python using python?'],\n",
       " ['Safely open a list of files in a context manager',\n",
       "  'Open a list of files in a context manager',\n",
       "  'Translate a list of files in a context manager',\n",
       "  'Safely open a list of files in a context manager in python',\n",
       "  'Open a list of files in a context manager using python'],\n",
       " ['Dictionary whose keys can be accessed as attributes',\n",
       "  'Translating a dictionary whose keys can be accessed as attributes',\n",
       "  'Dictionary whose keys can be accessed as attributes.n',\n",
       "  'Translating a dictionary into a dictionary whose keys can be accessed as attributes',\n",
       "  'Translating a dictionary whose keys can be accessed as attributes.n'],\n",
       " ['Reverse edits in python',\n",
       "  'Reverse edits in python using translate/utils.py',\n",
       "  'Reverse edits in python using python/translate/utils.py',\n",
       "  'Reverse edits in Python',\n",
       "  'Reverse-edits in Python'],\n",
       " ['Translating one-item-per-line vocabulary',\n",
       "  'Translating one-item-per-line vocabulary in Python',\n",
       "  'Translating one-item-per-line vocabulary in python',\n",
       "  'Translating one-item-per-line dictionary',\n",
       "  'Translating one-item-per-line dictionary in Python'],\n",
       " ['Convert a string to a list of integers representing token-ids',\n",
       "  'Convert a string to list of integers representing token-ids',\n",
       "  'Converting a string to a list of integers representing token-ids',\n",
       "  'Convert a string to a list of integers representing token-ids.nn',\n",
       "  'Converting a string to list of integers representing token-ids'],\n",
       " ['How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, dev_prefix, eval=None, **kwargs)',\n",
       "  'How to use os.path.join(data_dir, model_dir, extensions, train_prefix, dev_prefix, vocab_prefix, eval=None, eval=None, **kwargs)?'],\n",
       " ['Translate a text file into a python file using python/utils/python/translate/utils.py',\n",
       "  'Translate a text file into a python file using python and python/translate/utils.py',\n",
       "  'Translate a text file into a python file using python and python',\n",
       "  'Translating a sentence to a text file using python and translate/utils.py',\n",
       "  'Translate a text file into a text file using python and translate/utils.py'],\n",
       " ['How to make a random batch iterator in python?',\n",
       "  'How to write a random batch iterator in python?',\n",
       "  'How to make a random batch iterator in python',\n",
       "  'How to write a random batch iterator in python',\n",
       "  'How to make a random batch iterator with python?'],\n",
       " ['Is there a better way to write this batch iterator in python?',\n",
       "  'Is this batch iterator python or python?',\n",
       "  'Batch iterator in python',\n",
       "  'Is this batch iterator python or python or python or python?',\n",
       "  'Basic batch iterator in python'],\n",
       " ['Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)nn',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)n',\n",
       "  'Cycle through a dataset and yield batches (the dataset is shuffled at each new epoch)',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffled)n at each new epoch',\n",
       "  'Cycle through a dataset and yield batches (indefinitely cycle through a dataset and yield batches (the dataset is shuffledn at each new epoch)n'],\n",
       " ['read_ahead_batch_iterator in python',\n",
       "  'read_ahead_batch_iterator',\n",
       "  'python read_ahead_batch_iterator',\n",
       "  'read_ahead_batch_iterator in Python',\n",
       "  'read_ahead_batch_iterator for python'],\n",
       " ['What is wrong with my python batch iterator?',\n",
       "  'What is wrong with this python batch iterator?',\n",
       "  'What is wrong with my batch iterator?',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with this batch iterator?'],\n",
       " ['Segmenting a dataset into fixed-size batches',\n",
       "  'Segmenting data into fixed-size batches',\n",
       "  'Segmenting a dataset into fixed-size fixed-size batches',\n",
       "  'Segment data into fixed-size batches',\n",
       "  'Segment a dataset into fixed-size batches'],\n",
       " ['Reading a binary file containing vector features (MFCCs) and extracting audio features (MFCCs)',\n",
       "  'Reading a binary file containing vector features and extracting audio (MFCCs)',\n",
       "  'Reading a binary file containing vector features (MFCCs) and creating a file for audio (MFCCs)',\n",
       "  'Extracting audio features from a binary file',\n",
       "  'Reading a binary file containing vector features (MFCCs) and extracting audio (MFCCs)'],\n",
       " ['python - read_binary_features(path, binary=None) and open(path, binary_) in zip(path, binary_) and open(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(path, binary=None) and open(path, binary_features(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(paths, binary=None) and open(path, binary_features(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(path, binary=None) and open(path, binary_) in zip(path, binary_)',\n",
       "  'python - read_binary_features(paths, binary=None) and open(path, binary_) in zip(path, binary_) and open(path, binary_) in zip(path, binary_)'],\n",
       " ['How to read text from a file in python?',\n",
       "  'How to read text from a file in python using translate/utils.py?',\n",
       "  'How to read text from a file in python using python?',\n",
       "  'How to read text from a file using python?',\n",
       "  'How to read text from a file in python using translate/utils.py'],\n",
       " ['python - python - python - python - python - python - python - python - python -',\n",
       "  'What is wrong with my python python python python python python python python python python python py',\n",
       "  'python - python - python - python - python - python - python - python - python',\n",
       "  'python - python - python - python - python - python - python - python - python :',\n",
       "  'What is wrong with my python python python python python python python python python python python?'],\n",
       " ['Logging to a file, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to a file, or to standard output',\n",
       "  'Logging to a file, or to standard output, or to a standard output',\n",
       "  'Logging to a file, or to standard output, if the file is not None'],\n",
       " ['How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level, msg)?',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level, msg)',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level=logging.INFO)?',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__).log(level=logging.INFO)',\n",
       "  'How to translate python logging.getLogger(__name__).log(level=logging.INFO) to python logging.getLogger(__name__.log(level, msg)?'],\n",
       " ['How to debug a python script in python?',\n",
       "  'How to debug a python script with python?',\n",
       "  'How to debug a python script?',\n",
       "  'How to debug a python script using python?',\n",
       "  'How do I debug a python script in python?'],\n",
       " ['How to write a python script to warn a user of a warning message in python?',\n",
       "  'How to write a python script to log a warning message in python?',\n",
       "  'How to write a python script to warn a user about a warning message in python?',\n",
       "  'How to write a python script to warn a user of a warning message?',\n",
       "  'How to write a python script to warn a user of a warning message in a python script?'],\n",
       " ['Heatmap showing the alignment between two sequences',\n",
       "  'How to draw a heatmap showing the alignment between two sequences?',\n",
       "  'How to draw a heatmap showing the alignment between two sequences in python?',\n",
       "  'How to draw a heatmap showing the alignment between two sequences',\n",
       "  'How to draw a heatmap showing the alignment between two sequences in python'],\n",
       " ['Translate text to svg using python',\n",
       "  'Translating text to svg using python',\n",
       "  'Alignment to text in python',\n",
       "  'Translate text to svg in python',\n",
       "  'Translate text to svg using python and python'],\n",
       " ['Levenshtein implementation in python',\n",
       "  'Levenshtein implementation in Python',\n",
       "  'Levenshtein in python',\n",
       "  'Levenshtein python implementation',\n",
       "  'Levenshtein implementation'],\n",
       " ['Sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'Calculate sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'Calculating sentence-level BLEU score between a translation hypothesis and a reference',\n",
       "  'BLEU score between a translation hypothesis and a reference',\n",
       "  'Sentence level BLEU score between a translation hypothesis and a reference'],\n",
       " ['Reversed score function decorator in python',\n",
       "  'How can I get the score of a python function in python?',\n",
       "  'How do I get the score of a function in python?',\n",
       "  'How can I get the score of a function in python?',\n",
       "  'Reversed score decorator in python'],\n",
       " [\"python - divide x, y with np.errstate(divide='ignore', invalid='ignore') and z[( np.isfinite(z)) = 0\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore') and z[( np.isfinite(z\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore', return z[( np.isfinite(z\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore', z[( np.isfinite(z)\",\n",
       "  \"python - divide x, y with np.errstate(divide='ignore', invalid='ignore', invalid='ignore') and return z[( np.isfinite(\"],\n",
       " ['Compute BLEU score at the corpus-level between a list of translation hypotheses and references, smoothing=False, order=4, **kwargs',\n",
       "  'Compute BLEU score at the corpus-level between a list of translation hypotheses and references',\n",
       "  'Compute BLEU score at the corpus-level between a list of hypotheses and references, smoothing=False, order=4, **kwargs',\n",
       "  'Compute BLEU score at the corpus-level between a list of hypotheses and references',\n",
       "  'Compute BLEU score at the corpus-level between a list of translation hypotheses and references, with smoothing=False, order=4, **kwargs'],\n",
       " ['How to write a python code for a python code for a python code for a python code for a python code for a python code for a pyth',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code?',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code for python code',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code in a pyth',\n",
       "  'How to write a python code for a python code for a python code for a python code for a python code for a python code in python?'],\n",
       " ['What is wrong with my python code?',\n",
       "  'What is wrong with this python code? (Levenshtein)',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with my python code? (Levenshtein)',\n",
       "  'What is wrong with this python code? (Levenshtein, kwargs)'],\n",
       " ['How to translate a python code to a python code?',\n",
       "  'How to translate a python code into a python code?',\n",
       "  'How to translate a python script to a python script?',\n",
       "  'How to translate a python code in python?',\n",
       "  'How to translate a python script to python?'],\n",
       " ['python - python - python - python - python - python - python - python - python -',\n",
       "  'python - python - python - python - python - python - python - score_function_decorator(reversed',\n",
       "  'python - python - python - python - python - python - python - python - python',\n",
       "  'python - python - python - python - python - python - python - python - python :',\n",
       "  'python - python - python - python - python - python - python - python - score_function_'],\n",
       " ['Translate/evaluation.py',\n",
       "  'Translate/evaluation.py for python',\n",
       "  'Translate/evaluation python python python',\n",
       "  'Translate/evaluation.py with ordereddict',\n",
       "  'Translate/evaluation python python'],\n",
       " ['python corpus_scores_ter(*args, **kwargs)',\n",
       "  'python corpus_scores_ter(*arg, **kwargs)',\n",
       "  'python corpus_scores_ter(*args, **kwargs) not working in python',\n",
       "  'python corpus_scores_ter(*args, **kwargs) - python',\n",
       "  'python corpus_scores_ter(*args, **kwargs) not working'],\n",
       " ['python corpus_scores_wer(*args, **kwargs) - python - python - python - python - python - p',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python python - python - python - python - pyth',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python - python - python - python - translate/evaluation.py',\n",
       "  'python corpus_scores_wer(*args, **kwargs)',\n",
       "  'python corpus_scores_wer(*args, **kwargs) - python - python - python - python - python'],\n",
       " ['Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:]!= trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src, trg[1:], trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:], trg[1:], trg[1',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:], trg[1:])',\n",
       "  'Translate/evaluation.py - Levenshtein_rec(src, trg) - Levenshtein_rec(src[1:]!= trg[1:]) -'],\n",
       " ['How to use tercom_statistics in python?',\n",
       "  'Error while running tercom-statistics in python',\n",
       "  'How to use tercom_statistics in python',\n",
       "  'How to use tercom_statistics.py in python?',\n",
       "  'How to use tercom_statistics in a python script?'],\n",
       " ['Multitask model in python',\n",
       "  'Multitask model implementation in python',\n",
       "  'Multitask model with kwargs and python',\n",
       "  'Multitask model in python with kwargs',\n",
       "  'Multitask model in python using kwargs'],\n",
       " ['What is wrong with my seq2seq model?',\n",
       "  'What is wrong with my seq2seq model in python?',\n",
       "  'Error in seq2seq_model.py',\n",
       "  'What is wrong with my seq2seq_model.py?',\n",
       "  'What is wrong with my seq2seq model python code?'],\n",
       " ['What is wrong with my python translation model?',\n",
       "  'What is wrong with my translation model in python?',\n",
       "  'What is wrong with my translation model?',\n",
       "  'What is wrong with this translation model in python?',\n",
       "  'What is wrong with my kwargs translation model?'],\n",
       " [\"tf.train.get_checkpoint_state(checkpoint_dir) doesn't work\",\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) not working',\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) is not working',\n",
       "  'tf.train.get_checkpoint_state(checkpoint_dir) does not work',\n",
       "  \"tf.train.get_checkpoint_state(checkpoint_dir) doesn't work in python\"],\n",
       " ['tf.global_variables.write_meta_graph is not working in python',\n",
       "  'tf.global_variables.write_meta_graph is not working',\n",
       "  'tf.global_variables.write_meta_graph=False',\n",
       "  'tf.global_variables.write_meta_graph=False in python',\n",
       "  \"tf.global_variables.write_meta_graph doesn't work in python\"],\n",
       " ['What is wrong with my python code?',\n",
       "  'What is wrong with this python code?',\n",
       "  'What is wrong with my python script?',\n",
       "  'What is wrong with my python code? Is it a python code?',\n",
       "  'What is wrong with my python code? Is there a better way to do this?'],\n",
       " ['tf.Summary.HistogramProto() not working in tensorflow',\n",
       "  'tf.Summary.HistogramProto() is not working in tensorflow',\n",
       "  \"tf.Summary.HistogramProto() doesn't work in tensorflow\",\n",
       "  'tf.Summary.HistogramProto() does not work in tensorflow',\n",
       "  'tf.Summary.HistogramProto() not working'],\n",
       " ['How to extract a word from a list of words in python using python scripts/vocab-stats.py?',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocab-stats.py',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocabulary-stats.py?',\n",
       "  'How to extract a word from a list of words in python using python scripts/vocabulary-stats.py',\n",
       "  'How to extract a word from a list of words in python scripts/vocab-stats.py?'],\n",
       " ['Python script to get the best score for each step of a python python python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python python script',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python',\n",
       "  'Python script to get the best score for each step of a python python python python python python python python script'],\n",
       " ['Concat bpe pairs in python',\n",
       "  'Concatenate bpe_pairs in python',\n",
       "  'Concatenate bpe pairs in python',\n",
       "  'Concatenate bpe_pairs in Python',\n",
       "  'Concatenate bpe_pairs'],\n",
       " ['Encode word based on list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode a word based on list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode word based on list of BPE merge operations, which are applied consecutively',\n",
       "  'Encode a word based on a list of BPE merge operations, which are applied consecutivelyn',\n",
       "  'Encode a word based on list of BPE merge operations, which are applied consecutively'],\n",
       " ['How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python?',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python',\n",
       "  'How to use argparse.ArgumentParser with argparse.RawDescriptionHelpFormatter?'],\n",
       " ['How to get pairs of symbols in a word in python?',\n",
       "  'How to get all pairs of symbols in a word in python?',\n",
       "  'How to get a list of symbol pairs in a word in python?',\n",
       "  'How to get pairs of symbols in a word in python',\n",
       "  'How to get all pairs of symbols in a word in python'],\n",
       " ['How to boldify text in python?',\n",
       "  'How to boldify text in plot loss?',\n",
       "  'How to boldify text in python script?',\n",
       "  'How to boldify text in python',\n",
       "  'How to boldify text in a plot?'],\n",
       " ['Counting the number of unique items in a dict',\n",
       "  'Counting the number of unique items in a list',\n",
       "  'Counting the number of unique items in a list of dicts',\n",
       "  'Counting the number of items in an ordered dict',\n",
       "  'Counting the number of unique and average values in a dict'],\n",
       " ['What is wrong with my python scripts/stats.py?',\n",
       "  'What is wrong with my python stats.py code?',\n",
       "  'What is wrong with my python stats python script?',\n",
       "  'What is wrong with my python stats.py script?',\n",
       "  'What is wrong with my python stats.py?'],\n",
       " ['How to open a file in python using python codecs in python?',\n",
       "  'How to open a file in python using python and python?',\n",
       "  'How to open a file in python using python context manager?',\n",
       "  'How to open a file in python using python python context manager?',\n",
       "  'How to open a file in python using python and python'],\n",
       " ['How to open temporary files in python?',\n",
       "  'How to delete temporary files in python?',\n",
       "  'How to open temporary files in python using python context manager?',\n",
       "  'How to delete a temporary file in python?',\n",
       "  'How to delete a temporary file in python using python?'],\n",
       " ['How to enumerate words from a vocabulary file in python?',\n",
       "  'How to enumerate words from a vocabulary file using python?',\n",
       "  'How to enumerate words in a vocabulary file using python?',\n",
       "  'How to enumerate words in a vocabulary file in python?',\n",
       "  'How to enumerate words from a vocabulary file in python'],\n",
       " ['How to create a vocabulary from a text file in python?',\n",
       "  'Creating a vocabulary from a text file in python',\n",
       "  'Creating a vocabulary from a text file using python',\n",
       "  'How to create a vocabulary from a text file using python?',\n",
       "  'How to create a vocabulary from a text file in python'],\n",
       " ['Preparing data from a file using python',\n",
       "  'Preparing data from a file in python',\n",
       "  'Preparing data in python using python and python',\n",
       "  'Preparing data in python',\n",
       "  'Preparing data in python using python'],\n",
       " ['Filtering a corpus in python',\n",
       "  'Filtering data from a corpus in python',\n",
       "  'Filtering corpus in python',\n",
       "  'Filtering data from a corpus using python',\n",
       "  'Filtering data from a corpus in python using python'],\n",
       " ['Extracting data from a corpus using python',\n",
       "  'Extracting data from a corpus in python',\n",
       "  'Extracting data from a corpus',\n",
       "  'Preparing data from a corpus in python',\n",
       "  'Extracting data from a corpus in python using python'],\n",
       " ['Splitting a corpus into multiple files in python',\n",
       "  'Splitting a corpus into multiple files using python',\n",
       "  'Splitting a corpus into multiple files in python using python',\n",
       "  'How to split a corpus into multiple files in python?',\n",
       "  'Splitting a corpus into multiple files using python and python'],\n",
       " ['How to create subwords in python using bpe.py?',\n",
       "  'How to create subwords in python using python?',\n",
       "  'How to create subwords in python using python scripts?',\n",
       "  'How to create subwords using bpe.py in python?',\n",
       "  'How to create subwords in python using python script?'],\n",
       " ['How to apply subwords to a file using python?',\n",
       "  'How to apply subwords to a file in python?',\n",
       "  'How to apply subwords to a file in python using python?',\n",
       "  'How to apply subwords to a file using python',\n",
       "  'How to apply subwords to a file in python'],\n",
       " ['What is wrong with my python python python python python python python python python python python py',\n",
       "  'What is wrong with my python python python python python python python python python python python?',\n",
       "  'What is wrong with my python python python python python python python python python python python',\n",
       "  'What is wrong with my python python python python python python python python python python python script?',\n",
       "  'What is wrong with my python python python python python python python python python python script?'],\n",
       " ['python python python python python python python python python python python python py',\n",
       "  'python python python python python python python python python python python python',\n",
       "  'python python python python python python python python python python python',\n",
       "  'python python python python python python python python python python',\n",
       "  'python python python python python python python python python python python python rp'],\n",
       " ['How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter and argparse.RawDescriptionHelpFormatter in python',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter?',\n",
       "  'How to use argparse.ArgumentParser.RawDescriptionHelpFormatter with argparse.RawDescriptionHelpFormatter'],\n",
       " ['python scripts/learn_bpe.py get_vocabulary(fobj) return dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) returns dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj)',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) returns a dictionary that encodes vocabularyn',\n",
       "  'python scripts/learn_bpe.py get_vocabulary(fobj) not working'],\n",
       " ['Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated.',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only those pairs that overlap with occurrencesn of this pair are affected, and need to be updated',\n",
       "  'Update the indices and frequency of symbol pairsnn if we merge a pair of symbols, only pairs that overlap with occurrencesn of this pair are affected, and need to be updated. python'],\n",
       " ['Count frequency of all symbol pairs, and create index',\n",
       "  'Count frequency of all symbol pairs, and create index in python',\n",
       "  'Count Frequency of all symbol pairs, and create index',\n",
       "  'Count frequency of all symbol pairs and create index',\n",
       "  'Count frequency of all symbol pairs, and create index in Python'],\n",
       " [\"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Replacing all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Python - Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB'\",\n",
       "  \"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol\",\n",
       "  \"Replace all occurrences of a symbol pair ('A', 'B') with a new symbol 'AB' in Python\"],\n",
       " ['Is there a better way to prune bpe statistics in python?',\n",
       "  'Is there a better way to prune bpe stats in python?',\n",
       "  'Is there a better way to prune statistics in python?',\n",
       "  'Is there a better way to prune stats in python?',\n",
       "  'Is there a better way to prune stats in python than python?'],\n",
       " ['How to extract audio features from a text file in python?',\n",
       "  'How to extract audio features from a.rb file in python?',\n",
       "  'How to extract audio features from a video file in python?',\n",
       "  'How to extract audio features from a text file using python?',\n",
       "  'How to extract audio features from a text file in python'],\n",
       " ['Is this a good way to check if a line is well-formed?',\n",
       "  'Checking if a line is well-formed',\n",
       "  'Is this a good way to check if a line is well formed?',\n",
       "  'Check if a line is well-formed',\n",
       "  'Checking if a line is well formed'],\n",
       " ['Reverse edits in python',\n",
       "  'Applying edits to a post',\n",
       "  'Reverse edits in post-editing',\n",
       "  'Reverse edits in python script',\n",
       "  'Reverse edits for a post'],\n",
       " ['Extracting post edits with levenshtein_legacy',\n",
       "  'Extracting post edits with levenshtein_legacy in python',\n",
       "  'Extracting post edits with levenshtein_legacy in python using lru_cache',\n",
       "  'Extracting post edits in python using functools.lru_cache(maxsize=1024)',\n",
       "  'Extracting post edits in python using functools.lru_cache (maxsize=1024)'],\n",
       " ['Levenshtein in python',\n",
       "  'Levenshtein in Python',\n",
       "  'Levenshtein python implementation',\n",
       "  'Levenshtein python code',\n",
       "  'Levenshtein python script']]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(repo_functions['generated_queries'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f040e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a264cf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>function_code</th>\n",
       "      <th>generated_queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>failure</td>\n",
       "      <td>def failure(message):\\n    print('{}failure: {...</td>\n",
       "      <td>How to print a failure message in run-tests.py</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>success</td>\n",
       "      <td>def success(message):\\n    print('{}success: {...</td>\n",
       "      <td>Run-tests.py with a success message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>get_best_score</td>\n",
       "      <td>def get_best_score(log_file):\\n    scores = []...</td>\n",
       "      <td>Get the best score from a log file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>run-tests.py</td>\n",
       "      <td>run</td>\n",
       "      <td>def run(dir_, score=None):\\n    config_file = ...</td>\n",
       "      <td>Run seq2seq and compare scores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>translate/import_graph.py</td>\n",
       "      <td>ImportGraph</td>\n",
       "      <td>class ImportGraph():\\n    '  Importing and run...</td>\n",
       "      <td>Importing and running isolated TF graph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/speech/extract-audio-features.py</td>\n",
       "      <td>read_features</td>\n",
       "      <td>def read_features(filename):\\n    all_feats = ...</td>\n",
       "      <td>Read audio features from a file.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/well-formed.py</td>\n",
       "      <td>is_well_formed</td>\n",
       "      <td>def is_well_formed(line):\\n    if (len(line) &lt;...</td>\n",
       "      <td>Return True if a line is well-formed, False ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/apply-edits.py</td>\n",
       "      <td>reverse_edits</td>\n",
       "      <td>def reverse_edits(source, edits, fix=True, str...</td>\n",
       "      <td>Reverse the order of words in a list of edits.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/extract-edits.py</td>\n",
       "      <td>levenshtein_legacy</td>\n",
       "      <td>@functools.lru_cache(maxsize=1024)\\ndef levens...</td>\n",
       "      <td>Levenshtein algorithm for extracting edits usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>scripts/post_editing/extract-edits.py</td>\n",
       "      <td>levenshtein</td>\n",
       "      <td>def levenshtein(src, trg, sub_cost=1.0, del_co...</td>\n",
       "      <td>Find the Levenshtein distance between two stri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0        repo_name                                      path  \\\n",
       "0             0  trangvu/ape-npi                              run-tests.py   \n",
       "1             1  trangvu/ape-npi                              run-tests.py   \n",
       "2             2  trangvu/ape-npi                              run-tests.py   \n",
       "3             3  trangvu/ape-npi                              run-tests.py   \n",
       "4             4  trangvu/ape-npi                 translate/import_graph.py   \n",
       "..          ...              ...                                       ...   \n",
       "116         116  trangvu/ape-npi  scripts/speech/extract-audio-features.py   \n",
       "117         117  trangvu/ape-npi       scripts/post_editing/well-formed.py   \n",
       "118         118  trangvu/ape-npi       scripts/post_editing/apply-edits.py   \n",
       "119         119  trangvu/ape-npi     scripts/post_editing/extract-edits.py   \n",
       "120         120  trangvu/ape-npi     scripts/post_editing/extract-edits.py   \n",
       "\n",
       "          function_name                                      function_code  \\\n",
       "0               failure  def failure(message):\\n    print('{}failure: {...   \n",
       "1               success  def success(message):\\n    print('{}success: {...   \n",
       "2        get_best_score  def get_best_score(log_file):\\n    scores = []...   \n",
       "3                   run  def run(dir_, score=None):\\n    config_file = ...   \n",
       "4           ImportGraph  class ImportGraph():\\n    '  Importing and run...   \n",
       "..                  ...                                                ...   \n",
       "116       read_features  def read_features(filename):\\n    all_feats = ...   \n",
       "117      is_well_formed  def is_well_formed(line):\\n    if (len(line) <...   \n",
       "118       reverse_edits  def reverse_edits(source, edits, fix=True, str...   \n",
       "119  levenshtein_legacy  @functools.lru_cache(maxsize=1024)\\ndef levens...   \n",
       "120         levenshtein  def levenshtein(src, trg, sub_cost=1.0, del_co...   \n",
       "\n",
       "                                     generated_queries  \n",
       "0       How to print a failure message in run-tests.py  \n",
       "1                  Run-tests.py with a success message  \n",
       "2                  Get the best score from a log file.  \n",
       "3                       Run seq2seq and compare scores  \n",
       "4              Importing and running isolated TF graph  \n",
       "..                                                 ...  \n",
       "116                   Read audio features from a file.  \n",
       "117  Return True if a line is well-formed, False ot...  \n",
       "118     Reverse the order of words in a list of edits.  \n",
       "119  Levenshtein algorithm for extracting edits usi...  \n",
       "120  Find the Levenshtein distance between two stri...  \n",
       "\n",
       "[121 rows x 6 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d354f9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "      <th>repo</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>tasks</th>\n",
       "      <th>least_common_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38648</th>\n",
       "      <td>38648</td>\n",
       "      <td>https://paperswithcode.com/paper/automatic-pos...</td>\n",
       "      <td>Automatic Post-Editing of Machine Translation:...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.aclweb.org/anthology/D18-1341/</td>\n",
       "      <td>https://www.aclweb.org/anthology/D18-1341</td>\n",
       "      <td>https://github.com/trangvu/ape-npi</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "      <td>trangvu/ape-npi</td>\n",
       "      <td>Automatic Post-Editing of Machine Translation:...</td>\n",
       "      <td>Automated Post-Editing (PE) is the task of aut...</td>\n",
       "      <td>[automatic post editing, machine translation]</td>\n",
       "      <td>automatic post editing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          paper_url  \\\n",
       "38648       38648  https://paperswithcode.com/paper/automatic-pos...   \n",
       "\n",
       "                                             paper_title paper_arxiv_id  \\\n",
       "38648  Automatic Post-Editing of Machine Translation:...            NaN   \n",
       "\n",
       "                                    paper_url_abs  \\\n",
       "38648  https://www.aclweb.org/anthology/D18-1341/   \n",
       "\n",
       "                                   paper_url_pdf  \\\n",
       "38648  https://www.aclweb.org/anthology/D18-1341   \n",
       "\n",
       "                                 repo_url  mentioned_in_paper  \\\n",
       "38648  https://github.com/trangvu/ape-npi               False   \n",
       "\n",
       "       mentioned_in_github framework             repo  \\\n",
       "38648                False        tf  trangvu/ape-npi   \n",
       "\n",
       "                                                   title  \\\n",
       "38648  Automatic Post-Editing of Machine Translation:...   \n",
       "\n",
       "                                                abstract  \\\n",
       "38648  Automated Post-Editing (PE) is the task of aut...   \n",
       "\n",
       "                                               tasks       least_common_task  \n",
       "38648  [automatic post editing, machine translation]  automatic post editing  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df[paperswithcode_df['repo'] == \"trangvu/ape-npi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53afe526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated Queries:\n",
      "1: Reading a vocabulary from a file using python\n",
      "2: Reading a vocabulary from a file\n",
      "3: Reading a vocabulary from a file and enumerating the words in it\n",
      "4: Reading a vocabulary from a text file using python\n",
      "5: Reading a vocabulary from a text file in python\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated Queries:\")\n",
    "for i in range(len(outputs)):\n",
    "    print(f'{i + 1}: {query}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6870a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
