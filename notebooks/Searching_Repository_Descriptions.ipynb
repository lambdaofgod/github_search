{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:tensorflow or tensorflow-hub not found, loading tfhub models won't work\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from io import StringIO\n",
    "import sys\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import pypi_cli\n",
    "from sklearn import feature_extraction, metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bs4\n",
    "\n",
    "import mlutil.parallel\n",
    "\n",
    "import elasticsearch\n",
    "import haystack.document_store.memory\n",
    "import haystack.document_store.elasticsearch\n",
    "from haystack import document_store\n",
    "\n",
    "import haystack.retriever.sparse \n",
    "from haystack import retriever\n",
    "\n",
    "\n",
    "from github_search import repository_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wc: ../data/python/train.jsonl: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open '../data/python/train.jsonl' for reading: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!head  -1 ../data/python/train.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_codesearch_df = repository_descriptions.get_all_codesearch_df('data/python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['saltstack/salt', 'mitsei/dlkit', 'google/grr', 'bcbio/bcbio-nextgen',\n",
       "       'materialsproject/pymatgen', 'tensorflow/tensor2tensor',\n",
       "       'iotile/coretools', 'pandas-dev/pandas', 'cloud9ers/gurumate',\n",
       "       'spyder-ide/spyder', 'pypa/pipenv', 'apple/turicreate', 'gem/oq-engine',\n",
       "       'pantsbuild/pants', 'log2timeline/plaso',\n",
       "       'googleapis/google-cloud-python', 'inasafe/inasafe', 'gwastro/pycbc',\n",
       "       'apache/incubator-mxnet', 'senaite/senaite.core'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df['repo'].value_counts().index[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_descriptions_df = repository_descriptions.load_pypi_repo_descriptions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>pypi_description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>Tools for phylogenetic data analysis including visualization and cluster-com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mkouhei/bootstrap-py</td>\n",
       "      <td>Open-source algorithms for data-driven building analysis and control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elbow-jason/Uno-deprecated</td>\n",
       "      <td>Bootstrap Python package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>disqus/nydus</td>\n",
       "      <td>Extremely fast and easy feature based HTML generator.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jay-johnson/network-pipeline</td>\n",
       "      <td>Connection utilities</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    repo  \\\n",
       "Unnamed: 0                                 \n",
       "0                   smdabdoub/phylotoast   \n",
       "1                   mkouhei/bootstrap-py   \n",
       "2             elbow-jason/Uno-deprecated   \n",
       "3                           disqus/nydus   \n",
       "4           jay-johnson/network-pipeline   \n",
       "\n",
       "                                                                           pypi_description  \n",
       "Unnamed: 0                                                                                   \n",
       "0           Tools for phylogenetic data analysis including visualization and cluster-com...  \n",
       "1                      Open-source algorithms for data-driven building analysis and control  \n",
       "2                                                                  Bootstrap Python package  \n",
       "3                                     Extremely fast and easy feature based HTML generator.  \n",
       "4                                                                      Connection utilities  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_descriptions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>func_name</th>\n",
       "      <th>original_string</th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>sha</th>\n",
       "      <th>url</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>split_phylogeny</td>\n",
       "      <td>def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...</td>\n",
       "      <td>python</td>\n",
       "      <td>def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...</td>\n",
       "      <td>[def, split_phylogeny, (, p, ,, level, =, \"s\", ), :, level, =, level, +, \"__...</td>\n",
       "      <td>Return either the full or truncated version of a QIIME-formatted taxonomy st...</td>\n",
       "      <td>[Return, either, the, full, or, truncated, version, of, a, QIIME, -, formatt...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>ensure_dir</td>\n",
       "      <td>def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...</td>\n",
       "      <td>python</td>\n",
       "      <td>def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...</td>\n",
       "      <td>[def, ensure_dir, (, d, ), :, if, not, os, ., path, ., exists, (, d, ), :, t...</td>\n",
       "      <td>Check to make sure the supplied directory path does not exist, if so, create...</td>\n",
       "      <td>[Check, to, make, sure, the, supplied, directory, path, does, not, exist, if...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>file_handle</td>\n",
       "      <td>def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...</td>\n",
       "      <td>python</td>\n",
       "      <td>def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...</td>\n",
       "      <td>[def, file_handle, (, fnh, ,, mode, =, \"rU\", ), :, handle, =, None, if, isin...</td>\n",
       "      <td>Takes either a file path or an open file handle, checks validity and returns...</td>\n",
       "      <td>[Takes, either, a, file, path, or, an, open, file, handle, checks, validity,...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>gather_categories</td>\n",
       "      <td>def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...</td>\n",
       "      <td>python</td>\n",
       "      <td>def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...</td>\n",
       "      <td>[def, gather_categories, (, imap, ,, header, ,, categories, =, None, ), :, #...</td>\n",
       "      <td>Find the user specified categories in the map and create a dictionary to con...</td>\n",
       "      <td>[Find, the, user, specified, categories, in, the, map, and, create, a, dicti...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>parse_unifrac</td>\n",
       "      <td>def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...</td>\n",
       "      <td>python</td>\n",
       "      <td>def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...</td>\n",
       "      <td>[def, parse_unifrac, (, unifracFN, ), :, with, open, (, unifracFN, ,, \"rU\", ...</td>\n",
       "      <td>Parses the unifrac results file into a dictionary\\n\\n    :type unifracFN: st...</td>\n",
       "      <td>[Parses, the, unifrac, results, file, into, a, dictionary]</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   repo                path          func_name  \\\n",
       "0  smdabdoub/phylotoast  phylotoast/util.py    split_phylogeny   \n",
       "1  smdabdoub/phylotoast  phylotoast/util.py         ensure_dir   \n",
       "2  smdabdoub/phylotoast  phylotoast/util.py        file_handle   \n",
       "3  smdabdoub/phylotoast  phylotoast/util.py  gather_categories   \n",
       "4  smdabdoub/phylotoast  phylotoast/util.py      parse_unifrac   \n",
       "\n",
       "                                                                   original_string  \\\n",
       "0  def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...   \n",
       "1  def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...   \n",
       "2  def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...   \n",
       "3  def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...   \n",
       "4  def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...   \n",
       "\n",
       "  language  \\\n",
       "0   python   \n",
       "1   python   \n",
       "2   python   \n",
       "3   python   \n",
       "4   python   \n",
       "\n",
       "                                                                              code  \\\n",
       "0  def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...   \n",
       "1  def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...   \n",
       "2  def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...   \n",
       "3  def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...   \n",
       "4  def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...   \n",
       "\n",
       "                                                                       code_tokens  \\\n",
       "0  [def, split_phylogeny, (, p, ,, level, =, \"s\", ), :, level, =, level, +, \"__...   \n",
       "1  [def, ensure_dir, (, d, ), :, if, not, os, ., path, ., exists, (, d, ), :, t...   \n",
       "2  [def, file_handle, (, fnh, ,, mode, =, \"rU\", ), :, handle, =, None, if, isin...   \n",
       "3  [def, gather_categories, (, imap, ,, header, ,, categories, =, None, ), :, #...   \n",
       "4  [def, parse_unifrac, (, unifracFN, ), :, with, open, (, unifracFN, ,, \"rU\", ...   \n",
       "\n",
       "                                                                         docstring  \\\n",
       "0  Return either the full or truncated version of a QIIME-formatted taxonomy st...   \n",
       "1  Check to make sure the supplied directory path does not exist, if so, create...   \n",
       "2  Takes either a file path or an open file handle, checks validity and returns...   \n",
       "3  Find the user specified categories in the map and create a dictionary to con...   \n",
       "4  Parses the unifrac results file into a dictionary\\n\\n    :type unifracFN: st...   \n",
       "\n",
       "                                                                  docstring_tokens  \\\n",
       "0  [Return, either, the, full, or, truncated, version, of, a, QIIME, -, formatt...   \n",
       "1  [Check, to, make, sure, the, supplied, directory, path, does, not, exist, if...   \n",
       "2  [Takes, either, a, file, path, or, an, open, file, handle, checks, validity,...   \n",
       "3  [Find, the, user, specified, categories, in, the, map, and, create, a, dicti...   \n",
       "4                       [Parses, the, unifrac, results, file, into, a, dictionary]   \n",
       "\n",
       "                                        sha  \\\n",
       "0  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "1  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "2  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "3  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "4  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "\n",
       "                                                                               url  \\\n",
       "0  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "1  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "2  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "3  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "4  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "\n",
       "  partition  \n",
       "0     train  \n",
       "1     train  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline - retrieval by bag of words from descriptions\n",
    "\n",
    "Fit bag of words model to descriptions, then match 'descriptions' obtained from concatenating comments from all functions from repository\n",
    "\n",
    "The assumptions here are very optimistic, since we're only matching features from known repositories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['repo', 'path', 'func_name', 'original_string', 'language', 'code',\n",
       "       'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url',\n",
       "       'partition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>path</th>\n",
       "      <th>func_name</th>\n",
       "      <th>original_string</th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "      <th>code_tokens</th>\n",
       "      <th>docstring</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>sha</th>\n",
       "      <th>url</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>split_phylogeny</td>\n",
       "      <td>def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...</td>\n",
       "      <td>python</td>\n",
       "      <td>def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...</td>\n",
       "      <td>[def, split_phylogeny, (, p, ,, level, =, \"s\", ), :, level, =, level, +, \"__...</td>\n",
       "      <td>Return either the full or truncated version of a QIIME-formatted taxonomy st...</td>\n",
       "      <td>[Return, either, the, full, or, truncated, version, of, a, QIIME, -, formatt...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>ensure_dir</td>\n",
       "      <td>def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...</td>\n",
       "      <td>python</td>\n",
       "      <td>def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...</td>\n",
       "      <td>[def, ensure_dir, (, d, ), :, if, not, os, ., path, ., exists, (, d, ), :, t...</td>\n",
       "      <td>Check to make sure the supplied directory path does not exist, if so, create...</td>\n",
       "      <td>[Check, to, make, sure, the, supplied, directory, path, does, not, exist, if...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>file_handle</td>\n",
       "      <td>def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...</td>\n",
       "      <td>python</td>\n",
       "      <td>def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...</td>\n",
       "      <td>[def, file_handle, (, fnh, ,, mode, =, \"rU\", ), :, handle, =, None, if, isin...</td>\n",
       "      <td>Takes either a file path or an open file handle, checks validity and returns...</td>\n",
       "      <td>[Takes, either, a, file, path, or, an, open, file, handle, checks, validity,...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>gather_categories</td>\n",
       "      <td>def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...</td>\n",
       "      <td>python</td>\n",
       "      <td>def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...</td>\n",
       "      <td>[def, gather_categories, (, imap, ,, header, ,, categories, =, None, ), :, #...</td>\n",
       "      <td>Find the user specified categories in the map and create a dictionary to con...</td>\n",
       "      <td>[Find, the, user, specified, categories, in, the, map, and, create, a, dicti...</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smdabdoub/phylotoast</td>\n",
       "      <td>phylotoast/util.py</td>\n",
       "      <td>parse_unifrac</td>\n",
       "      <td>def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...</td>\n",
       "      <td>python</td>\n",
       "      <td>def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...</td>\n",
       "      <td>[def, parse_unifrac, (, unifracFN, ), :, with, open, (, unifracFN, ,, \"rU\", ...</td>\n",
       "      <td>Parses the unifrac results file into a dictionary\\n\\n    :type unifracFN: st...</td>\n",
       "      <td>[Parses, the, unifrac, results, file, into, a, dictionary]</td>\n",
       "      <td>0b74ef171e6a84761710548501dfac71285a58a3</td>\n",
       "      <td>https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   repo                path          func_name  \\\n",
       "0  smdabdoub/phylotoast  phylotoast/util.py    split_phylogeny   \n",
       "1  smdabdoub/phylotoast  phylotoast/util.py         ensure_dir   \n",
       "2  smdabdoub/phylotoast  phylotoast/util.py        file_handle   \n",
       "3  smdabdoub/phylotoast  phylotoast/util.py  gather_categories   \n",
       "4  smdabdoub/phylotoast  phylotoast/util.py      parse_unifrac   \n",
       "\n",
       "                                                                   original_string  \\\n",
       "0  def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...   \n",
       "1  def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...   \n",
       "2  def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...   \n",
       "3  def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...   \n",
       "4  def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...   \n",
       "\n",
       "  language  \\\n",
       "0   python   \n",
       "1   python   \n",
       "2   python   \n",
       "3   python   \n",
       "4   python   \n",
       "\n",
       "                                                                              code  \\\n",
       "0  def split_phylogeny(p, level=\"s\"):\\n    \"\"\"\\n    Return either the full or t...   \n",
       "1  def ensure_dir(d):\\n    \"\"\"\\n    Check to make sure the supplied directory p...   \n",
       "2  def file_handle(fnh, mode=\"rU\"):\\n    \"\"\"\\n    Takes either a file path or a...   \n",
       "3  def gather_categories(imap, header, categories=None):\\n    \"\"\"\\n    Find the...   \n",
       "4  def parse_unifrac(unifracFN):\\n    \"\"\"\\n    Parses the unifrac results file ...   \n",
       "\n",
       "                                                                       code_tokens  \\\n",
       "0  [def, split_phylogeny, (, p, ,, level, =, \"s\", ), :, level, =, level, +, \"__...   \n",
       "1  [def, ensure_dir, (, d, ), :, if, not, os, ., path, ., exists, (, d, ), :, t...   \n",
       "2  [def, file_handle, (, fnh, ,, mode, =, \"rU\", ), :, handle, =, None, if, isin...   \n",
       "3  [def, gather_categories, (, imap, ,, header, ,, categories, =, None, ), :, #...   \n",
       "4  [def, parse_unifrac, (, unifracFN, ), :, with, open, (, unifracFN, ,, \"rU\", ...   \n",
       "\n",
       "                                                                         docstring  \\\n",
       "0  Return either the full or truncated version of a QIIME-formatted taxonomy st...   \n",
       "1  Check to make sure the supplied directory path does not exist, if so, create...   \n",
       "2  Takes either a file path or an open file handle, checks validity and returns...   \n",
       "3  Find the user specified categories in the map and create a dictionary to con...   \n",
       "4  Parses the unifrac results file into a dictionary\\n\\n    :type unifracFN: st...   \n",
       "\n",
       "                                                                  docstring_tokens  \\\n",
       "0  [Return, either, the, full, or, truncated, version, of, a, QIIME, -, formatt...   \n",
       "1  [Check, to, make, sure, the, supplied, directory, path, does, not, exist, if...   \n",
       "2  [Takes, either, a, file, path, or, an, open, file, handle, checks, validity,...   \n",
       "3  [Find, the, user, specified, categories, in, the, map, and, create, a, dicti...   \n",
       "4                       [Parses, the, unifrac, results, file, into, a, dictionary]   \n",
       "\n",
       "                                        sha  \\\n",
       "0  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "1  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "2  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "3  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "4  0b74ef171e6a84761710548501dfac71285a58a3   \n",
       "\n",
       "                                                                               url  \\\n",
       "0  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "1  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "2  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "3  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "4  https://github.com/smdabdoub/phylotoast/blob/0b74ef171e6a84761710548501dfac7...   \n",
       "\n",
       "  partition  \n",
       "0     train  \n",
       "1     train  \n",
       "2     train  \n",
       "3     train  \n",
       "4     train  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "repo\n",
       "0101/pipetools                    8\n",
       "02strich/django-auth-kerberos     1\n",
       "05bit/peewee-async               30\n",
       "0compute/xtraceback               2\n",
       "0k/kids.cache                     2\n",
       "                                 ..\n",
       "zyga/padme                        2\n",
       "zyga/python-glibc                24\n",
       "zyga/python-phablet               2\n",
       "zzzsochi/includer                 2\n",
       "zzzsochi/resolver_deco            1\n",
       "Name: url, Length: 12361, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_codesearch_df.groupby('repo').agg('count')['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(repos_descriptions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "codesearch_df = all_codesearch_df[all_codesearch_df['repo'].isin(repos_descriptions_df['repo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_codesearch_df = codesearch_df[codesearch_df['partition'] == 'train']\n",
    "val_codesearch_df = codesearch_df[codesearch_df['partition'] == 'val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test', 'train', 'valid'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(all_codesearch_df['partition'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf_retriever(df, col, elasticsearch_client=elasticsearch.Elasticsearch()):\n",
    "    memory_docstring_store = document_store.elasticsearch.ElasticsearchDocumentStore(index=col)\n",
    "    df['text'] = df[col]\n",
    "    if not elasticsearch_client.count(index=col).get('count'):\n",
    "        memory_docstring_store.write_documents(df.to_dict('records'))\n",
    "    return retriever.sparse.ElasticsearchRetriever(document_store=memory_docstring_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-4a9075ba1e32>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df[col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 316 ms, total: 24.4 s\n",
      "Wall time: 7min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "docstring_tfidf_retriever = get_tfidf_retriever(codesearch_df, 'docstring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repos(ret, description, top_k=100):\n",
    "    return [rec.meta['repo'] for rec in ret.retrieve(query=description, top_k=top_k)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_docstrings = codesearch_df.groupby('repo')[['docstring']].agg(' '.join)\n",
    "aggregated_docstrings['repo'] = aggregated_docstrings.index\n",
    "aggregated_docstrings['aggregated_docstring'] = aggregated_docstrings['docstring']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8940/8940 [03:00<00:00, 49.56it/s]\n"
     ]
    }
   ],
   "source": [
    "docstring_matched_repos = [\n",
    "    get_repos(docstring_tfidf_retriever, descr)\n",
    "    for descr in tqdm.tqdm(repos_descriptions_df['pypi_description'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196876it [00:09, 20154.29it/s]\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    doc.text\n",
    "    for doc in tqdm.tqdm(docstring_tfidf_retriever.document_store.get_all_documents_generator())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8940"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docstring_matched_repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_at100= [\n",
    "    repo in potential_repos\n",
    "    for (repo, potential_repos) in zip(repos_descriptions_df['repo'], docstring_matched_repos)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007941834451901567"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(recall_at100) / len(docstring_matched_repos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pomysły\n",
    "\n",
    "- jako baseline wyszukiwanie zanurzeń komentarzy\n",
    "- wyszukiwanie po cechach korzystających z CodeBERTA\n",
    "- wytrenowanie modelu do rankingu (?) \n",
    "\n",
    "### Ogólne pomysły na podejścia\n",
    "\n",
    "Problem wydaje się dobrze opisywać podejście 'pairwise': mamy cechy jednego typu i drugiego typu, uczymy się dopasowywać jedne do drugich\n",
    "\n",
    "- ograniczyć się do komentarzy/kodu z wyższego poziomu hierarchii (wywołań/zależności)\n",
    "- agregowanie cech kodu z repozytoriów\n",
    "- agregowanie cech pochodzących od importów (Import2Vec) - **pokaż mi co importujesz, a powiem na jaki temat jest repo**\n",
    "- ogólniej cechy dla specjalnych tokenów: nazwy funkcji, nazwy argumentów\n",
    "- sprytniejsza agregacja - np hierarchiczna (np zrobić hiperboliczną wersję zanurzeń)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
