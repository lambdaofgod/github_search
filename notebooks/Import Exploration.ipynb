{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_files_df = pd.read_csv('data/sample_python_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>content</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BoiseState</td>\n",
       "      <td>bookdata-tools</td>\n",
       "      <td>bookdata/__init__.py</td>\n",
       "      <td>import os\\nimport sys\\nfrom pathlib import Pat...</td>\n",
       "      <td>dea642f49fd7e0a90133627e4f96193ca6d9627e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BoiseState</td>\n",
       "      <td>bookdata-tools</td>\n",
       "      <td>bookdata/db.py</td>\n",
       "      <td>import os\\nimport sys\\nimport re\\nimport time\\...</td>\n",
       "      <td>d369c1dbd5f18ed14e8735033877cb07fd4839f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BoiseState</td>\n",
       "      <td>bookdata-tools</td>\n",
       "      <td>bookdata/dvcpatch.py</td>\n",
       "      <td>\"\"\"\\nSupport code for our custom DVC remote.\\n...</td>\n",
       "      <td>c1305b94d20af17361b26505c9799a6c0652b882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BoiseState</td>\n",
       "      <td>bookdata-tools</td>\n",
       "      <td>bookdata/graph.py</td>\n",
       "      <td>\"\"\"\\nUtiltiies for loading &amp; working with the ...</td>\n",
       "      <td>f2ab933d0986671030e8343cb6fc8d6255bd04aa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BoiseState</td>\n",
       "      <td>bookdata-tools</td>\n",
       "      <td>bookdata/schema.py</td>\n",
       "      <td>\"\"\"\\nData schema information for the book data...</td>\n",
       "      <td>16f3874b8f8748971303648b94e3517ebe924d3f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        owner       repo_name             file_path  \\\n",
       "0  BoiseState  bookdata-tools  bookdata/__init__.py   \n",
       "1  BoiseState  bookdata-tools        bookdata/db.py   \n",
       "2  BoiseState  bookdata-tools  bookdata/dvcpatch.py   \n",
       "3  BoiseState  bookdata-tools     bookdata/graph.py   \n",
       "4  BoiseState  bookdata-tools    bookdata/schema.py   \n",
       "\n",
       "                                             content  \\\n",
       "0  import os\\nimport sys\\nfrom pathlib import Pat...   \n",
       "1  import os\\nimport sys\\nimport re\\nimport time\\...   \n",
       "2  \"\"\"\\nSupport code for our custom DVC remote.\\n...   \n",
       "3  \"\"\"\\nUtiltiies for loading & working with the ...   \n",
       "4  \"\"\"\\nData schema information for the book data...   \n",
       "\n",
       "                                        sha  \n",
       "0  dea642f49fd7e0a90133627e4f96193ca6d9627e  \n",
       "1  d369c1dbd5f18ed14e8735033877cb07fd4839f2  \n",
       "2  c1305b94d20af17361b26505c9799a6c0652b882  \n",
       "3  f2ab933d0986671030e8343cb6fc8d6255bd04aa  \n",
       "4  16f3874b8f8748971303648b94e3517ebe924d3f  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import parsing_imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import sys\n",
      "from pathlib import Path\n",
      "import pathlib\n",
      "import logging\n",
      "\n",
      "_simple_format = logging.Formatter('{asctime} [{levelname:7s}] {name} {message}',\n",
      "                                   datefmt='%Y-%m-%d %H:%M:%S',\n",
      "                                   style='{')\n",
      "\n",
      "_initialized = False\n",
      "\n",
      "data_dir = Path('data')\n",
      "tgt_dir = Path('target')\n",
      "bin_dir = tgt_dir / 'release'\n",
      "bdtool = bin_dir / 'bookdata'\n",
      "\n",
      "\n",
      "def setup(debug=False):\n",
      "    global _initialized\n",
      "    ch = logging.StreamHandler(sys.stderr)\n",
      "    ch.setLevel(logging.DEBUG if debug else logging.INFO)\n",
      "    ch.setFormatter(_simple_format)\n",
      "\n",
      "    root = logging.getLogger()\n",
      "    root.addHandler(ch)\n",
      "    root.setLevel(logging.INFO)\n",
      "\n",
      "    logging.getLogger('dvc').setLevel(logging.ERROR)\n",
      "    logging.getLogger('lenskit').setLevel(logging.DEBUG)\n",
      "    logging.getLogger('').setLevel(logging.DEBUG)\n",
      "    root.debug('log system configured')\n",
      "    _initialized = True\n",
      "\n",
      "\n",
      "def script_log(name, debug=False):\n",
      "    \"\"\"\n",
      "    Initialize logging and get a logger for a script.\n",
      "\n",
      "    Args:\n",
      "        name(str): The ``__name__`` of the script being run.\n",
      "        debug(bool): whether to enable debug logging to the console\n",
      "    \"\"\"\n",
      "\n",
      "    if not _initialized:\n",
      "        setup(debug)\n",
      "\n",
      "    logger = logging.getLogger(name)\n",
      "\n",
      "    return logger\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_file_content = python_files_df.iloc[0]['content']\n",
    "print(example_file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['os', 'sys', 'pathlib', 'pathlib', 'logging']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parsing_imports.get_modules(example_file_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modules_list(file_content):\n",
    "    return ' '.join(list(parsing_imports.get_modules(file_content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34678/34678 [00:39<00:00, 884.89it/s] \n"
     ]
    }
   ],
   "source": [
    "module_lists = []\n",
    "\n",
    "\n",
    "for content in tqdm.tqdm(python_files_df['content'].dropna()):\n",
    "    try:\n",
    "        module_lists.append(list(parsing_imports.get_modules(content)))\n",
    "    except SyntaxError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['os', 'sys', 'pathlib', 'pathlib', 'logging'],\n",
       " ['os',\n",
       "  'sys',\n",
       "  're',\n",
       "  'time',\n",
       "  'logging',\n",
       "  'hashlib',\n",
       "  'threading',\n",
       "  'configparser',\n",
       "  'pathlib',\n",
       "  'contextlib',\n",
       "  'datetime',\n",
       "  'typing',\n",
       "  'typing',\n",
       "  'docopt',\n",
       "  'natural',\n",
       "  'pandas',\n",
       "  'more_itertools',\n",
       "  'psycopg2',\n",
       "  'psycopg2',\n",
       "  'psycopg2',\n",
       "  'psycopg2',\n",
       "  'sqlalchemy',\n",
       "  'sqlparse',\n",
       "  'git'],\n",
       " ['logging', 'urllib', 'hashlib', 'dvc', 'dvc', 'dvc'],\n",
       " ['logging', 'pandas', 'numpy', 'graph_tool', 'schema'],\n",
       " ['pandas']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_lists[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_import_strings = [\n",
    "    ' '.join(modules)\n",
    "    for modules in module_lists\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer(min_df=5, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence_matrix = vectorizer.fit_transform(module_import_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_matrix = occurrence_matrix.T @ occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<984x984 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 41196 stored elements in Compressed Sparse Column format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooccurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = decomposition.NMF(n_components=50, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_vectors = nmf.fit_transform(cooccurrence_matrix.todense())\n",
    "module_vectors = module_vectors / (np.linalg.norm(module_vectors, axis=1) + 1e-12)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__future__',\n",
       " '_base',\n",
       " '_binary',\n",
       " '_caffe',\n",
       " '_constants',\n",
       " '_ext',\n",
       " '_init_paths',\n",
       " '_pickle',\n",
       " '_version',\n",
       " 'abc',\n",
       " 'absl',\n",
       " 'abstract_kernel',\n",
       " 'abstract_transformation',\n",
       " 'accuracy',\n",
       " 'acquisition',\n",
       " 'acquisition_functions',\n",
       " 'action_detection',\n",
       " 'activations',\n",
       " 'adet',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'airnet',\n",
       " 'aix360',\n",
       " 'albumentations',\n",
       " 'alexnet',\n",
       " 'allennlp',\n",
       " 'amr',\n",
       " 'anchor_generator',\n",
       " 'anchor_head',\n",
       " 'ann_app_utils',\n",
       " 'antlr4',\n",
       " 'anytime_models',\n",
       " 'apex',\n",
       " 'approver',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'arcsim',\n",
       " 'arg_parser',\n",
       " 'argparse',\n",
       " 'args',\n",
       " 'arguments',\n",
       " 'array',\n",
       " 'assign_result',\n",
       " 'assign_sampling',\n",
       " 'ast',\n",
       " 'astunparse',\n",
       " 'asyncio',\n",
       " 'atexit',\n",
       " 'attacks',\n",
       " 'attention',\n",
       " 'attmodel',\n",
       " 'attr',\n",
       " 'augment_model',\n",
       " 'augment_model_final',\n",
       " 'augment_model_new',\n",
       " 'augmentation_transforms',\n",
       " 'automl',\n",
       " 'backbone',\n",
       " 'backbones',\n",
       " 'base',\n",
       " 'base64',\n",
       " 'base_assigner',\n",
       " 'base_dataset',\n",
       " 'base_detector',\n",
       " 'base_model',\n",
       " 'base_options',\n",
       " 'base_sampler',\n",
       " 'base_sens',\n",
       " 'base_trainer',\n",
       " 'baseline',\n",
       " 'baselines',\n",
       " 'basemodel',\n",
       " 'basepifunet',\n",
       " 'bases',\n",
       " 'basetest_dqn_like',\n",
       " 'basetest_training',\n",
       " 'basic',\n",
       " 'basics',\n",
       " 'batch_norm',\n",
       " 'bayestorch',\n",
       " 'bbox',\n",
       " 'bbox_head',\n",
       " 'bbox_overlaps',\n",
       " 'bert',\n",
       " 'biom',\n",
       " 'bisect',\n",
       " 'blingfire',\n",
       " 'bo_policies',\n",
       " 'bokeh',\n",
       " 'bookdata',\n",
       " 'bootstrap',\n",
       " 'boto3',\n",
       " 'botocore',\n",
       " 'botorch',\n",
       " 'bottleneck',\n",
       " 'boundingbox',\n",
       " 'boundingboxes',\n",
       " 'box2d',\n",
       " 'box_head',\n",
       " 'bs4',\n",
       " 'build',\n",
       " 'build_data',\n",
       " 'builder',\n",
       " 'builtins',\n",
       " 'bz2',\n",
       " 'cached_property',\n",
       " 'caffe',\n",
       " 'caffe2',\n",
       " 'callbacks',\n",
       " 'camera_info',\n",
       " 'captioning',\n",
       " 'captionmodel',\n",
       " 'carla',\n",
       " 'cascade_rcnn',\n",
       " 'chainer',\n",
       " 'chainer_',\n",
       " 'chainercv',\n",
       " 'chainerrl',\n",
       " 'checkpoints',\n",
       " 'cifar',\n",
       " 'cifar10_cls_dataset',\n",
       " 'cityscapes',\n",
       " 'cityscapesscripts',\n",
       " 'class_names',\n",
       " 'classifier',\n",
       " 'cleanlab',\n",
       " 'click',\n",
       " 'cloudpickle',\n",
       " 'cls_dataset',\n",
       " 'coco',\n",
       " 'codebase',\n",
       " 'codecs',\n",
       " 'coinrun',\n",
       " 'collections',\n",
       " 'colorsys',\n",
       " 'comet_ml',\n",
       " 'comm',\n",
       " 'common',\n",
       " 'common_flags',\n",
       " 'compat',\n",
       " 'components',\n",
       " 'compose',\n",
       " 'concurrent',\n",
       " 'config',\n",
       " 'configargparse',\n",
       " 'configparser',\n",
       " 'configurable',\n",
       " 'configuration_utils',\n",
       " 'configure',\n",
       " 'const',\n",
       " 'constants',\n",
       " 'context',\n",
       " 'contextlib',\n",
       " 'contextlib2',\n",
       " 'conv',\n",
       " 'conv_ws',\n",
       " 'copy',\n",
       " 'core',\n",
       " 'corpus_processing',\n",
       " 'corpusiterator',\n",
       " 'corpusiteratorwiki',\n",
       " 'corpusiteratorwikiwords',\n",
       " 'cpickle',\n",
       " 'cstringio',\n",
       " 'csv',\n",
       " 'ctc_alignment',\n",
       " 'ctypes',\n",
       " 'cupy',\n",
       " 'custom',\n",
       " 'custom_layers',\n",
       " 'custom_ops',\n",
       " 'cv2',\n",
       " 'cv_bridge',\n",
       " 'cython',\n",
       " 'daiquiri',\n",
       " 'darknet',\n",
       " 'data',\n",
       " 'data_formatters',\n",
       " 'data_generator',\n",
       " 'data_list',\n",
       " 'data_load',\n",
       " 'data_loader',\n",
       " 'data_loaders',\n",
       " 'data_processing',\n",
       " 'data_provider',\n",
       " 'data_util',\n",
       " 'data_utils',\n",
       " 'dataclasses',\n",
       " 'dataio',\n",
       " 'dataloader',\n",
       " 'dataloaders',\n",
       " 'dataset',\n",
       " 'dataset_affwild2',\n",
       " 'dataset_loader',\n",
       " 'dataset_metainfo',\n",
       " 'dataset_wrappers',\n",
       " 'datasetmanager',\n",
       " 'datasets',\n",
       " 'datetime',\n",
       " 'dcn',\n",
       " 'ddsl',\n",
       " 'ddtn',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deepalign',\n",
       " 'deepctr_torch',\n",
       " 'deeph3',\n",
       " 'deeplab',\n",
       " 'deeplift',\n",
       " 'deepspeech',\n",
       " 'deepspeech_pytorch',\n",
       " 'deepy',\n",
       " 'defaults',\n",
       " 'defines',\n",
       " 'deform_conv',\n",
       " 'delf',\n",
       " 'densenet',\n",
       " 'deployment',\n",
       " 'detect_face',\n",
       " 'detector',\n",
       " 'detectors',\n",
       " 'detectron2',\n",
       " 'dface',\n",
       " 'dgl',\n",
       " 'dh_segment',\n",
       " 'dialogflow',\n",
       " 'diapreresnet',\n",
       " 'diaresnet',\n",
       " 'dict_use',\n",
       " 'differential_privacy',\n",
       " 'difflib',\n",
       " 'digits',\n",
       " 'dill',\n",
       " 'discriminator',\n",
       " 'distributed',\n",
       " 'distutils',\n",
       " 'django',\n",
       " 'dnnlib',\n",
       " 'docopt',\n",
       " 'docutils',\n",
       " 'dogcat',\n",
       " 'dominate',\n",
       " 'dopamine',\n",
       " 'dpipe',\n",
       " 'dpn',\n",
       " 'dppy',\n",
       " 'ds_ctcdecoder',\n",
       " 'dsgn',\n",
       " 'dsr_model',\n",
       " 'easydet',\n",
       " 'easydict',\n",
       " 'edgeml_pytorch',\n",
       " 'edgeml_tf',\n",
       " 'efficientnet',\n",
       " 'efficientnet_pytorch',\n",
       " 'emcee',\n",
       " 'emoji',\n",
       " 'encoder',\n",
       " 'encoderfactory',\n",
       " 'encoders',\n",
       " 'endtoendclassification',\n",
       " 'engine',\n",
       " 'ensure_segmappy_is_installed',\n",
       " 'enum',\n",
       " 'enums',\n",
       " 'env',\n",
       " 'env_spec',\n",
       " 'environments',\n",
       " 'envs',\n",
       " 'errno',\n",
       " 'esim',\n",
       " 'etcd',\n",
       " 'eval',\n",
       " 'evaluate',\n",
       " 'evaluation',\n",
       " 'evaluator',\n",
       " 'examples',\n",
       " 'exifutil',\n",
       " 'experiments',\n",
       " 'expert_finding',\n",
       " 'export_inference_graph',\n",
       " 'exps',\n",
       " 'external',\n",
       " 'face_image',\n",
       " 'face_preprocess',\n",
       " 'factory',\n",
       " 'fairlearn',\n",
       " 'fairseq',\n",
       " 'faiss',\n",
       " 'far_ho',\n",
       " 'fast_rcnn',\n",
       " 'fastai',\n",
       " 'fastseresnet',\n",
       " 'fasttext',\n",
       " 'fcn_mask_head',\n",
       " 'fcntl',\n",
       " 'fcos',\n",
       " 'fdensenet',\n",
       " 'fdmobilenet',\n",
       " 'features',\n",
       " 'ffcc',\n",
       " 'figet',\n",
       " 'file_utils',\n",
       " 'filelock',\n",
       " 'filterpy',\n",
       " 'fire',\n",
       " 'fit_and_predict',\n",
       " 'flags',\n",
       " 'flask',\n",
       " 'flops_counter',\n",
       " 'flow',\n",
       " 'flowrelated',\n",
       " 'fmobilenet',\n",
       " 'fnmatch',\n",
       " 'forwarder',\n",
       " 'fpn',\n",
       " 'fragile',\n",
       " 'fresnet',\n",
       " 'function',\n",
       " 'functions',\n",
       " 'functions_for_training',\n",
       " 'functools',\n",
       " 'future',\n",
       " 'fvcore',\n",
       " 'game',\n",
       " 'gast',\n",
       " 'gc',\n",
       " 'gcmc',\n",
       " 'gcn',\n",
       " 'gdp_accountant',\n",
       " 'general_utils',\n",
       " 'generate_tracklet',\n",
       " 'generator',\n",
       " 'genotypes',\n",
       " 'gensim',\n",
       " 'geometry',\n",
       " 'geometry_msgs',\n",
       " 'george',\n",
       " 'geotnf',\n",
       " 'getopt',\n",
       " 'getpass',\n",
       " 'gflags',\n",
       " 'gin',\n",
       " 'git',\n",
       " 'glob',\n",
       " 'glog',\n",
       " 'glow',\n",
       " 'gluon',\n",
       " 'gluoncv',\n",
       " 'gluoncv2',\n",
       " 'google',\n",
       " 'google3',\n",
       " 'gp_input_noise',\n",
       " 'gp_utilities',\n",
       " 'gpflow',\n",
       " 'gpflowopt',\n",
       " 'gpytorch',\n",
       " 'graph',\n",
       " 'graph_builder',\n",
       " 'graphs',\n",
       " 'graphviz',\n",
       " 'grpc',\n",
       " 'gslr',\n",
       " 'guided_anchor_head',\n",
       " 'gurobipy',\n",
       " 'gym',\n",
       " 'gym_minigrid',\n",
       " 'gym_sokoban',\n",
       " 'gym_sokoban_fast',\n",
       " 'gym_wmgds',\n",
       " 'gymfc',\n",
       " 'gymfc_nf',\n",
       " 'gzip',\n",
       " 'h5py',\n",
       " 'hashlib',\n",
       " 'haven',\n",
       " 'hbaselines',\n",
       " 'heads',\n",
       " 'heapq',\n",
       " 'helper',\n",
       " 'helper_utils',\n",
       " 'helpermethods',\n",
       " 'helpers',\n",
       " 'her_level',\n",
       " 'holder',\n",
       " 'holoviews',\n",
       " 'horovod',\n",
       " 'hparam',\n",
       " 'html',\n",
       " 'httplib',\n",
       " 'hydra',\n",
       " 'hyperopt',\n",
       " 'hyperparams',\n",
       " 'ibnresnet',\n",
       " 'icp_grad',\n",
       " 'icp_op',\n",
       " 'icp_util',\n",
       " 'ignite',\n",
       " 'iisignature',\n",
       " 'im2txt',\n",
       " 'image',\n",
       " 'image_classification',\n",
       " 'image_geometry',\n",
       " 'imageio',\n",
       " 'imagenet1k_cls_dataset',\n",
       " 'imagenet_preprocessing',\n",
       " 'imdb',\n",
       " 'imgaug',\n",
       " 'imgproc',\n",
       " 'imlib',\n",
       " 'imp',\n",
       " 'importlib',\n",
       " 'imutils',\n",
       " 'inception',\n",
       " 'inceptionresnetv2',\n",
       " 'inceptionv4',\n",
       " 'inferbeddings',\n",
       " 'inference',\n",
       " 'initialization',\n",
       " 'input_data',\n",
       " 'input_features',\n",
       " 'input_source',\n",
       " 'input_utils',\n",
       " 'inputs',\n",
       " 'inspect',\n",
       " 'intent_detection',\n",
       " 'interactive_markers',\n",
       " 'io',\n",
       " 'io_utils',\n",
       " 'iou',\n",
       " 'iou_loss',\n",
       " 'ipdb',\n",
       " 'ipython',\n",
       " 'isplutils',\n",
       " 'itertools',\n",
       " 'jieba',\n",
       " 'joblib',\n",
       " 'json',\n",
       " 'json_tricks',\n",
       " 'kafka',\n",
       " 'keras',\n",
       " 'keras_',\n",
       " 'keras_gcnn',\n",
       " 'keras_models',\n",
       " 'keras_preprocessing',\n",
       " 'kernel_kmeans',\n",
       " 'kgp',\n",
       " 'kitti_data',\n",
       " 'kw_utils',\n",
       " 'lark',\n",
       " 'lasagne',\n",
       " 'layer',\n",
       " 'layers',\n",
       " 'lcp_physics',\n",
       " 'learning_and_planning',\n",
       " 'lib',\n",
       " 'librosa',\n",
       " 'lifelines',\n",
       " 'linear',\n",
       " 'linecache',\n",
       " 'lmdb',\n",
       " 'load',\n",
       " 'load_data',\n",
       " 'loader',\n",
       " 'locale',\n",
       " 'log',\n",
       " 'logger',\n",
       " 'logging',\n",
       " 'logistic_regression_pyro',\n",
       " 'logzero',\n",
       " 'loss',\n",
       " 'loss_functions',\n",
       " 'losses',\n",
       " 'lpips',\n",
       " 'lr_scheduler',\n",
       " 'lstm_object_detection',\n",
       " 'lxml',\n",
       " 'machamp',\n",
       " 'mackelab_toolbox',\n",
       " 'main',\n",
       " 'maml',\n",
       " 'manifolds',\n",
       " 'mask',\n",
       " 'masked_conv',\n",
       " 'maskrcnn_benchmark',\n",
       " 'match_utils',\n",
       " 'math',\n",
       " 'matplotlib',\n",
       " 'max_iou_assigner',\n",
       " 'megengine',\n",
       " 'memory',\n",
       " 'meta_modules',\n",
       " 'metal',\n",
       " 'methods',\n",
       " 'metric',\n",
       " 'metrics',\n",
       " 'misc',\n",
       " 'miscc',\n",
       " 'mit_semseg',\n",
       " 'mixture',\n",
       " 'ml_utils',\n",
       " 'mlflow',\n",
       " 'mlp',\n",
       " 'mmap',\n",
       " 'mmcv',\n",
       " 'mmd',\n",
       " 'mmdet',\n",
       " 'mmvec',\n",
       " 'mnist',\n",
       " 'mobilenet',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'mock',\n",
       " 'model',\n",
       " 'model2',\n",
       " 'model_helper',\n",
       " 'model_language',\n",
       " 'model_speech',\n",
       " 'modeling',\n",
       " 'modeling_bert',\n",
       " 'modeling_common_test',\n",
       " 'modeling_utils',\n",
       " 'models',\n",
       " 'models_binary',\n",
       " 'models_lw_3d',\n",
       " 'module',\n",
       " 'modules',\n",
       " 'moe',\n",
       " 'momentumnet',\n",
       " 'motmetrics',\n",
       " 'mpi4py',\n",
       " 'mpl_toolkits',\n",
       " 'mrcnn',\n",
       " 'msgpack',\n",
       " 'mujoco_py',\n",
       " 'multiprocessing',\n",
       " 'musegan',\n",
       " 'mv3d',\n",
       " 'mv3d_net',\n",
       " 'mxnet',\n",
       " 'my',\n",
       " 'mypath',\n",
       " 'namespace_utils',\n",
       " 'nasnet',\n",
       " 'natasy',\n",
       " 'nav_msgs',\n",
       " 'nest',\n",
       " 'net',\n",
       " 'net_spec',\n",
       " 'nets',\n",
       " 'netvlad',\n",
       " 'network',\n",
       " 'networks',\n",
       " 'networkx',\n",
       " 'neural_networks',\n",
       " 'neuralprocesses',\n",
       " 'neuronlayer',\n",
       " 'neurvps',\n",
       " 'nibabel',\n",
       " 'nltk',\n",
       " 'nms',\n",
       " 'nmslib',\n",
       " 'nn',\n",
       " 'norm',\n",
       " 'normalization',\n",
       " 'nose',\n",
       " 'np2p_data_stream',\n",
       " 'np2p_model_graph',\n",
       " 'ntpath',\n",
       " 'numba',\n",
       " 'numbers',\n",
       " 'numpy',\n",
       " 'object_detection',\n",
       " 'objective',\n",
       " 'odeint_ext',\n",
       " 'official',\n",
       " 'omnibox',\n",
       " 'open3d',\n",
       " 'openmesh',\n",
       " 'operator',\n",
       " 'operator_py',\n",
       " 'ops',\n",
       " 'optim',\n",
       " 'optimization',\n",
       " 'optimizer',\n",
       " 'optimizers',\n",
       " 'options',\n",
       " 'optparse',\n",
       " 'opts',\n",
       " 'oracle',\n",
       " 'orbit',\n",
       " 'orthogonal',\n",
       " 'os',\n",
       " 'other',\n",
       " 'ourlib',\n",
       " 'overrides',\n",
       " 'padding',\n",
       " 'padding_utils',\n",
       " 'pandas',\n",
       " 'param',\n",
       " 'parameters',\n",
       " 'parametrization',\n",
       " 'params',\n",
       " 'parse',\n",
       " 'parse_config',\n",
       " 'parse_tracklet',\n",
       " 'pascal_voc',\n",
       " 'past',\n",
       " 'path',\n",
       " 'pathlib',\n",
       " 'paths',\n",
       " 'pdb',\n",
       " 'pennylane',\n",
       " 'perturbation_learning',\n",
       " 'pes',\n",
       " 'petridish',\n",
       " 'pickle',\n",
       " 'pil',\n",
       " 'pipes',\n",
       " 'pkg_resources',\n",
       " 'pkgutil',\n",
       " 'platform',\n",
       " 'plnn_bounds',\n",
       " 'plotly',\n",
       " 'plotting',\n",
       " 'plugins',\n",
       " 'plyfile',\n",
       " 'pointfly',\n",
       " 'pointnet2_ops',\n",
       " 'pointnet_util',\n",
       " 'policy',\n",
       " 'polygon',\n",
       " 'postprocessing',\n",
       " 'pprint',\n",
       " 'prado',\n",
       " 'pre_process',\n",
       " 'predictor',\n",
       " 'prepare_data',\n",
       " 'preprocess',\n",
       " 'preprocessing',\n",
       " 'preresnet',\n",
       " 'pretrain_classifier',\n",
       " 'pretrainedmodels',\n",
       " 'pretty_midi',\n",
       " 'prettytable',\n",
       " 'prettytensor',\n",
       " 'processing',\n",
       " 'progress',\n",
       " 'progressbar',\n",
       " 'project_settings',\n",
       " 'project_utils',\n",
       " 'proto',\n",
       " 'protodriver',\n",
       " 'provable_pruning',\n",
       " 'provider',\n",
       " 'proxyless_nas',\n",
       " 'proxylessnas',\n",
       " 'pseudo_decomp_utils',\n",
       " 'pspnet',\n",
       " 'psutil',\n",
       " 'pulp',\n",
       " 'px',\n",
       " 'pybullet',\n",
       " 'pycaffe',\n",
       " 'pycocotools',\n",
       " 'pydantic',\n",
       " 'pyflann',\n",
       " 'pygame',\n",
       " 'pyglet',\n",
       " 'pygln',\n",
       " 'pykdl',\n",
       " 'pylab',\n",
       " 'pylearn2',\n",
       " 'pylib',\n",
       " 'pymesh',\n",
       " 'pypse',\n",
       " 'pyqt5',\n",
       " 'pyramidnet',\n",
       " 'pyro',\n",
       " 'pyspark',\n",
       " 'pytest',\n",
       " 'python_backend',\n",
       " 'python_speech_features',\n",
       " 'pytorch',\n",
       " 'pytorch_msssim',\n",
       " 'pytorch_pretrained_bert',\n",
       " 'pytorch_transformers',\n",
       " 'pytorchcv',\n",
       " 'pytsetlinmachine',\n",
       " 'pyworld',\n",
       " 'qiime2',\n",
       " 'queue',\n",
       " 'random',\n",
       " 'random_sampler',\n",
       " 'rans',\n",
       " 'raw',\n",
       " 'ray',\n",
       " 'rcnn',\n",
       " 'rdkit',\n",
       " 're',\n",
       " 'reader',\n",
       " 'reagent',\n",
       " 'refinement_net',\n",
       " 'regex',\n",
       " 'registry',\n",
       " 'reid_net',\n",
       " 'requests',\n",
       " 'resampy',\n",
       " 'resnet',\n",
       " 'resneta',\n",
       " 'resnetd',\n",
       " 'resnext',\n",
       " 'resource',\n",
       " 'result_output',\n",
       " 'retina_head',\n",
       " 'retinaface',\n",
       " 'rl_games',\n",
       " 'rllib_models',\n",
       " 'rlpyt',\n",
       " 'robo',\n",
       " 'roi_align',\n",
       " 'roi_data_layer',\n",
       " 'roi_pool',\n",
       " 'rosbag',\n",
       " 'rospy',\n",
       " 'rpn',\n",
       " 'ruamel',\n",
       " 's2cnn',\n",
       " 'sac',\n",
       " 'sacred',\n",
       " 'salad',\n",
       " 'saliency_maps',\n",
       " 'sampler',\n",
       " 'samplers',\n",
       " 'sampling_result',\n",
       " 'scale',\n",
       " 'scenarios',\n",
       " 'scheduler',\n",
       " 'scipy',\n",
       " 'score',\n",
       " 'scripts',\n",
       " 'seaborn',\n",
       " 'seedot',\n",
       " 'seg_dataset',\n",
       " 'seg_metrics_np',\n",
       " 'seg_models',\n",
       " 'seg_utils',\n",
       " 'segmappy',\n",
       " 'selenium',\n",
       " 'semantic_segmentation',\n",
       " 'senet',\n",
       " 'sensor_msgs',\n",
       " 'sentencepiece',\n",
       " 'sepreresnet',\n",
       " 'seqeval',\n",
       " 'sequence_layers',\n",
       " 'seresnet',\n",
       " 'settings',\n",
       " 'setuptools',\n",
       " 'sevn_gym',\n",
       " 'sexpdata',\n",
       " 'sgnn',\n",
       " 'shake_drop',\n",
       " 'shake_shake',\n",
       " 'shapely',\n",
       " 'shared_utils',\n",
       " 'sharedarray',\n",
       " 'shield',\n",
       " 'shlex',\n",
       " 'shutil',\n",
       " 'sigmoid_focal_loss',\n",
       " 'signal',\n",
       " 'signatory',\n",
       " 'sigpy',\n",
       " 'simpleitk',\n",
       " 'simulator',\n",
       " 'single_stage',\n",
       " 'sinn',\n",
       " 'site',\n",
       " 'six',\n",
       " 'skbio',\n",
       " 'skimage',\n",
       " 'sklearn',\n",
       " 'skvideo',\n",
       " 'slc_dataset',\n",
       " 'slimmable_ops',\n",
       " 'smooth_l1_loss',\n",
       " 'socket',\n",
       " 'sockeye',\n",
       " 'softlearning',\n",
       " 'solver',\n",
       " 'songbird',\n",
       " 'sonnet',\n",
       " 'soundfile',\n",
       " 'source',\n",
       " 'sox',\n",
       " 'space',\n",
       " 'spacy',\n",
       " 'spearmint',\n",
       " 'sphinx',\n",
       " 'sphinx_rtd_theme',\n",
       " 'spinn',\n",
       " 'sqlite3',\n",
       " 'src',\n",
       " 'sre_compile',\n",
       " 'stance',\n",
       " 'stat',\n",
       " 'stat_parser',\n",
       " 'statistics',\n",
       " 'statsmodels',\n",
       " 'strawberryfields',\n",
       " 'string',\n",
       " 'struct',\n",
       " 'subprocess',\n",
       " 'surgery',\n",
       " 'symbol',\n",
       " 'symbol_utils',\n",
       " 'symbols',\n",
       " 'synthetic',\n",
       " 'synthetic_data_utils',\n",
       " 'sys',\n",
       " 'system',\n",
       " 'table',\n",
       " 'tables',\n",
       " 'tabulate',\n",
       " 'tacticnotationsparser',\n",
       " 'tarfile',\n",
       " 'task_saccades',\n",
       " 'task_specific',\n",
       " 'tasks',\n",
       " 'tempfile',\n",
       " 'template',\n",
       " 'tensorboard',\n",
       " 'tensorboard_logger',\n",
       " 'tensorboardx',\n",
       " 'tensorflow',\n",
       " 'tensorflow2',\n",
       " 'tensorflow_',\n",
       " 'tensorflow_addons',\n",
       " 'tensorflow_datasets',\n",
       " 'tensorflow_estimator',\n",
       " 'tensorflow_hub',\n",
       " 'tensorflow_privacy',\n",
       " 'tensorflow_probability',\n",
       " 'tensorflow_text',\n",
       " 'tensorflow_tts',\n",
       " 'tensorflowcv',\n",
       " 'tensorpack',\n",
       " 'termcolor',\n",
       " 'terminaltables',\n",
       " 'test',\n",
       " 'test_mixins',\n",
       " 'test_net',\n",
       " 'tests',\n",
       " 'textwrap',\n",
       " 'tf',\n",
       " 'tf2cv',\n",
       " 'tf_activation',\n",
       " 'tf_agents',\n",
       " 'tf_idf_model',\n",
       " 'tf_slim',\n",
       " 'tf_util',\n",
       " 'tfcaps',\n",
       " 'tflayer',\n",
       " 'tflib',\n",
       " 'tfutil',\n",
       " 'tfutils',\n",
       " 'theano',\n",
       " 'theano_shim',\n",
       " 'third_party',\n",
       " 'threading',\n",
       " 'thred',\n",
       " 'thumt',\n",
       " 'time',\n",
       " 'timeit',\n",
       " 'timm',\n",
       " 'tkinter',\n",
       " 'tokenization',\n",
       " 'tokenization_bert',\n",
       " 'tokenization_tests_commons',\n",
       " 'tokenization_utils',\n",
       " 'tokenize',\n",
       " 'toml',\n",
       " 'tools',\n",
       " 'topk',\n",
       " 'torch',\n",
       " 'torch_geometric',\n",
       " 'torch_rl',\n",
       " 'torch_scatter',\n",
       " 'torch_vae',\n",
       " 'torchdiffeq',\n",
       " 'torchmeta',\n",
       " 'torchreid',\n",
       " 'torchsso',\n",
       " 'torchsummary',\n",
       " 'torchtext',\n",
       " 'torchvision',\n",
       " 'torchvision_sunner',\n",
       " 'tornado',\n",
       " 'tower',\n",
       " 'tqdm',\n",
       " 'traceback',\n",
       " 'tracklets',\n",
       " 'train',\n",
       " 'train_utils',\n",
       " 'trainer',\n",
       " 'training',\n",
       " 'transform_data',\n",
       " 'transformer',\n",
       " 'transformers',\n",
       " 'transforms',\n",
       " 'transforms3d',\n",
       " 'tree',\n",
       " 'trial_data',\n",
       " 'trimesh',\n",
       " 'trivializations',\n",
       " 'tttboard',\n",
       " 'two_stage',\n",
       " 'typeguard',\n",
       " 'types',\n",
       " 'typing',\n",
       " 'unet',\n",
       " 'unet3d',\n",
       " 'unicodedata',\n",
       " 'unittest',\n",
       " 'unwrappedface',\n",
       " 'urllib',\n",
       " 'util',\n",
       " 'utilities',\n",
       " 'utility',\n",
       " 'utils',\n",
       " 'utils_motifs',\n",
       " 'utils_relation',\n",
       " 'uuid',\n",
       " 'vae',\n",
       " 'vard',\n",
       " 'vegasflow',\n",
       " 'vehicle_reid_pytorch',\n",
       " 'verification',\n",
       " 'version',\n",
       " 'vgg',\n",
       " 'vggish_input',\n",
       " 'vggish_params',\n",
       " 'vggish_postprocess',\n",
       " 'vggish_slim',\n",
       " 'video',\n",
       " 'video_prediction',\n",
       " 'visdom',\n",
       " 'visualization_msgs',\n",
       " 'visualize',\n",
       " 'viz',\n",
       " 'vizdoom',\n",
       " 'vmz',\n",
       " 'voc',\n",
       " 'voc_eval',\n",
       " 'voc_eval_py3',\n",
       " 'voc_seg_dataset',\n",
       " 'vocab',\n",
       " 'vocab_utils',\n",
       " 'w_utility',\n",
       " 'wand',\n",
       " 'wandb',\n",
       " 'warnings',\n",
       " 'wave',\n",
       " 'weakref',\n",
       " 'weight_drop',\n",
       " 'werkzeug',\n",
       " 'wget',\n",
       " 'wrappers',\n",
       " 'wrapt',\n",
       " 'wrn',\n",
       " 'xarray',\n",
       " 'xception',\n",
       " 'xdensenet',\n",
       " 'xgboost',\n",
       " 'xml',\n",
       " 'xml_style',\n",
       " 'xsearch',\n",
       " 'yacs',\n",
       " 'yaml',\n",
       " 'yamnet',\n",
       " 'zipfile',\n",
       " 'zlib',\n",
       " 'zsvision']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numpy',\n",
       " 'os',\n",
       " 'tensorflow',\n",
       " 'torch',\n",
       " '__future__',\n",
       " 'sys',\n",
       " 'collections',\n",
       " 'utils',\n",
       " 'math',\n",
       " 'time']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_module_idxs = np.array(occurrence_matrix.sum(axis=0))[0].argsort()[::-1][:10]\n",
    "modules = vectorizer.get_feature_names()\n",
    "\n",
    "[modules[i] for i in top_module_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_module_idx = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sys', 820)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[top_module_idxs[example_module_idx]], top_module_idxs[example_module_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_module_vector = module_vectors[top_module_idxs[example_module_idx]]\n",
    "example_module_vector_similarities = example_module_vector @ module_vectors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_vector_idxs = example_module_vector_similarities.argsort()[::-1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys 1.0\n",
      "sphinx_rtd_theme 0.8645\n",
      "version 0.8589\n",
      "score 0.8528\n",
      "surgery 0.8514\n",
      "site 0.8055\n",
      "pointnet_util 0.804\n",
      "python_backend 0.7943\n",
      "graphviz 0.7935\n",
      "tf_util 0.7915\n"
     ]
    }
   ],
   "source": [
    "for idx in most_similar_vector_idxs:\n",
    "    print(modules[idx], round(example_module_vector_similarities[idx], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(module_vectors[878] @ module_vectors.T).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.67290559,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.11910143, 0.03476049, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.24431886, 0.        , 0.12185708, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.05280244, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.61156985, 0.        , 0.        , 0.28365115, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_vectors[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec format\n",
    "\n",
    "Functions for writing a numpy matrix with specified vocabulary as Word2Vec format.\n",
    "\n",
    "This is useful as such format can be loaded using gensim KeyedVectors class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def _word_vectors_to_word2vec_format_generator(vocabulary, word_vectors):\n",
    "    for (word, vector) in zip(vocabulary, word_vectors):\n",
    "        yield word + ' ' + ' '.join([str('{:.5f}'.format(f)) for f in vector])\n",
    "\n",
    "        \n",
    "def store_word_vectors(words, word_vectors, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(str(len(words)) + ' ' + str(word_vectors.shape[1]) + '\\n')\n",
    "        for line in _word_vectors_to_word2vec_format_generator(words, module_vectors):\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_word_vectors(modules, module_vectors, 'data/nmf_module_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "module_keyed_vectors = gensim.models.KeyedVectors.load_word2vec_format('data/nmf_module_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/conda/envs/ml/lib/python3.7/site-packages/gensim/models/keyedvectors.py:2389: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('assign_result', 0.8605263829231262),\n",
       " ('dsr_model', 0.8605263829231262),\n",
       " ('box_head', 0.8605263829231262),\n",
       " ('base_assigner', 0.8605263829231262),\n",
       " ('signatory', 0.86052006483078),\n",
       " ('scale', 0.8596498966217041),\n",
       " ('efficientnet_pytorch', 0.8589223027229309),\n",
       " ('basepifunet', 0.8559807538986206),\n",
       " ('base_sampler', 0.855023205280304),\n",
       " ('base_sens', 0.8546276688575745)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
