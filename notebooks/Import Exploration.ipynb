{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp import_exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import gensim\n",
    "\n",
    "from github_search import parsing_imports\n",
    "from sklearn import feature_extraction, decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 s, sys: 2.13 s, total: 32 s\n",
      "Wall time: 32.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "python_files_df = pd.read_csv('data/python_files.csv').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>content</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>models</td>\n",
       "      <td>official/common/__init__.py</td>\n",
       "      <td>\\n</td>\n",
       "      <td>8b137891791fe96927ad78e64b0aad7bded08bdc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>models</td>\n",
       "      <td>official/common/distribute_utils.py</td>\n",
       "      <td># Copyright 2018 The TensorFlow Authors. All R...</td>\n",
       "      <td>7ae8772840f52b7d5c0a492e13659ca58c3730ce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>models</td>\n",
       "      <td>official/common/distribute_utils_test.py</td>\n",
       "      <td># Copyright 2018 The TensorFlow Authors. All R...</td>\n",
       "      <td>124c1c6f1c529a559d3af644826de8904d2075b2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>models</td>\n",
       "      <td>official/common/flags.py</td>\n",
       "      <td># Lint as: python3\\n# Copyright 2020 The Tenso...</td>\n",
       "      <td>ee86aca17b1e92a2aec476e70e23d90647e99ec9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensorflow</td>\n",
       "      <td>models</td>\n",
       "      <td>official/common/registry_imports.py</td>\n",
       "      <td># Copyright 2020 The TensorFlow Authors. All R...</td>\n",
       "      <td>021034568c4e10e4f46e59fd090b881fe8cd9d8b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        owner repo_name                                 file_path  \\\n",
       "1  tensorflow    models               official/common/__init__.py   \n",
       "2  tensorflow    models       official/common/distribute_utils.py   \n",
       "3  tensorflow    models  official/common/distribute_utils_test.py   \n",
       "4  tensorflow    models                  official/common/flags.py   \n",
       "5  tensorflow    models       official/common/registry_imports.py   \n",
       "\n",
       "                                             content  \\\n",
       "1                                                 \\n   \n",
       "2  # Copyright 2018 The TensorFlow Authors. All R...   \n",
       "3  # Copyright 2018 The TensorFlow Authors. All R...   \n",
       "4  # Lint as: python3\\n# Copyright 2020 The Tenso...   \n",
       "5  # Copyright 2020 The TensorFlow Authors. All R...   \n",
       "\n",
       "                                        sha  \n",
       "1  8b137891791fe96927ad78e64b0aad7bded08bdc  \n",
       "2  7ae8772840f52b7d5c0a492e13659ca58c3730ce  \n",
       "3  124c1c6f1c529a559d3af644826de8904d2075b2  \n",
       "4  ee86aca17b1e92a2aec476e70e23d90647e99ec9  \n",
       "5  021034568c4e10e4f46e59fd090b881fe8cd9d8b  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 888935 entries, 1 to 932381\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   owner      888935 non-null  object\n",
      " 1   repo_name  888935 non-null  object\n",
      " 2   file_path  888935 non-null  object\n",
      " 3   content    888935 non-null  object\n",
      " 4   sha        888935 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 40.7+ MB\n"
     ]
    }
   ],
   "source": [
    "python_files_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright 2018 The TensorFlow Authors. All Rights Reserved.\n",
      "#\n",
      "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
      "# you may not use this file except in compliance with the License.\n",
      "# You may obtain a copy of the License at\n",
      "#\n",
      "#     http://www.apache.org/licenses/LICENSE-2.0\n",
      "#\n",
      "# Unless required by applicable law or agreed to in writing, software\n",
      "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
      "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
      "# See the License for the specific language governing permissions and\n",
      "# limitations under the License.\n",
      "# ==============================================================================\n",
      "\"\"\"Helper functions for running models in a distributed setting.\"\"\"\n",
      "\n",
      "import json\n",
      "import os\n",
      "import random\n",
      "import string\n",
      "\n",
      "from absl import logging\n",
      "import tensorflow as tf\n",
      "\n",
      "\n",
      "def _collective_communication(all_reduce_alg):\n",
      "  \"\"\"Return a CollectiveCommunication based on all_reduce_alg.\n",
      "\n",
      "  Args:\n",
      "    all_reduce_alg: a string specifying which collective communication to pick,\n",
      "      or None.\n",
      "\n",
      "  Returns:\n",
      "    tf.distribute.experimental.CollectiveCommunication object\n",
      "\n",
      "  Raises:\n",
      "    ValueError: if `all_reduce_alg` not in [None, \"ring\", \"nccl\"]\n",
      "  \"\"\"\n",
      "  collective_communication_options = {\n",
      "      None: tf.distribute.experimental.CollectiveCommunication.AUTO,\n",
      "      \"ring\": tf.distribute.experimental.CollectiveCommunication.RING,\n",
      "      \"nccl\": tf.distribute.experimental.CollectiveCommunication.NCCL\n",
      "  }\n",
      "  if all_reduce_alg not in collective_communication_options:\n",
      "    raise ValueError(\n",
      "        \"When used with `multi_worker_mirrored`, valid values for \"\n",
      "        \"all_reduce_alg are [`ring`, `nccl`].  Supplied value: {}\".format(\n",
      "            all_reduce_alg))\n",
      "  return collective_communication_options[all_reduce_alg]\n",
      "\n",
      "\n",
      "def _mirrored_cross_device_ops(all_reduce_alg, num_packs):\n",
      "  \"\"\"Return a CrossDeviceOps based on all_reduce_alg and num_packs.\n",
      "\n",
      "  Args:\n",
      "    all_reduce_alg: a string specifying which cross device op to pick, or None.\n",
      "    num_packs: an integer specifying number of packs for the cross device op.\n",
      "\n",
      "  Returns:\n",
      "    tf.distribute.CrossDeviceOps object or None.\n",
      "\n",
      "  Raises:\n",
      "    ValueError: if `all_reduce_alg` not in [None, \"nccl\", \"hierarchical_copy\"].\n",
      "  \"\"\"\n",
      "  if all_reduce_alg is None:\n",
      "    return None\n",
      "  mirrored_all_reduce_options = {\n",
      "      \"nccl\": tf.distribute.NcclAllReduce,\n",
      "      \"hierarchical_copy\": tf.distribute.HierarchicalCopyAllReduce\n",
      "  }\n",
      "  if all_reduce_alg not in mirrored_all_reduce_options:\n",
      "    raise ValueError(\n",
      "        \"When used with `mirrored`, valid values for all_reduce_alg are \"\n",
      "        \"[`nccl`, `hierarchical_copy`].  Supplied value: {}\".format(\n",
      "            all_reduce_alg))\n",
      "  cross_device_ops_class = mirrored_all_reduce_options[all_reduce_alg]\n",
      "  return cross_device_ops_class(num_packs=num_packs)\n",
      "\n",
      "\n",
      "def tpu_initialize(tpu_address):\n",
      "  \"\"\"Initializes TPU for TF 2.x training.\n",
      "\n",
      "  Args:\n",
      "    tpu_address: string, bns address of master TPU worker.\n",
      "\n",
      "  Returns:\n",
      "    A TPUClusterResolver.\n",
      "  \"\"\"\n",
      "  cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n",
      "      tpu=tpu_address)\n",
      "  if tpu_address not in (\"\", \"local\"):\n",
      "    tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
      "  tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
      "  return cluster_resolver\n",
      "\n",
      "\n",
      "def get_distribution_strategy(distribution_strategy=\"mirrored\",\n",
      "                              num_gpus=0,\n",
      "                              all_reduce_alg=None,\n",
      "                              num_packs=1,\n",
      "                              tpu_address=None):\n",
      "  \"\"\"Return a DistributionStrategy for running the model.\n",
      "\n",
      "  Args:\n",
      "    distribution_strategy: a string specifying which distribution strategy to\n",
      "      use. Accepted values are \"off\", \"one_device\", \"mirrored\",\n",
      "      \"parameter_server\", \"multi_worker_mirrored\", and \"tpu\" -- case\n",
      "      insensitive. \"off\" means not to use Distribution Strategy; \"tpu\" means to\n",
      "      use TPUStrategy using `tpu_address`.\n",
      "    num_gpus: Number of GPUs to run this model.\n",
      "    all_reduce_alg: Optional. Specifies which algorithm to use when performing\n",
      "      all-reduce. For `MirroredStrategy`, valid values are \"nccl\" and\n",
      "      \"hierarchical_copy\". For `MultiWorkerMirroredStrategy`, valid values are\n",
      "      \"ring\" and \"nccl\".  If None, DistributionStrategy will choose based on\n",
      "      device topology.\n",
      "    num_packs: Optional.  Sets the `num_packs` in `tf.distribute.NcclAllReduce`\n",
      "      or `tf.distribute.HierarchicalCopyAllReduce` for `MirroredStrategy`.\n",
      "    tpu_address: Optional. String that represents TPU to connect to. Must not be\n",
      "      None if `distribution_strategy` is set to `tpu`.\n",
      "\n",
      "  Returns:\n",
      "    tf.distribute.DistibutionStrategy object.\n",
      "  Raises:\n",
      "    ValueError: if `distribution_strategy` is \"off\" or \"one_device\" and\n",
      "      `num_gpus` is larger than 1; or `num_gpus` is negative or if\n",
      "      `distribution_strategy` is `tpu` but `tpu_address` is not specified.\n",
      "  \"\"\"\n",
      "  if num_gpus < 0:\n",
      "    raise ValueError(\"`num_gpus` can not be negative.\")\n",
      "\n",
      "  distribution_strategy = distribution_strategy.lower()\n",
      "  if distribution_strategy == \"off\":\n",
      "    if num_gpus > 1:\n",
      "      raise ValueError(\"When {} GPUs are specified, distribution_strategy \"\n",
      "                       \"flag cannot be set to `off`.\".format(num_gpus))\n",
      "    return None\n",
      "\n",
      "  if distribution_strategy == \"tpu\":\n",
      "    # When tpu_address is an empty string, we communicate with local TPUs.\n",
      "    cluster_resolver = tpu_initialize(tpu_address)\n",
      "    return tf.distribute.experimental.TPUStrategy(cluster_resolver)\n",
      "\n",
      "  if distribution_strategy == \"multi_worker_mirrored\":\n",
      "    return tf.distribute.experimental.MultiWorkerMirroredStrategy(\n",
      "        communication=_collective_communication(all_reduce_alg))\n",
      "\n",
      "  if distribution_strategy == \"one_device\":\n",
      "    if num_gpus == 0:\n",
      "      return tf.distribute.OneDeviceStrategy(\"device:CPU:0\")\n",
      "    if num_gpus > 1:\n",
      "      raise ValueError(\"`OneDeviceStrategy` can not be used for more than \"\n",
      "                       \"one device.\")\n",
      "    return tf.distribute.OneDeviceStrategy(\"device:GPU:0\")\n",
      "\n",
      "  if distribution_strategy == \"mirrored\":\n",
      "    if num_gpus == 0:\n",
      "      devices = [\"device:CPU:0\"]\n",
      "    else:\n",
      "      devices = [\"device:GPU:%d\" % i for i in range(num_gpus)]\n",
      "    return tf.distribute.MirroredStrategy(\n",
      "        devices=devices,\n",
      "        cross_device_ops=_mirrored_cross_device_ops(all_reduce_alg, num_packs))\n",
      "\n",
      "  if distribution_strategy == \"parameter_server\":\n",
      "    return tf.distribute.experimental.ParameterServerStrategy()\n",
      "\n",
      "  raise ValueError(\"Unrecognized Distribution Strategy: %r\" %\n",
      "                   distribution_strategy)\n",
      "\n",
      "\n",
      "def configure_cluster(worker_hosts=None, task_index=-1):\n",
      "  \"\"\"Set multi-worker cluster spec in TF_CONFIG environment variable.\n",
      "\n",
      "  Args:\n",
      "    worker_hosts: comma-separated list of worker ip:port pairs.\n",
      "\n",
      "  Returns:\n",
      "    Number of workers in the cluster.\n",
      "  \"\"\"\n",
      "  tf_config = json.loads(os.environ.get(\"TF_CONFIG\", \"{}\"))\n",
      "  if tf_config:\n",
      "    num_workers = (\n",
      "        len(tf_config[\"cluster\"].get(\"chief\", [])) +\n",
      "        len(tf_config[\"cluster\"].get(\"worker\", [])))\n",
      "  elif worker_hosts:\n",
      "    workers = worker_hosts.split(\",\")\n",
      "    num_workers = len(workers)\n",
      "    if num_workers > 1 and task_index < 0:\n",
      "      raise ValueError(\"Must specify task_index when number of workers > 1\")\n",
      "    task_index = 0 if num_workers == 1 else task_index\n",
      "    os.environ[\"TF_CONFIG\"] = json.dumps({\n",
      "        \"cluster\": {\n",
      "            \"worker\": workers\n",
      "        },\n",
      "        \"task\": {\n",
      "            \"type\": \"worker\",\n",
      "            \"index\": task_index\n",
      "        }\n",
      "    })\n",
      "  else:\n",
      "    num_workers = 1\n",
      "  return num_workers\n",
      "\n",
      "\n",
      "def get_strategy_scope(strategy):\n",
      "  if strategy:\n",
      "    strategy_scope = strategy.scope()\n",
      "  else:\n",
      "    strategy_scope = DummyContextManager()\n",
      "\n",
      "  return strategy_scope\n",
      "\n",
      "\n",
      "class DummyContextManager(object):\n",
      "\n",
      "  def __enter__(self):\n",
      "    pass\n",
      "\n",
      "  def __exit__(self, *args):\n",
      "    pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_file_content = python_files_df.iloc[1]['content']\n",
    "print(example_file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['json', 'os', 'random', 'string', 'absl', 'tensorflow']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(parsing_imports.get_modules(example_file_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_modules_string(modules):\n",
    "    public_modules = [mod for mod in modules if not mod[0] == '_']\n",
    "    return ' '.join(public_modules)\n",
    "\n",
    "\n",
    "def get_module_corpus(file_contents):\n",
    "    module_lists = []\n",
    "\n",
    "    for content in tqdm.tqdm(file_contents):\n",
    "        try:\n",
    "            module_lists.append(list(parsing_imports.get_modules(content)))\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "    module_import_strings = list(map(get_modules_string, module_lists))\n",
    "    return module_import_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 888935/888935 [17:39<00:00, 838.66it/s]  \n"
     ]
    }
   ],
   "source": [
    "module_import_corpus = get_module_corpus(python_files_df['content'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.CountVectorizer(max_features=5000,binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.98 s, sys: 526 µs, total: 3.99 s\n",
      "Wall time: 3.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "occurrence_matrix = vectorizer.fit_transform(module_import_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856442, 5000)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurrence_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurrence_matrix = occurrence_matrix.T @ occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = decomposition.NMF(n_components=50, alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 39s, sys: 1min 13s, total: 3min 52s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "module_vectors = nmf.fit_transform(cooccurrence_matrix.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_vectors = module_vectors / (np.linalg.norm(module_vectors, axis=1) + 1e-12)[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a00_common_functions',\n",
       " 'a2_base_model',\n",
       " 'a2c',\n",
       " 'a2c_ppo_acktr',\n",
       " 'a3c',\n",
       " 'aapi',\n",
       " 'abc',\n",
       " 'abps',\n",
       " 'abs_to_coco',\n",
       " 'absl',\n",
       " 'abstract',\n",
       " 'abstract_feature',\n",
       " 'abstract_game',\n",
       " 'abstract_kernel',\n",
       " 'abstract_transformation',\n",
       " 'accountant',\n",
       " 'accuracy',\n",
       " 'acd',\n",
       " 'acme',\n",
       " 'action',\n",
       " 'action_gap_rl',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'activation_clustering',\n",
       " 'activation_functions',\n",
       " 'activations',\n",
       " 'actor',\n",
       " 'adabound',\n",
       " 'adam',\n",
       " 'adamod',\n",
       " 'adamp',\n",
       " 'adamw',\n",
       " 'adapter',\n",
       " 'adapters',\n",
       " 'adaptive_avgmax_pool',\n",
       " 'adaptive_input',\n",
       " 'adaptive_softmax',\n",
       " 'add_target_dataset',\n",
       " 'adda',\n",
       " 'addict',\n",
       " 'ade',\n",
       " 'ade20k',\n",
       " 'adet',\n",
       " 'adet_checkpoint',\n",
       " 'adler',\n",
       " 'admm',\n",
       " 'adnc',\n",
       " 'adopty',\n",
       " 'advanced',\n",
       " 'adversarial',\n",
       " 'adversarial_attacks',\n",
       " 'adversarial_evaluation',\n",
       " 'adversarial_losses',\n",
       " 'adversarial_perturbations',\n",
       " 'adversarial_training',\n",
       " 'advertorch',\n",
       " 'ae',\n",
       " 'aetools',\n",
       " 'affine',\n",
       " 'affine_grid',\n",
       " 'agent',\n",
       " 'agent_action_proto_pb2',\n",
       " 'agent_info_proto_pb2',\n",
       " 'agents',\n",
       " 'aggregator',\n",
       " 'aggregators',\n",
       " 'ahoproc_tools',\n",
       " 'ai',\n",
       " 'ai_safety_gridworlds',\n",
       " 'aif360',\n",
       " 'aiflearn',\n",
       " 'aiml',\n",
       " 'aiohttp',\n",
       " 'airdialogue',\n",
       " 'airnet',\n",
       " 'airope_processors',\n",
       " 'airsim',\n",
       " 'airsimclient',\n",
       " 'aitom',\n",
       " 'aix360',\n",
       " 'akro',\n",
       " 'albumentations',\n",
       " 'ale_python_interface',\n",
       " 'alembic',\n",
       " 'alexnet',\n",
       " 'algae_dice',\n",
       " 'algo',\n",
       " 'algorithm',\n",
       " 'algorithms',\n",
       " 'algos',\n",
       " 'alias',\n",
       " 'alias_multinomial',\n",
       " 'align',\n",
       " 'align_dlib',\n",
       " 'aligned_reid',\n",
       " 'alignment',\n",
       " 'all',\n",
       " 'all_output6',\n",
       " 'allennlp',\n",
       " 'allennlp_rc',\n",
       " 'allrank',\n",
       " 'alphabet',\n",
       " 'alphaction',\n",
       " 'alphafold_casp13',\n",
       " 'altair',\n",
       " 'am',\n",
       " 'amortized_bo',\n",
       " 'amplification',\n",
       " 'ampligraph',\n",
       " 'amr',\n",
       " 'amr_utils',\n",
       " 'anago',\n",
       " 'analysis',\n",
       " 'analyzer',\n",
       " 'anchor',\n",
       " 'anchor_free_head',\n",
       " 'anchor_generator',\n",
       " 'anchor_head',\n",
       " 'anchor_heads',\n",
       " 'anchor_target',\n",
       " 'anchor_target_layer',\n",
       " 'anchors',\n",
       " 'ancile',\n",
       " 'angle',\n",
       " 'animalai',\n",
       " 'ann',\n",
       " 'anndata',\n",
       " 'annotation',\n",
       " 'annoy',\n",
       " 'ansi',\n",
       " 'ansitowin32',\n",
       " 'antisymmetric',\n",
       " 'antlr4',\n",
       " 'anytime_models',\n",
       " 'aofp',\n",
       " 'apache_beam',\n",
       " 'apex',\n",
       " 'apex_playground',\n",
       " 'api',\n",
       " 'api_pb2',\n",
       " 'app',\n",
       " 'append_token_dataset',\n",
       " 'application_util',\n",
       " 'applications',\n",
       " 'apply_bpe',\n",
       " 'approx',\n",
       " 'approx_max_iou_assigner',\n",
       " 'approximate_inference',\n",
       " 'april',\n",
       " 'aprl',\n",
       " 'arch',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " 'architectures',\n",
       " 'archs',\n",
       " 'arct',\n",
       " 'arff',\n",
       " 'argparse',\n",
       " 'argparser',\n",
       " 'args',\n",
       " 'argument',\n",
       " 'arguments',\n",
       " 'argus',\n",
       " 'arhuaco',\n",
       " 'arithmeticcoding',\n",
       " 'arma',\n",
       " 'array',\n",
       " 'arxiv_public_data',\n",
       " 'asdl',\n",
       " 'ase',\n",
       " 'asr_dataset',\n",
       " 'asr_test_base',\n",
       " 'asreview',\n",
       " 'assemblenet',\n",
       " 'assign_result',\n",
       " 'assign_sampling',\n",
       " 'assigners',\n",
       " 'ast',\n",
       " 'aster',\n",
       " 'asteroid',\n",
       " 'astor',\n",
       " 'astra',\n",
       " 'astropy',\n",
       " 'astunparse',\n",
       " 'asyncio',\n",
       " 'asynctest',\n",
       " 'atari_py',\n",
       " 'atari_wrappers',\n",
       " 'ateam',\n",
       " 'atexit',\n",
       " 'athene',\n",
       " 'atm',\n",
       " 'atss',\n",
       " 'atss_assigner',\n",
       " 'atss_head',\n",
       " 'attack',\n",
       " 'attacker',\n",
       " 'attacks',\n",
       " 'attacks_multigpu',\n",
       " 'attention',\n",
       " 'attention_layer',\n",
       " 'attention_registry',\n",
       " 'attmodel',\n",
       " 'attr',\n",
       " 'attrdict',\n",
       " 'attribute',\n",
       " 'attributed',\n",
       " 'attributepool',\n",
       " 'attribution',\n",
       " 'attribution_bottleneck',\n",
       " 'au_rcnn',\n",
       " 'auction_parameters',\n",
       " 'audio',\n",
       " 'audio_processing',\n",
       " 'audioutils',\n",
       " 'augment',\n",
       " 'augment_model',\n",
       " 'augment_model_final',\n",
       " 'augmentation',\n",
       " 'augmentation_transforms',\n",
       " 'augmentations',\n",
       " 'augmenters',\n",
       " 'augmentor',\n",
       " 'aup',\n",
       " 'auth',\n",
       " 'auto_augment',\n",
       " 'auto_itl',\n",
       " 'auto_lirpa',\n",
       " 'auto_ml',\n",
       " 'autoai_libs',\n",
       " 'autoalign',\n",
       " 'autoaugment',\n",
       " 'autocorrect',\n",
       " 'autoencoder',\n",
       " 'autogluon',\n",
       " 'autogluon_utils',\n",
       " 'autograd',\n",
       " 'autokeras',\n",
       " 'autolab_core',\n",
       " 'autoregressive',\n",
       " 'autosklearn',\n",
       " 'aux',\n",
       " 'auxiliaries',\n",
       " 'auxiliary',\n",
       " 'average_precision_calculator',\n",
       " 'averagemeter',\n",
       " 'avod',\n",
       " 'avsr',\n",
       " 'awa_helper',\n",
       " 'ax',\n",
       " 'axial',\n",
       " 'axondeepseg',\n",
       " 'azad',\n",
       " 'azure',\n",
       " 'azure_chestxray_utils',\n",
       " 'azureml',\n",
       " 'b3',\n",
       " 'baal',\n",
       " 'babble',\n",
       " 'babel',\n",
       " 'babi_tools',\n",
       " 'babyai',\n",
       " 'backbone',\n",
       " 'backbone_utils',\n",
       " 'backbones',\n",
       " 'backend',\n",
       " 'backends',\n",
       " 'backtranslation_dataset',\n",
       " 'baking',\n",
       " 'balanced_l1_loss',\n",
       " 'balanced_positive_negative_sampler',\n",
       " 'bam',\n",
       " 'bandits',\n",
       " 'bane',\n",
       " 'bangbang_qaoa',\n",
       " 'bartpy',\n",
       " 'base',\n",
       " 'base64',\n",
       " 'base_agent',\n",
       " 'base_arch',\n",
       " 'base_assigner',\n",
       " 'base_bbox_coder',\n",
       " 'base_config',\n",
       " 'base_dataset',\n",
       " 'base_dense_head',\n",
       " 'base_detector',\n",
       " 'base_image_dataset',\n",
       " 'base_layer',\n",
       " 'base_metric',\n",
       " 'base_model',\n",
       " 'base_models',\n",
       " 'base_module',\n",
       " 'base_networks',\n",
       " 'base_oc_block',\n",
       " 'base_options',\n",
       " 'base_policy',\n",
       " 'base_rnn',\n",
       " 'base_roi_head',\n",
       " 'base_sampler',\n",
       " 'base_test_case',\n",
       " 'base_trainer',\n",
       " 'base_video_dataset',\n",
       " 'base_weapon',\n",
       " 'base_wrapper_dataset',\n",
       " 'baseline',\n",
       " 'baseline_constants',\n",
       " 'baselines',\n",
       " 'baselines0',\n",
       " 'basemodel',\n",
       " 'basenet',\n",
       " 'basernn',\n",
       " 'bases',\n",
       " 'basetest_dqn_like',\n",
       " 'basetest_training',\n",
       " 'basic',\n",
       " 'basic_cnn',\n",
       " 'basic_layers',\n",
       " 'basic_models',\n",
       " 'basic_ops',\n",
       " 'basic_utils',\n",
       " 'basics',\n",
       " 'basicsr',\n",
       " 'basis_module',\n",
       " 'batch',\n",
       " 'batch_env',\n",
       " 'batch_norm',\n",
       " 'batch_science',\n",
       " 'batcher',\n",
       " 'batchgenerators',\n",
       " 'batching',\n",
       " 'batchnorm',\n",
       " 'batext',\n",
       " 'bayes_opt',\n",
       " 'bayesian_benchmarks',\n",
       " 'bayesiancoresets',\n",
       " 'bbox',\n",
       " 'bbox_aug',\n",
       " 'bbox_head',\n",
       " 'bbox_heads',\n",
       " 'bbox_nms',\n",
       " 'bbox_overlaps',\n",
       " 'bbox_target',\n",
       " 'bbox_transform',\n",
       " 'bc',\n",
       " 'bcnn',\n",
       " 'bcolz',\n",
       " 'beam',\n",
       " 'beam_search',\n",
       " 'beamable_mm',\n",
       " 'beamsearch',\n",
       " 'beer',\n",
       " 'behavior_regularized_offline_rl',\n",
       " 'belady',\n",
       " 'benchexec',\n",
       " 'benchmark',\n",
       " 'benchmark_args_utils',\n",
       " 'benchmark_utils',\n",
       " 'benchmarks',\n",
       " 'bernoulli',\n",
       " 'bert',\n",
       " 'bert_base',\n",
       " 'bert_dictionary',\n",
       " 'bert_dp',\n",
       " 'bert_model',\n",
       " 'bert_score',\n",
       " 'bert_serving',\n",
       " 'berttat',\n",
       " 'bezier_align',\n",
       " 'bfp',\n",
       " 'bidder',\n",
       " 'bifpn',\n",
       " 'big5freq',\n",
       " 'big5prober',\n",
       " 'bigclam',\n",
       " 'bigdl',\n",
       " 'bigg',\n",
       " 'bilm',\n",
       " 'bilm_model',\n",
       " 'bilstm',\n",
       " 'binarizer',\n",
       " 'binary_ops',\n",
       " 'binarybrain',\n",
       " 'binascii',\n",
       " 'bindings',\n",
       " 'bindsnet',\n",
       " 'binstr',\n",
       " 'binvox_rw',\n",
       " 'bio',\n",
       " 'birl',\n",
       " 'bisect',\n",
       " 'bisimulation_aaai2020',\n",
       " 'bitempered_loss',\n",
       " 'biunilm',\n",
       " 'blackboxauditing',\n",
       " 'blended_noise',\n",
       " 'blender_utils',\n",
       " 'blendmask',\n",
       " 'bleu',\n",
       " 'bleu_scorer',\n",
       " 'blingfire',\n",
       " 'blink',\n",
       " 'block',\n",
       " 'block_lazy_tensor',\n",
       " 'block_location_shuffle',\n",
       " 'block_pair_dataset',\n",
       " 'block_zoo',\n",
       " 'blocks',\n",
       " 'blocks_extras',\n",
       " 'blockwise_scramble',\n",
       " 'blockworld',\n",
       " 'bloom_filter',\n",
       " 'blur',\n",
       " 'bn',\n",
       " 'bninception',\n",
       " 'bnn_hmc',\n",
       " 'board',\n",
       " 'bokeh',\n",
       " 'boltons',\n",
       " 'bonus_based_exploration',\n",
       " 'boostne',\n",
       " 'bootstrap',\n",
       " 'borealisflows',\n",
       " 'bot_transfer',\n",
       " 'boto3',\n",
       " 'botocore',\n",
       " 'botorch',\n",
       " 'bottle',\n",
       " 'bottleneck',\n",
       " 'bound_base',\n",
       " 'bound_interval',\n",
       " 'bound_spectral',\n",
       " 'boundary_attack',\n",
       " 'bounding_box',\n",
       " 'bounding_box_utils',\n",
       " 'boundingbox',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'box2d',\n",
       " 'box_head',\n",
       " 'box_regression',\n",
       " 'box_util',\n",
       " 'box_utils',\n",
       " 'boxes',\n",
       " 'bpemb',\n",
       " 'bpy',\n",
       " 'brain',\n",
       " 'brain_parameters_proto_pb2',\n",
       " 'brewer2mpl',\n",
       " 'bristol',\n",
       " 'broadcasting',\n",
       " 'bs4',\n",
       " 'bson',\n",
       " 'bsuite',\n",
       " 'btb',\n",
       " 'bucket_io',\n",
       " 'bucket_pad_length_dataset',\n",
       " 'budgetnet',\n",
       " 'buffer',\n",
       " 'build',\n",
       " 'build_data',\n",
       " 'build_feature_matrix',\n",
       " 'build_loader',\n",
       " 'build_model',\n",
       " 'build_utils',\n",
       " 'build_vocab',\n",
       " 'builder',\n",
       " 'builders',\n",
       " 'builtins',\n",
       " 'bunch',\n",
       " 'butterfly',\n",
       " 'byol',\n",
       " 'bz2',\n",
       " 'bz2file',\n",
       " 'cache',\n",
       " 'cache_replacement',\n",
       " 'cached_property',\n",
       " 'cachemodel',\n",
       " 'cachetools',\n",
       " 'cadgan',\n",
       " 'cadm',\n",
       " 'caffe',\n",
       " 'caffe2',\n",
       " 'caffe_parser',\n",
       " 'cairo',\n",
       " 'cairosvg',\n",
       " 'calendar',\n",
       " 'calibration',\n",
       " 'call_glove',\n",
       " 'callback',\n",
       " 'callbacks',\n",
       " 'camera',\n",
       " 'camera_info',\n",
       " 'cameras',\n",
       " 'camvid',\n",
       " 'candle',\n",
       " 'capsule_em',\n",
       " 'capsulenetwork',\n",
       " 'captcha',\n",
       " 'caption',\n",
       " 'caption_model',\n",
       " 'captioning',\n",
       " 'captionmodel',\n",
       " 'captum',\n",
       " 'caql',\n",
       " 'car',\n",
       " 'carafe',\n",
       " 'card',\n",
       " 'carla',\n",
       " 'carla08',\n",
       " 'cascade_rcnn',\n",
       " 'cascadenet',\n",
       " 'catalog',\n",
       " 'catalyst',\n",
       " 'catalyst_gan',\n",
       " 'catamount',\n",
       " 'catboost',\n",
       " 'catch_carry',\n",
       " 'cate_estimator',\n",
       " 'categorical',\n",
       " 'category',\n",
       " 'catkin_pkg',\n",
       " 'causallib',\n",
       " 'causalml',\n",
       " 'cbfssm',\n",
       " 'cbrain',\n",
       " 'ccg2lambda_tools',\n",
       " 'cdt',\n",
       " 'celeba',\n",
       " 'celeba_dataset',\n",
       " 'celery',\n",
       " 'cells',\n",
       " 'cem',\n",
       " 'cement',\n",
       " 'center_loss',\n",
       " 'centermask',\n",
       " 'certifi',\n",
       " 'cffi',\n",
       " 'cfg',\n",
       " 'cfgs',\n",
       " 'cfq',\n",
       " 'cfq_pt_vs_sa',\n",
       " 'cgi',\n",
       " 'cgp',\n",
       " 'cgpm',\n",
       " 'chainer',\n",
       " 'chainer_',\n",
       " 'chainer_chemistry',\n",
       " 'chainer_sort',\n",
       " 'chainer_tests',\n",
       " 'chainercv',\n",
       " 'chainercv2',\n",
       " 'chainerkfac',\n",
       " 'chainermn',\n",
       " 'chainerrl',\n",
       " 'chainerx',\n",
       " 'chainerx_tests',\n",
       " 'character_token_embedder',\n",
       " 'chardet',\n",
       " 'chardistribution',\n",
       " 'charsetgroupprober',\n",
       " 'charsetprober',\n",
       " 'chasingtrainframework_generaloneclassdetection',\n",
       " 'checkmate',\n",
       " 'checkpoint',\n",
       " 'checkpoint_dumper',\n",
       " 'checkpointer',\n",
       " 'checkpoints',\n",
       " 'checkpts',\n",
       " 'chemprop',\n",
       " 'chemutils',\n",
       " 'cherry',\n",
       " 'chess',\n",
       " 'chex',\n",
       " 'childes_srl',\n",
       " 'chiral_layers',\n",
       " 'christmais',\n",
       " 'chumpy',\n",
       " 'cider',\n",
       " 'cider_scorer',\n",
       " 'cifar',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar100_dataset',\n",
       " 'cifar10_cls_dataset',\n",
       " 'cifar10_dataset',\n",
       " 'cifar10_input',\n",
       " 'cifar10_utils',\n",
       " 'cifar_data_provider',\n",
       " 'cifar_input',\n",
       " 'cimodel',\n",
       " 'cirq',\n",
       " 'cirtorch',\n",
       " 'cis',\n",
       " 'citation',\n",
       " 'cityscape',\n",
       " 'cityscapes',\n",
       " 'cityscapes_eval',\n",
       " 'cityscapesscripts',\n",
       " 'ck',\n",
       " 'clang',\n",
       " 'clarinet',\n",
       " 'class_ids',\n",
       " 'class_mapping',\n",
       " 'class_names',\n",
       " 'classes',\n",
       " 'classification',\n",
       " 'classification_models',\n",
       " 'classifier',\n",
       " 'classifiers',\n",
       " 'classify',\n",
       " 'cleanlab',\n",
       " 'cleverhans',\n",
       " 'cleverhans_copy',\n",
       " 'cleverhans_tutorials',\n",
       " 'clevr',\n",
       " 'clevr_robot_env',\n",
       " 'cli',\n",
       " 'click',\n",
       " 'client',\n",
       " 'clinicadl',\n",
       " 'clipper_admin',\n",
       " 'cloudpickle',\n",
       " 'cls_dataset',\n",
       " 'clusim',\n",
       " 'cluster',\n",
       " 'clustering',\n",
       " 'clustering_normalized_cuts',\n",
       " 'cma',\n",
       " 'cmath',\n",
       " 'cmd',\n",
       " 'cmlm_transformer',\n",
       " 'cner_config',\n",
       " 'cner_dischargenote',\n",
       " 'cnf',\n",
       " 'cnn',\n",
       " 'cnn_img',\n",
       " 'cnn_model',\n",
       " 'cnn_models',\n",
       " 'cnn_quantization',\n",
       " 'cnn_util',\n",
       " 'cnnpref',\n",
       " 'cntk',\n",
       " 'coatt',\n",
       " 'coco',\n",
       " 'coco_eval',\n",
       " 'coco_eval_wrapper',\n",
       " 'coco_evaluation',\n",
       " 'coco_tasks',\n",
       " 'coco_utils',\n",
       " 'cocoprep',\n",
       " 'code',\n",
       " 'codebase',\n",
       " 'codec',\n",
       " 'codecs',\n",
       " 'codenets',\n",
       " 'codingstatemachine',\n",
       " 'coilutils',\n",
       " 'cold_posterior_bnn',\n",
       " 'collaborative_attention',\n",
       " 'collagen',\n",
       " 'collate_batch',\n",
       " 'collaters',\n",
       " 'collect_env',\n",
       " 'collections',\n",
       " 'color',\n",
       " 'colorama',\n",
       " 'coloredlogs',\n",
       " 'colorful',\n",
       " 'colorize',\n",
       " 'colorize_dataset',\n",
       " 'colorlog',\n",
       " 'colormap',\n",
       " 'colors',\n",
       " 'colorsys',\n",
       " 'colour',\n",
       " 'combined_sampler',\n",
       " 'combo',\n",
       " 'comet_ml',\n",
       " 'comm',\n",
       " 'command',\n",
       " 'command_proto_pb2',\n",
       " 'commands',\n",
       " 'common',\n",
       " 'common_flags',\n",
       " 'common_head',\n",
       " 'common_path',\n",
       " 'common_setup',\n",
       " 'common_structs',\n",
       " 'common_trainer',\n",
       " 'common_utils',\n",
       " 'commons',\n",
       " 'commpy',\n",
       " 'communicator',\n",
       " 'communicator_objects',\n",
       " 'community',\n",
       " 'compare_gan',\n",
       " 'compat',\n",
       " 'compileall',\n",
       " 'compiler',\n",
       " 'compilers',\n",
       " 'compiling_info',\n",
       " 'complex',\n",
       " 'complex_utils',\n",
       " 'compmem',\n",
       " 'component',\n",
       " 'components',\n",
       " 'compose',\n",
       " 'composes',\n",
       " 'composite_encoder',\n",
       " 'composites_utils',\n",
       " 'compression',\n",
       " 'compute',\n",
       " 'compute_associations',\n",
       " 'compute_flops',\n",
       " 'concat_dataset',\n",
       " 'concat_sentences_dataset',\n",
       " 'concern',\n",
       " 'concurrency',\n",
       " 'concurrent',\n",
       " 'cond_conv2d',\n",
       " 'cond_fn',\n",
       " 'condinst',\n",
       " 'conditionals',\n",
       " 'conf',\n",
       " 'conf_constant_costfunctions',\n",
       " 'conferences',\n",
       " 'confidnet',\n",
       " 'config',\n",
       " 'config_bayesian',\n",
       " 'config_dataset',\n",
       " 'config_rnn',\n",
       " 'config_training',\n",
       " 'config_util',\n",
       " 'configargparse',\n",
       " 'configparser',\n",
       " 'configs',\n",
       " 'configspace',\n",
       " 'configurable',\n",
       " 'configuration',\n",
       " 'configuration_albert',\n",
       " 'configuration_auto',\n",
       " 'configuration_bart',\n",
       " 'configuration_bert',\n",
       " 'configuration_bert_generation',\n",
       " 'configuration_bert_masked',\n",
       " 'configuration_bertabs',\n",
       " 'configuration_camembert',\n",
       " 'configuration_common_test',\n",
       " 'configuration_ctrl',\n",
       " 'configuration_distilbert',\n",
       " 'configuration_dpr',\n",
       " 'configuration_electra',\n",
       " 'configuration_encoder_decoder',\n",
       " 'configuration_flaubert',\n",
       " 'configuration_funnel',\n",
       " 'configuration_gpt2',\n",
       " 'configuration_longformer',\n",
       " 'configuration_lxmert',\n",
       " 'configuration_marian',\n",
       " 'configuration_mbart',\n",
       " 'configuration_mmbt',\n",
       " 'configuration_mobilebert',\n",
       " 'configuration_openai',\n",
       " 'configuration_pegasus',\n",
       " 'configuration_reformer',\n",
       " 'configuration_retribert',\n",
       " 'configuration_roberta',\n",
       " 'configuration_t5',\n",
       " 'configuration_transfo_xl',\n",
       " 'configuration_utils',\n",
       " 'configuration_xlm',\n",
       " 'configuration_xlm_roberta',\n",
       " 'configuration_xlnet',\n",
       " 'configuration_xxx',\n",
       " 'configurations',\n",
       " 'configurationsmulticlass',\n",
       " 'configurationsprimetest',\n",
       " 'configure',\n",
       " 'configure_data',\n",
       " 'configure_finetuning',\n",
       " 'conftest',\n",
       " 'conll',\n",
       " 'conllu',\n",
       " 'connection',\n",
       " 'connectionpool',\n",
       " 'conqur',\n",
       " 'const',\n",
       " 'constant',\n",
       " 'constants',\n",
       " 'constraint',\n",
       " 'constraints',\n",
       " 'consts',\n",
       " 'container',\n",
       " 'containers',\n",
       " 'context',\n",
       " 'context_block',\n",
       " 'contextlib',\n",
       " 'contextlib2',\n",
       " 'continual_learner',\n",
       " 'contractions',\n",
       " 'contrast',\n",
       " 'contrib',\n",
       " 'control',\n",
       " 'controller',\n",
       " 'controllers',\n",
       " 'conv',\n",
       " 'conv2d',\n",
       " 'conv2d_same',\n",
       " 'conv_bn_act',\n",
       " 'conv_module',\n",
       " 'conv_tbc',\n",
       " 'conv_with_kaiming_uniform',\n",
       " 'conv_ws',\n",
       " 'convert',\n",
       " 'convert_bart_original_pytorch_checkpoint_to_pytorch',\n",
       " 'convert_pl_checkpoint_to_hf',\n",
       " 'convert_symbol',\n",
       " 'converter',\n",
       " 'convex_adversarial',\n",
       " 'convfc_bbox_head',\n",
       " 'convlab2',\n",
       " 'convnet',\n",
       " 'convolution',\n",
       " 'convolutional',\n",
       " 'cookies',\n",
       " 'copy',\n",
       " 'copy_of_sgd',\n",
       " 'copy_reg',\n",
       " 'copycat',\n",
       " 'copyreg',\n",
       " 'coq',\n",
       " 'coq_analyzer',\n",
       " 'core',\n",
       " 'coref_model',\n",
       " 'coref_ops',\n",
       " 'coremltools',\n",
       " 'corenet',\n",
       " 'corenlp',\n",
       " 'coreset',\n",
       " 'cormorant',\n",
       " 'corpus',\n",
       " 'corpus_processing',\n",
       " 'corpusiterator',\n",
       " 'corpusiteratorwiki',\n",
       " 'corpusiteratorwikiwords',\n",
       " 'correct_batch_effects_wdn',\n",
       " 'correlation',\n",
       " 'correlation_clustering',\n",
       " 'correlation_cuda',\n",
       " 'correlation_package',\n",
       " 'cort',\n",
       " 'cosine_lr',\n",
       " 'costar_models',\n",
       " 'costar_task_plan',\n",
       " 'costs',\n",
       " 'coupled_deep_cph',\n",
       " 'coupled_deep_cph_utils',\n",
       " 'coupled_deep_cph_vae',\n",
       " 'coupling',\n",
       " 'cox',\n",
       " 'cp949prober',\n",
       " 'cpab',\n",
       " 'cpickle',\n",
       " 'cplex',\n",
       " 'cpp',\n",
       " 'cpp_wrappers',\n",
       " 'cprofile',\n",
       " 'cpu_nms',\n",
       " 'create_act',\n",
       " 'create_conv2d',\n",
       " 'create_norm_act',\n",
       " 'create_tokenizer',\n",
       " 'creates',\n",
       " 'crf',\n",
       " 'crfnet',\n",
       " 'criteria',\n",
       " 'criterion',\n",
       " 'critic',\n",
       " 'crnn',\n",
       " 'crnn_model',\n",
       " 'crocodl',\n",
       " 'cross_entropy',\n",
       " 'cross_entropy_loss',\n",
       " 'crowd_nav',\n",
       " 'crowd_sim',\n",
       " 'cryptography',\n",
       " 'cs',\n",
       " 'cs_gan',\n",
       " 'csbdeep',\n",
       " 'cshelpers',\n",
       " 'csrank',\n",
       " 'cstringio',\n",
       " 'csv',\n",
       " 'csv_handler',\n",
       " 'csvec',\n",
       " 'ctc_decoders',\n",
       " 'ctdet',\n",
       " 'ctpn',\n",
       " 'ctrnn_model',\n",
       " 'ctypes',\n",
       " 'cube',\n",
       " 'cubert',\n",
       " 'cuda',\n",
       " 'cupy',\n",
       " 'curl',\n",
       " 'curline_file',\n",
       " 'curriculum',\n",
       " 'curses',\n",
       " 'custom',\n",
       " 'custom_getters',\n",
       " 'custom_hyperparameters',\n",
       " 'custom_layers',\n",
       " 'custom_lpips',\n",
       " 'custom_metrics',\n",
       " 'custom_ops',\n",
       " 'custom_trading_env',\n",
       " 'custom_transforms',\n",
       " 'customize',\n",
       " 'cv',\n",
       " 'cv2',\n",
       " 'cv_bridge',\n",
       " 'cvangysel',\n",
       " 'cvpack',\n",
       " 'cvx2',\n",
       " 'cvxopt',\n",
       " 'cvxpy',\n",
       " 'cvxpylayers',\n",
       " 'cycada',\n",
       " 'cycler',\n",
       " 'cython',\n",
       " 'cython_bbox',\n",
       " 'cytoolz',\n",
       " 'd2t',\n",
       " 'd3m',\n",
       " 'd4',\n",
       " 'daiquiri',\n",
       " 'danmf',\n",
       " 'darc_agent',\n",
       " 'darc_envs',\n",
       " 'darknet',\n",
       " 'darkon',\n",
       " 'dash',\n",
       " 'dash_core_components',\n",
       " 'dash_html_components',\n",
       " 'dask',\n",
       " 'dask_jobqueue',\n",
       " 'data',\n",
       " 'data_augment',\n",
       " 'data_engine',\n",
       " 'data_file',\n",
       " 'data_formatters',\n",
       " 'data_gen',\n",
       " 'data_generation',\n",
       " 'data_generator',\n",
       " 'data_generators',\n",
       " 'data_handler',\n",
       " 'data_handlers',\n",
       " 'data_helper',\n",
       " 'data_helper_covertype',\n",
       " 'data_helpers',\n",
       " 'data_info',\n",
       " 'data_input',\n",
       " 'data_io',\n",
       " 'data_iter',\n",
       " 'data_iterator',\n",
       " 'data_list',\n",
       " 'data_load',\n",
       " 'data_loader',\n",
       " 'data_loaders',\n",
       " 'data_manager',\n",
       " 'data_parallel',\n",
       " 'data_prep_util',\n",
       " 'data_preparation',\n",
       " 'data_preprocessing',\n",
       " 'data_process',\n",
       " 'data_processing',\n",
       " 'data_processor',\n",
       " 'data_provider',\n",
       " 'data_providers',\n",
       " 'data_reader',\n",
       " 'data_sets',\n",
       " 'data_sources',\n",
       " 'data_store',\n",
       " 'data_stream',\n",
       " 'data_structures',\n",
       " 'data_util',\n",
       " 'data_util_zhihu',\n",
       " 'data_utils',\n",
       " 'database',\n",
       " 'database_connector',\n",
       " 'dataclasses',\n",
       " 'dataflow',\n",
       " 'dataframe',\n",
       " 'datagen',\n",
       " 'datagenerator',\n",
       " 'datahandler',\n",
       " 'datahelpers',\n",
       " 'dataio',\n",
       " 'dataload',\n",
       " 'dataloader',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['numpy',\n",
       " 'os',\n",
       " 'tensorflow',\n",
       " 'torch',\n",
       " 'sys',\n",
       " 'argparse',\n",
       " 'math',\n",
       " 'time',\n",
       " 'collections',\n",
       " 'utils']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_module_idxs = np.array(occurrence_matrix.sum(axis=0))[0].argsort()[::-1][:10]\n",
    "modules = vectorizer.get_feature_names()\n",
    "\n",
    "[modules[i] for i in top_module_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec format\n",
    "\n",
    "Functions for writing a numpy matrix with specified vocabulary as Word2Vec format.\n",
    "\n",
    "This is useful as such format can be loaded using gensim KeyedVectors class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def _word_vectors_to_word2vec_format_generator(vocabulary, word_vectors):\n",
    "    for (word, vector) in zip(vocabulary, word_vectors):\n",
    "        yield word + ' ' + ' '.join([str('{:.5f}'.format(f)) for f in vector])\n",
    "\n",
    "        \n",
    "def store_word_vectors(words, word_vectors, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(str(len(words)) + ' ' + str(word_vectors.shape[1]) + '\\n')\n",
    "        for line in _word_vectors_to_word2vec_format_generator(words, module_vectors):\n",
    "            f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_word_vectors(modules, module_vectors, 'data/nmf_module_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_keyed_vectors = gensim.models.KeyedVectors.load_word2vec_format('data/nmf_module_vectors.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/conda/envs/ml/lib/python3.7/site-packages/gensim/models/keyedvectors.py:2389: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (m / dist).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('confidnet', 0.901949942111969),\n",
       " ('correlation_package', 0.8937965035438538),\n",
       " ('corenet', 0.8932680487632751),\n",
       " ('backbone', 0.8890403509140015),\n",
       " ('lnets', 0.8880048990249634),\n",
       " ('roi_heads', 0.8856840133666992),\n",
       " ('deepem', 0.8751028776168823),\n",
       " ('functions', 0.8749309182167053),\n",
       " ('slimcut', 0.8740584254264832),\n",
       " ('resblocks', 0.8708397150039673)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('planet', 0.936939001083374),\n",
       " ('tensor2tensor', 0.9350528120994568),\n",
       " ('fivo', 0.933452308177948),\n",
       " ('magenta', 0.9310630559921265),\n",
       " ('open_seq2seq', 0.9295987486839294),\n",
       " ('pointcnn', 0.9281453490257263),\n",
       " ('dragnn', 0.9206544756889343),\n",
       " ('task_adaptation', 0.9179682731628418),\n",
       " ('openseq2seq', 0.915902853012085),\n",
       " ('texar', 0.9105595946311951)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('resnet50', 0.9902965426445007),\n",
       " ('crfnet', 0.9791890382766724),\n",
       " ('example_correctness_test_utils', 0.9787250757217407),\n",
       " ('dvrk', 0.9767580628395081),\n",
       " ('multi_sampler', 0.9744220972061157),\n",
       " ('fpn_network', 0.9725858569145203),\n",
       " ('pysts', 0.9711136817932129),\n",
       " ('other_utils', 0.9696723818778992),\n",
       " ('multi', 0.9658380150794983),\n",
       " ('mhp_loss', 0.9654721617698669)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test_base', 0.988355278968811),\n",
       " ('decisiontree', 0.9822568893432617),\n",
       " ('treeinterpreter', 0.9801574349403381),\n",
       " ('lale', 0.9794420599937439),\n",
       " ('modl', 0.9713461995124817),\n",
       " ('modal', 0.9607591032981873),\n",
       " ('tpot', 0.9551683068275452),\n",
       " ('tdparse', 0.9530482888221741),\n",
       " ('rllim', 0.9527280926704407),\n",
       " ('readdata', 0.9506838917732239)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('sklearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('python_visual_mpc', 0.8991244435310364),\n",
       " ('simple_tokenizer', 0.8910014033317566),\n",
       " ('download_gdrive', 0.8768919110298157),\n",
       " ('awa_helper', 0.8731268644332886),\n",
       " ('netdef_slim', 0.8731244802474976),\n",
       " ('notebook_runner', 0.8731184601783752),\n",
       " ('register_coco', 0.8730090856552124),\n",
       " ('pycodestyle', 0.8702559471130371),\n",
       " ('fairseq_lr_scheduler', 0.8690776228904724),\n",
       " ('fairseq_optimizer', 0.8654027581214905)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('os')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pycorrector', 0.9400977492332458),\n",
       " ('pythainlp', 0.9391024112701416),\n",
       " ('qamodel', 0.9381730556488037),\n",
       " ('charsetprober', 0.9379682540893555),\n",
       " ('helperinclude', 0.9373955130577087),\n",
       " ('ansitowin32', 0.9370496869087219),\n",
       " ('new_tihtn_planner', 0.9369609951972961),\n",
       " ('blockworld', 0.9369609951972961),\n",
       " ('codingstatemachine', 0.9369609951972961),\n",
       " ('chardistribution', 0.9369609951972961)]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_keyed_vectors.most_similar('sys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
