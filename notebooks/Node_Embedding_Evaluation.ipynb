{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96371c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp node_embedding_evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a22e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import csrgraph as cg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from github_search import python_tokens, paperswithcode_tasks\n",
    "from mlutil.feature_extraction import embeddings\n",
    "from mlutil import prototype_selection\n",
    "import mlutil\n",
    "from mlutil.feature_extraction import embeddings \n",
    "\n",
    "import ast\n",
    "import astunparse\n",
    "import csrgraph\n",
    "import nodevectors\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import igraph\n",
    "from sklearn import metrics\n",
    "import gensim\n",
    "\n",
    "from operator import itemgetter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c97fe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6787788",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df = pd.read_csv('data/dependency_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1775d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = list(dependency_records_df.iloc[:,[1,0]].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe3d0473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def make_igraph(call_records_df):\n",
    "    vertices = list(set(call_records_df['source'].unique()).union(call_records_df['destination'].unique()))\n",
    "    edges = [\n",
    "        (source, destination)\n",
    "        for (source, destination) in zip(\n",
    "            call_records_df['source'].values,\n",
    "            call_records_df['destination'].values\n",
    "        )\n",
    "    ]\n",
    "    graph = igraph.Graph()\n",
    "    graph.add_vertices(vertices)\n",
    "    graph.add_edges(edges)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05cd7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = make_igraph(dependency_records_df[['source', 'destination']].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291319c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graph, open(\"data/call_igraph.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c2726f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "197702"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.vcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fb82bc62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Clustering with 197702 elements and 1 clusters'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.components().summary() #()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4c40e",
   "metadata": {},
   "source": [
    "## nodevectors & csrgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01560a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "\n",
    "def get_nodes(call_graph, node_names):\n",
    "    selected_nodes = call_graph.names[call_graph.names.isin(node_names)]\n",
    "    return selected_nodes\n",
    "\n",
    "\n",
    "def get_node_embedding_model_and_results(node_embeddings, call_graph, example_nodes, selected_names=None, topk=10):\n",
    "    if selected_names is None:\n",
    "        selected_nodes = call_graph.names\n",
    "    else:\n",
    "        selected_nodes = get_node_indices(call_graph, selected_names)\n",
    "        \n",
    "    \n",
    "    results = []\n",
    "    for (i, node_name) in enumerate(example_nodes.values):\n",
    "        distances = metrics.euclidean_distances(node_embeddings[example_nodes.index[[i]]], node_embeddings) \n",
    "        results.append((call_graph.names[np.argsort(distances)[0,:topk]].values))\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.index =  example_nodes.values\n",
    "    return results_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "980fd749",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df[['source', 'destination']].to_csv('data/dependency_records_raw.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3fe21007",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_graph = cg.read_edgelist('data/dependency_records_raw.csv', sep=',')\n",
    "example_nodes = get_nodes(call_graph, example_node_names)\n",
    "pickle.dump(call_graph, open('call_csrgraph.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d0d41452",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_repo_node_names = [\n",
    "    'fairseq', 'mmdetection', 'transformers', 'Recommenders-movielens', 'xfer', 'wgan'\n",
    "]\n",
    "example_node_names = [\n",
    "    'train', 'fit', 'test', '__init__', 'DistilBertForMaskedLM',\n",
    "    'tensorflow', \n",
    "    'hate-speech-detection', 'variational-dropout-sparsifies-dnn']\n",
    "\n",
    "\n",
    "\n",
    "def get_node_indices(call_graph, node_names):\n",
    "    return call_graph.names.isin(node_names)\n",
    "\n",
    "\n",
    "def get_nodes(call_graph, node_names):\n",
    "    return call_graph.names[call_graph.names.isin(node_names)]\n",
    "\n",
    "\n",
    "example_nodes = get_nodes(call_graph, example_node_names)\n",
    "example_repo_nodes = get_nodes(call_graph, example_repo_node_names)\n",
    "\n",
    "\n",
    "def get_node_embedding_model_and_results(\n",
    "        node_embeddings,\n",
    "        call_graph,\n",
    "        example_nodes,\n",
    "        selected_names=None,\n",
    "        topk=10\n",
    "    ):\n",
    "    if not selected_names is None:\n",
    "        selected_node_indices = get_node_indices(call_graph, selected_names)\n",
    "        compared_node_embeddings = node_embeddings[selected_node_indices]\n",
    "    else:\n",
    "        compared_node_embeddings = node_embeddings\n",
    "        \n",
    "    print(len(node_embeddings))\n",
    "    results = []\n",
    "    for (i, node_name) in enumerate(example_nodes.values):\n",
    "        distances = metrics.euclidean_distances(node_embeddings[example_nodes.index[[i]]], compared_node_embeddings) \n",
    "        results.append((call_graph.names[np.argsort(distances)[0,:topk]].values))\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.index =  example_nodes.values\n",
    "    return results_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7382cc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "185735    transformers\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nodes(call_graph, ['transformers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c15e02f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30484</th>\n",
       "      <td>fairseq</td>\n",
       "      <td>__init__</td>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30485</th>\n",
       "      <td>fairseq</td>\n",
       "      <td>conf</td>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source destination edge_type\n",
       "30484  fairseq    __init__      repo\n",
       "30485  fairseq        conf      repo"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df[dependency_records_df['source'] == 'fairseq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89d0f1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>fairseq</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12235</th>\n",
       "      <td>IR2</td>\n",
       "      <td>fairseq</td>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       source destination edge_type\n",
       "1878   <ROOT>     fairseq      root\n",
       "12235     IR2     fairseq      repo"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df[dependency_records_df['destination'] == 'fairseq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9a59aa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>-Adversarial-Latent-Autoencoders</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>110kDBRD</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>2020-CBMS-DoubleU-Net</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>2020-NeurIPS-CLEARER</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>2020-Ultramicro-fast</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2802</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>yolov3_jetbot</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>yolov4_train</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2804</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>youtube</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>youtube-8m</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>&lt;ROOT&gt;</td>\n",
       "      <td>zsl-gcn-pth</td>\n",
       "      <td>root</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2807 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      source                       destination edge_type\n",
       "0     <ROOT>  -Adversarial-Latent-Autoencoders      root\n",
       "1     <ROOT>                          110kDBRD      root\n",
       "2     <ROOT>             2020-CBMS-DoubleU-Net      root\n",
       "3     <ROOT>              2020-NeurIPS-CLEARER      root\n",
       "4     <ROOT>              2020-Ultramicro-fast      root\n",
       "...      ...                               ...       ...\n",
       "2802  <ROOT>                     yolov3_jetbot      root\n",
       "2803  <ROOT>                      yolov4_train      root\n",
       "2804  <ROOT>                           youtube      root\n",
       "2805  <ROOT>                        youtube-8m      root\n",
       "2806  <ROOT>                       zsl-gcn-pth      root\n",
       "\n",
       "[2807 rows x 3 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df[dependency_records_df['source'] == '<ROOT>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a19521cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_graph_nodes = call_graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b2af9140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['source', 'destination', 'edge_type'], dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0affdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_graph_repo_nodes = call_graph_nodes[call_graph_nodes.isin(dependency_records_df[dependency_records_df['edge_type'] == 'repo']['source'])].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "457541a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "      <th>edge_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32209</th>\n",
       "      <td>hate-speech-detection</td>\n",
       "      <td>test</td>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32210</th>\n",
       "      <td>hate-speech-detection</td>\n",
       "      <td>train</td>\n",
       "      <td>repo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      source destination edge_type\n",
       "32209  hate-speech-detection        test      repo\n",
       "32210  hate-speech-detection       train      repo"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df[dependency_records_df['source'] == 'hate-speech-detection']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8be5e43",
   "metadata": {},
   "source": [
    "%%time\n",
    "ggvec_model = nodevectors.GGVec(n_components=100, max_epoch=1000)\n",
    "ggvec_embeddings = ggvec_model.fit_transform(call_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4200983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 24s, sys: 1min 27s, total: 3min 51s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "prone_model = nodevectors.ProNE(n_components=100, step=100)\n",
    "prone_embeddings = prone_model.fit_transform(call_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c542558",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "get_node_embedding_model_and_results(ggvec_embeddings, call_graph, example_repo_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "03fddc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"ElapsedTime\" in call_graph_repo_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "188e0f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84180         fairseq\n",
       "124656    mmdetection\n",
       "193654           wgan\n",
       "195959           xfer\n",
       "dtype: object"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_repo_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "61ebc0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommenders-movielens</th>\n",
       "      <th>fairseq</th>\n",
       "      <th>mmdetection</th>\n",
       "      <th>transformers</th>\n",
       "      <th>wgan</th>\n",
       "      <th>xfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recommenders-movielens</td>\n",
       "      <td>fairseq</td>\n",
       "      <td>mmdetection</td>\n",
       "      <td>transformers</td>\n",
       "      <td>wgan</td>\n",
       "      <td>xfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict2</td>\n",
       "      <td>autopool</td>\n",
       "      <td>StandAloneSelfAttentionCifar10</td>\n",
       "      <td>showoff</td>\n",
       "      <td>wgancnnmimic</td>\n",
       "      <td>klcpd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutual-Channel-Loss</td>\n",
       "      <td>test_modelling_funcs</td>\n",
       "      <td>ResBlockCifar10</td>\n",
       "      <td>show_offset</td>\n",
       "      <td>ive</td>\n",
       "      <td>training-mixed-precision-quantized-networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdcar</td>\n",
       "      <td>plotting_with_arrows</td>\n",
       "      <td>chirality_nets</td>\n",
       "      <td>ICP</td>\n",
       "      <td>train_multi_gpu</td>\n",
       "      <td>intrinsic-rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep_exchangeable_tensors</td>\n",
       "      <td>product_kernel</td>\n",
       "      <td>coco_semantic_segmentation_dataset</td>\n",
       "      <td>hello_car</td>\n",
       "      <td>build_train_transformer</td>\n",
       "      <td>esrnn_torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>samplefocus2</td>\n",
       "      <td>fabolas</td>\n",
       "      <td>_random_saturation</td>\n",
       "      <td>print_hook</td>\n",
       "      <td>base_sampler</td>\n",
       "      <td>text-to-image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>round_through</td>\n",
       "      <td>from_hyperparameters</td>\n",
       "      <td>_random_hue</td>\n",
       "      <td>aligning</td>\n",
       "      <td>features_config</td>\n",
       "      <td>test_finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ant_data_collect</td>\n",
       "      <td>OpenMatch</td>\n",
       "      <td>_random_lighting_noise</td>\n",
       "      <td>dropout_unet</td>\n",
       "      <td>def_autoencoder_training</td>\n",
       "      <td>config_dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_all_transfer_irl</td>\n",
       "      <td>ElapsedTime</td>\n",
       "      <td>gmvi</td>\n",
       "      <td>residual_short</td>\n",
       "      <td>global_config</td>\n",
       "      <td>MS-CornerNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ant_irl_debug</td>\n",
       "      <td>elmo-chinese-oversimplified</td>\n",
       "      <td>ram</td>\n",
       "      <td>dependency</td>\n",
       "      <td>modeling_rgcn</td>\n",
       "      <td>VisionForPedestrian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recommenders-movielens                      fairseq  \\\n",
       "0     Recommenders-movielens                      fairseq   \n",
       "1                   predict2                     autopool   \n",
       "2        Mutual-Channel-Loss         test_modelling_funcs   \n",
       "3                      sdcar         plotting_with_arrows   \n",
       "4  deep_exchangeable_tensors               product_kernel   \n",
       "5               samplefocus2                      fabolas   \n",
       "6              round_through         from_hyperparameters   \n",
       "7           ant_data_collect                    OpenMatch   \n",
       "8       run_all_transfer_irl                  ElapsedTime   \n",
       "9              ant_irl_debug  elmo-chinese-oversimplified   \n",
       "\n",
       "                          mmdetection    transformers  \\\n",
       "0                         mmdetection    transformers   \n",
       "1      StandAloneSelfAttentionCifar10         showoff   \n",
       "2                     ResBlockCifar10     show_offset   \n",
       "3                      chirality_nets             ICP   \n",
       "4  coco_semantic_segmentation_dataset       hello_car   \n",
       "5                  _random_saturation      print_hook   \n",
       "6                         _random_hue        aligning   \n",
       "7              _random_lighting_noise    dropout_unet   \n",
       "8                                gmvi  residual_short   \n",
       "9                                 ram      dependency   \n",
       "\n",
       "                       wgan                                         xfer  \n",
       "0                      wgan                                         xfer  \n",
       "1              wgancnnmimic                                        klcpd  \n",
       "2                       ive  training-mixed-precision-quantized-networks  \n",
       "3           train_multi_gpu                            intrinsic-rewards  \n",
       "4   build_train_transformer                                  esrnn_torch  \n",
       "5              base_sampler                                text-to-image  \n",
       "6           features_config                              test_finetuning  \n",
       "7  def_autoencoder_training                                  config_dict  \n",
       "8             global_config                                 MS-CornerNet  \n",
       "9             modeling_rgcn                          VisionForPedestrian  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_repo_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8629a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommenders-movielens</th>\n",
       "      <th>fairseq</th>\n",
       "      <th>mmdetection</th>\n",
       "      <th>transformers</th>\n",
       "      <th>wgan</th>\n",
       "      <th>xfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AimsunKernelScenario</td>\n",
       "      <td>AuxEncoder</td>\n",
       "      <td>BFFT</td>\n",
       "      <td>BaseTestClass</td>\n",
       "      <td>BasicDecoder</td>\n",
       "      <td>BasicLSTMCell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdamaxOptimizer</td>\n",
       "      <td>AsciiTable</td>\n",
       "      <td>Att_P</td>\n",
       "      <td>AnswerAccessor</td>\n",
       "      <td>BIDILSTM</td>\n",
       "      <td>BBoxUtility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BalancedPositiveNegativeSampler</td>\n",
       "      <td>AddMaskParamsToBatch</td>\n",
       "      <td>AnswerType</td>\n",
       "      <td>BaseEncoder</td>\n",
       "      <td>AuthenticationError</td>\n",
       "      <td>BaseSuperResolutionModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AudioEncoder</td>\n",
       "      <td>BODY_UV_ON</td>\n",
       "      <td>Att_PD</td>\n",
       "      <td>0001_initial</td>\n",
       "      <td>AccessSpecifier</td>\n",
       "      <td>BBGT_ymax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AdvPatch_dir</td>\n",
       "      <td>AutoPilotBaseline</td>\n",
       "      <td>AnswererAgent</td>\n",
       "      <td>AIF_CNN_RaIS</td>\n",
       "      <td>AddSign</td>\n",
       "      <td>AutoencoderODEfunc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Anti</td>\n",
       "      <td>BSDS500Crop128</td>\n",
       "      <td>BFS</td>\n",
       "      <td>ATTPNLT</td>\n",
       "      <td>Auditor</td>\n",
       "      <td>BasePredModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AimsunKernelSimulation</td>\n",
       "      <td>BENCHMARK</td>\n",
       "      <td>ASPP</td>\n",
       "      <td>ADE20KTestImageDataset</td>\n",
       "      <td>BNN_Kernel</td>\n",
       "      <td>ActiveSearcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BaseEmbed</td>\n",
       "      <td>BIDILSTM</td>\n",
       "      <td>AttPoolLayer</td>\n",
       "      <td>AxisError</td>\n",
       "      <td>AlternatingTrainer</td>\n",
       "      <td>ApplyAttention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BSDS500PipelinesGray</td>\n",
       "      <td>BaseGenerationDataset</td>\n",
       "      <td>AttU_Net</td>\n",
       "      <td>ArcFaceModel</td>\n",
       "      <td>BERTEncoder</td>\n",
       "      <td>BBS-Net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alpha1_auc</td>\n",
       "      <td>BGModelMetric</td>\n",
       "      <td>AttUnitBiLi</td>\n",
       "      <td>BERT_cluster_sentences</td>\n",
       "      <td>Analogy</td>\n",
       "      <td>4_collect_experiments_dtu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Recommenders-movielens                fairseq    mmdetection  \\\n",
       "0             AimsunKernelScenario             AuxEncoder           BFFT   \n",
       "1                  AdamaxOptimizer             AsciiTable          Att_P   \n",
       "2  BalancedPositiveNegativeSampler   AddMaskParamsToBatch     AnswerType   \n",
       "3                     AudioEncoder             BODY_UV_ON         Att_PD   \n",
       "4                     AdvPatch_dir      AutoPilotBaseline  AnswererAgent   \n",
       "5                             Anti         BSDS500Crop128            BFS   \n",
       "6           AimsunKernelSimulation              BENCHMARK           ASPP   \n",
       "7                        BaseEmbed               BIDILSTM   AttPoolLayer   \n",
       "8             BSDS500PipelinesGray  BaseGenerationDataset       AttU_Net   \n",
       "9                       Alpha1_auc          BGModelMetric    AttUnitBiLi   \n",
       "\n",
       "             transformers                 wgan                       xfer  \n",
       "0           BaseTestClass         BasicDecoder              BasicLSTMCell  \n",
       "1          AnswerAccessor             BIDILSTM                BBoxUtility  \n",
       "2             BaseEncoder  AuthenticationError   BaseSuperResolutionModel  \n",
       "3            0001_initial      AccessSpecifier                  BBGT_ymax  \n",
       "4            AIF_CNN_RaIS              AddSign         AutoencoderODEfunc  \n",
       "5                 ATTPNLT              Auditor              BasePredModel  \n",
       "6  ADE20KTestImageDataset           BNN_Kernel             ActiveSearcher  \n",
       "7               AxisError   AlternatingTrainer             ApplyAttention  \n",
       "8            ArcFaceModel          BERTEncoder                    BBS-Net  \n",
       "9  BERT_cluster_sentences              Analogy  4_collect_experiments_dtu  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_repo_nodes, selected_names=call_graph_repo_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "874f90e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "prone_kv = KeyedVectors(prone_embeddings.shape[1])\n",
    "prone_kv.add(call_graph.names, prone_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0c37ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "prone_kv.save(\"data/prone_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "07233402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'tensorflow' in prone_kv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2e58ce00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'torch' in prone_kv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "47a39177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hp_confmats', 0.9999670386314392),\n",
       " ('running', 0.9999670386314392),\n",
       " ('evaluate_prob_pred', 0.9999670386314392),\n",
       " ('create_csv', 0.9999670386314392),\n",
       " ('zfilter', 0.9999670386314392),\n",
       " ('imagenet2012', 0.9249542951583862),\n",
       " ('view_test_images', 0.8785645961761475),\n",
       " ('hyper_anchor_target_layer', 0.8640199899673462),\n",
       " ('lstm_gesture', 0.8464738726615906),\n",
       " ('rnn_gesture', 0.8464738726615906)]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prone_kv.most_similar(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "9a2d02a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['allennlp_cmd', 'allennlp_coref', 'use_allennlp']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for k in prone_kv.vocab.keys() if 'allenn' in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "3746d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(repo_edges[0].values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3ad7912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'__init__',\n",
       "           'checkpoint',\n",
       "           'data_split',\n",
       "           'dataloader',\n",
       "           'framework',\n",
       "           'get_model',\n",
       "           'google_quantization',\n",
       "           'loss_function',\n",
       "           'main',\n",
       "           'option',\n",
       "           'qmobilenet',\n",
       "           'qresnet',\n",
       "           'regularizer',\n",
       "           'util'})"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(repo_edges[0].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fecb1ab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46007       allennlp_cmd\n",
       "46008     allennlp_coref\n",
       "188702      use_allennlp\n",
       "dtype: object"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_graph.names[call_graph.names.str.contains('allennlp')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "930a4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[k for item in repo_edges for (k, v) in item.items() if 'basic_allennlp' in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70925b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommenders-movielens</th>\n",
       "      <th>fairseq</th>\n",
       "      <th>mmdetection</th>\n",
       "      <th>wgan</th>\n",
       "      <th>xfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recommenders-movielens</td>\n",
       "      <td>fairseq</td>\n",
       "      <td>mmdetection</td>\n",
       "      <td>wgan</td>\n",
       "      <td>xfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict2</td>\n",
       "      <td>autopool</td>\n",
       "      <td>StandAloneSelfAttentionCifar10</td>\n",
       "      <td>wgancnnmimic</td>\n",
       "      <td>klcpd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutual-Channel-Loss</td>\n",
       "      <td>test_modelling_funcs</td>\n",
       "      <td>ResBlockCifar10</td>\n",
       "      <td>ive</td>\n",
       "      <td>training-mixed-precision-quantized-networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdcar</td>\n",
       "      <td>plotting_with_arrows</td>\n",
       "      <td>chirality_nets</td>\n",
       "      <td>train_multi_gpu</td>\n",
       "      <td>intrinsic-rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep_exchangeable_tensors</td>\n",
       "      <td>product_kernel</td>\n",
       "      <td>coco_semantic_segmentation_dataset</td>\n",
       "      <td>build_train_transformer</td>\n",
       "      <td>esrnn_torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>samplefocus2</td>\n",
       "      <td>fabolas</td>\n",
       "      <td>_random_saturation</td>\n",
       "      <td>base_sampler</td>\n",
       "      <td>text-to-image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>round_through</td>\n",
       "      <td>from_hyperparameters</td>\n",
       "      <td>_random_hue</td>\n",
       "      <td>features_config</td>\n",
       "      <td>test_finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ant_data_collect</td>\n",
       "      <td>OpenMatch</td>\n",
       "      <td>_random_lighting_noise</td>\n",
       "      <td>def_autoencoder_training</td>\n",
       "      <td>config_dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_all_transfer_irl</td>\n",
       "      <td>ElapsedTime</td>\n",
       "      <td>gmvi</td>\n",
       "      <td>global_config</td>\n",
       "      <td>MS-CornerNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ant_irl_debug</td>\n",
       "      <td>elmo-chinese-oversimplified</td>\n",
       "      <td>ram</td>\n",
       "      <td>modeling_rgcn</td>\n",
       "      <td>VisionForPedestrian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recommenders-movielens                      fairseq  \\\n",
       "0     Recommenders-movielens                      fairseq   \n",
       "1                   predict2                     autopool   \n",
       "2        Mutual-Channel-Loss         test_modelling_funcs   \n",
       "3                      sdcar         plotting_with_arrows   \n",
       "4  deep_exchangeable_tensors               product_kernel   \n",
       "5               samplefocus2                      fabolas   \n",
       "6              round_through         from_hyperparameters   \n",
       "7           ant_data_collect                    OpenMatch   \n",
       "8       run_all_transfer_irl                  ElapsedTime   \n",
       "9              ant_irl_debug  elmo-chinese-oversimplified   \n",
       "\n",
       "                          mmdetection                      wgan  \\\n",
       "0                         mmdetection                      wgan   \n",
       "1      StandAloneSelfAttentionCifar10              wgancnnmimic   \n",
       "2                     ResBlockCifar10                       ive   \n",
       "3                      chirality_nets           train_multi_gpu   \n",
       "4  coco_semantic_segmentation_dataset   build_train_transformer   \n",
       "5                  _random_saturation              base_sampler   \n",
       "6                         _random_hue           features_config   \n",
       "7              _random_lighting_noise  def_autoencoder_training   \n",
       "8                                gmvi             global_config   \n",
       "9                                 ram             modeling_rgcn   \n",
       "\n",
       "                                          xfer  \n",
       "0                                         xfer  \n",
       "1                                        klcpd  \n",
       "2  training-mixed-precision-quantized-networks  \n",
       "3                            intrinsic-rewards  \n",
       "4                                  esrnn_torch  \n",
       "5                                text-to-image  \n",
       "6                              test_finetuning  \n",
       "7                                  config_dict  \n",
       "8                                 MS-CornerNet  \n",
       "9                          VisionForPedestrian  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_repo_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c85821c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197702\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommenders-movielens</th>\n",
       "      <th>fairseq</th>\n",
       "      <th>mmdetection</th>\n",
       "      <th>wgan</th>\n",
       "      <th>xfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Recommenders-movielens</td>\n",
       "      <td>fairseq</td>\n",
       "      <td>mmdetection</td>\n",
       "      <td>wgan</td>\n",
       "      <td>xfer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>predict2</td>\n",
       "      <td>autopool</td>\n",
       "      <td>StandAloneSelfAttentionCifar10</td>\n",
       "      <td>wgancnnmimic</td>\n",
       "      <td>klcpd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mutual-Channel-Loss</td>\n",
       "      <td>test_modelling_funcs</td>\n",
       "      <td>ResBlockCifar10</td>\n",
       "      <td>ive</td>\n",
       "      <td>training-mixed-precision-quantized-networks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdcar</td>\n",
       "      <td>plotting_with_arrows</td>\n",
       "      <td>chirality_nets</td>\n",
       "      <td>train_multi_gpu</td>\n",
       "      <td>intrinsic-rewards</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>deep_exchangeable_tensors</td>\n",
       "      <td>product_kernel</td>\n",
       "      <td>coco_semantic_segmentation_dataset</td>\n",
       "      <td>build_train_transformer</td>\n",
       "      <td>esrnn_torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>samplefocus2</td>\n",
       "      <td>fabolas</td>\n",
       "      <td>_random_saturation</td>\n",
       "      <td>base_sampler</td>\n",
       "      <td>text-to-image</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>round_through</td>\n",
       "      <td>from_hyperparameters</td>\n",
       "      <td>_random_hue</td>\n",
       "      <td>features_config</td>\n",
       "      <td>test_finetuning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ant_data_collect</td>\n",
       "      <td>OpenMatch</td>\n",
       "      <td>_random_lighting_noise</td>\n",
       "      <td>def_autoencoder_training</td>\n",
       "      <td>config_dict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>run_all_transfer_irl</td>\n",
       "      <td>ElapsedTime</td>\n",
       "      <td>gmvi</td>\n",
       "      <td>global_config</td>\n",
       "      <td>MS-CornerNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ant_irl_debug</td>\n",
       "      <td>elmo-chinese-oversimplified</td>\n",
       "      <td>ram</td>\n",
       "      <td>modeling_rgcn</td>\n",
       "      <td>VisionForPedestrian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Recommenders-movielens                      fairseq  \\\n",
       "0     Recommenders-movielens                      fairseq   \n",
       "1                   predict2                     autopool   \n",
       "2        Mutual-Channel-Loss         test_modelling_funcs   \n",
       "3                      sdcar         plotting_with_arrows   \n",
       "4  deep_exchangeable_tensors               product_kernel   \n",
       "5               samplefocus2                      fabolas   \n",
       "6              round_through         from_hyperparameters   \n",
       "7           ant_data_collect                    OpenMatch   \n",
       "8       run_all_transfer_irl                  ElapsedTime   \n",
       "9              ant_irl_debug  elmo-chinese-oversimplified   \n",
       "\n",
       "                          mmdetection                      wgan  \\\n",
       "0                         mmdetection                      wgan   \n",
       "1      StandAloneSelfAttentionCifar10              wgancnnmimic   \n",
       "2                     ResBlockCifar10                       ive   \n",
       "3                      chirality_nets           train_multi_gpu   \n",
       "4  coco_semantic_segmentation_dataset   build_train_transformer   \n",
       "5                  _random_saturation              base_sampler   \n",
       "6                         _random_hue           features_config   \n",
       "7              _random_lighting_noise  def_autoencoder_training   \n",
       "8                                gmvi             global_config   \n",
       "9                                 ram             modeling_rgcn   \n",
       "\n",
       "                                          xfer  \n",
       "0                                         xfer  \n",
       "1                                        klcpd  \n",
       "2  training-mixed-precision-quantized-networks  \n",
       "3                            intrinsic-rewards  \n",
       "4                                  esrnn_torch  \n",
       "5                                text-to-image  \n",
       "6                              test_finetuning  \n",
       "7                                  config_dict  \n",
       "8                                 MS-CornerNet  \n",
       "9                          VisionForPedestrian  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_repo_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d08ce265",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prone_closest_repos.md', 'w') as f:\n",
    "    f.write(get_node_embedding_model_and_results(prone_embeddings, call_graph, example_repo_nodes).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ac3e96de",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prone_closest_nodes.md', 'w') as f:\n",
    "    f.write(get_node_embedding_model_and_results(prone_embeddings, call_graph, example_nodes).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b123a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | DistilBertForMaskedLM           | __init__   | fit                     | hate-speech-detection      | tensorflow                  | test       | train       | variational-dropout-sparsifies-dnn                   |\r\n",
      "|---:|:--------------------------------|:-----------|:------------------------|:---------------------------|:----------------------------|:-----------|:------------|:-----------------------------------------------------|\r\n",
      "|  0 | gluLookAt                       | __init__   | fit                     | loss_opr                   | Gaussian_estimators         | test       | train       | variational-dropout-sparsifies-dnn                   |\r\n",
      "|  1 | make_2d                         | train      | pass_epoch              | mlp_policy_disc            | util_causality              | main       | __init__    | virtual                                              |\r\n",
      "|  2 | make_2way_boxplot               | main       | validate                | normalization_preprocessor | c_to_dir                    | evaluate   | main        | BCANet                                               |\r\n",
      "|  3 | make_EuclideanClusterExtraction | model      | train_model             | duplicate_detector         | configure_file              | train      | model       | 4200_0_mt_fold_1_stackedImages_18x256x256_AE_v2_Adam |\r\n",
      "|  4 | make_Grams                      | utils      | train_network_one_epoch | mlp_selfconfid             | treatment_outcome_predictor | __init__   | test        | 4300_1_mt_fold_1_stackedImages_1x256x256_AE_v2_Adam  |\r\n",
      "|  5 | make_RegionGrowing              | test       | train_node_classifier   | default_algorithm          | gen_protos                  | run        | run         | GripNet                                              |\r\n",
      "|  6 | make_U_in_image_form            | evaluate   | train_step              | tensor_ops                 | coverage-info               | preprocess | utils       | PyDnet                                               |\r\n",
      "|  7 | makeValuation                   | run        | adversarial_network     | c4_backbone                | gen3_reg                    | inference  | train_model | Dagger                                               |\r\n",
      "|  8 | make_accuracy                   | resnet     | create_optimizer        | mlp_discriminator          | structure                   | setup      | evaluate    | FUHS_GraphCNN                                        |\r\n",
      "|  9 | make_affinity                   | dataset    | create_model            | extract_wmt16_segment_ids  | gen_reg                     | read_data  | config      | eccv18_mtvae                                         |"
     ]
    }
   ],
   "source": [
    "!cat prone_closest_nodes.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1ed292",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_nodes).to_csv(open('prone_closest_nodes.md', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8256ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node_embedding_model_and_results(ggvec_embeddings, call_graph, example_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_node_embedding_model_and_results(prone_embeddings, call_graph, example_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45cab8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import poincare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d6b5a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_edges = list(dependency_records_df[['source', 'destination']].itertuples(index=False, name=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "35079ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(836456, 3)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "f8d3cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poincare.PoincareModel(example_edges, negative=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1c7d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_model = poincare.PoincareModel.load(\"data/poincare_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53e4a622",
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_kv = poincare_model.kv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54608008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bgd_regression_example', 0.055222270997060584),\n",
       " ('commen_preprocess', 0.057124899473131624),\n",
       " ('improved_wgan', 0.05768017085423108),\n",
       " ('print_logs', 0.05830966264658537),\n",
       " ('nomulti_prepare_arxiv_hd2v_file', 0.061538445115199444),\n",
       " ('east_text_detector', 0.06154781278261005),\n",
       " ('sceneNet_format', 0.06346886368788779),\n",
       " ('Isbi_2018_Lung_Nodule_Classification', 0.06377140430083916),\n",
       " ('GroundTruthReconstruction', 0.06727481745779648),\n",
       " ('SawyerPegUnplugSideEnvV2', 0.06777548400380728),\n",
       " ('yoloV4-keras-techi', 0.06792303777515296),\n",
       " ('mySolutionToOCR_opencv', 0.06882321114408725),\n",
       " ('passive_voice_index-checkpoint', 0.07011745106564095),\n",
       " ('TestDiagMatrixTransform', 0.07012234963371795),\n",
       " ('deduplicate_references_arxivmag', 0.07195459693486138),\n",
       " ('Fair-Pooling-Causal-Models', 0.0720021328927757),\n",
       " ('trac_dataloader', 0.07225447093701734),\n",
       " ('GDELT', 0.07271997309776126),\n",
       " ('BitcoinOTC', 0.07277222101134585),\n",
       " ('adapt_LTA', 0.07283559970629622),\n",
       " ('q_cart_fast_v2', 0.07308006261367075),\n",
       " ('index_unpaywallmag_en_cs', 0.07308101666350562),\n",
       " ('func_su', 0.07329797084279209),\n",
       " ('reinbo', 0.07393759295450232),\n",
       " ('CoMA', 0.07481608787112416),\n",
       " ('TestUserInput', 0.07523242169365557),\n",
       " ('2', 0.07545144757252567),\n",
       " ('TransformTests', 0.0758981223064078),\n",
       " ('passive_voice_index', 0.07590669784540618),\n",
       " ('map_acl_to_mag', 0.07604098290170999),\n",
       " ('main_mountaincar', 0.07610001397732954),\n",
       " ('deduplicate_references_aclmag', 0.07616231944862878),\n",
       " ('make_mcmc_results_figures', 0.07655266728128095),\n",
       " ('tpe_space', 0.07677889750454758),\n",
       " ('buildHTMLForSkelViz', 0.07686763025982522),\n",
       " ('dependency_trees_to_zgen_format', 0.07688514523001522),\n",
       " ('pre_model_test', 0.07689892233836898),\n",
       " ('print_chainer_config', 0.077283619178941),\n",
       " ('AdapInp', 0.07746696407238209),\n",
       " ('effmpeg', 0.07845817740596464),\n",
       " ('tf-YOLO-pascalVOC', 0.0785933224105581),\n",
       " ('HybridCite', 0.07862498008335692),\n",
       " ('DescriptionGenerator', 0.078748917311305),\n",
       " ('r04_verilog_generator_grayscale_file', 0.07889140500835921),\n",
       " ('SawyerPushBackEnv', 0.07903597465815036),\n",
       " ('depth2room', 0.07916212560497875),\n",
       " ('MySimulator', 0.07921724025644633),\n",
       " ('dnn_para_tune', 0.07929637896242846),\n",
       " ('cyclicLR', 0.07932119946282043),\n",
       " ('SawyerPlateSlideBackEnv', 0.08038407859288181)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_kv.most_similar(\"yolo4\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8e1d3088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cor-gan', 0.36010273643336665),\n",
       " ('wgancnnmimic', 0.3846111736823422),\n",
       " ('crop_data', 0.4704451245945559),\n",
       " ('test_parallel_wavegan', 0.4868179405269457),\n",
       " ('TenCrop', 0.4905563570797422),\n",
       " ('optimize-coordconv', 0.49662299346398875),\n",
       " ('piecewise-quantization', 0.5076261900313741),\n",
       " ('RandomRotation', 0.511829127078771),\n",
       " ('RandomColorWarp', 0.5164052449311531),\n",
       " ('VisionForPedestrian', 0.5284535570715543),\n",
       " ('base_sampler', 0.5327480348409799),\n",
       " ('RandomVerticalFlip', 0.5329071120123472),\n",
       " ('Chatbot', 0.5454516559776406),\n",
       " ('RandomHorizontalFlip', 0.5489152015640574),\n",
       " ('RandomChoice', 0.5491908817983115),\n",
       " ('ssd_vgg_preprocessing', 0.5501988972814966),\n",
       " ('Randomswap', 0.5514325606734396),\n",
       " ('seg_pallete', 0.5530243766670637),\n",
       " ('poolers', 0.5533109909138446),\n",
       " ('build_ssd', 0.5539133897309043),\n",
       " ('resnet_ss0', 0.5539186592045329),\n",
       " ('RandomGrayscale', 0.5570556206025081),\n",
       " ('RandomShift', 0.5576184739574569),\n",
       " ('ColorJitter', 0.560925339729286),\n",
       " ('RandomAffine', 0.5618394224961668),\n",
       " ('Pad', 0.5640818310877718),\n",
       " ('keras-attention-mechanism', 0.5642337842909244),\n",
       " ('RandomCrop', 0.5711340597441518),\n",
       " ('AngleLinear', 0.5715389194546183),\n",
       " ('RandomMirror', 0.5763247343969328),\n",
       " ('LAHeart', 0.5771096215918794),\n",
       " ('ArrayToTensor', 0.5777358704812978),\n",
       " ('Onepixelshift', 0.5779944246597376),\n",
       " ('autofeat', 0.5782134647761495),\n",
       " ('klcpd', 0.5790243265613947),\n",
       " ('FiveCrop', 0.579212719815512),\n",
       " ('RandomTransforms', 0.5794504529569207),\n",
       " ('gym-gridworld', 0.5797096335569729),\n",
       " ('train_MapNet', 0.5798485605114378),\n",
       " ('global_config', 0.5802443132825342),\n",
       " ('DispResNet', 0.5823228471440297),\n",
       " ('context-gated-convolution', 0.5827984826110336),\n",
       " ('paths_catalog_cc', 0.583475391071823),\n",
       " ('elmo-chinese-oversimplified', 0.5853026702849552),\n",
       " ('RandomApply', 0.5891083676324758),\n",
       " ('AAE', 0.590213720344416),\n",
       " ('OpenMatch', 0.591395416425162),\n",
       " ('build_head', 0.5954843587579428),\n",
       " ('transformer_legacy', 0.596726583009622),\n",
       " ('hit-scir-ucca-parser', 0.5970861136541178)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_kv.most_similar(\"wgan\", topn=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d566cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SequenceWise', 0.21982638626002737),\n",
       " ('LaneEval', 0.2268351803323228),\n",
       " ('revert_move', 0.23120355355611),\n",
       " ('activation_matrix', 0.23620672927628403),\n",
       " ('linear_gradient', 0.24174259508339097),\n",
       " ('copy_attr', 0.24663925981300197),\n",
       " ('input_matrix', 0.24718141628827364),\n",
       " ('check_version', 0.24918287770955216),\n",
       " ('conv_general_dilated_local', 0.24936446305194832),\n",
       " ('x_section', 0.24998583497547072)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_kv.most_similar(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "87408844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MJCModel'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poincare_kv.closest_child(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231512a",
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_kv.most_similar(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "df230b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 30min 20s, sys: 446 ms, total: 2h 30min 20s\n",
      "Wall time: 2h 30min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.train(epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3f7daa2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['util_causality',\n",
       " 'gen_mx_table',\n",
       " 'gen_reg',\n",
       " 'representations',\n",
       " 'causal-network-embeddings']"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.kv.descendants(\"tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "81ef7ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"data/poincare_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d436c65a",
   "metadata": {},
   "source": [
    "# Hyperbolic embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590c4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358840a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fdad2e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-0698741a3d71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1b45ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function    560451\n",
       "file        230560\n",
       "repo         42638\n",
       "root          2807\n",
       "Name: edge_type, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependency_records_df['edge_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc413c64",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- expore call graph\n",
    "- better call graph\n",
    "- Node2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1bb496",
   "metadata": {},
   "source": [
    "Exploring call graph\n",
    "\n",
    "what is the problem?\n",
    "\n",
    "Graph is not even connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be8a871",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d48b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
