{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICE'] = \"1\"\n",
    "\n",
    "\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "from github_search import lm_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 247 ms, total: 11.7 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "elmo = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18020617961883545"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"]\n",
    "vectors = elmo.embed_sentence(tokens)\n",
    "\n",
    "assert(len(vectors) == 3) # one for each layer in the ELMo output\n",
    "assert(len(vectors[0]) == len(tokens)) # the vector elements correspond with the input tokens\n",
    "\n",
    "import scipy\n",
    "vectors2 = elmo.embed_sentence([\"I\", \"ate\", \"a\", \"carrot\", \"for\", \"breakfast\"])\n",
    "scipy.spatial.distance.cosine(vectors[2][3], vectors2[2][3]) # cosine distance between \"apple\" and \"carrot\" in the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://allennlp.s3.amazonaws.com/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Compute two different representation for each token.\n",
    "# Each representation is a linear weighted combination for the\n",
    "# 3 layers in ELMo (i.e., charcnn, the outputs of the two BiLSTM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 291 ms, total: 11.8 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use batch_to_ids to convert sentences to character ids\n",
    "sentences = [['First', 'sentence', '.'], ['Another', '.'], ['Yet', 'another', 'sentence', '.']]\n",
    "character_ids = batch_to_ids(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = elmo(character_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_lstm = elmo._elmo_lstm._elmo_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4064, -1.2748, -1.7271,  ...,  1.0071,  1.3740,  0.8320],\n",
       "          [-0.2691, -1.1981, -1.4729,  ...,  0.9367,  1.4424,  0.8069],\n",
       "          [-0.3681, -1.2980, -1.8114,  ...,  0.9643,  1.2113,  1.0951]],\n",
       " \n",
       "         [[-0.6784, -0.6880, -1.6490,  ..., -0.2163, -1.6589, -0.3530],\n",
       "          [-0.8312, -1.0318, -1.7815,  ...,  0.2974, -1.2278, -0.3933],\n",
       "          [-0.4312, -0.8275, -1.4842,  ..., -0.1300, -1.5446, -0.6574]]]),\n",
       " tensor([[[ 2.0361e-10,  3.6427e-06,  4.3772e-11,  ..., -1.3933e-03,\n",
       "           -4.7057e-06, -9.9355e-01],\n",
       "          [ 7.2584e-11,  2.0872e-05,  3.8905e-11,  ..., -3.1245e-03,\n",
       "           -1.6488e-06, -9.9408e-01],\n",
       "          [ 4.9811e-11,  2.0812e-06,  4.4098e-11,  ..., -1.3348e-03,\n",
       "           -6.3097e-06, -9.9413e-01]],\n",
       " \n",
       "         [[-4.5433e-01,  2.3301e-04,  2.6471e-01,  ...,  8.6803e-02,\n",
       "            6.6469e-03, -2.1674e-01],\n",
       "          [-5.3327e-01, -9.4982e-04,  4.9209e-01,  ...,  3.0989e-01,\n",
       "            1.8197e-01, -2.6571e-01],\n",
       "          [-3.9661e-01,  3.5231e-04,  3.4671e-01,  ...,  2.1070e-01,\n",
       "            4.5374e-01, -2.0401e-01]]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_lstm._states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_wrapper = lm_utils.AllenELMoWrapper(elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mlm_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAllenELMoWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0melmo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mAllenELMoWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f05286b82f0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m Initialize self.  See help(type(self)) for accurate signature.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tokenizer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Projects/github_search/notebooks/<attrs generated init 5023b717227d90a767cea6eece2f5c36e902b82c>\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "??lm_utils.AllenELMoWrapper.__init__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [' '.join(toks) for toks in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.4064, -1.2748, -1.7271,  ...,  1.0071,  1.3740,  0.8320],\n",
       "          [-0.2691, -1.1981, -1.4729,  ...,  0.9367,  1.4424,  0.8069],\n",
       "          [-0.3681, -1.2980, -1.8114,  ...,  0.9643,  1.2113,  1.0951]],\n",
       " \n",
       "         [[-0.6784, -0.6880, -1.6490,  ..., -0.2163, -1.6589, -0.3530],\n",
       "          [-0.8312, -1.0318, -1.7815,  ...,  0.2974, -1.2278, -0.3933],\n",
       "          [-0.4312, -0.8275, -1.4842,  ..., -0.1300, -1.5446, -0.6574]]]),\n",
       " tensor([[[ 2.0361e-10,  3.6427e-06,  4.3772e-11,  ..., -1.3933e-03,\n",
       "           -4.7057e-06, -9.9355e-01],\n",
       "          [ 7.2584e-11,  2.0872e-05,  3.8905e-11,  ..., -3.1245e-03,\n",
       "           -1.6488e-06, -9.9408e-01],\n",
       "          [ 4.9811e-11,  2.0812e-06,  4.4098e-11,  ..., -1.3348e-03,\n",
       "           -6.3097e-06, -9.9413e-01]],\n",
       " \n",
       "         [[-4.5433e-01,  2.3301e-04,  2.6471e-01,  ...,  8.6803e-02,\n",
       "            6.6469e-03, -2.1674e-01],\n",
       "          [-5.3327e-01, -9.4982e-04,  4.9209e-01,  ...,  3.0989e-01,\n",
       "            1.8197e-01, -2.6571e-01],\n",
       "          [-3.9661e-01,  3.5231e-04,  3.4671e-01,  ...,  2.1070e-01,\n",
       "            4.5374e-01, -2.0401e-01]]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_wrapper.get_last_hiddens_batch(texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
