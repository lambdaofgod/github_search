{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61bf0a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from github_search import python_tokens\n",
    "from mlutil.feature_extraction import embeddings\n",
    "from mlutil import prototype_selection\n",
    "import mlutil\n",
    "from mlutil.feature_extraction import embeddings \n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99363ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7598dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_files_df = pd.read_csv('data/python_files.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58bfbf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7253bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21a32a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import astunparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac184c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "# Author: Rico Sennrich\n",
      "\n",
      "\"\"\"Use operations learned with learn_bpe.py to encode a new text.\n",
      "The text will not be smaller, but use only a fixed vocabulary, with rare words\n",
      "encoded as variable-length sequences of subword units.\n",
      "\n",
      "Reference:\n",
      "Rico Sennrich, Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units.\n",
      "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin, Germany.\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "import codecs\n",
      "import argparse\n",
      "import functools\n",
      "from collections import defaultdict\n",
      "\n",
      "class BPE(object):\n",
      "    def encode(self, orig):\n",
      "        \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n",
      "        \"\"\"\n",
      "        word = tuple(orig) + ('</w>',)\n",
      "        pairs = get_pairs(word)\n",
      "\n",
      "        while True:\n",
      "            bigram = min(pairs, key=lambda pair: self.bpe_codes.get(pair, float('inf')))\n",
      "            if bigram not in self.bpe_codes:\n",
      "                break\n",
      "            first, second = bigram\n",
      "            new_word = []\n",
      "            i = 0\n",
      "            while i < len(word):\n",
      "                try:\n",
      "                    j = word.index(first, i)\n",
      "                    new_word.extend(word[i:j])\n",
      "                    i = j\n",
      "                except:\n",
      "                    new_word.extend(word[i:])\n",
      "                    break\n",
      "\n",
      "                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
      "                    new_word.append(first + second)\n",
      "                    i += 2\n",
      "                else:\n",
      "                    new_word.append(word[i])\n",
      "                    i += 1\n",
      "            new_word = tuple(new_word)\n",
      "            word = new_word\n",
      "            if len(word) == 1:\n",
      "                break\n",
      "            else:\n",
      "                pairs = get_pairs(word)\n",
      "\n",
      "        # don't print end-of-word symbols\n",
      "        if word[-1] == '</w>':\n",
      "            word = word[:-1]\n",
      "        elif word[-1].endswith('</w>'):\n",
      "            word = word[:-1] + (word[-1].replace('</w>', ''),)\n",
      "\n",
      "        return word\n",
      "\n",
      "    def __init__(self, codes, separator='@@'):\n",
      "        self.encode = functools.lru_cache(maxsize=65536)(self.encode)\n",
      "        self.bpe_codes = [tuple(item.split()) for item in codes]\n",
      "        # some hacking to deal with duplicates (only consider first instance)\n",
      "        self.bpe_codes = dict([(code,i) for (i,code) in reversed(list(enumerate(self.bpe_codes)))])\n",
      "\n",
      "        self.separator = separator\n",
      "\n",
      "    def segment(self, sentence):\n",
      "        \"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"\n",
      "\n",
      "        output = []\n",
      "        for word in sentence.split():\n",
      "            new_word = self.encode(word)\n",
      "\n",
      "            for item in new_word[:-1]:\n",
      "                output.append(item + self.separator)\n",
      "            output.append(new_word[-1])\n",
      "\n",
      "        return ' '.join(output)\n",
      "\n",
      "\n",
      "def create_parser():\n",
      "    parser = argparse.ArgumentParser(\n",
      "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "        description=\"learn BPE-based word segmentation\")\n",
      "\n",
      "    parser.add_argument(\n",
      "        '--input', '-i', type=argparse.FileType('r'), default=sys.stdin,\n",
      "        metavar='PATH',\n",
      "        help=\"Input file (default: standard input).\")\n",
      "    parser.add_argument(\n",
      "        '--codes', '-c', type=argparse.FileType('r'), metavar='PATH',\n",
      "        required=True,\n",
      "        help=\"File with BPE codes (created by learn_bpe.py).\")\n",
      "    parser.add_argument(\n",
      "        '--output', '-o', type=argparse.FileType('w'), default=sys.stdout,\n",
      "        metavar='PATH',\n",
      "        help=\"Output file (default: standard output)\")\n",
      "    parser.add_argument(\n",
      "        '--separator', '-s', type=str, default='@@', metavar='STR',\n",
      "        help=\"Separator between non-final subword units (default: '%(default)s'))\")\n",
      "\n",
      "    return parser\n",
      "\n",
      "def get_pairs(word):\n",
      "    \"\"\"Return set of symbol pairs in a word.\n",
      "\n",
      "    word is represented as tuple of symbols (symbols being variable-length strings)\n",
      "    \"\"\"\n",
      "    pairs = set()\n",
      "    prev_char = word[0]\n",
      "    for char in word[1:]:\n",
      "        pairs.add((prev_char, char))\n",
      "        prev_char = char\n",
      "    return pairs\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = create_parser()\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    bpe = BPE(args.codes, args.separator)\n",
      "\n",
      "    for line in args.input:\n",
      "        args.output.write(bpe.segment(line).strip())\n",
      "        args.output.write('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_file = python_files_df['content'].iloc[1]\n",
    "print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b8ff529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef get_pairs(word):\\n    'Return set of symbol pairs in a word.\\\\n\\\\n    word is represented as tuple of symbols (symbols being variable-length strings)\\\\n    '\\n    pairs = set()\\n    prev_char = word[0]\\n    for char in word[1:]:\\n        pairs.add((prev_char, char))\\n        prev_char = char\\n    return pairs\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(ast.parse(example_file).body[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc78b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_code = ast.parse(example_file).body[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abba8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor char in word[1:]:\\n    pairs.add((prev_char, char))\\n    prev_char = char\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(fn_code.body[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e1f475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef get_pairs(word):\\n    'Return set of symbol pairs in a word.\\\\n\\\\n    word is represented as tuple of symbols (symbols being variable-length strings)\\\\n    '\\n    pairs = set()\\n    prev_char = word[0]\\n    for char in word[1:]:\\n        pairs.add((prev_char, char))\\n        prev_char = char\\n    return pairs\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(fn_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12e01224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\ndef get_pairs(word):\\n    'Return set of symbol pairs in a word.\\\\n\\\\n    word is represented as tuple of symbols (symbols being variable-length strings)\\\\n    '\\n    pairs = set()\\n    prev_char = word[0]\\n    for char in word[1:]:\\n        pairs.add((prev_char, char))\\n        prev_char = char\\n    return pairs\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(fn_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4491a35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_pairs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn_code.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42d6004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'word\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(fn_code.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41bcf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f53f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyan.modvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f716b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor = pyan.modvis.ImportVisitor(contents=[example_file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e4a95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "visitor.prepare_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "803cdb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_options = {\n",
    "        \"draw_defines\": False,  # we have no defines edges\n",
    "        \"draw_uses\": True,\n",
    "        \"colored\": False,\n",
    "        \"grouped_alt\": False,\n",
    "        \"grouped\": True,\n",
    "        \"nested_groups\": True,\n",
    "        \"annotated\": False,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21784f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2bb15cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pyan.visgraph.VisualGraph.from_visitor(visitor, options=graph_options, logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53c000d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#!/usr/bin/env python3\\n# Author: Rico Sennrich\\n\\n\"\"\"Use operations learned with learn_bpe.py to encode a new text.\\nThe text will not be smaller, but use only a fixed vocabulary, with rare words\\nencoded as variable-length sequences of subword units.\\n\\nReference:\\nRico Sennrich, Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units.\\nProceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin, Germany.\\n\"\"\"\\n\\nimport sys\\nimport codecs\\nimport argparse\\nimport functools\\nfrom collections import defaultdict\\n\\nclass BPE(object):\\n    def encode(self, orig):\\n        \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\\n        \"\"\"\\n        word = tuple(orig) + (\\'</w>\\',)\\n        pairs = get_pairs(word)\\n\\n        while True:\\n            bigram = min(pairs, key=lambda pair: self.bpe_codes.get(pair, float(\\'inf\\')))\\n            if bigram not in self.bpe_codes:\\n                break\\n            first, second = bigram\\n            new_word = []\\n            i = 0\\n            while i < len(word):\\n                try:\\n                    j = word.index(first, i)\\n                    new_word.extend(word[i:j])\\n                    i = j\\n                except:\\n                    new_word.extend(word[i:])\\n                    break\\n\\n                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\\n                    new_word.append(first + second)\\n                    i += 2\\n                else:\\n                    new_word.append(word[i])\\n                    i += 1\\n            new_word = tuple(new_word)\\n            word = new_word\\n            if len(word) == 1:\\n                break\\n            else:\\n                pairs = get_pairs(word)\\n\\n        # don\\'t print end-of-word symbols\\n        if word[-1] == \\'</w>\\':\\n            word = word[:-1]\\n        elif word[-1].endswith(\\'</w>\\'):\\n            word = word[:-1] + (word[-1].replace(\\'</w>\\', \\'\\'),)\\n\\n        return word\\n\\n    def __init__(self, codes, separator=\\'@@\\'):\\n        self.encode = functools.lru_cache(maxsize=65536)(self.encode)\\n        self.bpe_codes = [tuple(item.split()) for item in codes]\\n        # some hacking to deal with duplicates (only consider first instance)\\n        self.bpe_codes = dict([(code,i) for (i,code) in reversed(list(enumerate(self.bpe_codes)))])\\n\\n        self.separator = separator\\n\\n    def segment(self, sentence):\\n        \"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"\\n\\n        output = []\\n        for word in sentence.split():\\n            new_word = self.encode(word)\\n\\n            for item in new_word[:-1]:\\n                output.append(item + self.separator)\\n            output.append(new_word[-1])\\n\\n        return \\' \\'.join(output)\\n\\n\\ndef create_parser():\\n    parser = argparse.ArgumentParser(\\n        formatter_class=argparse.RawDescriptionHelpFormatter,\\n        description=\"learn BPE-based word segmentation\")\\n\\n    parser.add_argument(\\n        \\'--input\\', \\'-i\\', type=argparse.FileType(\\'r\\'), default=sys.stdin,\\n        metavar=\\'PATH\\',\\n        help=\"Input file (default: standard input).\")\\n    parser.add_argument(\\n        \\'--codes\\', \\'-c\\', type=argparse.FileType(\\'r\\'), metavar=\\'PATH\\',\\n        required=True,\\n        help=\"File with BPE codes (created by learn_bpe.py).\")\\n    parser.add_argument(\\n        \\'--output\\', \\'-o\\', type=argparse.FileType(\\'w\\'), default=sys.stdout,\\n        metavar=\\'PATH\\',\\n        help=\"Output file (default: standard output)\")\\n    parser.add_argument(\\n        \\'--separator\\', \\'-s\\', type=str, default=\\'@@\\', metavar=\\'STR\\',\\n        help=\"Separator between non-final subword units (default: \\'%(default)s\\'))\")\\n\\n    return parser\\n\\ndef get_pairs(word):\\n    \"\"\"Return set of symbol pairs in a word.\\n\\n    word is represented as tuple of symbols (symbols being variable-length strings)\\n    \"\"\"\\n    pairs = set()\\n    prev_char = word[0]\\n    for char in word[1:]:\\n        pairs.add((prev_char, char))\\n        prev_char = char\\n    return pairs\\n\\n\\nif __name__ == \\'__main__\\':\\n    parser = create_parser()\\n    args = parser.parse_args()\\n\\n    bpe = BPE(args.codes, args.separator)\\n\\n    for line in args.input:\\n        args.output.write(bpe.segment(line).strip())\\n        args.output.write(\\'\\\\n\\')\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ebc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load notebooks/construct_call_graph.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "generates call graph of given python code file\n",
    "in dot format input for graphviz.\n",
    "\n",
    "limitations:\n",
    "* statically tried to figure out functions calls\n",
    "* does not understand classes\n",
    "* algorithm is naive and may not statically find\n",
    "  all cases\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import parser\n",
    "import symbol, token\n",
    "import pprint\n",
    "import optparse\n",
    "\n",
    "try: s = set()\n",
    "except: import sets; set = sets.Set\n",
    "\n",
    "def annotate_ast_list(ast_list):\n",
    "    code = ast_list[0]\n",
    "    if code in symbol.sym_name: code = symbol.sym_name[code]\n",
    "    else: code = token.tok_name[code]\n",
    "    ast_list[0] = code\n",
    "\n",
    "    for index, item in enumerate(ast_list):\n",
    "        if index == 0: continue\n",
    "        if isinstance(item, list):\n",
    "            ast_list[index] = annotate_ast_list(item) \n",
    "    return ast_list\n",
    " \n",
    "def get_atom_name(atom):\n",
    "    first_child = atom[1]\n",
    "    first_child_code = first_child[0]\n",
    "    if first_child_code != token.NAME: return None\n",
    "    return first_child[1]\n",
    "\n",
    "def get_fn_call_data(ast_list):\n",
    "    if len(ast_list) < 3: return None\n",
    "    first_child, second_child = ast_list[1:3]\n",
    "    first_child_code = first_child[0]\n",
    "    if first_child_code != symbol.atom: return None\n",
    "    fn_name = get_atom_name(first_child)\n",
    "\n",
    "    second_child_code = second_child[0]\n",
    "    if second_child_code != symbol.trailer: return None\n",
    "    \n",
    "    if len(second_child) < 3: return None\n",
    "    if second_child[1][0] == token.LPAR and second_child[-1][0] == token.RPAR:\n",
    "        return fn_name\n",
    "    else: return None\n",
    "\n",
    "def find_fn_call(ast_list, calls):\n",
    "    code = ast_list[0]\n",
    "    if code == symbol.power:\n",
    "        fn_name = get_fn_call_data(ast_list)\n",
    "        if fn_name != None and getattr(__builtins__, fn_name, None) == None: calls.add(fn_name) \n",
    "   \n",
    "    for item in ast_list[1:]:\n",
    "        if isinstance(item, list):\n",
    "            find_fn_call(item, calls)\n",
    "\n",
    "def process_fn(fn_ast_list, call_graph):\n",
    "    dummy, dummy, func_name = fn_ast_list[:3]\n",
    "    dummy, func_name = func_name\n",
    "\n",
    "    calls = set()\n",
    "    find_fn_call(fn_ast_list, calls)\n",
    "\n",
    "    call_graph[func_name] = list(calls)\n",
    "\n",
    "def construct_call_graph(ast_list, call_graph):\n",
    "    code = ast_list[0]\n",
    "    if code == symbol.funcdef:\n",
    "        process_fn(ast_list, call_graph)\n",
    "\n",
    "    for item in ast_list[1:]:\n",
    "        if isinstance(item, list):\n",
    "            construct_call_graph(item, call_graph)\n",
    "\n",
    "    return call_graph\n",
    "\n",
    "def generate_dot_code(python_code):\n",
    "    ast_list = ast.parse(python_code).body\n",
    "    #annotated_ast_list = annotate_ast_list(ast_list)\n",
    "    #pprint.pprint(annotated_ast_list)\n",
    "\n",
    "    call_graph = {}\n",
    "    construct_call_graph(ast_list, call_graph)\n",
    "    #pprint.pprint(call_graph)\n",
    "\n",
    "    dot = []\n",
    "\n",
    "    dot.append(\"digraph G {\")\n",
    "    dot.append(\"rankdir=LR\")\n",
    "    for from_fn, to_fns in call_graph.items():\n",
    "        if not to_fns:\n",
    "            dot.append('%s;' % from_fn)\n",
    "\n",
    "        for to_fn in to_fns:\n",
    "            if to_fn not in call_graph: continue\n",
    "            dot.append('%s -> %s;' % (from_fn, to_fn))\n",
    "    dot.append(\"}\")\n",
    "\n",
    "    return '\\n'.join(dot)\n",
    "\n",
    "dot_code = generate_dot_code(example_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca78087",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "def foo():\n",
    "    bar()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4bf8613",
   "metadata": {},
   "outputs": [],
   "source": [
    "function_ast = (ast.parse(code).body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "566b2335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foo'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ast.parse(code).body[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5855016",
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = ast.parse(code).body[0].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48dce80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = exprs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a0dbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "71582254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assign_calls(expr):\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "220c7bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calls(function_ast):\n",
    "    return frozenset(\n",
    "        expr.value.func.id if type(expr.value.func) is ast.Name else expr.value.func.attr\n",
    "        for expr in function_ast.body\n",
    "        if type(expr) is ast.Expr or type(expr) is ast.Assign and type(expr.value) is ast.Call\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "452cefb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "expr_ast = ast.parse(\"word = tuple(orig) + ''\").body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08f0c3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.BinOp at 0x7f504830ff70>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_ast.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "1faf6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calls_from_expr_or_assign(expr):\n",
    "    try:\n",
    "        if type(expr) is ast.Name:\n",
    "            return [expr.id]\n",
    "        if type(expr) is ast.Call:\n",
    "            return get_calls_from_expr_or_assign(expr.func) + get_calls_from_expr_or_assign(expr.args)\n",
    "        elif type(expr) is ast.Attribute:\n",
    "            return [astunparse.unparse(expr).strip()]\n",
    "        elif type(expr) is ast.BinOp:\n",
    "            return get_calls_from_expr_or_assign(expr.left) + get_calls_from_expr_or_assign(expr.right)\n",
    "        elif type(expr) is ast.Expr:\n",
    "            return get_calls_from_expr_or_assign(expr.value)\n",
    "        elif type(expr) is ast.Assign:\n",
    "            return get_calls_from_expr_or_assign(expr.value)\n",
    "        elif type(expr) is ast.While or type(expr) is ast.If:\n",
    "            return (\n",
    "                get_calls_from_expr_or_assign(expr.test) +\n",
    "                get_calls_from_expr_or_assign(expr.orelse) +\n",
    "                get_calls_from_expr_or_assign(expr.body)\n",
    "            )\n",
    "        elif type(expr) is ast.For:\n",
    "            return (\n",
    "                get_calls_from_expr_or_assign(expr.target) +\n",
    "                get_calls_from_expr_or_assign(expr.body) +\n",
    "                get_calls_from_expr_or_assign(expr.iter)\n",
    "            )\n",
    "        elif type(expr) is ast.Try:\n",
    "            return get_calls_from_expr_or_assign(expr.body)\n",
    "        elif type(expr) is list:\n",
    "            return [res for subexpr in expr for res in get_calls_from_expr_or_assign(subexpr)]\n",
    "        else:\n",
    "            return []\n",
    "    except Exception as e:\n",
    "        print(str(astunparse.unparse(expr)), ' ', str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "d7dec138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Constant at 0x7f504830f8e0>"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_ast.value.right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "bd2b4733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.BinOp at 0x7f504830ff70>"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_ast.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ec8a2ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(tuple(orig) + '')\\n\""
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(expr_ast.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "16b1a4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tuple'"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_ast.value.left.func.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "3746cd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuple', 'orig']"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calls_from_expr_or_assign(expr_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "24183158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Call at 0x7f504830f5e0>"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr_ast.value.left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "2278f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_code = \"\"\"def encode(self, orig):\n",
    "    word = tuple(orig) + ('</w>',)\n",
    "    pairs = get_pairs(word)\n",
    "\n",
    "    while True:\n",
    "        bigram = min(pairs, key=lambda pair: self.bpe_codes.get(pair, float('inf')))\n",
    "        if bigram not in self.bpe_codes:\n",
    "            break\n",
    "        first, second = bigram\n",
    "        new_word = []\n",
    "        i = 0\n",
    "        while i < len(word):\n",
    "            try:\n",
    "                j = word.index(first, i)\n",
    "                new_word.extend(word[i:j])\n",
    "                i = j\n",
    "            except:\n",
    "                new_word.extend(word[i:])\n",
    "                break\n",
    "\n",
    "            if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
    "                new_word.append(first + second)\n",
    "                i += 2\n",
    "            else:\n",
    "                new_word.append(word[i])\n",
    "                i += 1\n",
    "        new_word = tuple(new_word)\n",
    "        word = new_word\n",
    "        if len(word) == 1:\n",
    "            break\n",
    "        else:\n",
    "            pairs = get_pairs(word)\n",
    "\n",
    "    # don't print end-of-word symbols\n",
    "    if word[-1] == '</w>':\n",
    "        word = word[:-1]\n",
    "    elif word[-1].endswith('</w>'):\n",
    "        word = word[:-1] + (word[-1].replace('</w>', ''),)\n",
    "\n",
    "    return word\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "d79b61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_ast = ast.parse(encode_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "2ca638e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_body = encode_ast.body[0].body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "f008192b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.BinOp at 0x7f4fefbfb550>"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_body.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "4efc6476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(tuple(orig) + ('</w>',))\\n\""
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(assign_body.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ffb098c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'bar'})"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calls(function_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "c30cf376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_def = ast.parse(code).body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "90762863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_ast.FunctionDef at 0x7f4fd16adfa0>,\n",
       " <_ast.FunctionDef at 0x7f4fefc0cb20>,\n",
       " <_ast.FunctionDef at 0x7f4fefc409a0>]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_def.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "44e5bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zip_dicts(dicts):\n",
    "    res = {}\n",
    "    for d in dicts:\n",
    "        res = {**res, **d}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "77923c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': '2', '2': '3'}"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_dicts([{\"1\": \"2\"}, {\"2\": \"3\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "5a3a70f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ast_function_calls(code_ast, calls={}):\n",
    "    if type(code_ast) is ast.FunctionDef:\n",
    "        return {code_ast.name: sum([get_calls_from_expr_or_assign(expr) for expr in code_ast.body], [])}\n",
    "    else:\n",
    "        return zip_dicts([get_ast_function_calls(item) for item in code_ast.body])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "605c7261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([[],[]], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "dc5d8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_function_calls(code):\n",
    "    code_ast = ast.parse(code)\n",
    "    return get_ast_function_calls(code_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "0e330258",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ast.parse(\"tuple(orig)\").body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e47ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "fded3191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Name at 0x7f4fd177a9a0>"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.value.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "a0c3c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ast.parse(\"functools.lru_cache(maxsize=65536)(self.encode)\").body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "8fbea152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['functools.lru_cache', 'self.encode']"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calls_from_expr_or_assign(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c44b87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "dda7d5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ev  = e.value.func.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "5a284863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'functools'"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ev.value.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "7026bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = ast.parse('functools.lru_cache').body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "2151d46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Attribute at 0x7f4fefbfb970>"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "24e863f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfunctools.lru_cache\\n'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "d96ac49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "class BPE(object):\n",
      "\n",
      "    def encode(self, orig):\n",
      "        word = (tuple(orig) + ('</w>',))\n",
      "        pairs = get_pairs(word)\n",
      "        while True:\n",
      "            bigram = min(pairs, key=(lambda pair: self.bpe_codes.get(pair, float('inf'))))\n",
      "            if (bigram not in self.bpe_codes):\n",
      "                break\n",
      "            (first, second) = bigram\n",
      "            new_word = []\n",
      "            i = 0\n",
      "            while (i < len(word)):\n",
      "                try:\n",
      "                    j = word.index(first, i)\n",
      "                    new_word.extend(word[i:j])\n",
      "                    i = j\n",
      "                except:\n",
      "                    new_word.extend(word[i:])\n",
      "                    break\n",
      "                if ((word[i] == first) and (i < (len(word) - 1)) and (word[(i + 1)] == second)):\n",
      "                    new_word.append((first + second))\n",
      "                    i += 2\n",
      "                else:\n",
      "                    new_word.append(word[i])\n",
      "                    i += 1\n",
      "            new_word = tuple(new_word)\n",
      "            word = new_word\n",
      "            if (len(word) == 1):\n",
      "                break\n",
      "            else:\n",
      "                pairs = get_pairs(word)\n",
      "        if (word[(- 1)] == '</w>'):\n",
      "            word = word[:(- 1)]\n",
      "        elif word[(- 1)].endswith('</w>'):\n",
      "            word = (word[:(- 1)] + (word[(- 1)].replace('</w>', ''),))\n",
      "        return word\n",
      "\n",
      "    def __init__(self, codes, separator='@@'):\n",
      "        self.encode = functools.lru_cache(maxsize=65536)(self.encode)\n",
      "        self.bpe_codes = [tuple(item.split()) for item in codes]\n",
      "        self.bpe_codes = dict([(code, i) for (i, code) in reversed(list(enumerate(self.bpe_codes)))])\n",
      "        self.separator = separator\n",
      "\n",
      "    def segment(self, sentence):\n",
      "        output = []\n",
      "        for word in sentence.split():\n",
      "            new_word = self.encode(word)\n",
      "            for item in new_word[:(- 1)]:\n",
      "                output.append((item + self.separator))\n",
      "            output.append(new_word[(- 1)])\n",
      "        return ' '.join(output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(astunparse.unparse(class_def))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "af7dfcfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encode': ['tuple',\n",
       "  'orig',\n",
       "  'get_pairs',\n",
       "  'word',\n",
       "  'min',\n",
       "  'pairs',\n",
       "  'bigram',\n",
       "  'word.index',\n",
       "  'first',\n",
       "  'i',\n",
       "  'new_word.extend',\n",
       "  'j',\n",
       "  'new_word.append',\n",
       "  'new_word.append',\n",
       "  'first',\n",
       "  'second',\n",
       "  'tuple',\n",
       "  'new_word',\n",
       "  'new_word',\n",
       "  'get_pairs',\n",
       "  'word',\n",
       "  'word[(- 1)].endswith'],\n",
       " '__init__': ['functools.lru_cache', 'self.encode', 'dict', 'separator'],\n",
       " 'segment': ['word',\n",
       "  'self.encode',\n",
       "  'word',\n",
       "  'item',\n",
       "  'output.append',\n",
       "  'item',\n",
       "  'self.separator',\n",
       "  'output.append',\n",
       "  'sentence.split']}"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_function_calls(class_def)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7d4cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "8011c670",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e = ast.parse(\n",
    "\"new_word.extend(word[i:j])\"\n",
    ").body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "09056b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_word.extend']"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calls_from_expr_or_assign(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7bc2d154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_ast.Assign at 0x7f4fd1c70070>,\n",
       " <_ast.Assign at 0x7f4fd1f5ba90>,\n",
       " <_ast.While at 0x7f4fd1f5b400>,\n",
       " <_ast.If at 0x7f4fd16499a0>,\n",
       " <_ast.Return at 0x7f4fd1e29820>]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_ast.body[0].body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "11b11c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encode': ['tuple', 'get_pairs']}"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ast_function_calls(encode_ast.body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b27cef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "728bffae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encode': ['tuple', 'get_pairs']}"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ast_function_calls(ast.parse(encode_code).body[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5646f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "cd25af20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encode': ['tuple', 'get_pairs'],\n",
       " '__init__': ['functools.lru_cache', 'dict', 'separator'],\n",
       " 'segment': ['word', 'sentence.split']}"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_function_calls(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "609c0afb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-93f0f0fb9079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_function_calls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bar\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert get_function_calls(code) == {\"foo\": frozenset([\"bar\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f1afacf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = ast.parse(code).body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "19c8853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "class BPE(object):\n",
    "    def encode(self, orig):\n",
    "        word = tuple(orig) + ('</w>',)\n",
    "        pairs = get_pairs(word)\n",
    "\n",
    "        while True:\n",
    "            bigram = min(pairs, key=lambda pair: self.bpe_codes.get(pair, float('inf')))\n",
    "            if bigram not in self.bpe_codes:\n",
    "                break\n",
    "            first, second = bigram\n",
    "            new_word = []\n",
    "            i = 0\n",
    "            while i < len(word):\n",
    "                try:\n",
    "                    j = word.index(first, i)\n",
    "                    new_word.extend(word[i:j])\n",
    "                    i = j\n",
    "                except:\n",
    "                    new_word.extend(word[i:])\n",
    "                    break\n",
    "\n",
    "                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
    "                    new_word.append(first + second)\n",
    "                    i += 2\n",
    "                else:\n",
    "                    new_word.append(word[i])\n",
    "                    i += 1\n",
    "            new_word = tuple(new_word)\n",
    "            word = new_word\n",
    "            if len(word) == 1:\n",
    "                break\n",
    "            else:\n",
    "                pairs = get_pairs(word)\n",
    "\n",
    "        # don't print end-of-word symbols\n",
    "        if word[-1] == '</w>':\n",
    "            word = word[:-1]\n",
    "        elif word[-1].endswith('</w>'):\n",
    "            word = word[:-1] + (word[-1].replace('</w>', ''),)\n",
    "\n",
    "        return word\n",
    "\n",
    "    def __init__(self, codes, separator='@@'):\n",
    "        self.encode = functools.lru_cache(maxsize=65536)(self.encode)\n",
    "        self.bpe_codes = [tuple(item.split()) for item in codes]\n",
    "        # some hacking to deal with duplicates (only consider first instance)\n",
    "        self.bpe_codes = dict([(code,i) for (i,code) in reversed(list(enumerate(self.bpe_codes)))])\n",
    "\n",
    "        self.separator = separator\n",
    "\n",
    "    def segment(self, sentence):\n",
    "        output = []\n",
    "        for word in sentence.split():\n",
    "            new_word = self.encode(word)\n",
    "\n",
    "            for item in new_word[:-1]:\n",
    "                output.append(item + self.separator)\n",
    "            output.append(new_word[-1])\n",
    "\n",
    "        return ' '.join(output)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "32435aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python3\n",
      "# Author: Rico Sennrich\n",
      "\n",
      "\"\"\"Use operations learned with learn_bpe.py to encode a new text.\n",
      "The text will not be smaller, but use only a fixed vocabulary, with rare words\n",
      "encoded as variable-length sequences of subword units.\n",
      "\n",
      "Reference:\n",
      "Rico Sennrich, Barry Haddow and Alexandra Birch (2016). Neural Machine Translation of Rare Words with Subword Units.\n",
      "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016). Berlin, Germany.\n",
      "\"\"\"\n",
      "\n",
      "import sys\n",
      "import codecs\n",
      "import argparse\n",
      "import functools\n",
      "from collections import defaultdict\n",
      "\n",
      "class BPE(object):\n",
      "    def encode(self, orig):\n",
      "        \"\"\"Encode word based on list of BPE merge operations, which are applied consecutively\n",
      "        \"\"\"\n",
      "        word = tuple(orig) + ('</w>',)\n",
      "        pairs = get_pairs(word)\n",
      "\n",
      "        while True:\n",
      "            bigram = min(pairs, key=lambda pair: self.bpe_codes.get(pair, float('inf')))\n",
      "            if bigram not in self.bpe_codes:\n",
      "                break\n",
      "            first, second = bigram\n",
      "            new_word = []\n",
      "            i = 0\n",
      "            while i < len(word):\n",
      "                try:\n",
      "                    j = word.index(first, i)\n",
      "                    new_word.extend(word[i:j])\n",
      "                    i = j\n",
      "                except:\n",
      "                    new_word.extend(word[i:])\n",
      "                    break\n",
      "\n",
      "                if word[i] == first and i < len(word) - 1 and word[i + 1] == second:\n",
      "                    new_word.append(first + second)\n",
      "                    i += 2\n",
      "                else:\n",
      "                    new_word.append(word[i])\n",
      "                    i += 1\n",
      "            new_word = tuple(new_word)\n",
      "            word = new_word\n",
      "            if len(word) == 1:\n",
      "                break\n",
      "            else:\n",
      "                pairs = get_pairs(word)\n",
      "\n",
      "        # don't print end-of-word symbols\n",
      "        if word[-1] == '</w>':\n",
      "            word = word[:-1]\n",
      "        elif word[-1].endswith('</w>'):\n",
      "            word = word[:-1] + (word[-1].replace('</w>', ''),)\n",
      "\n",
      "        return word\n",
      "\n",
      "    def __init__(self, codes, separator='@@'):\n",
      "        self.encode = functools.lru_cache(maxsize=65536)(self.encode)\n",
      "        self.bpe_codes = [tuple(item.split()) for item in codes]\n",
      "        # some hacking to deal with duplicates (only consider first instance)\n",
      "        self.bpe_codes = dict([(code,i) for (i,code) in reversed(list(enumerate(self.bpe_codes)))])\n",
      "\n",
      "        self.separator = separator\n",
      "\n",
      "    def segment(self, sentence):\n",
      "        \"\"\"segment single sentence (whitespace-tokenized string) with BPE encoding\"\"\"\n",
      "\n",
      "        output = []\n",
      "        for word in sentence.split():\n",
      "            new_word = self.encode(word)\n",
      "\n",
      "            for item in new_word[:-1]:\n",
      "                output.append(item + self.separator)\n",
      "            output.append(new_word[-1])\n",
      "\n",
      "        return ' '.join(output)\n",
      "\n",
      "\n",
      "def create_parser():\n",
      "    parser = argparse.ArgumentParser(\n",
      "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
      "        description=\"learn BPE-based word segmentation\")\n",
      "\n",
      "    parser.add_argument(\n",
      "        '--input', '-i', type=argparse.FileType('r'), default=sys.stdin,\n",
      "        metavar='PATH',\n",
      "        help=\"Input file (default: standard input).\")\n",
      "    parser.add_argument(\n",
      "        '--codes', '-c', type=argparse.FileType('r'), metavar='PATH',\n",
      "        required=True,\n",
      "        help=\"File with BPE codes (created by learn_bpe.py).\")\n",
      "    parser.add_argument(\n",
      "        '--output', '-o', type=argparse.FileType('w'), default=sys.stdout,\n",
      "        metavar='PATH',\n",
      "        help=\"Output file (default: standard output)\")\n",
      "    parser.add_argument(\n",
      "        '--separator', '-s', type=str, default='@@', metavar='STR',\n",
      "        help=\"Separator between non-final subword units (default: '%(default)s'))\")\n",
      "\n",
      "    return parser\n",
      "\n",
      "def get_pairs(word):\n",
      "    \"\"\"Return set of symbol pairs in a word.\n",
      "\n",
      "    word is represented as tuple of symbols (symbols being variable-length strings)\n",
      "    \"\"\"\n",
      "    pairs = set()\n",
      "    prev_char = word[0]\n",
      "    for char in word[1:]:\n",
      "        pairs.add((prev_char, char))\n",
      "        prev_char = char\n",
      "    return pairs\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    parser = create_parser()\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    bpe = BPE(args.codes, args.separator)\n",
      "\n",
      "    for line in args.input:\n",
      "        args.output.write(bpe.segment(line).strip())\n",
      "        args.output.write('\\n')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "896ef999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'encode': ['tuple',\n",
       "  'orig',\n",
       "  'get_pairs',\n",
       "  'word',\n",
       "  'min',\n",
       "  'pairs',\n",
       "  'bigram',\n",
       "  'word.index',\n",
       "  'first',\n",
       "  'i',\n",
       "  'new_word.extend',\n",
       "  'j',\n",
       "  'new_word.append',\n",
       "  'new_word.append',\n",
       "  'first',\n",
       "  'second',\n",
       "  'tuple',\n",
       "  'new_word',\n",
       "  'new_word',\n",
       "  'get_pairs',\n",
       "  'word',\n",
       "  'word[(- 1)].endswith'],\n",
       " '__init__': ['functools.lru_cache', 'self.encode', 'dict', 'separator'],\n",
       " 'segment': ['word',\n",
       "  'self.encode',\n",
       "  'word',\n",
       "  'item',\n",
       "  'output.append',\n",
       "  'item',\n",
       "  'self.separator',\n",
       "  'output.append',\n",
       "  'sentence.split']}"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_function_calls(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "338346c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items = ast.parse(\"a.append(1)\").body\n",
    "expr = items[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "c71bb943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a.append']"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_calls_from_expr_or_assign(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "30fdf04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ast.Attribute at 0x7f4fefc9f610>"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "45e5fc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a.append(1)\\n'"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b0060351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_ast.Expr"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2a8a58b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Expr' object has no attribute 'attr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-76c45e27e7a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Expr' object has no attribute 'attr'"
     ]
    }
   ],
   "source": [
    "expr.attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4c522a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbar()\\n'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "astunparse.unparse(expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "12f71194",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FunctionDef' object has no attribute 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-3900b8421785>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'FunctionDef' object has no attribute 'value'"
     ]
    }
   ],
   "source": [
    "items[0].body[0].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "02d1ef65",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'call' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-8388f7b334c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'call' is not defined"
     ]
    }
   ],
   "source": [
    "call.func.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cefaa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710acc6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97420fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686987ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a0036e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
