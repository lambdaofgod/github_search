{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4b285009",
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4ea0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "from github_search import paperswithcode_tasks\n",
    "import gensim.models\n",
    "import pandas as pd\n",
    "\n",
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a74bebe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "283c90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:15:07: Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO - 13:15:07: NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "paperswithcode_df, all_papers_df = paperswithcode_tasks.get_paperswithcode_dfs()\n",
    "papers_with_readmes_df = pd.read_csv(\"output/papers_with_readmes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55758acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_with_readmes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f5535c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/papers_with_readmes.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/*readme*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b09e757",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_sentences(papers_df, papers_with_readmes_df, max_length=1000):\n",
    "    abstract_sentences = papers_df['abstract'].str.lower().str.split(\" \").dropna()\n",
    "    readme_sentences = papers_with_readmes_df['readme'].str.lower().str.split(\" \").dropna()\n",
    "    sentences = list(abstract_sentences) + list(readme_sentences)\n",
    "    return [sent[:max_length] for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6355848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = get_sentences(all_papers_df, papers_with_readmes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcfb84a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = get_sentences(all_papers_df, papers_with_readmes_df)\n",
    "lengths = pd.Series(map(len, sentences))#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42fd1863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class LossLogger(CallbackAny2Vec):\n",
    "    '''Output loss at each epoch'''\n",
    "    def __init__(self):\n",
    "        self.epoch = 1\n",
    "        self.losses = []\n",
    "\n",
    "    def on_epoch_begin(self, model):\n",
    "        print(f'Epoch: {self.epoch}', end='\\t')\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        self.losses.append(loss)\n",
    "        print(f'  Loss: {loss}')\n",
    "        self.epoch += 1\n",
    "        \n",
    "        \n",
    "        \n",
    "class LossCallback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "803e6324",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c387ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def make_w2v_model(sentences, embedding_dim=200):\n",
    "    w2v_model = gensim.models.Word2Vec(size=embedding_dim, window=5, min_count=5, workers=24, callbacks=[LossCallback()])\n",
    "    w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "    return w2v_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73451d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def train_abstract_readme_w2v(embedding_dim, epochs, upstream, product):\n",
    " \n",
    "    paperswithcode_df, all_papers_df = paperswithcode_tasks.get_paperswithcode_dfs()\n",
    "    papers_with_readmes_df = pd.read_csv(upstream[\"make_readmes\"])\n",
    "    \n",
    "    sentences = get_sentences(all_papers_df, papers_with_readmes_df)\n",
    "    lengths = pd.Series(map(len, sentences))#.describe()\n",
    "   \n",
    "    w2v_model = make_w2v_model(sentences)\n",
    "    w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=epochs, report_delay=1, compute_loss=True)\n",
    "    w2v_model.save(str(product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "49335e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:22:06: collecting all words and their counts\n",
      "INFO - 13:22:06: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #10000, processed 1533202 words, keeping 112056 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #20000, processed 3081944 words, keeping 184077 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #30000, processed 4592495 words, keeping 245351 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #40000, processed 6095252 words, keeping 302891 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #50000, processed 7600080 words, keeping 356535 word types\n",
      "INFO - 13:22:06: PROGRESS: at sentence #60000, processed 9071210 words, keeping 408868 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #70000, processed 10566770 words, keeping 457473 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #80000, processed 12088703 words, keeping 502932 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #90000, processed 13668998 words, keeping 547426 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #100000, processed 15216529 words, keeping 592193 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #110000, processed 16750039 words, keeping 634003 word types\n",
      "INFO - 13:22:07: PROGRESS: at sentence #120000, processed 18298322 words, keeping 673591 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #130000, processed 19707591 words, keeping 712049 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #140000, processed 20968010 words, keeping 751111 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #150000, processed 22186397 words, keeping 788934 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #160000, processed 23359043 words, keeping 824469 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #170000, processed 24708350 words, keeping 863793 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #180000, processed 26012957 words, keeping 900375 word types\n",
      "INFO - 13:22:08: PROGRESS: at sentence #190000, processed 27374281 words, keeping 936973 word types\n",
      "INFO - 13:22:09: PROGRESS: at sentence #200000, processed 29158432 words, keeping 1036745 word types\n",
      "INFO - 13:22:09: PROGRESS: at sentence #210000, processed 33806726 words, keeping 1532425 word types\n",
      "INFO - 13:22:09: collected 1557868 word types from a corpus of 34072111 raw words and 210651 sentences\n",
      "INFO - 13:22:09: Loading a fresh vocabulary\n",
      "INFO - 13:22:10: effective_min_count=5 retains 144098 unique words (9% of original 1557868, drops 1413770)\n",
      "INFO - 13:22:10: effective_min_count=5 leaves 32222340 word corpus (94% of original 34072111, drops 1849771)\n",
      "INFO - 13:22:10: deleting the raw counts dictionary of 1557868 items\n",
      "INFO - 13:22:10: sample=0.001 downsamples 28 most-common words\n",
      "INFO - 13:22:10: downsampling leaves estimated 24859368 word corpus (77.1% of prior 32222340)\n",
      "INFO - 13:22:10: estimated required memory for 144098 words and 200 dimensions: 302605800 bytes\n",
      "INFO - 13:22:10: resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model = make_w2v_model(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4bca7bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144098"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4f7890db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:22:22: training model with 24 workers on 144098 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "INFO - 13:22:23: EPOCH 1 - PROGRESS: at 7.43% examples, 1786780 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:22:24: EPOCH 1 - PROGRESS: at 15.66% examples, 1878979 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:25: EPOCH 1 - PROGRESS: at 23.61% examples, 1876082 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:26: EPOCH 1 - PROGRESS: at 32.00% examples, 1886753 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:27: EPOCH 1 - PROGRESS: at 40.30% examples, 1911051 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:22:28: EPOCH 1 - PROGRESS: at 48.32% examples, 1923741 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:29: EPOCH 1 - PROGRESS: at 56.23% examples, 1926390 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:30: EPOCH 1 - PROGRESS: at 65.16% examples, 1926468 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:22:31: EPOCH 1 - PROGRESS: at 75.15% examples, 1918257 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:32: EPOCH 1 - PROGRESS: at 84.52% examples, 1921214 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:22:33: EPOCH 1 - PROGRESS: at 93.55% examples, 1920077 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:34: EPOCH 1 - PROGRESS: at 96.96% examples, 1913341 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:22:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:22:35: EPOCH - 1 : training on 34072111 raw words (24860898 effective words) took 13.0s, 1913156 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 2057522.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:22:36: EPOCH 2 - PROGRESS: at 7.73% examples, 1861076 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:37: EPOCH 2 - PROGRESS: at 15.90% examples, 1903972 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:22:38: EPOCH 2 - PROGRESS: at 23.87% examples, 1894421 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:39: EPOCH 2 - PROGRESS: at 32.09% examples, 1897040 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:40: EPOCH 2 - PROGRESS: at 40.24% examples, 1911448 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:22:41: EPOCH 2 - PROGRESS: at 48.14% examples, 1908642 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:22:42: EPOCH 2 - PROGRESS: at 56.35% examples, 1922902 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:22:43: EPOCH 2 - PROGRESS: at 65.54% examples, 1927768 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:22:44: EPOCH 2 - PROGRESS: at 75.88% examples, 1927803 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:45: EPOCH 2 - PROGRESS: at 85.14% examples, 1925170 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:22:46: EPOCH 2 - PROGRESS: at 94.36% examples, 1929417 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:47: EPOCH 2 - PROGRESS: at 97.40% examples, 1928941 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:22:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:22:48: EPOCH - 2 : training on 34072111 raw words (24858887 effective words) took 12.9s, 1930484 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 1: 1819594.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:22:49: EPOCH 3 - PROGRESS: at 7.73% examples, 1840435 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:50: EPOCH 3 - PROGRESS: at 16.06% examples, 1916283 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:22:51: EPOCH 3 - PROGRESS: at 24.25% examples, 1925502 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:52: EPOCH 3 - PROGRESS: at 32.84% examples, 1944272 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:53: EPOCH 3 - PROGRESS: at 40.81% examples, 1943535 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:54: EPOCH 3 - PROGRESS: at 48.57% examples, 1939869 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:55: EPOCH 3 - PROGRESS: at 56.88% examples, 1952650 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:22:56: EPOCH 3 - PROGRESS: at 65.77% examples, 1944586 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:22:57: EPOCH 3 - PROGRESS: at 75.99% examples, 1939641 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:58: EPOCH 3 - PROGRESS: at 85.54% examples, 1942053 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:22:59: EPOCH 3 - PROGRESS: at 94.59% examples, 1948144 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:00: EPOCH 3 - PROGRESS: at 97.59% examples, 1944189 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:23:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:23:01: EPOCH - 3 : training on 34072111 raw words (24856817 effective words) took 12.8s, 1945846 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 2: 1651906.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:23:02: EPOCH 4 - PROGRESS: at 7.79% examples, 1878169 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:03: EPOCH 4 - PROGRESS: at 15.88% examples, 1879934 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:23:04: EPOCH 4 - PROGRESS: at 23.93% examples, 1891679 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:05: EPOCH 4 - PROGRESS: at 31.81% examples, 1875084 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:06: EPOCH 4 - PROGRESS: at 39.54% examples, 1872515 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:07: EPOCH 4 - PROGRESS: at 47.21% examples, 1875319 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:23:08: EPOCH 4 - PROGRESS: at 55.46% examples, 1891495 words/s, in_qsize 47, out_qsize 1\n",
      "INFO - 13:23:09: EPOCH 4 - PROGRESS: at 64.29% examples, 1897249 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:10: EPOCH 4 - PROGRESS: at 74.48% examples, 1897747 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:23:11: EPOCH 4 - PROGRESS: at 83.66% examples, 1894502 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:12: EPOCH 4 - PROGRESS: at 92.91% examples, 1899416 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:13: EPOCH 4 - PROGRESS: at 96.87% examples, 1902890 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:23:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:23:14: EPOCH - 4 : training on 34072111 raw words (24859970 effective words) took 13.1s, 1900533 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 3: 1492426.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:23:15: EPOCH 5 - PROGRESS: at 7.73% examples, 1870772 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:16: EPOCH 5 - PROGRESS: at 15.97% examples, 1909369 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:17: EPOCH 5 - PROGRESS: at 24.34% examples, 1932697 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:18: EPOCH 5 - PROGRESS: at 32.39% examples, 1909217 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:19: EPOCH 5 - PROGRESS: at 40.15% examples, 1899050 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:20: EPOCH 5 - PROGRESS: at 48.29% examples, 1917656 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:21: EPOCH 5 - PROGRESS: at 56.57% examples, 1931535 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:22: EPOCH 5 - PROGRESS: at 65.88% examples, 1936716 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:23: EPOCH 5 - PROGRESS: at 76.30% examples, 1938511 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:24: EPOCH 5 - PROGRESS: at 85.54% examples, 1936081 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:25: EPOCH 5 - PROGRESS: at 94.42% examples, 1933465 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:26: EPOCH 5 - PROGRESS: at 97.41% examples, 1932639 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:23:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:23:27: EPOCH - 5 : training on 34072111 raw words (24860811 effective words) took 12.9s, 1927047 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 4: 1462750.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:23:28: EPOCH 6 - PROGRESS: at 7.55% examples, 1832605 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:23:29: EPOCH 6 - PROGRESS: at 15.62% examples, 1881147 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:30: EPOCH 6 - PROGRESS: at 23.61% examples, 1876663 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:31: EPOCH 6 - PROGRESS: at 32.00% examples, 1892954 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:32: EPOCH 6 - PROGRESS: at 39.89% examples, 1885165 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:33: EPOCH 6 - PROGRESS: at 47.59% examples, 1890008 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:34: EPOCH 6 - PROGRESS: at 55.58% examples, 1895958 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:35: EPOCH 6 - PROGRESS: at 64.33% examples, 1897148 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:36: EPOCH 6 - PROGRESS: at 74.27% examples, 1894352 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:37: EPOCH 6 - PROGRESS: at 83.81% examples, 1897953 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:38: EPOCH 6 - PROGRESS: at 92.92% examples, 1899938 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:39: EPOCH 6 - PROGRESS: at 96.80% examples, 1898692 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:23:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:23:40: EPOCH - 6 : training on 34072111 raw words (24858972 effective words) took 13.1s, 1898564 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 5: 1328508.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:23:41: EPOCH 7 - PROGRESS: at 7.61% examples, 1841138 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:42: EPOCH 7 - PROGRESS: at 15.66% examples, 1880140 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:43: EPOCH 7 - PROGRESS: at 24.00% examples, 1909642 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:44: EPOCH 7 - PROGRESS: at 32.21% examples, 1902162 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:45: EPOCH 7 - PROGRESS: at 40.39% examples, 1916975 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:46: EPOCH 7 - PROGRESS: at 47.83% examples, 1906001 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:23:47: EPOCH 7 - PROGRESS: at 55.87% examples, 1910029 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:48: EPOCH 7 - PROGRESS: at 64.75% examples, 1913099 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:49: EPOCH 7 - PROGRESS: at 74.91% examples, 1910494 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:50: EPOCH 7 - PROGRESS: at 83.73% examples, 1900392 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:51: EPOCH 7 - PROGRESS: at 92.35% examples, 1891119 words/s, in_qsize 40, out_qsize 7\n",
      "INFO - 13:23:52: EPOCH 7 - PROGRESS: at 96.57% examples, 1889483 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:53: EPOCH 7 - PROGRESS: at 99.71% examples, 1886367 words/s, in_qsize 25, out_qsize 1\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:23:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:23:53: EPOCH - 7 : training on 34072111 raw words (24859390 effective words) took 13.2s, 1887953 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 6: 1316486.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:23:54: EPOCH 8 - PROGRESS: at 7.52% examples, 1818033 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:55: EPOCH 8 - PROGRESS: at 15.47% examples, 1838028 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:56: EPOCH 8 - PROGRESS: at 23.71% examples, 1860652 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:23:57: EPOCH 8 - PROGRESS: at 32.18% examples, 1884680 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:23:58: EPOCH 8 - PROGRESS: at 40.12% examples, 1887221 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:23:59: EPOCH 8 - PROGRESS: at 48.04% examples, 1895736 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:00: EPOCH 8 - PROGRESS: at 56.08% examples, 1905779 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:01: EPOCH 8 - PROGRESS: at 64.82% examples, 1904261 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:24:02: EPOCH 8 - PROGRESS: at 74.87% examples, 1900175 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:03: EPOCH 8 - PROGRESS: at 84.02% examples, 1898878 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:04: EPOCH 8 - PROGRESS: at 92.73% examples, 1893733 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:05: EPOCH 8 - PROGRESS: at 96.86% examples, 1899022 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:24:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:24:06: EPOCH - 8 : training on 34072111 raw words (24861307 effective words) took 13.1s, 1897377 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 7: 1275684.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:24:07: EPOCH 9 - PROGRESS: at 7.70% examples, 1861543 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:08: EPOCH 9 - PROGRESS: at 15.87% examples, 1893453 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:09: EPOCH 9 - PROGRESS: at 23.90% examples, 1897904 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:10: EPOCH 9 - PROGRESS: at 31.97% examples, 1889130 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:24:11: EPOCH 9 - PROGRESS: at 39.80% examples, 1888150 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:12: EPOCH 9 - PROGRESS: at 47.47% examples, 1890515 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:13: EPOCH 9 - PROGRESS: at 55.40% examples, 1897453 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:14: EPOCH 9 - PROGRESS: at 64.03% examples, 1892525 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:15: EPOCH 9 - PROGRESS: at 73.96% examples, 1890743 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:16: EPOCH 9 - PROGRESS: at 82.98% examples, 1880399 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:17: EPOCH 9 - PROGRESS: at 91.87% examples, 1880016 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:18: EPOCH 9 - PROGRESS: at 96.51% examples, 1882293 words/s, in_qsize 40, out_qsize 7\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:24:19: EPOCH 9 - PROGRESS: at 99.78% examples, 1886194 words/s, in_qsize 20, out_qsize 1\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:24:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:24:19: EPOCH - 9 : training on 34072111 raw words (24859402 effective words) took 13.2s, 1887999 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 8: 1307585.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:24:20: EPOCH 10 - PROGRESS: at 7.61% examples, 1839313 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:21: EPOCH 10 - PROGRESS: at 15.72% examples, 1886720 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:22: EPOCH 10 - PROGRESS: at 24.03% examples, 1915056 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:24:23: EPOCH 10 - PROGRESS: at 32.12% examples, 1900598 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:24:24: EPOCH 10 - PROGRESS: at 40.36% examples, 1920696 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:24:25: EPOCH 10 - PROGRESS: at 48.28% examples, 1929029 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:26: EPOCH 10 - PROGRESS: at 55.97% examples, 1922102 words/s, in_qsize 42, out_qsize 5\n",
      "INFO - 13:24:27: EPOCH 10 - PROGRESS: at 64.78% examples, 1920074 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:24:28: EPOCH 10 - PROGRESS: at 74.99% examples, 1918392 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:29: EPOCH 10 - PROGRESS: at 83.91% examples, 1910462 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:24:30: EPOCH 10 - PROGRESS: at 92.80% examples, 1905903 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:31: EPOCH 10 - PROGRESS: at 96.84% examples, 1907481 words/s, in_qsize 42, out_qsize 5\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:24:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:24:32: EPOCH - 10 : training on 34072111 raw words (24860667 effective words) took 13.0s, 1905728 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 9: 1258963.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:24:33: EPOCH 11 - PROGRESS: at 7.79% examples, 1875602 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:34: EPOCH 11 - PROGRESS: at 16.03% examples, 1913749 words/s, in_qsize 48, out_qsize 3\n",
      "INFO - 13:24:35: EPOCH 11 - PROGRESS: at 24.16% examples, 1917328 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:37: EPOCH 11 - PROGRESS: at 32.37% examples, 1910481 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:38: EPOCH 11 - PROGRESS: at 40.27% examples, 1909539 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:39: EPOCH 11 - PROGRESS: at 48.10% examples, 1912675 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:40: EPOCH 11 - PROGRESS: at 56.08% examples, 1918751 words/s, in_qsize 48, out_qsize 4\n",
      "INFO - 13:24:41: EPOCH 11 - PROGRESS: at 64.91% examples, 1915730 words/s, in_qsize 40, out_qsize 7\n",
      "INFO - 13:24:42: EPOCH 11 - PROGRESS: at 75.09% examples, 1912284 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:24:43: EPOCH 11 - PROGRESS: at 84.02% examples, 1904290 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:44: EPOCH 11 - PROGRESS: at 93.10% examples, 1902934 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:45: EPOCH 11 - PROGRESS: at 96.96% examples, 1903582 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:45: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:24:45: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:24:45: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:24:45: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:24:45: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:24:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:24:46: EPOCH - 11 : training on 34072111 raw words (24860272 effective words) took 13.1s, 1903644 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 10: 1272975.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:24:47: EPOCH 12 - PROGRESS: at 7.58% examples, 1836383 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:48: EPOCH 12 - PROGRESS: at 15.47% examples, 1849761 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:24:49: EPOCH 12 - PROGRESS: at 23.33% examples, 1853938 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:50: EPOCH 12 - PROGRESS: at 31.50% examples, 1864278 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:51: EPOCH 12 - PROGRESS: at 39.59% examples, 1878235 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:52: EPOCH 12 - PROGRESS: at 47.36% examples, 1886532 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:53: EPOCH 12 - PROGRESS: at 55.28% examples, 1892191 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:24:54: EPOCH 12 - PROGRESS: at 63.88% examples, 1888315 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:24:55: EPOCH 12 - PROGRESS: at 73.69% examples, 1884294 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:56: EPOCH 12 - PROGRESS: at 83.05% examples, 1885708 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:24:57: EPOCH 12 - PROGRESS: at 91.84% examples, 1882931 words/s, in_qsize 42, out_qsize 5\n",
      "INFO - 13:24:58: EPOCH 12 - PROGRESS: at 96.50% examples, 1885822 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:24:59: EPOCH 12 - PROGRESS: at 99.62% examples, 1883425 words/s, in_qsize 31, out_qsize 3\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:24:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:24:59: EPOCH - 12 : training on 34072111 raw words (24858879 effective words) took 13.2s, 1886173 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 11: 1135052.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:25:00: EPOCH 13 - PROGRESS: at 7.55% examples, 1826397 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:01: EPOCH 13 - PROGRESS: at 15.74% examples, 1893800 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:25:02: EPOCH 13 - PROGRESS: at 23.45% examples, 1871971 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:03: EPOCH 13 - PROGRESS: at 31.40% examples, 1859375 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:04: EPOCH 13 - PROGRESS: at 39.09% examples, 1857137 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:05: EPOCH 13 - PROGRESS: at 46.55% examples, 1853925 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:06: EPOCH 13 - PROGRESS: at 54.65% examples, 1866029 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:07: EPOCH 13 - PROGRESS: at 62.95% examples, 1868589 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:08: EPOCH 13 - PROGRESS: at 73.11% examples, 1874065 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:09: EPOCH 13 - PROGRESS: at 82.36% examples, 1872224 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:25:10: EPOCH 13 - PROGRESS: at 91.28% examples, 1872178 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:11: EPOCH 13 - PROGRESS: at 96.21% examples, 1871457 words/s, in_qsize 39, out_qsize 8\n",
      "INFO - 13:25:12: EPOCH 13 - PROGRESS: at 99.34% examples, 1872080 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:25:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:25:12: EPOCH - 13 : training on 34072111 raw words (24859646 effective words) took 13.3s, 1871692 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 12: 1017576.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:25:13: EPOCH 14 - PROGRESS: at 7.46% examples, 1749318 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:14: EPOCH 14 - PROGRESS: at 15.72% examples, 1862260 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:15: EPOCH 14 - PROGRESS: at 23.58% examples, 1860941 words/s, in_qsize 42, out_qsize 5\n",
      "INFO - 13:25:16: EPOCH 14 - PROGRESS: at 31.93% examples, 1868402 words/s, in_qsize 47, out_qsize 1\n",
      "INFO - 13:25:17: EPOCH 14 - PROGRESS: at 39.63% examples, 1865981 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:25:18: EPOCH 14 - PROGRESS: at 47.36% examples, 1871540 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:19: EPOCH 14 - PROGRESS: at 55.17% examples, 1876893 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:25:20: EPOCH 14 - PROGRESS: at 63.77% examples, 1881607 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:21: EPOCH 14 - PROGRESS: at 73.70% examples, 1875684 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:22: EPOCH 14 - PROGRESS: at 83.15% examples, 1879150 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:23: EPOCH 14 - PROGRESS: at 92.24% examples, 1882819 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:25:24: EPOCH 14 - PROGRESS: at 96.64% examples, 1886304 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:25: EPOCH 14 - PROGRESS: at 99.71% examples, 1880530 words/s, in_qsize 23, out_qsize 4\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:25:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:25:25: EPOCH - 14 : training on 34072111 raw words (24859102 effective words) took 13.2s, 1883193 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 13: 1032434.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:25:26: EPOCH 15 - PROGRESS: at 7.79% examples, 1867722 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:25:27: EPOCH 15 - PROGRESS: at 16.00% examples, 1906783 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:28: EPOCH 15 - PROGRESS: at 24.00% examples, 1901651 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:29: EPOCH 15 - PROGRESS: at 32.15% examples, 1893289 words/s, in_qsize 41, out_qsize 6\n",
      "INFO - 13:25:30: EPOCH 15 - PROGRESS: at 40.12% examples, 1899814 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:31: EPOCH 15 - PROGRESS: at 47.93% examples, 1905666 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:32: EPOCH 15 - PROGRESS: at 56.14% examples, 1921464 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:33: EPOCH 15 - PROGRESS: at 64.44% examples, 1907477 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:34: EPOCH 15 - PROGRESS: at 74.34% examples, 1902948 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:35: EPOCH 15 - PROGRESS: at 83.59% examples, 1895272 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:36: EPOCH 15 - PROGRESS: at 92.58% examples, 1895799 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:37: EPOCH 15 - PROGRESS: at 96.75% examples, 1898405 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:25:38: EPOCH 15 - PROGRESS: at 99.96% examples, 1897082 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:25:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:25:38: EPOCH - 15 : training on 34072111 raw words (24861243 effective words) took 13.1s, 1896812 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 14: 1001370.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:25:39: EPOCH 16 - PROGRESS: at 7.85% examples, 1873307 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:40: EPOCH 16 - PROGRESS: at 15.84% examples, 1891225 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:25:41: EPOCH 16 - PROGRESS: at 23.77% examples, 1884882 words/s, in_qsize 48, out_qsize 4\n",
      "INFO - 13:25:42: EPOCH 16 - PROGRESS: at 31.87% examples, 1883801 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:25:43: EPOCH 16 - PROGRESS: at 39.74% examples, 1885473 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:44: EPOCH 16 - PROGRESS: at 47.24% examples, 1881533 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:25:45: EPOCH 16 - PROGRESS: at 55.28% examples, 1892590 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:46: EPOCH 16 - PROGRESS: at 63.81% examples, 1892356 words/s, in_qsize 42, out_qsize 5\n",
      "INFO - 13:25:47: EPOCH 16 - PROGRESS: at 73.81% examples, 1889074 words/s, in_qsize 40, out_qsize 7\n",
      "INFO - 13:25:48: EPOCH 16 - PROGRESS: at 83.16% examples, 1887475 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:49: EPOCH 16 - PROGRESS: at 92.43% examples, 1893818 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:50: EPOCH 16 - PROGRESS: at 96.66% examples, 1895801 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:51: EPOCH 16 - PROGRESS: at 99.69% examples, 1886380 words/s, in_qsize 27, out_qsize 1\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:25:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:25:51: EPOCH - 16 : training on 34072111 raw words (24859122 effective words) took 13.2s, 1889493 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 15: 996368.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:25:53: EPOCH 17 - PROGRESS: at 7.79% examples, 1881651 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:54: EPOCH 17 - PROGRESS: at 15.93% examples, 1915782 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:55: EPOCH 17 - PROGRESS: at 24.00% examples, 1907497 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:25:56: EPOCH 17 - PROGRESS: at 32.00% examples, 1895000 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:57: EPOCH 17 - PROGRESS: at 40.03% examples, 1903620 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:25:58: EPOCH 17 - PROGRESS: at 47.74% examples, 1904681 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:25:59: EPOCH 17 - PROGRESS: at 55.70% examples, 1910418 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:26:00: EPOCH 17 - PROGRESS: at 64.22% examples, 1904199 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:01: EPOCH 17 - PROGRESS: at 74.18% examples, 1900723 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:02: EPOCH 17 - PROGRESS: at 83.34% examples, 1895858 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:03: EPOCH 17 - PROGRESS: at 92.54% examples, 1894937 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:04: EPOCH 17 - PROGRESS: at 96.76% examples, 1896887 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:26:05: EPOCH 17 - PROGRESS: at 99.96% examples, 1894912 words/s, in_qsize 4, out_qsize 1\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:26:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:26:05: EPOCH - 17 : training on 34072111 raw words (24857806 effective words) took 13.1s, 1895882 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 16: 989056.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:26:06: EPOCH 18 - PROGRESS: at 7.46% examples, 1797936 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:07: EPOCH 18 - PROGRESS: at 15.47% examples, 1853033 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:08: EPOCH 18 - PROGRESS: at 23.08% examples, 1839122 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:26:09: EPOCH 18 - PROGRESS: at 30.45% examples, 1807135 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:26:10: EPOCH 18 - PROGRESS: at 38.12% examples, 1806343 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:11: EPOCH 18 - PROGRESS: at 45.34% examples, 1803523 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:26:12: EPOCH 18 - PROGRESS: at 53.02% examples, 1811081 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:26:13: EPOCH 18 - PROGRESS: at 60.81% examples, 1811454 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:26:14: EPOCH 18 - PROGRESS: at 70.63% examples, 1821600 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:15: EPOCH 18 - PROGRESS: at 79.53% examples, 1812122 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:16: EPOCH 18 - PROGRESS: at 88.55% examples, 1817098 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:17: EPOCH 18 - PROGRESS: at 95.25% examples, 1819321 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:26:18: EPOCH 18 - PROGRESS: at 98.15% examples, 1817327 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:26:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:26:18: EPOCH - 18 : training on 34072111 raw words (24862285 effective words) took 13.7s, 1817822 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 17: 974142.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:26:19: EPOCH 19 - PROGRESS: at 7.34% examples, 1767251 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:26:20: EPOCH 19 - PROGRESS: at 15.72% examples, 1888360 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:21: EPOCH 19 - PROGRESS: at 23.55% examples, 1872425 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:22: EPOCH 19 - PROGRESS: at 31.87% examples, 1887386 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:23: EPOCH 19 - PROGRESS: at 39.77% examples, 1891959 words/s, in_qsize 43, out_qsize 4\n",
      "INFO - 13:26:24: EPOCH 19 - PROGRESS: at 47.84% examples, 1909108 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:25: EPOCH 19 - PROGRESS: at 55.61% examples, 1908154 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:26: EPOCH 19 - PROGRESS: at 64.33% examples, 1906627 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:27: EPOCH 19 - PROGRESS: at 74.59% examples, 1909016 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:28: EPOCH 19 - PROGRESS: at 83.98% examples, 1910309 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:29: EPOCH 19 - PROGRESS: at 92.89% examples, 1906216 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:30: EPOCH 19 - PROGRESS: at 96.92% examples, 1912161 words/s, in_qsize 48, out_qsize 0\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:26:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:26:31: EPOCH - 19 : training on 34072111 raw words (24857757 effective words) took 13.0s, 1912283 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 18: 937938.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:26:32: EPOCH 20 - PROGRESS: at 7.34% examples, 1777550 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:33: EPOCH 20 - PROGRESS: at 15.10% examples, 1802488 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:34: EPOCH 20 - PROGRESS: at 22.86% examples, 1814998 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:35: EPOCH 20 - PROGRESS: at 30.68% examples, 1813076 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:36: EPOCH 20 - PROGRESS: at 38.24% examples, 1808284 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:37: EPOCH 20 - PROGRESS: at 45.56% examples, 1809384 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:38: EPOCH 20 - PROGRESS: at 53.27% examples, 1814629 words/s, in_qsize 44, out_qsize 3\n",
      "INFO - 13:26:39: EPOCH 20 - PROGRESS: at 61.00% examples, 1815879 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:40: EPOCH 20 - PROGRESS: at 70.75% examples, 1819457 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:41: EPOCH 20 - PROGRESS: at 79.99% examples, 1818181 words/s, in_qsize 47, out_qsize 0\n",
      "INFO - 13:26:42: EPOCH 20 - PROGRESS: at 88.49% examples, 1812940 words/s, in_qsize 46, out_qsize 1\n",
      "INFO - 13:26:43: EPOCH 20 - PROGRESS: at 95.15% examples, 1811248 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:44: EPOCH 20 - PROGRESS: at 97.89% examples, 1801919 words/s, in_qsize 45, out_qsize 2\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 23 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 22 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 21 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 20 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 19 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 18 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 17 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 16 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 15 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 13:26:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 13:26:45: EPOCH - 20 : training on 34072111 raw words (24856128 effective words) took 13.8s, 1805975 effective words/s\n",
      "INFO - 13:26:45: training on a 681442220 raw words (497189361 effective words) took 262.9s, 1891356 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 19: 936440.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(497189361, 681442220)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=20, report_delay=1, compute_loss=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0598dbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 13:26:48: saving Word2Vec object under output/abstract_readme_w2v200.bin, separately None\n",
      "INFO - 13:26:48: storing np array 'vectors' to output/abstract_readme_w2v200.bin.wv.vectors.npy\n",
      "INFO - 13:26:48: not storing attribute vectors_norm\n",
      "INFO - 13:26:48: storing np array 'syn1neg' to output/abstract_readme_w2v200.bin.trainables.syn1neg.npy\n",
      "INFO - 13:26:48: not storing attribute cum_table\n",
      "INFO - 13:26:48: saved output/abstract_readme_w2v200.bin\n"
     ]
    }
   ],
   "source": [
    "w2v_model.save(\"output/abstract_readme_w2v{}.bin\".format(embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ee5b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abstract_w2v100.bin\r\n",
      "abstract_w2v100.bin.trainables.syn1neg.npy\r\n",
      "abstract_w2v100.bin.wv.vectors.npy\r\n",
      "abstract_w2v200.bin\r\n",
      "abstract_w2v200.bin.trainables.syn1neg.npy\r\n",
      "abstract_w2v200.bin.wv.vectors.npy\r\n",
      "abstract_w2v300.bin\r\n",
      "abstract_w2v300.bin.trainables.syn1neg.npy\r\n",
      "abstract_w2v300.bin.wv.vectors.npy\r\n",
      "abstract_w2v.bin\r\n",
      "abstract_w2v.bin.trainables.syn1neg.npy\r\n",
      "abstract_w2v.bin.wv.vectors.npy\r\n",
      "call_igraph.pkl\r\n",
      "data_w2v.bin\r\n",
      "data_w2v.bin.trainables.syn1neg.npy\r\n",
      "data_w2v.bin.wv.vectors.npy\r\n",
      "dependency_records.csv\r\n",
      "gnn_embeddings_fasttext_dim200_epochs2_dim200_layers2.bin\r\n",
      "gnn_embeddings_fasttext_dim200_epochs2_dim200_layers2.bin.vectors.npy\r\n",
      "gnn_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin\r\n",
      "gnn_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin.vectors.npy\r\n",
      "gnn_model_2_dim200_layers2.pth\r\n",
      "gnn_model_50_dim200_layers2.pth\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs100_dim200_layers2.bin\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs100_dim200_layers2.bin.vectors.npy\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs1_dim200_layers2.bin\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs1_dim200_layers2.bin.vectors.npy\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin\r\n",
      "graph_infomax_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin.vectors.npy\r\n",
      "graph_infomax_model_100_dim200_layers2.pth\r\n",
      "graph_infomax_model_10_dim200_layers2.pth\r\n",
      "graph_infomax_model_1_dim200_layers2.pth\r\n",
      "graph_infomax_model_50_dim200_layers2.pth\r\n",
      "graphsage_embeddings.bin\r\n",
      "graphsage_embeddings.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs100_dim100_layers2.bin\r\n",
      "graphsage_embeddings_epochs100_dim100_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs100_dim200_layers2.bin\r\n",
      "graphsage_embeddings_epochs100_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs1.bin\r\n",
      "graphsage_embeddings_epochs1.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs2_dim200_layers2.bin\r\n",
      "graphsage_embeddings_epochs2_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs50_dim200_layers2.bin\r\n",
      "graphsage_embeddings_epochs50_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_epochs50_dim200_layers3.bin\r\n",
      "graphsage_embeddings_epochs50_dim200_layers3.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs100_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs100_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs10_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs10_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs11_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs11_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs1_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs1_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs200_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs200_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs21_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs21_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs2_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs2_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs40_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs50_dim100_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs50_dim100_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs51_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs51_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs60_dim200_layers2.bin\r\n",
      "graphsage_embeddings_fasttext_dim200_epochs60_dim200_layers2.bin.vectors.npy\r\n",
      "graphsage_model_100_dim100_layers2.pth\r\n",
      "graphsage_model_100_dim200_layers2.pth\r\n",
      "graphsage_model_10_dim200_layers2.pth\r\n",
      "graphsage_model_11_dim200_layers2.pth\r\n",
      "graphsage_model_1_dim200_layers2.pth\r\n",
      "graphsage_model_200_dim200_layers2.pth\r\n",
      "graphsage_model_20_dim200_layers2.pth\r\n",
      "graphsage_model_21_dim200_layers2.pth\r\n",
      "graphsage_model_2_dim200_layers2.pth\r\n",
      "graphsage_model_40_dim200_layers2.pth\r\n",
      "graphsage_model_50_dim100_layers2.pth\r\n",
      "graphsage_model_50_dim200_layers2.pth\r\n",
      "graphsage_model_50_dim200_layers3.pth\r\n",
      "graphsage_model_51_dim200_layers2.pth\r\n",
      "graphsage_model_60_dim200_layers2.pth\r\n",
      "graphsage_model_no_root.pth\r\n",
      "graphsage_model.pth\r\n",
      "import2vec_module_vectors.bin\r\n",
      "loss_graph_infomax_fasttext_dim200_epochs100_dim200_layers2.png\r\n",
      "loss_graph_infomax_fasttext_dim200_epochs1_dim200_layers2.png\r\n",
      "loss_graph_infomax_fasttext_dim200_epochs50_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs100_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs10_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs11_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs1_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs200_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs21_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs50_dim200_layers2.png\r\n",
      "loss_graphsage_fasttext_dim200_epochs51_dim200_layers2.png\r\n",
      "module_corpus.csv\r\n",
      "papers_with_imports.csv\r\n",
      "papers_with_readmes.csv\r\n",
      "processed_dependency_records.csv\r\n",
      "python_fasttext\r\n",
      "python_fasttext.bin\r\n",
      "python_files_corpus.csv\r\n",
      "python_files_fasttext_dim200.bin\r\n",
      "python_functions.csv\r\n",
      "residual_graphsage_embeddings.bin\r\n",
      "residual_graphsage_embeddings.bin.vectors.npy\r\n",
      "residual_graphsage_model.pth\r\n",
      "sage_model.pth\r\n",
      "shared_task_repos.csv\r\n",
      "similarity_scorer.pt\r\n",
      "test_tasks.csv\r\n",
      "tmp_graph_data.pkl\r\n",
      "token2vec_training.ipynb\r\n",
      "train_tasks.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17eaf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tasks = pd.read_csv('output/test_tasks.csv').iloc[:,0]\n",
    "train_tasks = pd.read_csv('output/train_tasks.csv').iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7c7828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlutil.feature_extraction import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea8ad5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_embedder = embeddings.AverageWordEmbeddingsVectorizer(w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0933b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_task_embeddings = avg_embedder.transform(test_tasks)\n",
    "train_task_embeddings = avg_embedder.transform(train_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8aecee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_similarities = pd.DataFrame(test_task_embeddings @ train_task_embeddings.T, columns=train_tasks, index=test_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74a5edc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image classification': 'audio classification',\n",
       " 'representation learning': 'sparse learning',\n",
       " 'object detection': 'object recognition',\n",
       " 'neural architecture search': 'bilevel optimization',\n",
       " 'optical character recognition': 'object recognition',\n",
       " 'time series': 'real-time strategy games',\n",
       " 'car racing': 'autonomous vehicles',\n",
       " 'dimensionality reduction': 'sparse learning',\n",
       " 'pose estimation': 'density estimation',\n",
       " 'knowledge graphs': 'dependency parsing',\n",
       " 'machine translation': 'speech-to-text translation',\n",
       " 'text matching': 'semantic parsing',\n",
       " 'hyperparameter optimization': 'bilevel optimization',\n",
       " 'information retrieval': 'semantic segmentation',\n",
       " 'word alignment': 'word sense disambiguation',\n",
       " 'natural language inference': 'natural language understanding',\n",
       " 'variational inference': 'bilevel optimization',\n",
       " 'boundary detection': 'lane detection',\n",
       " 'point processes': 'latent variable models',\n",
       " 'sentiment analysis': 'lexical analysis',\n",
       " 'named entity recognition': 'entity linking',\n",
       " 'stochastic optimization': 'bilevel optimization',\n",
       " 'combinatorial optimization': 'bilevel optimization',\n",
       " 'depth estimation': 'density estimation',\n",
       " 'document summarization': 'code summarization',\n",
       " 'link prediction': 'saliency prediction',\n",
       " 'open information extraction': 'entity linking',\n",
       " 'object classification': 'object recognition',\n",
       " 'transfer learning': 'meta-learning',\n",
       " 'speech recognition': 'object recognition',\n",
       " 'gaussian processes': 'latent variable models',\n",
       " 'emotion recognition': 'object recognition',\n",
       " 'word embeddings': 'word sense disambiguation',\n",
       " 'activity recognition': 'object recognition',\n",
       " 'hate speech detection': 'audio classification',\n",
       " 'active learning': 'sparse learning',\n",
       " 'dialogue generation': 'vision-language navigation',\n",
       " 'style transfer': 'domain adaptation',\n",
       " 'quantization': 'bilevel optimization',\n",
       " 'image generation': 'image-to-image translation',\n",
       " 'eye tracking': 'object recognition',\n",
       " 'topic models': 'latent variable models',\n",
       " 'entity embeddings': 'entity linking',\n",
       " 'data augmentation': 'domain adaptation',\n",
       " 'outlier detection': 'lane detection',\n",
       " 'noise estimation': 'density estimation',\n",
       " 'sentence classification': 'node classification',\n",
       " 'question answering': 'natural language understanding',\n",
       " 'anomaly detection': 'lane detection',\n",
       " 'visual question answering': 'vision-language navigation',\n",
       " 'community detection': 'lane detection',\n",
       " 'recommendation systems': 'autonomous vehicles',\n",
       " 'image inpainting': 'image-to-image translation',\n",
       " 'scene text': 'semantic parsing',\n",
       " 'video classification': 'audio classification',\n",
       " 'image retrieval': 'image-to-image translation',\n",
       " 'autonomous driving': 'autonomous vehicles',\n",
       " 'bayesian inference': 'bilevel optimization',\n",
       " 'text classification': 'audio classification',\n",
       " 'coreference resolution': 'image super-resolution',\n",
       " 'reading comprehension': 'natural language understanding',\n",
       " 'continuous control': 'safe exploration',\n",
       " 'imitation learning': 'federated learning',\n",
       " 'disease prediction': 'seizure prediction',\n",
       " 'denoising': '3d reconstruction',\n",
       " 'image quality assessment': 'image-to-image translation',\n",
       " 'structured prediction': 'saliency prediction',\n",
       " 'object tracking': 'object recognition',\n",
       " 'eeg': 'audio classification',\n",
       " 'fairness': 'federated learning',\n",
       " 'entity extraction using gan': 'entity linking',\n",
       " 'robust classification': 'node classification',\n",
       " 'speaker identification': 'speaker verification',\n",
       " 'text simplification': 'speech-to-text translation',\n",
       " 'action detection': 'lane detection',\n",
       " 'face detection': 'lane detection',\n",
       " 'program synthesis': 'novel view synthesis',\n",
       " 'code generation': 'code summarization',\n",
       " 'activity prediction': 'seizure prediction',\n",
       " 'chatbot': 'natural language understanding',\n",
       " 'offline rl': 'multi-agent reinforcement learning',\n",
       " '3d point cloud matching': '3d reconstruction',\n",
       " 'image compression': 'image-to-image translation',\n",
       " 'ssim': 'stereo matching',\n",
       " 'robot navigation': 'autonomous vehicles',\n",
       " 'computed tomography (ct)': '3d reconstruction',\n",
       " 'action classification': 'object recognition',\n",
       " 'image forensics': 'image-to-image translation',\n",
       " 'general reinforcement learning': 'federated learning',\n",
       " 'music classification': 'audio classification',\n",
       " 'text categorization': 'arabic text diacritization',\n",
       " 'tensor networks': 'matrix completion',\n",
       " 'audio generation': 'audio classification',\n",
       " 'probabilistic programming': 'bilevel optimization',\n",
       " 'dictionary learning': 'sparse learning',\n",
       " 'feature selection': 'prototype selection',\n",
       " 'conversational response generation': 'natural language understanding',\n",
       " 'slot filling': 'entity linking',\n",
       " 'graph construction': 'matrix completion',\n",
       " 'face recognition': 'object recognition',\n",
       " 'graph classification': 'node classification',\n",
       " 'hyperspectral unmixing': '3d reconstruction',\n",
       " 'motion planning': 'human motion prediction',\n",
       " 'face verification': 'speaker verification',\n",
       " 'music transcription': 'speech-to-text translation',\n",
       " 'binarization': 'colorization',\n",
       " 'image captioning': 'image-to-image translation',\n",
       " 'relation extraction': 'entity linking',\n",
       " 'morphological analysis': 'lexical analysis',\n",
       " 'argument mining': 'entity linking',\n",
       " 'text generation': 'speech-to-text translation',\n",
       " 'future prediction': 'saliency prediction',\n",
       " 'autonomous navigation': 'autonomous vehicles',\n",
       " 'text summarization': 'code summarization',\n",
       " 'atari games': 'fps games',\n",
       " 'data visualization': 'image-to-image translation',\n",
       " 'model compression': 'latent variable models',\n",
       " 'language identification': 'language modelling',\n",
       " 'medical image segmentation': 'semantic segmentation',\n",
       " 'drug discovery': 'entity linking',\n",
       " 'model selection': 'prototype selection',\n",
       " 'genre classification': 'audio classification',\n",
       " 'image enhancement': 'image-to-image translation',\n",
       " 'texture synthesis': '3d reconstruction',\n",
       " 'causal inference': 'interpretable machine learning',\n",
       " 'dialogue management': 'vision-language navigation',\n",
       " 'document classification': 'audio classification',\n",
       " 'image reconstruction': '3d reconstruction',\n",
       " 'object discovery': 'object recognition',\n",
       " 'lesion segmentation': 'semantic segmentation',\n",
       " 'knowledge graph embeddings': 'semantic parsing',\n",
       " 'music generation': 'speech-to-text translation',\n",
       " 'sequential pattern mining': 'interpretable machine learning',\n",
       " 'neural rendering': '3d reconstruction',\n",
       " 'feature engineering': 'interpretable machine learning',\n",
       " 'motion capture': 'human motion prediction',\n",
       " 'action recognition': 'object recognition',\n",
       " 'image registration': 'image-to-image translation',\n",
       " 'chunking': 'dependency parsing',\n",
       " 'hierarchical structure': 'semantic parsing',\n",
       " 'football action valuation': 'fps games',\n",
       " 'automated theorem proving': 'autonomous vehicles',\n",
       " 'arrhythmia detection': 'lane detection',\n",
       " 'electron microscopy': '3d reconstruction',\n",
       " 'facial landmark detection': 'object recognition',\n",
       " 'amr parsing': 'dependency parsing',\n",
       " 'hierarchical reinforcement learning': 'sparse learning',\n",
       " 'speech synthesis': 'speech-to-text translation',\n",
       " 'visual tracking': 'object recognition',\n",
       " 'language acquisition': 'language modelling',\n",
       " 'semantic role labeling': 'semantic parsing',\n",
       " 'network pruning': 'sparse learning',\n",
       " 'facial expression recognition': 'object recognition',\n",
       " 'scene understanding': 'video understanding',\n",
       " 'semantic textual similarity': 'semantic parsing',\n",
       " 'image clustering': 'image-to-image translation',\n",
       " 'survival analysis': 'lexical analysis',\n",
       " '3d face reconstruction': '3d reconstruction',\n",
       " 'discourse parsing': 'dependency parsing',\n",
       " 'saliency detection': 'lane detection',\n",
       " 'speech separation': 'speech-to-text translation',\n",
       " 'topological data analysis': 'lexical analysis',\n",
       " 'metric learning': 'sparse learning',\n",
       " 'imputation': 'matrix completion',\n",
       " 'video generation': 'video understanding',\n",
       " 'relational reasoning': 'entity linking',\n",
       " 'skeleton based action recognition': 'object recognition',\n",
       " 'object localization': 'object recognition',\n",
       " 'conditional image generation': 'image-to-image translation',\n",
       " 'scene text detection': 'semantic segmentation',\n",
       " 'bayesian optimisation': 'bilevel optimization',\n",
       " 'graph embedding': 'node classification',\n",
       " 'openai gym': 'fps games',\n",
       " 'speaker diarization': 'speaker verification',\n",
       " 'domain generalization': 'domain adaptation',\n",
       " 'curriculum learning': 'meta-learning'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_similarities.idxmax().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7939b3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 19:02:03: loading Word2Vec object from output/abstract_w2v.bin\n",
      "INFO - 19:02:03: loading wv recursively from output/abstract_w2v.bin.wv.* with mmap=None\n",
      "INFO - 19:02:03: loading vectors from output/abstract_w2v.bin.wv.vectors.npy with mmap=None\n",
      "INFO - 19:02:04: setting ignored attribute vectors_norm to None\n",
      "INFO - 19:02:04: loading vocabulary recursively from output/abstract_w2v.bin.vocabulary.* with mmap=None\n",
      "INFO - 19:02:04: loading trainables recursively from output/abstract_w2v.bin.trainables.* with mmap=None\n",
      "INFO - 19:02:04: loading syn1neg from output/abstract_w2v.bin.trainables.syn1neg.npy with mmap=None\n",
      "INFO - 19:02:04: setting ignored attribute cum_table to None\n",
      "INFO - 19:02:04: loaded output/abstract_w2v.bin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x7f8c81468520>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.models.Word2Vec.load('output/abstract_w2v.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c528a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
