{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cd42d2-99f5-4ced-830f-d9da36a6e841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "\n",
    "\n",
    "from beir.retrieval.search.dense import DenseRetrievalExactSearch as DRES\n",
    "from beir.retrieval.models import SPLADE, SentenceBERT, UniCOIL\n",
    "from beir.retrieval.search.sparse import SparseSearch\n",
    "\n",
    "\n",
    "from beir import util, LoggingHandler\n",
    "from beir.datasets.data_loader import GenericDataLoader\n",
    "from github_search.evaluation.beir_evaluation import EvaluateRetrievalCustom as EvaluateRetrieval, CorpusDataLoader\n",
    "from beir.retrieval.search.lexical import BM25Search as BM25\n",
    "\n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8967a0ce-5bad-4061-993a-cfc9a4eb1a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('readme', 6612),\n",
       " ('generated_readme', 6612),\n",
       " ('selected_code', 6612),\n",
       " ('generated_rationale', 6612),\n",
       " ('generation_context', 6612),\n",
       " ('dependency_signature', 6612),\n",
       " ('repository_signature', 6612),\n",
       " ('generated_tasks', 6612),\n",
       " ('pagerank_dependency_signature', 6612),\n",
       " ('pagerank_repository_signature', 6612),\n",
       " ('pagerank_generated_tasks', 6612)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"/home/kuba/Projects/github_search/.dagster/storage/corpus_information\", \"rb\") as f:\n",
    "    corpora = json.loads(pickle.load(f))\n",
    "\n",
    "[(cname, len(corpora[cname].keys())) for cname in corpora.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da73bc-c3ee-4e89-a06a-59a17e936333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6af53a-04d8-4e5b-8a3b-91e4e7471340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks', 'pagerank_dependency_signature', 'pagerank_repository_signature', 'pagerank_generated_tasks'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f005a3a6-de4b-460a-aadf-3962f5def8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repos_for_query(query, repos_df):\n",
    "    return repos_df[repos_df[\"tasks\"].apply(lambda ts: query in ts)]\n",
    "\n",
    "\n",
    "def get_queries(repos_df, min_query_count):\n",
    "    all_queries = repos_df[\"query_tasks\"].explode()\n",
    "    qcounts = all_queries.value_counts()\n",
    "    return qcounts[qcounts >= min_query_count].index.to_list()\n",
    "\n",
    "def prepare_query_data(repos_df, min_query_count=5):\n",
    "    task_queries = {str(i): query for (i, query) in enumerate(get_queries(repos_df, min_query_count=min_query_count))}\n",
    "\n",
    "    task_qrels = {\n",
    "        qid: {str(corpus_id): 1 for corpus_id in get_repos_for_query(task_queries[qid], repos_df).index}\n",
    "        for qid in task_queries.keys()\n",
    "    }\n",
    "    return task_queries, task_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2dc99ab-6021-4d6e-9273-50c9f2a258a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/kuba/Projects/github_search/.dagster/storage/sampled_repos\", \"rb\") as f:\n",
    "    sampled_repos_df = pickle.load(f)\n",
    "\n",
    "\n",
    "repos_sorted = [rec[\"title\"] for rec in list(corpora[\"readme\"].values())]\n",
    "sampled_repos_df = pd.Series(repos_sorted, name=\"repo\").reset_index().merge(sampled_repos_df, on=\"repo\")\n",
    "task_queries, task_qrels = prepare_query_data(sampled_repos_df, min_query_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "065e32c3-742a-480f-a5e1-8f9b259d185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    693.000000\n",
       "mean      24.288600\n",
       "std       30.528634\n",
       "min       10.000000\n",
       "25%       11.000000\n",
       "50%       14.000000\n",
       "75%       23.000000\n",
       "max      258.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(map(len, task_qrels.values())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d20cb1a2-6e2d-4478-8988-d9d383815382",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df = sampled_repos_df[sampled_repos_df[\"tasks\"].apply(len) <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b228c43-b209-4731-bb8a-308733c30562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "706e4557-3e76-4ef7-a071-c1ef40983caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6612, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_repos_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f88c6013-ca4d-41b7-8512-9a134b0c3d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/elasticsearch/queries_qrels.json\", \"w\") as f:\n",
    "    json.dump({\"task_queries\": task_queries, \"task_qrels\": task_qrels}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc5caf7e-5d2b-4283-acc3-9bcf03d432a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cid in corpora[\"readme\"].keys():\n",
    "    assert corpora[\"readme\"][cid][\"title\"] == corpora[\"readme\"][cid][\"title\"], f\"no match at {cid}\"\n",
    "    #assert corpora[\"readme\"][cid][\"title\"] == corpora[(\"dependency_signature\", 0)][cid][\"title\"], f\"no match at {cid}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83edb572-ef27-470b-b16d-90a8621b9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf282096-1c70-453a-a73e-219386ba86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import elasticsearch\n",
    "\n",
    "es_client = elasticsearch.Elasticsearch()\n",
    "def retrieve_repos_with_es(query, k=50, index=\"readme\", es_client=es_client):\n",
    "    es_result = es_client.search(index=index, body={\"query\": {\"match\": {\"txt\": query}}}, size=k)\n",
    "    return [\n",
    "        hit[\"_source\"][\"title\"]\n",
    "        for hit in es_result[\"hits\"][\"hits\"]\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "def get_elasticsearch_results():\n",
    "    retrieved_repo_tasks = {}\n",
    "\n",
    "    qcounts = sampled_repos_df[\"tasks\"].explode().value_counts()\n",
    "    used_queries = [\n",
    "        query\n",
    "        for query in sampled_repos_df[\"tasks\"].explode().drop_duplicates()\n",
    "        if qcounts.loc[query] > 5\n",
    "    ]\n",
    "    # [task_queries[qid] for qid in task_queries.keys()]\n",
    "    \n",
    "    index=\"selected_code\"\n",
    "    for query in used_queries:\n",
    "        retrieved_tasks = sampled_repos_df[sampled_repos_df[\"repo\"].isin(retrieve_repos_with_es(query, index=index))][\"tasks\"].to_list()\n",
    "        retrieved_repo_tasks[query] = retrieved_tasks\n",
    "    \n",
    "    k = 10\n",
    "    query_hits = pd.Series({\n",
    "        query: sum([query in tasks for tasks in retrieved_repo_tasks[query][:k]])\n",
    "        for query in retrieved_repo_tasks.keys()\n",
    "    })\n",
    "\n",
    "def show_elasticsearch_results(qid='10'):\n",
    "    query = task_queries[qid]\n",
    "    \n",
    "    print(query)\n",
    "    print(query_hits[query], \"hits\")\n",
    "    \n",
    "    for hit in es_client.search(index=index, body={\"query\": {\"match\": {\"txt\": task_queries[qid]}}}, size=k)[\"hits\"][\"hits\"]:\n",
    "        print(\"#\" * 100)\n",
    "        print(\"#\" * 100)\n",
    "        repo_name = hit[\"_source\"][\"title\"]\n",
    "        repo_record = sampled_repos_df[sampled_repos_df[\"repo\"] == repo_name].iloc[0]\n",
    "        is_hit = query in repo_record[\"tasks\"]\n",
    "        print(repo_name, \"HIT\" if is_hit else \"NO HIT\")\n",
    "        \n",
    "        if is_hit:\n",
    "            print(\"#\" * 100)\n",
    "            print(\"#\" * 100)\n",
    "            print(hit['_source']['txt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4604b8c5-a332-4213-b1c3-3101fd14e78f",
   "metadata": {},
   "source": [
    "## Evaluating with BEIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29db4c1f-942f-4eab-afdd-8383454bee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v_sentence_transformer(w2v_model_path):\n",
    "    w2v_layer = sentence_transformers.models.WordEmbeddings.load(w2v_model_path)\n",
    "    return sentence_transformers.SentenceTransformer(modules=[w2v_layer, sentence_transformers.models.Pooling(200)])\n",
    "\n",
    "\n",
    "\n",
    "def load_sentence_bert(model_name):\n",
    "    st_model = SentenceBERT(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    st_model.doc_model = sentence_transformers.SentenceTransformer(model_name, trust_remote_code=True)\n",
    "    st_model.q_model = st_model.doc_model\n",
    "    return st_model\n",
    "\n",
    "def get_w2v_retriever(w2v_model_path=\"../models/rnn_abstract_readme_w2v/0_WordEmbeddings\"):\n",
    "    w2v_model = load_w2v_sentence_transformer(w2v_model_path)\n",
    "    st_model = SentenceBERT(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "    st_model.q_model = w2v_model\n",
    "    st_model.doc_model = w2v_model\n",
    "    return EvaluateRetrieval(DRES(st_model), score_function=\"cos_sim\")\n",
    "\n",
    "def get_splade_retriever(splade_model_path = \"splade/weights/distilsplade_max\", batch_size=128):\n",
    "    splade_model = DRES(SPLADE(splade_model_path), batch_size=128)\n",
    "    return EvaluateRetrieval(splade_model, score_function=\"dot\")\n",
    "\n",
    "\n",
    "def get_bm25_retrievers(corpora):\n",
    "    def sanitize_index_name(index_name):\n",
    "        if type(index_name) is str:\n",
    "            return index_name\n",
    "        else:\n",
    "            return \"\".join(map(str, index_name))\n",
    "    \n",
    "    bm25_retrievers = {}\n",
    "    for corpus_name, corpus in corpora.items():\n",
    "        model = BM25(index_name=sanitize_index_name(corpus_name))\n",
    "        retriever = EvaluateRetrieval(model)\n",
    "        bm25_retrievers[corpus_name] = retriever\n",
    "    return bm25_retrievers\n",
    "\n",
    "\n",
    "sentence_transformer_model_names = [\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L12-v2\",\n",
    "    #\"nomic-ai/modernbert-embed-base\",\n",
    "    \n",
    "    #\"estrogen/ModernBERT-base-nli-v3\"\n",
    "    #\"BAAI/bge-large-en-v1.5\",\n",
    "    #\"mixedbread-ai/mxbai-embed-large-v1\"\n",
    "]\n",
    "\n",
    "def get_sentence_transformer_retriever(model_name=\"sentence-transformers/all-mpnet-base-v2\", batch_size=8):\n",
    "    model = DRES(load_sentence_bert(model_name), batch_size=batch_size)\n",
    "    return EvaluateRetrieval(model, score_function=\"cos_sim\")\n",
    "\n",
    "def get_unicoil_retriever(model_name=\"castorini/unicoil-msmarco-passage\"):\n",
    "    \"\"\"\n",
    "    THERE IS A BUG WITH BEIR THAT MAKES THIS UNUSABLE\n",
    "    \"\"\"\n",
    "    model = SparseSearch(UniCOIL(model_path=model_name), batch_size=32)\n",
    "    return EvaluateRetrieval(model, score_function=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ed3348-debd-45ec-b586-fe6f943d9e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34cb1626-55ea-4e1e-9e87-45a6a4e21c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corpus_samples(corpora, n_repos=10):\n",
    "    records = []\n",
    "\n",
    "\n",
    "    for k in range(n_repos):\n",
    "        for cname in corpora.keys():\n",
    "            if type(cname) is tuple:\n",
    "                if 0 in cname:\n",
    "                    display_name = cname[0]\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                display_name = cname\n",
    "            record = corpora[cname][str(k)]\n",
    "            record[\"corpus\"] = display_name\n",
    "            records.append(record)\n",
    "    \n",
    "    return pd.DataFrame.from_records(records).rename(columns = {\"title\": \"repo_name\", \"corpus\": \"representation\"}).fillna(method=\"ffill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5210f6e-bfd0-44ad-b5c1-d95eb081832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘../output/visualization’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir ../output/visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe4c6b5-6062-4968-9c3f-d43d5975e5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443875/3647930632.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  return pd.DataFrame.from_records(records).rename(columns = {\"title\": \"repo_name\", \"corpus\": \"representation\"}).fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "df = get_corpus_samples(corpora)#.to_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfe95090-1f4a-4c85-bedb-e4173bb667e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_repomaps_df(repo_names, repomap_path=\"../output/aider/selected_repo_maps_1024.json\"):\n",
    "    with open(repomap_path) as f:\n",
    "        repomaps = json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for repo in repo_names:\n",
    "        records.append({\"repo_name\": repo, \"text\": repomaps[repo], \"representation\": \"repomap\"})\n",
    "    return pd.DataFrame.from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bbd5a42-e6e2-487a-b387-0f6e7eec2d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9092ee5-62dd-4b79-84e2-217d4716f056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_443875/1298409671.py:3: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  ).sort_values(\"repo_name\").fillna(method=\"ffill\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat(\n",
    "    [df, get_repomaps_df(df[\"repo_name\"].unique())]\n",
    ").sort_values(\"repo_name\").fillna(method=\"ffill\")\n",
    "#df[\"representation\"] = df[\"representation\"].apply(lambda c: c if c not in [\"generated_readme\", \"generated_rationale\", \"generation_context\"] else c + \" (repomap)\")\n",
    "#df.to_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b94a5f0-9e64-42ce-8ba5-91bc75d0e8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    df,\n",
    "    pd.read_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")\n",
    "]).drop_duplicates(subset=[\"repo_name\", \"representation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9425195f-1d01-4de7-954e-263d531e53a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5662080-549e-49da-a11a-3062c94b55f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8805f3b-eb8f-4ab5-a4b7-0b5b5a9e722e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"representation\"] = df[\"representation\"].apply(lambda c: c if c not in [\"generated_readme\", \"generated_rationale\", \"generation_context\"] else c + \" (repomap)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccdb881f-28cc-4f3a-89b0-c4c6a3349afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_json(\"../output/visualization/corpus_samples.jsonl\", lines=True, orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5df4ee24-b553-4adb-83dc-58ca61e78483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(corpora[\"selected_code\"]['0'][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "340ddf1d-935c-442f-867b-7f260a53840f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '# PyTorch Implementation of Differentiable ODE Solvers\\n\\nThis library provides ordinary differential equation (ODE) solvers implemented in PyTorch. Backpropagation through all solvers is supported using the adjoint method. For usage of ODE solvers in deep learning applications, see [1].\\n\\nAs the solvers are implemented in PyTorch, algorithms in this repository are fully supported to run on the GPU.\\n\\n---\\n\\n<p align=\"center\">\\n  <img align=\"middle\" src=\"./assets/resnet_0_viz.png\" alt=\"Discrete-depth network\" width=\"240\" height=\"330\" />\\n  <img align=\"middle\" src=\"./assets/odenet_0_viz.png\" alt=\"Continuous-depth network\" width=\"240\" height=\"330\" />\\n</p>\\n\\n## Installation\\n```\\ngit clone https://github.com/rtqichen/torchdiffeq.git\\ncd torchdiffeq\\npip install -e .\\n```\\n\\n## Examples\\nExamples are placed in the [`examples`](./examples) directory.\\n\\nWe encourage those who are interested in using this library to take a look at [`examples/ode_demo.py`](./examples/ode_demo.py) for understanding how to use `torchdiffeq` to fit a simple spiral ODE.\\n\\n<p align=\"center\">\\n<img align=\"middle\" src=\"./assets/ode_demo.gif\" alt=\"ODE Demo\" width=\"500\" height=\"250\" />\\n</p>\\n\\n## Basic usage\\nThis library provides one main interface `odeint` which contains general-purpose algorithms for solving initial value problems (IVP), with gradients implemented for all main arguments. An initial value problem consists of an ODE and an initial value,\\n```\\ndy/dt = f(t, y)    y(t_0) = y_0.\\n```\\nThe goal of an ODE solver is to find a continuous trajectory satisfying the ODE that passes through the initial condition.\\n\\nTo solve an IVP using the default solver:\\n```\\nfrom torchdiffeq import odeint\\n\\nodeint(func, y0, t)\\n```\\nwhere `func` is any callable implementing the ordinary differential equation `f(t, x)`, `y0` is an _any_-D Tensor or a tuple of _any_-D Tensors representing the initial values, and `t` is a 1-D Tensor containing the evaluation points. The initial time is taken to be `t[0]`.\\n\\nBackpropagation through `odeint` goes through the internals of the solver, but this is not supported for all solvers. Instead, we encourage the use of the adjoint method explained in [1], which will allow solving with as many steps as necessary due to O(1) memory usage.\\n\\nTo use the adjoint method:\\n```\\nfrom torchdiffeq import odeint_adjoint as odeint\\n\\nodeint(func, y0, t)\\n```\\n`odeint_adjoint` simply wraps around `odeint`, but will use only O(1) memory in exchange for solving an adjoint ODE in the backward call.\\n\\nThe biggest **gotcha** is that `func` must be a `nn.Module` when using the adjoint method. This is used to collect parameters of the differential equation.\\n\\n### Keyword Arguments\\n - `rtol` Relative tolerance.\\n - `atol` Absolute tolerance.\\n - `method` One of the solvers listed below.\\n\\n#### List of ODE Solvers:\\n\\nAdaptive-step:\\n - `dopri5` Runge-Kutta 4(5) [default].\\n - `adams` Adaptive-order implicit Adams.\\n\\nFixed-step:\\n - `euler` Euler method.\\n - `midpoint` Midpoint method.\\n - `rk4` Fourth-order Runge-Kutta with 3/8 rule.\\n - `explicit_adams` Explicit Adams.\\n - `fixed_adams` Implicit Adams.\\n\\n### References\\n[1] Ricky T. Q. Chen, Yulia Rubanova, Jesse Bettencourt, David Duvenaud. \"Neural Ordinary Differential Equations.\" *Advances in Neural Processing Information Systems.* 2018. [[arxiv]](https://arxiv.org/abs/1806.07366)\\n\\n---\\n\\nIf you found this library useful in your research, please consider citing\\n```\\n@article{chen2018neural,\\n  title={Neural Ordinary Differential Equations},\\n  author={Chen, Ricky T. Q. and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},\\n  journal={Advances in Neural Information Processing Systems},\\n  year={2018}\\n}\\n```\\n',\n",
       " 'title': '000Justin000/torchdiffeq',\n",
       " 'tasks': ['multivariate time series forecasting',\n",
       "  'point processes',\n",
       "  'multivariate time series imputation',\n",
       "  'time series'],\n",
       " 'corpus': 'readme'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpora[\"readme\"][\"0\"]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "430a4a4d-7544-481c-9162-0dea50557b2b",
   "metadata": {},
   "source": [
    "from pylate import indexes, models, retrieve\n",
    "\n",
    "model = models.ColBERT(\n",
    "    model_name_or_path=\"jinaai/jina-colbert-v2\",\n",
    "    query_prefix=\"[QueryMarker]\",\n",
    "    document_prefix=\"[DocumentMarker]\",\n",
    "    attend_to_expansion_tokens=True,\n",
    "    trust_remote_code=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f71ad01-be83-4c5b-81a7-0ac6e2125515",
   "metadata": {},
   "source": [
    "from pylate import indexes, models, retrieve\n",
    "\n",
    "\n",
    "class PyLateBEIRWrapper:\n",
    "\n",
    "    def __init__(self, model_name=\"lightonai/colbertv2.0\"):\n",
    "        \n",
    "        self.model = models.ColBERT(\n",
    "            model_name_or_path=model_name,\n",
    "        )\n",
    "        self.index = indexes.Voyager(\n",
    "            index_folder=f\"../output/pylate-index/{model_name}\",\n",
    "            index_name=\"index\",\n",
    "            override=True,\n",
    "        )\n",
    "        self.retriever = None\n",
    "\n",
    "    def index_corpus(self, corpus):\n",
    "        documents = corpus.values()\n",
    "        documents_embeddings = self.model.encode(\n",
    "            documents,\n",
    "            batch_size=32,\n",
    "            is_query=False, # Encoding documents\n",
    "            show_progress_bar=True,\n",
    "        )\n",
    "        \n",
    "        # Add the documents ids and embeddings to the Voyager index\n",
    "        self.index.add_documents(\n",
    "            documents_ids=corpus.keys(),\n",
    "            documents_embeddings=documents_embeddings,\n",
    "        )\n",
    "        self.retriever = retrieve.ColBERT(index=self.index)\n",
    "\n",
    "    def retrieve(self, query):\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "pylate_model = PyLateBEIRWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e14491d-8bea-4763-b085-6032bbdb15bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cef6e243-b9da-448e-a770-7bab0ab911ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_retriever = get_w2v_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e9510f3e-a487-401a-b26a-9500a18a207c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<github_search.evaluation.beir_evaluation.EvaluateRetrievalCustom at 0x7cebdc1e6060>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81ca835a-6dd8-4613-91da-8d6ac91fd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splade_retriever = get_splade_retriever() \n",
    "\n",
    "# change sentence-transformers to 2.7?\n",
    "sentence_transformer_retrievers = {\n",
    "    model_name: get_sentence_transformer_retriever(model_name)\n",
    "    for model_name in sentence_transformer_model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c3b2d5d-a0a6-4d33-8756-08440e8d5b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_retrievers = get_bm25_retrievers(corpora)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd6f53b-0741-4917-90f9-7ae398521920",
   "metadata": {},
   "source": [
    "## Per query results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e571da2-af1a-4c13-9789-b6a59f00006c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import Dict\n",
    "\n",
    "class RetrieverInput(BaseModel):\n",
    "    corpus: Dict[str, dict]\n",
    "    queries: Dict[str, str]\n",
    "    qrels: Dict[str, Dict[str, int]]\n",
    "\n",
    "\n",
    "class RetrievalEvaluationResults(BaseModel):\n",
    "    retrieval_results: Dict[str, Dict[str, float]]\n",
    "    metrics: dict\n",
    "    model_type: str\n",
    "\n",
    "    @classmethod\n",
    "    def from_retriever(cls, retriever, retriever_input, metric_names=[\"accuracy@k\", \"hits@k\", \"r_cap@k\", \"mrr@k\"]):\n",
    "        retrieval_results = retriever.retrieve(retriever_input.corpus, retriever_input.queries)\n",
    "        custom_metrics = retriever.evaluate_custom_multi(retriever_input.qrels, retrieval_results, retriever.k_values, metrics=metric_names)\n",
    "        other_metrics = retriever.evaluate(retriever_input.qrels, retrieval_results, retriever.k_values, ignore_identical_ids=False)\n",
    "        metrics = custom_metrics | cls.tuple_to_dict(other_metrics)\n",
    "        try:\n",
    "            model_type = str(retriever.retriever.model)\n",
    "        except:\n",
    "            model_type = \"bm25\"\n",
    "        return RetrievalEvaluationResults(metrics=metrics, model_type=model_type, retrieval_results=retrieval_results)\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def tuple_to_dict(cls, dicts):\n",
    "        merged_dict = {}\n",
    "        for d in dicts:\n",
    "            merged_dict = d | merged_dict\n",
    "        return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9aab7e48-bb1b-4904-956a-aff69d6bd7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_inputs = {\n",
    "    corpus_name: RetrieverInput(corpus=corpus, queries=task_queries, qrels=task_qrels)\n",
    "    for (corpus_name, corpus) in corpora.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0d2c2f9-ab24-4d28-8d20-458ae701c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.evaluation.beir_evaluation import PerQueryIREvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "55ede412-7562-482c-8d79-c27b26191517",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_query_evaluator = PerQueryIREvaluator(k_values=[1, 5, 10, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb3a3bd3-4b79-463f-b909-fbbff6b9376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_inputs = {\n",
    "    corpus_name: RetrieverInput(corpus=corpus, queries=task_queries, qrels=task_qrels)\n",
    "    for (corpus_name, corpus) in corpora.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e02f94e-dfb8-45c8-b5a8-c244592cccda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce6fc5cd-56be-4217-9456-728129458a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "named_retrievers = {\n",
    "    corpus_name: [\n",
    "        (\"bm25\", bm25_retrievers[corpus_name]),\n",
    "        (\"word2vec\", w2v_retriever),\n",
    "    ] + list(sentence_transformer_retrievers.items())\n",
    "    for corpus_name in retriever_inputs.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3ffb8937-220b-4d2e-85b3-69362f1bdfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['readme', 'generated_readme', 'selected_code', 'generated_rationale', 'generation_context', 'dependency_signature', 'repository_signature', 'generated_tasks'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d998e90-afe3-43fa-a949-0519f3b53c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.01it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 74.53it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 38.59it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 159.72it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:34<00:00, 23.81it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 185.53it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:09<00:00, 88.07it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.86it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1570.12it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 149.70it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 170.74it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:28<00:00, 28.67it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 185.81it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 154.11it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.72it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1362.45it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:02<00:00, 23.30it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 151.83it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:37<00:00, 21.90it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 183.19it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:11<00:00, 71.70it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.98it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1522.80it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 140.00it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 170.66it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:29<00:00, 27.79it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 188.67it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 157.99it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.51it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1527.15it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 75.58it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 161.78it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:35<00:00, 23.45it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 184.70it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:06<00:00, 120.07it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 13.61it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1584.85it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 658.89it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 167.54it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:13<00:00, 61.10it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 186.52it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 166.87it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  4.65it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 35.34it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 483.69it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 169.47it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:14<00:00, 55.62it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 187.82it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 165.97it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.16it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1469.28it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 1093.53it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 169.26it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 162.57it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 183.80it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 179.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 7s, sys: 39.3 s, total: 18min 47s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "per_query_results = {\n",
    "    (corpus_name, retriever_name): per_query_evaluator.get_scores(retriever=retriever, ir_data=retriever_inputs[corpus_name])\n",
    "    for corpus_name in retriever_inputs.keys()\n",
    "    for (retriever_name, retriever) in named_retrievers[corpus_name]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d284270-306b-41de-b57d-9eb53954feb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_query_results_df = pd.concat([\n",
    "    df.assign(retriever=[retriever_name]*len(df)).assign(corpus=[corpus_name]*len(df))\n",
    "    for ((corpus_name, retriever_name), df) in per_query_results.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9263c1a-9c32-4ceb-ab37-692e742eb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_query_results_df = per_query_results_df.assign(\n",
    "    corpus=per_query_results_df[\"corpus\"].apply(lambda cname: cname if type(cname) is str else cname[0]),\n",
    "    generation=per_query_results_df[\"corpus\"].apply(lambda cname: 0 if type(cname) is str else cname[1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b98b1e9-5916-4f8e-95f2-f1ebc7717c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_query_results_df = (\n",
    "    per_query_results_df\n",
    "        .groupby([\"query\", \"retriever\", \"corpus\"]).agg(\"mean\").drop(columns=[\"generation\"])\n",
    "        .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2d4252cd-d2d6-48da-a77c-f995b4a8ddbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>retriever</th>\n",
       "      <th>corpus</th>\n",
       "      <th>Hits@1</th>\n",
       "      <th>Hits@5</th>\n",
       "      <th>Hits@10</th>\n",
       "      <th>Hits@25</th>\n",
       "      <th>Accuracy@1</th>\n",
       "      <th>Accuracy@5</th>\n",
       "      <th>Accuracy@10</th>\n",
       "      <th>Accuracy@25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2d human pose estimation</td>\n",
       "      <td>bm25</td>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2d human pose estimation</td>\n",
       "      <td>bm25</td>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d human pose estimation</td>\n",
       "      <td>bm25</td>\n",
       "      <td>generated_readme</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d human pose estimation</td>\n",
       "      <td>bm25</td>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2d human pose estimation</td>\n",
       "      <td>bm25</td>\n",
       "      <td>generation_context</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22171</th>\n",
       "      <td>zero shot learning</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22172</th>\n",
       "      <td>zero shot learning</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>generation_context</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22173</th>\n",
       "      <td>zero shot learning</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>readme</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22174</th>\n",
       "      <td>zero shot learning</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>repository_signature</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22175</th>\n",
       "      <td>zero shot learning</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>selected_code</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22176 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          query retriever                corpus  Hits@1  \\\n",
       "0      2d human pose estimation      bm25  dependency_signature     0.0   \n",
       "1      2d human pose estimation      bm25   generated_rationale     0.0   \n",
       "2      2d human pose estimation      bm25      generated_readme     0.0   \n",
       "3      2d human pose estimation      bm25       generated_tasks     0.0   \n",
       "4      2d human pose estimation      bm25    generation_context     0.0   \n",
       "...                         ...       ...                   ...     ...   \n",
       "22171        zero shot learning  word2vec       generated_tasks     0.0   \n",
       "22172        zero shot learning  word2vec    generation_context     0.0   \n",
       "22173        zero shot learning  word2vec                readme     1.0   \n",
       "22174        zero shot learning  word2vec  repository_signature     0.0   \n",
       "22175        zero shot learning  word2vec         selected_code     0.0   \n",
       "\n",
       "       Hits@5  Hits@10  Hits@25  Accuracy@1  Accuracy@5  Accuracy@10  \\\n",
       "0         1.0      3.0      3.0         0.0         1.0          1.0   \n",
       "1         4.0      6.0      7.0         0.0         1.0          1.0   \n",
       "2         3.0      5.0      7.0         0.0         1.0          1.0   \n",
       "3         1.0      1.0      3.0         0.0         1.0          1.0   \n",
       "4         0.0      1.0      2.0         0.0         0.0          1.0   \n",
       "...       ...      ...      ...         ...         ...          ...   \n",
       "22171     0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "22172     0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "22173     1.0      1.0      1.0         1.0         1.0          1.0   \n",
       "22174     0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "22175     0.0      0.0      0.0         0.0         0.0          0.0   \n",
       "\n",
       "       Accuracy@25  \n",
       "0              1.0  \n",
       "1              1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "...            ...  \n",
       "22171          0.0  \n",
       "22172          0.0  \n",
       "22173          1.0  \n",
       "22174          0.0  \n",
       "22175          0.0  \n",
       "\n",
       "[22176 rows x 11 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_query_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cd6679d6-d7ad-4b13-82d9-ee07a4431e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_query_results_df.to_csv(\"../results/per_query_ir_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fee2dee-1b17-47ae-b92a-36cea4a81aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>retriever</th>\n",
       "      <th>Hits@10</th>\n",
       "      <th>Accuracy@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>0.163059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.266955</td>\n",
       "      <td>0.197691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.419913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.782107</td>\n",
       "      <td>0.447330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.450216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.970760</td>\n",
       "      <td>0.502924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>readme</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>1.209235</td>\n",
       "      <td>0.581530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>bm25</td>\n",
       "      <td>1.501453</td>\n",
       "      <td>0.640988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>1.503608</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>word2vec</td>\n",
       "      <td>1.535354</td>\n",
       "      <td>0.655123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>bm25</td>\n",
       "      <td>1.540698</td>\n",
       "      <td>0.662791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>1.574315</td>\n",
       "      <td>0.665224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>1.733045</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>bm25</td>\n",
       "      <td>1.859216</td>\n",
       "      <td>0.687954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>1.694084</td>\n",
       "      <td>0.694084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>1.717172</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>1.818182</td>\n",
       "      <td>0.708514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>1.854257</td>\n",
       "      <td>0.724387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.733045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>1.988456</td>\n",
       "      <td>0.743146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>2.187590</td>\n",
       "      <td>0.764791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>2.197691</td>\n",
       "      <td>0.774892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>bm25</td>\n",
       "      <td>2.355072</td>\n",
       "      <td>0.784058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>2.896104</td>\n",
       "      <td>0.841270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>3.033189</td>\n",
       "      <td>0.852814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>bm25</td>\n",
       "      <td>2.884058</td>\n",
       "      <td>0.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>bm25</td>\n",
       "      <td>2.850725</td>\n",
       "      <td>0.856522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>3.147186</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>3.037518</td>\n",
       "      <td>0.860029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>readme</td>\n",
       "      <td>bm25</td>\n",
       "      <td>4.217893</td>\n",
       "      <td>0.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>readme</td>\n",
       "      <td>sentence-transformers/all-MiniLM-L12-v2</td>\n",
       "      <td>4.060606</td>\n",
       "      <td>0.919192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>readme</td>\n",
       "      <td>sentence-transformers/all-mpnet-base-v2</td>\n",
       "      <td>4.269841</td>\n",
       "      <td>0.926407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  corpus                                retriever   Hits@10  \\\n",
       "3   dependency_signature                                 word2vec  0.202020   \n",
       "31         selected_code                                 word2vec  0.266955   \n",
       "19    generation_context                                 word2vec  0.705628   \n",
       "15       generated_tasks                                 word2vec  0.782107   \n",
       "27  repository_signature                                 word2vec  0.792208   \n",
       "0   dependency_signature                                     bm25  0.970760   \n",
       "23                readme                                 word2vec  1.209235   \n",
       "12       generated_tasks                                     bm25  1.501453   \n",
       "7    generated_rationale                                 word2vec  1.503608   \n",
       "11      generated_readme                                 word2vec  1.535354   \n",
       "24  repository_signature                                     bm25  1.540698   \n",
       "29         selected_code  sentence-transformers/all-MiniLM-L12-v2  1.574315   \n",
       "13       generated_tasks  sentence-transformers/all-MiniLM-L12-v2  1.733045   \n",
       "28         selected_code                                     bm25  1.859216   \n",
       "14       generated_tasks  sentence-transformers/all-mpnet-base-v2  1.694084   \n",
       "30         selected_code  sentence-transformers/all-mpnet-base-v2  1.717172   \n",
       "1   dependency_signature  sentence-transformers/all-MiniLM-L12-v2  1.818182   \n",
       "25  repository_signature  sentence-transformers/all-MiniLM-L12-v2  1.854257   \n",
       "2   dependency_signature  sentence-transformers/all-mpnet-base-v2  2.000000   \n",
       "26  repository_signature  sentence-transformers/all-mpnet-base-v2  1.988456   \n",
       "18    generation_context  sentence-transformers/all-mpnet-base-v2  2.187590   \n",
       "17    generation_context  sentence-transformers/all-MiniLM-L12-v2  2.197691   \n",
       "16    generation_context                                     bm25  2.355072   \n",
       "5    generated_rationale  sentence-transformers/all-MiniLM-L12-v2  2.896104   \n",
       "9       generated_readme  sentence-transformers/all-MiniLM-L12-v2  3.033189   \n",
       "8       generated_readme                                     bm25  2.884058   \n",
       "4    generated_rationale                                     bm25  2.850725   \n",
       "10      generated_readme  sentence-transformers/all-mpnet-base-v2  3.147186   \n",
       "6    generated_rationale  sentence-transformers/all-mpnet-base-v2  3.037518   \n",
       "20                readme                                     bm25  4.217893   \n",
       "21                readme  sentence-transformers/all-MiniLM-L12-v2  4.060606   \n",
       "22                readme  sentence-transformers/all-mpnet-base-v2  4.269841   \n",
       "\n",
       "    Accuracy@10  \n",
       "3      0.163059  \n",
       "31     0.197691  \n",
       "19     0.419913  \n",
       "15     0.447330  \n",
       "27     0.450216  \n",
       "0      0.502924  \n",
       "23     0.581530  \n",
       "12     0.640988  \n",
       "7      0.646465  \n",
       "11     0.655123  \n",
       "24     0.662791  \n",
       "29     0.665224  \n",
       "13     0.686869  \n",
       "28     0.687954  \n",
       "14     0.694084  \n",
       "30     0.701299  \n",
       "1      0.708514  \n",
       "25     0.724387  \n",
       "2      0.733045  \n",
       "26     0.743146  \n",
       "18     0.764791  \n",
       "17     0.774892  \n",
       "16     0.784058  \n",
       "5      0.841270  \n",
       "9      0.852814  \n",
       "8      0.855072  \n",
       "4      0.856522  \n",
       "10     0.857143  \n",
       "6      0.860029  \n",
       "20     0.919192  \n",
       "21     0.919192  \n",
       "22     0.926407  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(per_query_results_df\n",
    "    .drop(columns=[\"query\"])\n",
    "    .groupby([\"corpus\", \"retriever\"])\n",
    "    .agg(\"mean\").reset_index(drop=False)\n",
    "    .sort_values(\"Accuracy@10\")\n",
    ")[[\"corpus\", \"retriever\", \"Hits@10\", \"Accuracy@10\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36399d0-61d6-4852-84a1-e83e472f0197",
   "metadata": {},
   "source": [
    "## Aggregated results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46855b2c-4388-4a40-ada7-6eb7be84c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.82it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.78it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.74it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.87it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:04<00:02,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generation_context\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dependency_signature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repository_signature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated_tasks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for corpus_name in corpora.keys():\n",
    "    try:\n",
    "        RetrievalEvaluationResults.from_retriever(bm25_retrievers[corpus_name], retriever_inputs[corpus_name])\n",
    "    except:\n",
    "        print(corpus_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77c1a0f1-f9c2-44fc-a6b8-0f45691c93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                           | 1/6612 [00:00<26:36,  4.14docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|████████████▋                                                                                                                                                          | 501/6612 [00:00<00:04, 1524.69docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████████████████████████▏                                                                                                                                            | 1001/6612 [00:00<00:02, 2121.94docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████████████████████████████████▋                                                                                                                                | 1501/6612 [00:00<00:01, 2598.13docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▏                                                                                                                   | 2001/6612 [00:00<00:01, 2769.71docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████████████████████████████████████████████████████▊                                                                                                       | 2501/6612 [00:01<00:01, 2856.44docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▎                                                                                          | 3001/6612 [00:01<00:01, 2934.41docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3501/6612 [00:01<00:01, 3010.52docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 4001/6612 [00:01<00:00, 3074.59docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 4501/6612 [00:01<00:00, 3024.22docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 5001/6612 [00:01<00:00, 2990.60docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 5501/6612 [00:02<00:00, 2922.62docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 6001/6612 [00:02<00:00, 2983.90docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "que:   0%|                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  17%|████████████████████████████▌                                                                                                                                              | 1/6 [00:01<00:05,  1.12s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  33%|█████████████████████████████████████████████████████████                                                                                                                  | 2/6 [00:01<00:03,  1.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 3/6 [00:02<00:02,  1.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:02<00:01,  1.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 5/6 [00:03<00:00,  1.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|████████████▋                                                                                                                                                          | 501/6612 [00:00<00:01, 3504.01docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████████████████████████████████▋                                                                                                                                | 1501/6612 [00:00<00:00, 6294.34docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████████████████████████████████████████████████████▊                                                                                                       | 2501/6612 [00:00<00:00, 7427.27docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3501/6612 [00:00<00:00, 7930.41docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 4501/6612 [00:00<00:00, 8122.12docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 5501/6612 [00:00<00:00, 7727.11docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 6501/6612 [00:00<00:00, 8260.86docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "que:   0%|                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  17%|████████████████████████████▌                                                                                                                                              | 1/6 [00:00<00:02,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  33%|█████████████████████████████████████████████████████████                                                                                                                  | 2/6 [00:00<00:01,  2.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 3/6 [00:01<00:01,  2.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:01<00:00,  2.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 5/6 [00:01<00:00,  2.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                           | 1/6612 [00:00<28:01,  3.93docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|████████████▋                                                                                                                                                          | 501/6612 [00:00<00:05, 1220.09docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████████████████████████▏                                                                                                                                            | 1001/6612 [00:00<00:03, 1758.64docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████████████████████████████████▋                                                                                                                                | 1501/6612 [00:00<00:02, 2004.79docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▏                                                                                                                   | 2001/6612 [00:01<00:02, 2201.85docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████████████████████████████████████████████████████▊                                                                                                       | 2501/6612 [00:01<00:01, 2247.92docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▎                                                                                          | 3001/6612 [00:01<00:01, 2341.19docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|███████████████████████████████████████████████████████████████████████████████████████▉                                                                              | 3501/6612 [00:01<00:01, 2288.65docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 4001/6612 [00:01<00:01, 2323.30docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 4501/6612 [00:02<00:00, 2262.91docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 5001/6612 [00:02<00:00, 2234.83docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 5501/6612 [00:02<00:00, 2272.70docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 6001/6612 [00:02<00:00, 2269.74docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "que:   0%|                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  17%|████████████████████████████▌                                                                                                                                              | 1/6 [00:01<00:05,  1.02s/it]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  33%|█████████████████████████████████████████████████████████                                                                                                                  | 2/6 [00:01<00:03,  1.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 3/6 [00:02<00:02,  1.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:02<00:01,  1.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 5/6 [00:03<00:00,  1.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:03<00:00,  1.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                           | 1/6612 [00:00<11:31,  9.56docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████████████████████████▏                                                                                                                                            | 1001/6612 [00:00<00:01, 4897.10docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▏                                                                                                                   | 2001/6612 [00:00<00:00, 6573.14docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▎                                                                                          | 3001/6612 [00:00<00:00, 7404.16docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 4001/6612 [00:00<00:00, 7832.97docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 5001/6612 [00:00<00:00, 8104.60docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 6001/6612 [00:00<00:00, 7570.38docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "que:   0%|                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  17%|████████████████████████████▌                                                                                                                                              | 1/6 [00:00<00:02,  2.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  33%|█████████████████████████████████████████████████████████                                                                                                                  | 2/6 [00:00<00:01,  2.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 3/6 [00:01<00:01,  2.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:01<00:00,  2.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 5/6 [00:01<00:00,  2.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  3.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                           | 1/6612 [00:00<13:24,  8.22docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████████████████████████▏                                                                                                                                            | 1001/6612 [00:00<00:01, 3989.28docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|██████████████████████████████████████████████████▏                                                                                                                   | 2001/6612 [00:00<00:00, 4815.87docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████████████████████████████████████████████████████████████▎                                                                                          | 3001/6612 [00:00<00:00, 5201.03docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                 | 4001/6612 [00:00<00:00, 5133.91docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                     | 4502/6612 [00:00<00:00, 4986.73docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                        | 5001/6612 [00:01<00:00, 4888.07docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋               | 6001/6612 [00:01<00:00, 4984.81docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "que:   0%|                                                                                                                                                                                   | 0/6 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  17%|████████████████████████████▌                                                                                                                                              | 1/6 [00:00<00:02,  1.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [02:53<?, ?docs/s]\u001b[A\u001b[A\u001b[A\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [02:22<?, ?docs/s]\n",
      "\n",
      "\n",
      "\n",
      "que:  50%|█████████████████████████████████████████████████████████████████████████████████████▌                                                                                     | 3/6 [00:01<00:01,  1.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  67%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                         | 4/6 [00:01<00:00,  2.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                            | 5/6 [00:02<00:00,  2.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:02<00:00,  2.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 12.43it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:01<00:00,  5.02it/s]\n",
      "  0%|                                                                                                                                                                                   | 0/6612 [00:00<?, ?docs/s]\n",
      "que: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.84it/s]\n"
     ]
    }
   ],
   "source": [
    "bm25_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(bm25_retrievers[corpus_name], retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b932e725-af99-4b97-9eb1-8c29b7a2570c",
   "metadata": {},
   "source": [
    "splade_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(splade_retriever, retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b18db778-cfd3-4495-be41-755b5a48085a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 413.14it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 39.83it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1352.64it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 141.94it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1237.93it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:02<00:00, 24.21it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1394.00it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 140.85it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1335.55it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 73.31it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1382.74it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 587.68it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1475.31it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 513.06it/s]\n",
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 1437.39it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 52/52 [00:00<00:00, 1036.59it/s]\n"
     ]
    }
   ],
   "source": [
    "word2vec_results = {\n",
    "    corpus_name: RetrievalEvaluationResults.from_retriever(w2v_retriever, retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfbbc87e-18a4-4492-af66-0851f1ae17b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 168.07it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:36<00:00, 22.75it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 183.88it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:09<00:00, 87.93it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 163.81it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:29<00:00, 28.14it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 185.97it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 153.73it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 166.35it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:37<00:00, 22.23it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 182.16it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:12<00:00, 67.85it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 164.36it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:30<00:00, 27.17it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 180.65it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 150.59it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 166.16it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:35<00:00, 23.37it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 179.98it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:06<00:00, 126.36it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 165.34it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:13<00:00, 60.67it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 186.11it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 168.86it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 167.20it/s]\n",
      "Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:14<00:00, 57.23it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 184.66it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 169.92it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 167.21it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:05<00:00, 164.14it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 179.12it/s]\n",
      "Batches: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 827/827 [00:04<00:00, 178.92it/s]\n"
     ]
    }
   ],
   "source": [
    "sentence_transformer_results = {\n",
    "    (corpus_name, model_name.split(\"/\")[1]): RetrievalEvaluationResults.from_retriever(sentence_transformer_retrievers[model_name], retriever_inputs[corpus_name])\n",
    "    for corpus_name in corpora.keys()\n",
    "    for model_name in sentence_transformer_model_names\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "168d970f-1613-40cd-bf39-ccc755c0f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm25_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": \"bm25\", **bm25_results[corpus_name].metrics}\n",
    "    for corpus_name in corpora.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2b5ca892-7b81-4a1d-aef0-8d98a2b48be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": \"Python code word2vec\", **word2vec_results[corpus_name].metrics}\n",
    "    for corpus_name in corpora.keys()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4bba502a-d4ba-401e-bf43-d553a755e63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splade_metrics = [\n",
    "#    {\"corpus\": corpus_name, \"retriever\": \"splade\", **splade_results[corpus_name].metrics}\n",
    "#     for corpus_name in corpora.keys()\n",
    "#]\n",
    " \n",
    "sentence_transformer_metrics = [\n",
    "    {\"corpus\": corpus_name, \"retriever\": f\"{model_name} (sentence_transformer)\", **sentence_transformer_results[(corpus_name, model_name)].metrics}\n",
    "    for (corpus_name, model_name) in sentence_transformer_results.keys()\n",
    "]\n",
    "\n",
    "all_metrics_df = pd.DataFrame.from_records(bm25_metrics + word2vec_metrics +  sentence_transformer_metrics).sort_values(\"Hits@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8ea85bb-ad62-4cad-8ae5-52ba3a61e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 50)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e96fc7bd-7971-4065-b62b-2a4d702284df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>retriever</th>\n",
       "      <th>Accuracy@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>readme</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.92641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>readme</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.91919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>readme</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.91919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.85714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.86003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.84127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.85137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.85281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.78066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.77489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.76479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.73304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.74315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.72439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.68398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.70851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.68687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.70130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>all-mpnet-base-v2 (sentence_transformer)</td>\n",
       "      <td>0.69408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>all-MiniLM-L12-v2 (sentence_transformer)</td>\n",
       "      <td>0.66522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>generated_readme</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.65512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.65801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>generated_rationale</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.64646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.63636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>readme</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.58153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>bm25</td>\n",
       "      <td>0.49639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>repository_signature</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.45022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>generated_tasks</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.44733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>generation_context</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.41991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>selected_code</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.19769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dependency_signature</td>\n",
       "      <td>Python code word2vec</td>\n",
       "      <td>0.16306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  corpus                                 retriever  \\\n",
       "16                readme  all-mpnet-base-v2 (sentence_transformer)   \n",
       "0                 readme                                      bm25   \n",
       "17                readme  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "18      generated_readme  all-mpnet-base-v2 (sentence_transformer)   \n",
       "22   generated_rationale  all-mpnet-base-v2 (sentence_transformer)   \n",
       "19      generated_readme  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "23   generated_rationale  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "1       generated_readme                                      bm25   \n",
       "3    generated_rationale                                      bm25   \n",
       "4     generation_context                                      bm25   \n",
       "25    generation_context  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "24    generation_context  all-mpnet-base-v2 (sentence_transformer)   \n",
       "26  dependency_signature  all-mpnet-base-v2 (sentence_transformer)   \n",
       "28  repository_signature  all-mpnet-base-v2 (sentence_transformer)   \n",
       "29  repository_signature  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "2          selected_code                                      bm25   \n",
       "27  dependency_signature  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "31       generated_tasks  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "20         selected_code  all-mpnet-base-v2 (sentence_transformer)   \n",
       "30       generated_tasks  all-mpnet-base-v2 (sentence_transformer)   \n",
       "21         selected_code  all-MiniLM-L12-v2 (sentence_transformer)   \n",
       "9       generated_readme                      Python code word2vec   \n",
       "6   repository_signature                                      bm25   \n",
       "11   generated_rationale                      Python code word2vec   \n",
       "7        generated_tasks                                      bm25   \n",
       "8                 readme                      Python code word2vec   \n",
       "5   dependency_signature                                      bm25   \n",
       "14  repository_signature                      Python code word2vec   \n",
       "15       generated_tasks                      Python code word2vec   \n",
       "12    generation_context                      Python code word2vec   \n",
       "10         selected_code                      Python code word2vec   \n",
       "13  dependency_signature                      Python code word2vec   \n",
       "\n",
       "    Accuracy@10  \n",
       "16      0.92641  \n",
       "0       0.91919  \n",
       "17      0.91919  \n",
       "18      0.85714  \n",
       "22      0.86003  \n",
       "19      0.85281  \n",
       "23      0.84127  \n",
       "1       0.85137  \n",
       "3       0.85281  \n",
       "4       0.78066  \n",
       "25      0.77489  \n",
       "24      0.76479  \n",
       "26      0.73304  \n",
       "28      0.74315  \n",
       "29      0.72439  \n",
       "2       0.68398  \n",
       "27      0.70851  \n",
       "31      0.68687  \n",
       "20      0.70130  \n",
       "30      0.69408  \n",
       "21      0.66522  \n",
       "9       0.65512  \n",
       "6       0.65801  \n",
       "11      0.64646  \n",
       "7       0.63636  \n",
       "8       0.58153  \n",
       "5       0.49639  \n",
       "14      0.45022  \n",
       "15      0.44733  \n",
       "12      0.41991  \n",
       "10      0.19769  \n",
       "13      0.16306  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f8dfde14-0798-49f9-b212-420979936de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['corpus', 'retriever', 'Accuracy@1', 'Accuracy@3', 'Accuracy@5',\n",
       "       'Accuracy@10', 'Accuracy@100', 'Accuracy@1000', 'Hits@1', 'Hits@3',\n",
       "       'Hits@5', 'Hits@10', 'Hits@100', 'Hits@1000', 'R_cap@1', 'R_cap@3',\n",
       "       'R_cap@5', 'R_cap@10', 'R_cap@100', 'R_cap@1000', 'MRR@1', 'MRR@3',\n",
       "       'MRR@5', 'MRR@10', 'MRR@100', 'MRR@1000', 'P@1', 'P@3', 'P@5', 'P@10',\n",
       "       'P@100', 'P@1000', 'Recall@1', 'Recall@3', 'Recall@5', 'Recall@10',\n",
       "       'Recall@100', 'Recall@1000', 'MAP@1', 'MAP@3', 'MAP@5', 'MAP@10',\n",
       "       'MAP@100', 'MAP@1000', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10',\n",
       "       'NDCG@100', 'NDCG@1000'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_metrics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ae614836-1547-4c72-bfd6-90e92ad9a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"qwen2.5:7b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c3e17de-6297-41f2-a031-6cc47d895d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.to_csv(f\"../output/code2doc/beir_results_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9cba07cc-0836-4760-bc45-d7943eaead1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_metrics_df.to_csv(f\"../output/code2doc/beir_results_with_modernbert_{model_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380e81d-e1d5-4e3b-bbe4-c6842ade4eb2",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "By default we will use min_task_count=10 (as we used originally)\n",
    "\n",
    "We can switch to smaller task counts like 5 to incorporate the fact that we use sample of repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3834435-49fe-4530-b371-5b5e046a4c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df_cols = [\"corpus\", \"retriever\", \"Accuracy@10\", \"Hits@10\", \"R_cap@10\", \"P@1\", \"P@5\", \"P@10\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7c057a-4e95-4faa-aa2b-392c521913fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[metric_df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0a584-a9b8-4f44-9ae5-403c36501fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[metric_df_cols].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84006df9-9b52-430b-8366-842b536e29fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"corpus\").apply(lambda df: df.sort_values(\"Accuracy@10\", ascending=False).iloc[0])[metric_df_cols].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792258e0-5684-48af-852b-5a605d28d0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\").apply(lambda df: df.sort_values(\"Accuracy@10\", ascending=False).iloc[0])[metric_df_cols].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe046c-2a0d-45f1-9312-2c3b946da92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[all_metrics_df[\"retriever\"] == \"bm25\"][metric_df_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779c9fac-7d0e-4435-ad1a-c19c399c1ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(task_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d20918-117d-43d7-8f65-5dd9f8cb077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task count = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624352d5-f9be-4b0d-b4ae-383794166137",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ca4f6d-9a5b-45d0-98ff-5d103203a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c7855-7279-4170-9fd5-1360e8fef5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f9993-0773-4de9-8dad-e55f5e458c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a421d2ec-14b5-46e4-91ad-701e16a041f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9e80f-9263-4092-93df-c316df93f91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"retriever\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2fe2e-b314-4bc4-b33b-4ee1048601fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df.groupby(\"corpus\")[\"Accuracy@10\"].agg(\"mean\").sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e56598d-9dc5-4804-8bf4-d3133832208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_repos_df[\"tasks\"].explode().value_counts().loc[list(task_queries.values())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e72a823-c74f-45f3-ac25-9b4b0ab9be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdd8ff1-3a58-44f1-bebf-fd4face2563a",
   "metadata": {},
   "source": [
    "## Does combining rationale with generated readme help?\n",
    "\n",
    "It seems that the best sentence transformer retrievers can only get worse when using any other information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b12853e-cec3-4cca-a9fb-1644f172090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc79a75-9a8a-4d2b-b22a-e4ef0c42c7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_generated_readme_results= sentence_transformer_results[('generated_readme', 'all-mpnet-base-v2')].retrieval_results\n",
    "st_rationale_results = sentence_transformer_results[('generated_rationale', 'all-mpnet-base-v2')].retrieval_results\n",
    "bm25_generated_readme_results = bm25_results[\"generated_readme\"].retrieval_results\n",
    "st_context_results = sentence_transformer_results[('generation_context', 'all-mpnet-base-v2')].retrieval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5f56b-00cf-44b9-aeef-aee8bca3e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(bm25_generated_readme_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328808cf-3f7b-4fd6-927c-76d7f0f76ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(st_generated_readme_results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bec109-8530-48d7-a3cf-27d522a9b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_qrels(qrels1, qrels2):\n",
    "    merged_qrels = {}\n",
    "    for k in qrels1.keys():\n",
    "        tmp_rel = dict()\n",
    "        for rel_k in set(qrels1[k].keys()).union(qrels2[k]):\n",
    "            tmp_rel[rel_k] = qrels1[k].get(rel_k, 0) +  qrels2[k].get(rel_k, 0)\n",
    "        merged_qrels[k] = tmp_rel\n",
    "    return merged_qrels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52804e89-a816-42b6-8f74-938ad36b5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_generation_results = merge_qrels(bm25_generated_readme_results, st_generated_readme_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85cbbaf-9966-4aee-8364-ea160f208ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_generation_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11896681-5362-49fe-abbc-c029c245dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_generated_readme_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891037fc-0580-4e20-90d7-7b4c7c94f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EvaluateRetrieval().evaluate_custom(task_qrels, st_rationale_results, metric=\"acc\", k_values=[1,5,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80909711-5f02-4854-97d0-6554f40d9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_df[all_metrics_df[\"retriever\"] == \"bm25\"][[\"corpus\", \"retriever\", \"Accuracy@10\"]].sort_values(\"Accuracy@10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2491390e-ee04-4559-b945-13dc91919c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Splitting does not make much sense as the most of generated data is under the sentence-transformer context length (384 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6992cd4f-32e3-4793-8e9f-b4c6e10c29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_corpus_by_lengths(corpus, chunk_length):\n",
    "    splitted_corpora = [dict() for _ in range(n_splits)]\n",
    "    for c_id in corpus.keys():\n",
    "        text = corpus[c_id][\"text\"]\n",
    "        chunk_length =  len(text) // n_splits\n",
    "        for i in range(0, n_splits):\n",
    "            splitted_corpora[i] = text[i*chunk_length:(i+1)*chunk_length]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfda84b-0d7d-427c-8feb-724c0521078f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTextEvaluator(BaseModel):\n",
    "    \"\"\"\n",
    "    Evaluate a dataframe that has multiple texts for each query (multiple generation experiments)\n",
    "    iteration_col says which experiment it was\n",
    "    \"\"\"\n",
    "    iteration_col: str\n",
    "    text_cols: List[str]\n",
    "    k_values: List[int] = [1,5,10,25]\n",
    "\n",
    "    def get_ir_datas(self, df):\n",
    "        for iter in df[self.iteration_col].unique():\n",
    "            ir_data = load_ir_data(df[df[self.iteration_col] == iter], self.text_cols)\n",
    "            yield (iter, ir_data)\n",
    "\n",
    "    def evaluate(self, df, retriever):\n",
    "        ir_datas = dict(self.get_ir_datas(df))\n",
    "        dfs = []\n",
    "        for iter, ir_data in ir_datas.items():\n",
    "            per_query_evaluator = PerQueryIREvaluator(k_values=self.k_values)\n",
    "            df = per_query_evaluator.get_scores(ir_data, retriever)\n",
    "            df[self.iteration_col] = iter\n",
    "            dfs.append(df)\n",
    "        metrics_df = pd.concat(dfs)\n",
    "        metrics_df[\"query\"] = metrics_df.index\n",
    "        return metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "github_search",
   "language": "python",
   "name": "github_search"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
