{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp matching_zsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import ast\n",
    "import tqdm\n",
    "import json\n",
    "import attr\n",
    "from operator import itemgetter\n",
    "\n",
    "from scarce_learn import zero_shot\n",
    "from mlutil.feature_extraction import embeddings\n",
    "import itertools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, metrics, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "from github_search import paperswithcode_tasks\n",
    "\n",
    "import mlutil\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from scarce_learn.zero_shot import devise_jax, devise_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "\n",
    "import_corpus_path = 'output/module_corpus.csv'\n",
    "word_vectors_filename = 'output/import2vec_module_vectors.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)\n",
    "import_corpus_df['imports'] = import_corpus_df['imports'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 51s, sys: 2.98 s, total: 2min 54s\n",
      "Wall time: 2min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "python_files_df = pd.read_csv('data/crawled_python_files.csv', encoding='latin-1')\n",
    "repo_names = python_files_df['repo_name']\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1402272, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375818, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      trangvu/ape-npi\n",
       "1                      trangvu/ape-npi\n",
       "2                      trangvu/ape-npi\n",
       "3                      trangvu/ape-npi\n",
       "4                      trangvu/ape-npi\n",
       "                      ...             \n",
       "1402267    wayne1204/NOAA-fish-finding\n",
       "1402268    wayne1204/NOAA-fish-finding\n",
       "1402269    wayne1204/NOAA-fish-finding\n",
       "1402270    wayne1204/NOAA-fish-finding\n",
       "1402271    wayne1204/NOAA-fish-finding\n",
       "Name: repo_name, Length: 1402272, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18933,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python_files_df['repo'] = python_files_df['repo_name'].str.split(\"/\").apply(itemgetter(1))  + '/' + python_files_df['repo_name']\n",
    "repo_names_tmp = python_files_df['repo_name']\n",
    "repo_names = repo_names_tmp.unique()\n",
    "python_files_df['repo_name'] = python_files_df['repo']\n",
    "python_files_df['repo'] = repo_names_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.05 ms, sys: 43 Âµs, total: 9.09 ms\n",
      "Wall time: 10.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import2vec = gensim.models.KeyedVectors.load(word_vectors_filename)\n",
    "import2vec_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(import2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = pd.read_csv('output/papers_with_imports.csv')\n",
    "paperswithcode_with_imports_df['tasks'] = paperswithcode_with_imports_df['tasks'].str.replace(\"2d \", \"\").str.replace(\"3d \", \"\").str.replace(\"4d \", \"\").str.replace(\"6d \", \"\").str.lower().apply(ast.literal_eval)\n",
    "paperswithcode_with_imports_df['imports'] = paperswithcode_with_imports_df['imports'].str.replace(\"set\\(\\)\", \"{}\").apply(ast.literal_eval)#str.replace(\"2d \", \"\").str.replace(\"3d \", \"\").str.replace(\"4d \", \"\").str.replace(\"6d \", \"\").str.lower().apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports'] = paperswithcode_with_imports_df['imports'].apply(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports_with_embeddings'] = paperswithcode_with_imports_df['imports'].apply(lambda imps: len([imp in import2vec.vocab.keys() for imp in imps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33.6 s, sys: 250 ms, total: 33.8 s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_embeddings = mlutil.feature_extraction.embeddings.load_gensim_embedding_model('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_word_embeddings = gensim.models.Word2Vec.load('output/abstract_w2v100.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class RepoTaskData:\n",
    "    \n",
    "    tasks = attr.ib()\n",
    "    repos = attr.ib()\n",
    "    X = attr.ib()\n",
    "    all_tasks = attr.ib()\n",
    "    y = attr.ib()\n",
    "    \n",
    "    def split_tasks(area_grouped_tasks, test_size=0.2):\n",
    "        tasks_train, tasks_test = model_selection.train_test_split(area_grouped_tasks['task'], stratify=area_grouped_tasks['area'], test_size=test_size, random_state=0)\n",
    "        return tasks_train, tasks_test\n",
    "    \n",
    "    def create_split(tasks_train, all_tasks, paperswithcode_with_features_df, X_repr):\n",
    "        train_indicator = paperswithcode_with_features_df['most_common_task'].isin(tasks_train)\n",
    "        print(train_indicator.shape)\n",
    "        repos_train = paperswithcode_with_features_df['repo'][train_indicator]\n",
    "        repos_test = paperswithcode_with_features_df['repo'][~train_indicator]\n",
    "        X_repr = X_repr.apply(lambda x: \" \".join(x))\n",
    "        X_train = X_repr[train_indicator]\n",
    "        X_test = X_repr[~train_indicator]\n",
    "        all_tasks_train = all_tasks[train_indicator]\n",
    "        all_tasks_test = all_tasks[~train_indicator]\n",
    "        y_train = paperswithcode_with_features_df[train_indicator]['most_common_task'].str.lower()\n",
    "        y_test = paperswithcode_with_features_df[~train_indicator]['most_common_task'].str.lower()\n",
    "        \n",
    "        return (\n",
    "            RepoTaskData(tasks_train, repos_train, X_train, all_tasks_train, y_train),\n",
    "            RepoTaskData(tasks_test, repos_test, X_test, all_tasks_test, y_test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_first_vocab_entry(vocab):\n",
    "    return list(itertools.islice(vocab.items(), 1))[0][0] \n",
    "\n",
    "\n",
    "class PairedKeyedVectors:\n",
    "    \n",
    "    @attr.s\n",
    "    class wv:\n",
    "        vocab = attr.ib()\n",
    "    \n",
    "    def __init__(self, kv1, kv2):\n",
    "        self.kv1 = kv1\n",
    "        self.kv2 = kv2\n",
    "        self.vocab = {**kv1.vocab, **kv2.vocab} \n",
    "        self.dim1 = len(kv1[get_first_vocab_entry(kv1.vocab)])\n",
    "        self.dim2 = len(kv2[get_first_vocab_entry(kv2.vocab)])\n",
    "        self.wv= PairedKeyedVectors.wv(self.vocab)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not item in self.kv1.vocab.keys():\n",
    "            return np.concatenate([np.zeros(self.dim1), self.kv2[item]])\n",
    "        elif not item in self.kv2.vocab.keys():\n",
    "            return np.concatenate([self.kv1[item], np.zeros(self.dim2)])\n",
    "        else:\n",
    "            return np.concatenate([self.kv1[item], self.kv2[item]])\n",
    "    \n",
    "\n",
    "\n",
    "@attr.s\n",
    "class RetrieverLearner:\n",
    "    \n",
    "    zs_learner: zero_shot.ZeroShotClassifier = attr.ib()\n",
    "    input_embedder: embeddings.EmbeddingVectorizer = attr.ib() \n",
    "    y_embedder: embeddings.EmbeddingVectorizer = attr.ib()\n",
    "    input_embedder_kwargs = attr.ib(default=dict())\n",
    "        \n",
    "    @staticmethod\n",
    "    def create(\n",
    "        zs_learner: zero_shot.ZeroShotClassifier,\n",
    "        input_embeddings: gensim.models.KeyedVectors,\n",
    "        target_embeddings: gensim.models.KeyedVectors,\n",
    "        input_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        y_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        input_embedder_kwargs=dict()\n",
    "    ):\n",
    "        input_embedder = input_embedding_method(input_embeddings, **input_embedder_kwargs) \n",
    "        y_embedder = y_embedding_method(target_embeddings)\n",
    "        return RetrieverLearner(zs_learner, input_embedder, y_embedder)\n",
    "    \n",
    "    def get_target_embeddings(self, y):\n",
    "        unique_y = pd.Series(y.unique())\n",
    "        y_embeddings = self.y_embedder.transform(unique_y)\n",
    "        return unique_y, y_embeddings\n",
    "    \n",
    "    def fit_learner(self, data, **kwargs):\n",
    "        self.input_embedder.fit(data.X)\n",
    "        X_embeddings = self.input_embedder.transform(data.X)\n",
    "        self.y_embedder.fit(data.y)\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        self.zs_learner.fit(np.array(X_embeddings), np.array(input_y_idxs), np.array(y_embeddings), **kwargs)\n",
    "        \n",
    "    def predict_idxs(self, X, y_embeddings):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        return self.zs_learner.predict(X_embeddings, y_embeddings)\n",
    "    \n",
    "    def predict_topk(self, X, y_embeddings, target_names, k=5, similarity=metrics.pairwise.cosine_similarity):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        predictions = self.zs_learner.predict_raw(X_embeddings)\n",
    "        target_similarities = similarity(predictions, y_embeddings)\n",
    "        targets = [target_names[row[:k]] for row in (-target_similarities).argsort(axis=1)]\n",
    "        return targets\n",
    "        \n",
    "    def evaluate(self, data, metric):\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        predicted_idxs = self.predict_idxs(data.X, y_embeddings)\n",
    "        return metric(input_y_idxs, predicted_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_accuracy(learner, X, y, y_names, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    input_embeddings = learner.input_embedder.transform(X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    target_similarities = similarity(predictions, y_embeddings)\n",
    "    target_idxs = (-target_similarities).argsort(axis=1)\n",
    "    targets = [y_names.iloc[row[:k]] for row in target_idxs]\n",
    "\n",
    "    accuracies = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        true_tasks = set(all_tasks_test.iloc[i])\n",
    "        accuracies[i] = len(true_tasks.intersection(set(targets[i].values))) / min(len(true_tasks), k)\n",
    "    return accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "graph = pickle.load(open('output/call_igraph.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18934"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.get_vertex_dataframe().iloc[graph.neighborhood(vertices=[\"<ROOT>\"])[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get repos that are in graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes = graph.get_vertex_dataframe()['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 555 ms, sys: 12 ms, total: 567 ms\n",
      "Wall time: 572 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paperswithcode_with_features_df = paperswithcode_with_imports_df[\n",
    "    paperswithcode_with_imports_df['repo'].isin(graph.get_vertex_dataframe()['name']) |\n",
    "    paperswithcode_with_imports_df['repo'].apply(lambda s: s.split(\"/\")[1]).isin(graph.get_vertex_dataframe()['name'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(paperswithcode_with_features_df['repo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_task_name(task_name):\n",
    "    return task_name.replace(\"2d \", \"\").replace(\"3d \", \"\").replace(\"4d \", \"\").replace(\"6d \", \"\").lower()\n",
    "\n",
    "paperswithcode_with_features_df['most_common_task'] = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = tasks.apply(clean_task_name)\n",
    "all_tasks = paperswithcode_with_features_df['tasks'].apply(lambda s: [clean_task_name(t) for t in s])\n",
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "semantic segmentation             1066\n",
       "object detection                  1050\n",
       "image classification               946\n",
       "language modelling                 494\n",
       "representation learning            454\n",
       "                                  ... \n",
       "cell segmentation                   70\n",
       "nuclear segmentation                69\n",
       "natural language understanding      69\n",
       "multi-person pose estimation        69\n",
       "feature engineering                 68\n",
       "Name: tasks, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks.explode().value_counts()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_area_grouped_tasks(paperswithcode_tasks_path='data/paperswithcode_tasks.csv'):\n",
    "    area_grouped_tasks = pd.read_csv('data/paperswithcode_tasks.csv')\n",
    "    area_grouped_tasks['task'] = area_grouped_tasks['task'].str.replace(\"-\", ' ')\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['task'].isin(tasks)]\n",
    "    area_counts = area_grouped_tasks['area'].value_counts()\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['area'].isin(area_counts.index[area_counts > 1])]\n",
    "    return area_grouped_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_grouped_tasks = get_area_grouped_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_train, tasks_test = RepoTaskData.split_tasks(area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467                        object counting\n",
       "1253    conversational response generation\n",
       "854              probabilistic programming\n",
       "525          facial expression recognition\n",
       "1683                   montezuma's revenge\n",
       "                       ...                \n",
       "896                      data augmentation\n",
       "926                                    eeg\n",
       "1646            neural architecture search\n",
       "592                       graph regression\n",
       "1230               sentence classification\n",
       "Name: task, Length: 74, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               dictionary learning\n",
       "1                   region proposal\n",
       "2                  image generation\n",
       "3        natural language inference\n",
       "4        natural language inference\n",
       "                    ...            \n",
       "12219             anomaly detection\n",
       "12220             anomaly detection\n",
       "12221             anomaly detection\n",
       "12222                style transfer\n",
       "12223       representation learning\n",
       "Name: most_common_task, Length: 12224, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task'].isin(tasks_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import github_readmes\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_decode(s, codec=\"utf-8\"):\n",
    "    try:\n",
    "        return s.decode(codec)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_readme_summaries(upstream, product, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, paperswithcode_with_features_df['repo']))\n",
    "    readmes = pd.Series(raw_readmes).apply(try_decode)\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import python_call_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readme_summaries(df, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, df['repo']))\n",
    "    readmes = list(map(try_decode, raw_readmes))\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'paper_url', 'arxiv_id', 'title', 'abstract', 'url_abs',\n",
       "       'url_pdf', 'proceeding', 'authors', 'tasks', 'date', 'methods',\n",
       "       'framework', 'mentioned_in_github', 'mentioned_in_paper',\n",
       "       'paper_arxiv_id', 'paper_title', 'paper_url_abs', 'paper_url_pdf',\n",
       "       'repo', 'repo_url', 'most_common_task', 'imports', 'n_imports',\n",
       "       'n_imports_with_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "readme_keywords = get_readme_summaries(paperswithcode_with_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(readme_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def try_keywords(text):\n",
    "    return python_call_graph.try_run(gensim.summarization.keywords)(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "readme_keywords = pd.Series(pool.map(try_keywords, readmes)).str.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for repo, readme in zip(paperswithcode_with_features_df['repo'], readmes):\n",
    "    if not readme is None:\n",
    "        try:\n",
    "            readme.decode(\"utf-8\")\n",
    "        except:\n",
    "            print(repo)\n",
    "            print(readme)\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df = pd.read_csv('output/processed_dependency_records.csv').dropna()#.iloc[:1000000]\n",
    "non_root_dependency_records_df = dependency_records_df[\n",
    "    (dependency_records_df['source'] != \"<ROOT>\") &\n",
    "    (dependency_records_df['edge_type'] != 'repo-repo')\n",
    "]\n",
    "repo_descriptions = non_root_dependency_records_df[['source', 'repo_description']].groupby('source').apply(lambda df: df['repo_description'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describable_paperswithcode_with_features_df = paperswithcode_with_features_df[paperswithcode_with_features_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_repo_tasks = all_tasks[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describable_paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describable_paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_train, import_data_test = RepoTaskData.create_split(tasks_train, describable_repo_tasks, describable_paperswithcode_with_features_df, describable_paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_train.X.shape, import_data_test.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_train.repos.isin(repo_descriptions.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_test.repos.isin(repo_descriptions.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_outgoing_edges(graph, node):\n",
    "    #idx = pd.Index(graph.names).get_loc(node)\n",
    "    #outgoing_edges_idx = np.where(graph.mat[idx].todense())[1]\n",
    "    return graph.get_vertex_dataframe().iloc[graph.successors(node)]['name']\n",
    "    #return graph.names[outgoing_edges_idx]\n",
    "\n",
    "\n",
    "def get_repo_functions(graph, repo):\n",
    "    return ' '.join(get_outgoing_edges(graph, repo).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_records = pd.read_csv('output/dependency_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if os.path.exists(\"output/tmp_graph_data.pkl\"):\n",
    "    (graph_data_train, graph_data_test) = pickle.load(open(\"output/tmp_graph_data.pkl\", \"rb\"))\n",
    "else:\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "    graph_data_train.X = graph_data_train.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    graph_data_test.X = graph_data_test.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    pickle.dump((graph_data_train, graph_data_test), open(\"output/tmp_graph_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_descriptions.loc[graph_data_train.repos[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, describable_repo_tasks, describable_paperswithcode_with_features_df, describable_paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.X = pd.Series(repo_descriptions.loc[graph_data_train.repos].values, index=graph_data_train.repos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_test.X = pd.Series(repo_descriptions.loc[graph_data_test.repos].values, index=graph_data_test.repos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.repos.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_outgoing_edges(graph, get_outgoing_edges(graph, graph_data_train.repos.iloc[0]).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(graph_data_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def retrieve_query_results(learner, data, query, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform([query])\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "    return data.X.iloc[np.argsort(-input_target_similarities[:,0])[:k]]\n",
    "\n",
    "    \n",
    "def get_retrieval_results(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "\n",
    "    X_recalled = [\n",
    "        np.argsort(-input_target_similarities[:,y_idx])[:k]\n",
    "        for (y_idx, __) in enumerate(y_names)\n",
    "    ]\n",
    "    return X_recalled\n",
    "\n",
    "\n",
    "def get_retrieval_accuracies(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    recalled_X = get_retrieval_results(learner, data, k=k, similarity=similarity)\n",
    "    recalled_X_actual_y = [data.y.iloc[idxs_recalled].explode() for idxs_recalled in recalled_X]\n",
    "    accurately_recalled = [\n",
    "        y_name in recalled_X_actual_y[y_idx].values \n",
    "        for (y_idx, y_name) in enumerate(y_names)\n",
    "    ]\n",
    "    return pd.Series(data=accurately_recalled, index=y_names)\n",
    "\n",
    "\n",
    "def get_retrieval_accuracy(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    return np.mean(get_retrieval_accuracies(learner, data, k, similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_abstract = ~paperswithcode_with_imports_df['abstract'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_train[has_abstract]\n",
    "paperswithcode_with_features_df[has_abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_data_train, abstract_data_test = RepoTaskData.create_split(tasks_train[has_abstract], all_tasks[has_abstract], paperswithcode_with_features_df[has_abstract], paperswithcode_with_features_df[has_abstract]['abstract'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarce_learn.zero_shot import devise_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "fasttext_model = fasttext.load_model(\"output/python_files_fasttext_dim200.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "abstract_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner.evaluate(abstract_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner.evaluate(abstract_data_test, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(abstract_learner, abstract_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(abstract_learner, abstract_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract model using fasttext trained on Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "abstract_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "abstract_fasttext_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_fasttext_learner.evaluate(abstract_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner.evaluate(abstract_data_test, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(abstract_fasttext_learner, abstract_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(abstract_fasttext_learner, abstract_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext model on READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['readme'] = readmes\n",
    "paperswithcode_with_features_df['readme'] = readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_readme = ~paperswithcode_with_imports_df['readme'].isna()\n",
    "\n",
    "readme_data_train, readme_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], paperswithcode_with_features_df[has_readme]['readme'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "readme_learner.fit_learner(readme_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_learner.evaluate(readme_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_learner, readme_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_learner, readme_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext on READMEs - worse than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "readme_fasttext_learner.fit_learner(readme_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_fasttext_learner.evaluate(readme_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_fasttext_learner, readme_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_fasttext_learner, readme_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_keywords_data_train, readme_keywords_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], readme_keywords[has_readme].str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_keywords_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "readme_keywords_learner.fit_learner(readme_keywords_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_keywords_learner.evaluate(readme_keywords_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_keywords_learner, readme_keywords_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(readme_keywords_learner, readme_keywords_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "import2vec_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(lmbda=100.0, gamma=10.0),\n",
    "    import2vec,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "import2vec_learner.fit_learner(import_data_train)#, n_epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import2vec_learner.evaluate(import_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import2vec_learner.evaluate(import_data_test, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(import2vec_learner, import_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(import2vec_learner, import_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRoNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prone_embeddings = gensim.models.KeyedVectors.load(\"data/prone_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using repo embedding from node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prone_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    prone_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "prone_learner.fit_learner(graph_data_train)#, n_epochs=10, batch_size=32)\n",
    "prone_learner.evaluate(graph_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(prone_learner, graph_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(prone_learner, graph_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregating vertex embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output/*graphsage*bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_embeddings = gensim.models.KeyedVectors.load(\"output/graphsage_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(graphsage_embeddings.vocab)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "graphsage_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    graphsage_embeddings,\n",
    "    graphsage_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "graphsage_learner.fit_learner(graph_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graph_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graph_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_devise_learner = RetrieverLearner.create(\n",
    "    devise_jax.DEVISELearner(margin=0.5),\n",
    "    graphsage_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "graphsage_devise_learner.fit_learner(graph_data_train, batch_size=64, n_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_devise_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_devise_learner, graph_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_devise_learner, graph_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using GraphSAGE model for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_data_train.repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaTransformer:\n",
    "    \n",
    "    def __init__(self, transform_fn):\n",
    "        self.transform = transform_fn\n",
    "        \n",
    "    def fit(self, X, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.pytorch_geometric_data import PygGraphWrapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embedder = embeddings.FastTextVectorizer(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dependency_graph_wrapper = PygGraphWrapper(fasttext_embedder.transform, non_root_dependency_records_df, \"repo_description\", \"file_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_model = torch.load(\"output/graphsage_model_11_dim200_layers2.pth\").cpu()#\"output/graphsage_model_60_dim200_layers3.pth\").cpu()\n",
    "graphsage_model.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_root_dependency_records_df.merge(graph_data_train.repos, left_on=\"source\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9205489346334417"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_train.repos.isin(repo_descriptions.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12224,)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['zzz1515151/self-supervised_learning_sketch', 'zhoubolei/moments_models', 'zacwellmer/WorldModels', 'yueqiw/gqn-world-model', 'zhang-huihui/git-repository', 'zapplea/bert', 'EthanWYB/bert-classification', 'svakulenk0/response_eval', 'zsweet/BERT_zsw', 'zhen-he/tracking-by-animation', 'xinge008/Cylinder3D', 'zhanghainan/RNN-encdec', 'zhanghainan/TailoredSeq2Seq2DifferentConversationScenarios', 'yichigo/Chest-X-Ray', 'zju-3dv/multiway', 'zqhl/Wide-Area-Crowd-Counting_CVPR2019', 'yeshaokai/Robustness-Aware-Pruning-ADMM', 'zalandoresearch/flair', 'zhaoyuzhi/Legacy-Photo-Editing-with-Learned-Noise-Prior', 'yeoedward/Robust-Fill', 'codchen/CRE', 'LLNL/FAST', 'zliucr/coach', 'songyadong106/111', 'myrtleSoftware/deepspeech', 'zhengziqiang/P2C', 'yikegami/openpose', 'yinzhiyan43/openpose-dev', 'lucidrains/siren-pytorch', 'zhangsilu17/Gini_distance_statistics', 'zhen-dong/hawq', 'yuekai146/NMT', 'yzhou359/MakeItTalk', 'zhougroup/BAM', 'carrenD/ummkd', 'ziangqin-stu/impl_data-effiient-hrl', 'yhw-yhw/PVAMVSNet', 'zphang/usc_dae', 'XiaoxiaoGuo/rcdqn', 'zhegan27/LXMERT-AdvTrain', 'yangdsh/VQA-BUTD-demo', 'brandontrabucco/up_down_cell', 'brandontrabucco/up_down_rnn_cell', 'zaeemzadeh/Active-Learning-UCF101-IPM', 'zhangzx-sjtu/LANTERN-NeurIPS-2019', 'zaccharieramzi/fastmri-reproducible-benchmark', 'drigoni/ComparisonsDGM', 'ceciliavision/perceptual-reflection-removal', 'yiskw713/ClassActivationMapping', 'hursung1/GradientEpisodicMemory', 'facebookresearch/GradientEpisodicMemory', 'yistLin/FragmentVC', 'j-min/VL-T5', 'j-duan/VS-Net', 'Kelym/FAST', 'akuzeee/AFLAC', 'uber-research/LaneGCN', 'zheyejs/3D-convolutional-speaker-recognition', 'yjhong89/Domain-Adaptation', 'yyunon/reproducibility-project-group-71', 'ztoString/CRNN_CTC_OCR_TensorFlow', 'zyasjtu/CNN-RNN-CTC', 'Gitikameher/Domain-Adaptive-Single-View-3D-Reconstruction', 'young-zonglin/bilm-tf-extended', 'yangrui123/Hidden', 'yuanjing-zhu/elmo', 'NaoyukiKanda/LibriSpeechMix', 'ywu94/Code-Notes', 'yaodongyu/TRADES', 'zjfheart/Friendly-Adversarial-Training', 'zju3dv/neuralbody', 'vinsis/ternary-quantization', 'youshyee/CEP', 'zhang2010hao/cw2vec-pytorch', 'mwydmuch/extremeText', 'Xianhang/EDSC-pytorch', 'yrbahn/Deep-AutoEncoders-for-Collaborative-Filtering', 'g-jozsef/sampling-framework', 'benedekrozemberczki/Splitter', 'nkmjm/qiML', 'yitong91/StoryGAN', 'SaeedNajafi/ac-tagger', 'yilundu/improved_contrastive_divergence', 'rnradon/gender_emotion_classification', 'zangobot/secml_malware', 'GillesVandewiele/WalkExperiments', 'Binbose/keras-layer-normalization-rnn', 'yotharit/image_style_transfer', 'MIMBCD-UI/dataset-uta4-rates', 'Stephenfang51/Grad_CAM', 'mzymzy/paper3-quantized_distillzation', 'dropoutlabs/encrypted-skin-cancer-detection', 'yytyvonne/DQN_agent_Chatbot', 'Kakoedlinnoeslovo/fairseq', 'overwindows/PALM', 'facebookresearch/GloRe', 'carlo-/sepconv-ios', 'zhusiling/UNets', 'zhongpeixiang/SemEval2019-Task3-EmotionDetection', 'euranova/CASS-dataset', 'yangliuy/NeuralResponseRanking', 'ybyangpku/CADGMs', 'KeqiangSun/FAB', 'yagyapandeya/CNN-with-Few-Data-VGGish-', 'RICE-EIC/FracTrain', 'zhengshou/AutoLoc', 'yzcjtr/GeoNet', 'ymcidence/Zero-Shot-Sketch-Image-Hashing', 'yule-BUAA/HGConv', 'yongbowin/pkuseg-python_annotation', 'sourabhdattawad/TabNet', 'ymirsky/KitNET-py', 'ymirsky/Kitsune-py', 'yumaloop/LSTMAutoEncoderOnMovingMNIST', 'overlapping-instances/MultiStar', 'yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning', 'zy1998/inception_v3_flowerIdentify', 'zjZSTU/GoogLeNet', 'zzs1994/CVQN', 'yijie0710/GeoNet_pytorch', 'youngbin-ro/Multi2OIE', 'yky138495/awesome-matlab-rank-1000', 'mushfiqur11/SS-VideoCaptioning', 'yoomambo/BayesianOptimization_Tuned', 'code2k13/nlppipe', 'Carco-git/CW_Attack_on_MNIST', 'KangchengHou/gntk', 'dariush-salami/gcn-gesture-recognition', 'hszhao/PSPNet', 'zzxslp/CosRec', 'yongzx/SDEC-Keras', 'NanboLi/MulMON', 'zanyarz/NeuralTwinsTalk', 'yangsenius/TransPose', 'facebookresearch/EmpatheticDialogues', 'zhanglinfeng1997/Sentiment-Analysis-via-GCN', 'ReemHal/Browser-Based-Annotator', 'yogeshbalaji/robustOT', 'yuleiniu/vc', 'yoavnavon/GRU4REC-spotify', 'yxinjiang/Unet-for-foreground-segmentation', 'cocoxu/simplification', 'Stepphonwol/my_yowo', 'zgahhblhc/DialogueFairness', 'yaxingwang/Mix-and-match-networks', 'yamizi/FeatureNet', 'mgong2/DA_Infer', 'yurayli/image-caption-pytorch', 'cod3licious/conec', 'surafelml/improving-zeroshot-nmt', 'Sachin19/adversarial-classify', 'yurayli/stanford-cs224n-sol', 'yuji-roh/fr-train', 'NLPLearn/QANet', 'zhangjiong724/autoassist-exp', 'mohaseeb/wisture', 'yuzhimanhua/lm-lstm-crf', 'yuzhimanhua/Multi-BioNER', 'yshenaw/GNN-Resource-Management', 'yechengxi/deconvolution', 'shuohangwang/Cross-Thought', 'Nachwa/object_states', 'yinglunz/ROAI_ICML2020', 'darkreapyre/HaaS-dev', 'darkreapyre/HaaS-GitOps', 'yan-roo/SpineNet-Pytorch', 'darkreapyre/HaaS', 'yahoo/crow', 'ziqi92/Modof', 'zhangjy2008327/lane-detection-with-double-convgrus', 'wi-pi/GDPR', 'youngminPIL/rollback', 'zoj613/polya-gamma', 'yanfengliu/layered_embeddings', 'yfletberliac/adversarially-guided-actor-critic', 'KentonMurray/ProxGradPytorch', 'yahsieh37/Visual-Saliency-Prediction', 'yubowen-ph/JointER', 'zalkikar/BBOX_GradCAM', 'vinayprabhu/Kannada_MNIST', 'XinJCheng/CSPN', 'zyang-16/MCNS', 'joaoreis-feup/hyper_process_model', 'jpcreis/Hyper-Process-Model', 'yaxingwang/MineGAN', 'yaxingwang/DeepI2I', 'shubhamguptaiitd/GraphRNN', 'yihui-he/Estimated-Depth-Map-Helps-Image-Classification', 'SachinIchake/KALM', 'zygmuntz/hyperband', 'yueqiw/ncp-sort', 'drgriffis/Extrinsic-Evaluation-tasks', 'zhudanhao/g-gnn', 'zxok365/On-Demand-Ridesourcing-Project', 'liamcli/darts', 'yezhang-xiaofan/Rationale-CNN', 'zju-vipa/NetGraft', 'lianbin/VIOSLAM', 'CanCanZeng/LearnVIORB', 'ZuoJiaxing/Learn-ORB-VIO-Stereo-Mono', 'yuzhe630/adder-DSE', 'ychnlgy/DeepConsensus-experimental-FROZEN', 'carolinlawrence/nematus', 'zhengzx-nlp/past-and-future-nmt', 'zswang666/Stereo-LiDAR-CCVNorm', 'SuryanarayanaMK/PDE-STRIDE', 'zhangxiaoyu11/OmiEmbed', 'suvojit-0x55aa/A2S2K-ResNet', 'zhiyongc/Graph-Markov-Network', 'coastalcph/koepsala-parser', 'Nadavc220/DomainAdversarialTrainingOfNeuralNetworks', 'yujiapingyu/Deep-Hashing', 'SungjoonPark/KoreanWordVectors', 'xingyizhou/3DKeypoints-DA', 'vishal-burman/Neural-Machine-Translation', 'ykrmm/ICLR_2020', 'daphne12345/SummarizationRadiologyReports', 'belaalb/TI-DG', 'ianRDavies/LeMOL', 'yang-song/score_sde', 'yfreedomliTHU/mos-pytorch1.1', 'ybisk/charNMT-noise', 'StephanieWyt/RDGCN', 'zju-vipa/TransferbilityFromAttributionMaps', 'yehengchen/SmartCar-FaceRecognition', 'yehengchen/FaceRecognition-FaceNet', 'zhaolongkzz/human_motion', 'zth667/Diverse-Image-Synthesis-from-Semantic-Layout', 'yaohungt/GSTEG_CVPR_2019', 'yipersevere/text-sentiment-classification-with-deep-neural-networks', 'yipersevere/thesis', 'iamkucuk/DCGAN-Face-Generation', 'yzhu319/dlnd_face_generation_git', 'yujuezhao/AC-GAN', 'NadimKawwa/DCGAN_faces', 'yashyenugu/Anime-Face-GAN', 'virafpatrawala/DCGAN', 'suzana-ilic/DCGANs_pytorch', 'suzana-ilic/pytorch_DCGANs', 'toru34/li_emnlp_2017', 'ycccccccccc/Learning-unbiased-zero-shot-semantic-segmentation-networks-via-transductive-transfer', 'yunshengb/SimGNN', 'zhangzjn/DTVNet', 'yashkant/PNAS-Binarized-Neural-Networks', 'spikeeSakshu/CharacterRecognition', 'iamjanvijay/rnnt_decoder_cuda', 'zcyang/imageqa-san', 'zihangJiang/DR-Learning-for-3D-Face', 'zhengwang100/RECT', 'yqx7150/EASEL', 'yunzhusong/AAAI20-PORLHG', 'carlini/pixel-deflection', 'zion-king/Deep-Learning-for-Person-Re-identification', 'ayanc/rpcnn', 'XiaoxiaoGuo/fashion-retrieval', 'KamitaniLab/cnnpref', 'uber-research/FSDM', 'KelestZ/CondGen', 'ykiiiiii/CosmoVAE', 'mit-acl/clear', 'myagues/flax_nerf', 'yenchenlin/nerf-pytorch', 'yalharbi/StructuredNoiseInjection', 'zhangxiangxiao/glyph', 'songlab-cal/tape', 'xiangzhang1015/OATM', 'drimpossible/GDumb', 'yzjiao/Subg-Con', 'zhaofang0627/HPBTT', 'yuantiku/PoDA', 'zalanborsos/online-variance-reduction', 'yaxingwang/Transferring-GANs', 'MartinHahner88/FoggySynscapes', 'chuhang/SurfConv', 'StephenPauwels/edbn_ecmlpkdd', 'ds4dm/branch-search-trees', 'SSL92/hyperIQA', 'suyeecav/model-targeted-poisoning', 'XinGla/RCF', 'zengxianyu/jsws', 'zxlzr/RAN', 'zhengzx-nlp/dynamic-nmt', 'zhezh/adafuse-3d-human-pose', 'zhangboshen/A2J', 'zdou0830/DAFE', 'Xiangyi1996/PPNet-PyTorch', 'zoeyuchao/LFNet_modify', 'ypeleg/komplex', 'zenroad/modifypointnet', 'ycszen/TorchSeg', 'vinnik-dmitry07/PlaceRecognition', 'Xnsam/clothing_classification', 'mgonzalezrivero/reef_learning', 'carolgithubv1/convnets-keras', 'yuhuixu1993/Trained-Rank-Pruning', 'yahoo/object_relation_transformer', 'ymcui/Chinese-PreTrained-XLNet', 'zetayue/CPA', 'cruvadom/Logit_Separation', 'yogeshbalaji/Normalized-Wasserstein', 'carrenD/Med-CMDA', 'johanna-einsiedler/covid-19-air-pollution', 'benedekrozemberczki/APPNP', 'j96w/6-PACK', 'ziyin-dl/global-anchor-method', 'aaaasssddf/global-anchor-method', 'pbizopoulos/signal2image-modules-in-deep-neural-networks-for-eeg-classification', 'zhiweiuu/secs', 'coastalcph/Sequence_classification_with_human_attention', 'FuzhenZhuang/Transfer-Learning-Toolkit', 'zerohd4869/SLK-NER', 'yifan-h/CS-GNN', 'iamkissg/cpae-pytorch', 'yao8839836/text_gcn', 'selim-iitdu/STANCT', 'nithishkaviyan/Sentiment-Analysis-of-Yelp-Reviews', 'audqhsid/-Review-CNN-for-Sentence-Classification', 'yongjincho/cnn-text-classification-pytorch', 'sebastian-hofstaetter/neural-ranking-kd', 'yenchenlin/fid', 'yanx27/Pointnet', 'zgx0534/pointnet_win', 'y2kmz/pointnetv2', 'ytng001/sensemaking', 'ysenarath/hate-detection-icsc-2020', 'yitu-opensource/T2T-ViT', 'ysyushi/HyperMine', 'yatharthagarwal/x_ray', 'yongjie-lin/bert-opensesame', 'code-gen/cscg', 'code-gen/cgcs', 'TIXFeniks/neurips2019_intrus', 'yanx27/3DGNN_pytorch', 'gan3sh500/octaveconv-pytorch', 'yagyapandeya/Music_Source_Seperation_TF2', 'yoojungsun0/Psych239', 'jobdataexchange/competensor', 'zmd971202/IronyGeneration', 'zhaoyanpeng/vpcfg', 'iamgroot42/nelec', 'carljohanhoel/BayesianRLForAutonomousDriving', 'yyysbysb/al_obs_neurips19', 'ArashRahnama/Adversarial-Explanations-for-Artificial-Intelligence-Systems-AXAI', 'yixuan/cdtau', 'dhirajpatnaik16297/IMG-TXT-Generative-Adversarial-Network', 'htconquer/ddh', 'ayanc/edgeml.mdp', 'zekarias-tilahun/GAP', 'rochesterxugroup/HAM_dataset', 'WeijiaLau/MHCH-DAMI', 'yliu1021/HandGestureClassifierCNN', 'yujiali/ggnn', 'drsleep/nas-segm-pytorch', 'yiskw713/boundary_loss_for_remote_sensing', 'johanna-rock/imRICnn', 'dariopavllo/style-semantics', 'zhuoyang125/simple_classifier', 'benedekrozemberczki/AttentionWalk', 'yromano/fair_dummies', 'zalandoresearch/famos', 'vinojjayasundara/textcaps', 'violet-zct/DeMa-BWE', 'yangliuy/HybridNCM', 'rktamplayo/LeTraNets', 'yanrucheng/PINet-demo', 'zeyofu/EDL', 'zjunlp/DiagnoseRE', 'zhengdao-chen/GNN4CD', 'balbok0/bayes-nn-qsh', 'zphang/bert_on_stilts', 'ysharma1126/Split-Brain-Autoencoder', 'yanminglai/Malware-GAN', 'benedekrozemberczki/TENE', 'rktamplayo/DenoiseSum', 'yitianhoulai/ART', 'zhuchen03/FreeLB', 'sdyy6211/plant-segmentation', 'zhenxun-zhuang/SGD-Exponential-Stepsize', 'asprenger/keras_acgan', 'yongleex/AGT-ME', 'zhangtj1996/lottery-ticket-hypothesis-Mxnet', 'arnavdodiedo/DenseNet-MNIST', 'zhangweichen2006/iCAN', 'fsahli/MFclass', 'blablabananarama/ukiyoGAN', 'zhao-lab/kalidindi_dpgp_multi_vehicle_2019', 'zju3dv/pvnet', 'yumeng5/JoSH', 'zhaoxlpku/KnowledGPT', 'york2210/MedicalChatbot-HRL', 'cod3licious/simec', 'sourabhmadur/Neural-Style-Transfer', 'shizuo-kaji/StyleTransfer', 'kidach1/NeuralArtisticStyle', 'RyanWu2233/Style_Transfer', 'patconrey/ANN-Example', 'ialhashim/StyleGAN-Tensorflow2', 'tr1pzz/stylegan2-pytorch', 'xiangyue9607/BioNEV', 'zhyack/SCC', 'HongyuGong/Geometry-of-Compositionality', 'zychen423/KE-VIST', 'zomux/neuralcompressor', 'zhanxinrui/tracking_wo_bnw_fork', 'KhenAharon/Deep-Learning-SNLI-Residual-Stacked-Encoders', 'SharifAmit/OCT_Classification', 'zhawhjw/yolact-interpret', 'zhhchen4njit/yolact', 'ywang07/nmt_soft_prototype', 'j96w/DenseFusion', 'bayrameda/MrAP', 'XiangLiu0731/MFGNet', 'zxleong/GPRNet', 'belkakari/cellular-automata-pytorch', 'z-fabian/transfer_lowerbounds_arXiv', 'nithishkaviyan/Show-and-Tell-Neural-Network-Image-Caption-Generator-', 'zhaitongqing233/Backdoor-attack-against-speaker-verification', 'yuanyuanli85/Stacked_Hourglass_Network_Keras', 'zehuichen123/DSEBM', 'iamhankai/attribute-aware-attention', 'j-a-lin/DFANet_PyTorch', 'yongheng1991/qec_net', 'yfsong0709/RA-GCNv2', 'yzhan238/CGExpan', 'SaeedSharifiMa/AIF', 'yardstick17/AspectBasedSentimentAnalysis', 'XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN', 'yuxi120407/DIB', 'Information-Fusion-Lab-Umass/causal_transfer_learning', 'yredwood/fewshot_blogpost', 'zuoxingdong/VIN_PyTorch_Visdom', 'yqian4/optuna', 'yuxi120407/semi-supervised_tensorflow2.0', 'yijiuzai/Matching-Networks-for-One-Shot-Learning', 'yumoh/speech-keras', 'yeeeqichen/Bert', 'yamad07/NeuralProcess', 'mireshghallah/shredder-v1', 'y0ast/Variational-Autoencoder', 'rmehta1987/CoZINB', 'yolu1055/conditional-glow', 'avinashsai/BERT-Aspect', 'yjparkLiCS/18-NIPS-APIAE', 'yechens/QiuZhao-ChongChongChong', 'yuanyu255/PCNN_C2SA', 'RElbers/region-mutual-information-pytorch', 'subhayanmukherjee/cnninsar', 'zekarias-tilahun/goat', 'pierreHmbt/Tensor_CDL', 'zh3nis/lstm-syl', 'nlpub/watset-java', 'yellowtownhz/STIGCN', 'ybayle/ReproducibleResearchCode', 'bmda-unibas/InverseLearningOfSymmetries', 'zhliping/Deep-Learning', 'yingtaomj/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing', 'yikangli/video-rhythm', 'yougoforward/hlzhu_DANet_git', 'zhenxingsh/Pytorch_DANet', 'favae/favae_ijcai2019', 'jbarnesspain/blse', 'zetayue/MXMNet', 'nch08a/EDVizPhenotyping', 'yqx7150/IFR-Net-Code', 'yuzhimanhua/MetaCat', 'NLP-Discourse-SoochowU/t2d_discourseparser', 'umautobots/pixelwise-deblurring', 'youngryan1993/PrDA-Progressive-Domain-Adaptation-from-a-Source-Pre-trained-Model', 'youngryan1993/SFDA-Domain-Adaptation-without-Source-Data', 'IndustAI/risk-and-uncertainty', 'zhiyongc/Graph_Convolutional_LSTM', 'zhenpeiyang/RelativePose', 'zsef123/EfficientNets-PyTorch', 'zake7749/WSDM-Cup-2019', 'yftah89/TRL-PBLM', 'yumoxu/detnet', 'liernisestorain/zero-shot-dual-MT', 'yu20103983/FOTS', 'huangleiBuaa/OthogonalWN', 'mx54039q/cnn-visualizing', 'zidixiu/VIE', 'jmfacil/single-view-place-recognition', 'nikolamilosevic86/SerbianStemmer', 'pykao/ABCD-MICCAI2019', 'yasinyazici/Venn_GAN', 'tranc012/SMILE-Rep', 'bloodwass/mixout', 'zhangpur/SR-LSTM', 'zhangyu233/mvscode', 'zekunhao1995/PointFlowRenderer', 'yuriautsumi/PersonalizedGP', 'myaldiz/deep_violence_detection', 'yanqi1811/PWC-Net', 'zhengzhe97/yolactpaddle', 'Aoi-hosizora/FFDNet_pytorch', 'zhujiagang/gating-ConvNet-code', 'zhengwang100/RSDNE-python', 'zhenghuazx/BayesianLRPolicySearch', 'uber-research/D3G', 'vishalanand/MultiSeg', 'ynahshan/nn-quantization-pytorch', 'ovchinnikovdk/graph_clf', 'zchenry/ambiguity-comparison', 'belaalb/frameGAN', 'uber-research/DeepPruner', 'yli1/CGPS', 'SaeedNajafi/pytorch-ocd', 'SaeedNajafi/OCD-Learning', 'zhenngbolun/Learnbale_Bandpass_Filter', 'yzhangcs/crfpar', 'iamollas/Altruist', 'yaohungt/Capsules-Inverted-Attention-Routing', 'htanwar922/Language-Adversarial-Network', 'zhoujf620/Motif-based-inductive-GNN-training', 'amikael/ncdigraphs', 'yarotsky/voxelfeatures', 'fostiropoulos/dvq', 'yli1/CLCL', 'yahoo/maaf', 'codeRimoe/DL_for_RSIs', 'chuanraoCV/INQ-incremental-network-quantization-towards-lossless-CNNs-with-low-precision-weights', 'WeijiaZhang24/TEDVAE', 'yukang2017/RENAS', 'Nadav-Barak/AWP', 'mwray/Joint-Part-of-Speech-Embeddings', 'princetonvisualai/SPICE-U', 'jsgaobiao/superpoint_graph', 'ydecastro/lar_testing', 'rktamplayo/HCSC', 'ZurichNLP/ContraPro', 'Huangdebo/YOLOv4-MultiTask', 'ucals/cvae', 'violet-zct/pytorch-reorder-nmt', 'zaf11/xDeepFM-', 'carinanorre/Brain-Tumour-Segmentation-Dissertation', 'overshiki/unet-pytorch', 'zhugoldman/CNN-segmentation-for-Lung-cancer-OARs', 'Will-J-Gale/Self-Driving-Car-Vision', 'yassineAlouini/data-science-bowl-2018', 'SharifAmit/Fundus2Angio', 'black0017/3D-GAN-pytorch', 'ducha-aiki/LSUV-keras', 'yaoli/nade_k', 'tommoral/dicodile', 'yschroecker/universal_value_density_estimation', 'Ximilar-com/tf-image', 'zimengq/PyTorch-ReCode', 'zhezhaoa/neural_BOW_toolkit', 'benedekrozemberczki/SEAL-CI', 'zzd1992/Adversarial-Defense-by-Suppressing-High-Frequencies', 'zotrick/Pneumonia_classification_Xception', 'N0vel/weighted-hausdorff-distance-tensorflow-keras-loss', 'roccotrip/antisem', 'yaoqi-zd/SGAN', 'carpedm20/simulated-unsupervised-tensorflow', 'yeLer/fcn', 'zb12138/sph3d', 'yyyaoyuan/CWAN', 'yanivbl6/fixup', 'yifjiang/relative-depth-using-pytorch', 'yclavinas/ai_big_data_quantum_compution', 'zqwhu/SegDAwithBoundary', 'morningmoni/HiLAP', 'zerohd4869/HIN-SR', 'yaircarmon/semisup-adv', 'benedekrozemberczki/graph2vec', 'yinanzhu12/SegNet-keras', 'okn-yu/SegNet-A-Deep-Convolutional-Encoder-Decoder-Architecture-for-Image-Segmentation', 'yinanzhu12/SegNet-keras-implementation', 'georgeberry/role-action-embeddings', 'dariozanca/eymol', 'SSE-PT/SSE-PT', 'zju3dv/snake', 'yuvalpinter/m3gm', 'KanchiShimono/KGCN', 'benathi/word2gm', 'zhaobomin/pytorch-ocr', 'yunhai0920/company-name-id', 'tranbahien/CTPN-TensorFlow', 'zhenqifu/Twice-Mixing', 'Kanaderu/nlp_credibility', 'ziqizhang/semrerank', 'zengxianyu/crfill', 'Refefer/Dagger', 'ytsvetko/qvec', 'yaoshuwang/SelNet-Estimation', 'ucasir/NPRF', 'yueliukth/decoupling_breast_cancer_risk', 'corinadima/gWordcomp', 'benedekrozemberczki/BANE', 'yhchen12101/FGP-ICL', 'yang1fan2/Dota2-Prediction', 'ytsvetko/metaphor', 'xiangzhang1015/adversarial_seizure_detection', 'yuke93/RL-Restore', 'svakulenk0/semantic_coherence', 'aws-samples/amazon-sagemaker-visual-transformer', 'benathi/density-order-emb', 'yorkerlin/iBayesLRule', 'zhangmeishan/wordstructures', 'MIDA-group/sdt', 'zhd96/pi-vae', 'zihangdai/cegan_iclr2017', 'yuxiaochen1103/DG-STA', 'comicencyclo/TransferLearning_DiscriminativeFineTuning', 'yikeqicn/DeepErase', 'lcary/keras-program-induction', 'yjxiong/temporal-segment-networks', 'caroline171/content_based_recommendation', 'yccyenchicheng/p2pvg', 'pablovin/iCubUno', 'zhusiling/Pytorch-Encoding-boundary', 'ziyuan400/video_segmentation', 'swabhs/open-sesame', 'dssg/hiv-retention-public', 'zhanhaoliu09/auto_tv_denoise', 'zubair-irshad/imitation_learning', 'zhengjingwei/cluster_GCN', 'benedekrozemberczki/ClusterGCN', 'vinodkkurmi/PQG', 'yfsong0709/ResGCNv1', 'zbyte64/pytorch-dagsearch', 'yashkant/ENAS-Quantized-Neural-Networks', 'MINGUKKANG/PNU_Termproject_ENAS', 'www0wwwjs1/Matrix-Capsules-EM-Tensorflow', 'yashkalani/DRAW', 'rktamplayo/MCFA', 'yomnaa/AbsrtactiveApi', 'youngjie-cho/csci1470final', 'yougoforward/Fast_psaa', 'yougoforward/can', 'ywcmaike/TianchiVideoCharacterSegmentationPreliminary', 'zyasjtu/EAST', 'ydup/Anomaly-Detection-in-Time-Series-with-Triadic-Motif-Fields', 'yuhaozhang/tacred-relation', 'zhanjunlang/Span_OIE', 'zsef123/PGGAN-Pytorch', 'ANLGBOY/RealNVP-with-PyTorch', 'yanivbl6/quantized_meanfield', 'zi-lin/on-lstm-tensorflow', 'yikangshen/Ordered-Neurons', 'ben-ix/AdaptiveTPOT', 'zhling2020/RIS-GAN', 'mgermain/MADE', 'carpedm20/BEGAN-tensorflow', 'n-akram/SafeML', 'yuzhou-git/deep-casa', 'zsjdddhr/GraphRfi', 'yusuke0519/constrastive_predictive_coding', 'zjuym/chinese_cws_ner', 'DixinFan/st-gcn', 'yysijie/st-gcn', 'bpucla/latent-space-EBM-prior', 'laowang666888/ECSP1', 'zlai0/MAST', 'zh3nis/scrn', 'ranjanisubramanyan/Patient-data-representation', 'jsalsman/featex', 'ySalaun/LineSfM', 'zhanhuijing/ECC_PYCHARM'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-213-cedcbdb1ee91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgraphsage_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphsage_data_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepoTaskData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaperswithcode_with_features_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaperswithcode_with_imports_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imports'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgraphsage_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_descriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgraphsage_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepo_descriptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgraph_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1151\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot index with multidimensional key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1153\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m             \u001b[0;31m# nested tuple slicing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m         \u001b[0;31m# A collection of keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m         return self.obj._reindex_with_indexers(\n\u001b[1;32m   1095\u001b[0m             \u001b[0;34m{\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         if needs_i8_conversion(ax.dtype) or isinstance(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1377\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['zzz1515151/self-supervised_learning_sketch', 'zhoubolei/moments_models', 'zacwellmer/WorldModels', 'yueqiw/gqn-world-model', 'zhang-huihui/git-repository', 'zapplea/bert', 'EthanWYB/bert-classification', 'svakulenk0/response_eval', 'zsweet/BERT_zsw', 'zhen-he/tracking-by-animation', 'xinge008/Cylinder3D', 'zhanghainan/RNN-encdec', 'zhanghainan/TailoredSeq2Seq2DifferentConversationScenarios', 'yichigo/Chest-X-Ray', 'zju-3dv/multiway', 'zqhl/Wide-Area-Crowd-Counting_CVPR2019', 'yeshaokai/Robustness-Aware-Pruning-ADMM', 'zalandoresearch/flair', 'zhaoyuzhi/Legacy-Photo-Editing-with-Learned-Noise-Prior', 'yeoedward/Robust-Fill', 'codchen/CRE', 'LLNL/FAST', 'zliucr/coach', 'songyadong106/111', 'myrtleSoftware/deepspeech', 'zhengziqiang/P2C', 'yikegami/openpose', 'yinzhiyan43/openpose-dev', 'lucidrains/siren-pytorch', 'zhangsilu17/Gini_distance_statistics', 'zhen-dong/hawq', 'yuekai146/NMT', 'yzhou359/MakeItTalk', 'zhougroup/BAM', 'carrenD/ummkd', 'ziangqin-stu/impl_data-effiient-hrl', 'yhw-yhw/PVAMVSNet', 'zphang/usc_dae', 'XiaoxiaoGuo/rcdqn', 'zhegan27/LXMERT-AdvTrain', 'yangdsh/VQA-BUTD-demo', 'brandontrabucco/up_down_cell', 'brandontrabucco/up_down_rnn_cell', 'zaeemzadeh/Active-Learning-UCF101-IPM', 'zhangzx-sjtu/LANTERN-NeurIPS-2019', 'zaccharieramzi/fastmri-reproducible-benchmark', 'drigoni/ComparisonsDGM', 'ceciliavision/perceptual-reflection-removal', 'yiskw713/ClassActivationMapping', 'hursung1/GradientEpisodicMemory', 'facebookresearch/GradientEpisodicMemory', 'yistLin/FragmentVC', 'j-min/VL-T5', 'j-duan/VS-Net', 'Kelym/FAST', 'akuzeee/AFLAC', 'uber-research/LaneGCN', 'zheyejs/3D-convolutional-speaker-recognition', 'yjhong89/Domain-Adaptation', 'yyunon/reproducibility-project-group-71', 'ztoString/CRNN_CTC_OCR_TensorFlow', 'zyasjtu/CNN-RNN-CTC', 'Gitikameher/Domain-Adaptive-Single-View-3D-Reconstruction', 'young-zonglin/bilm-tf-extended', 'yangrui123/Hidden', 'yuanjing-zhu/elmo', 'NaoyukiKanda/LibriSpeechMix', 'ywu94/Code-Notes', 'yaodongyu/TRADES', 'zjfheart/Friendly-Adversarial-Training', 'zju3dv/neuralbody', 'vinsis/ternary-quantization', 'youshyee/CEP', 'zhang2010hao/cw2vec-pytorch', 'mwydmuch/extremeText', 'Xianhang/EDSC-pytorch', 'yrbahn/Deep-AutoEncoders-for-Collaborative-Filtering', 'g-jozsef/sampling-framework', 'benedekrozemberczki/Splitter', 'nkmjm/qiML', 'yitong91/StoryGAN', 'SaeedNajafi/ac-tagger', 'yilundu/improved_contrastive_divergence', 'rnradon/gender_emotion_classification', 'zangobot/secml_malware', 'GillesVandewiele/WalkExperiments', 'Binbose/keras-layer-normalization-rnn', 'yotharit/image_style_transfer', 'MIMBCD-UI/dataset-uta4-rates', 'Stephenfang51/Grad_CAM', 'mzymzy/paper3-quantized_distillzation', 'dropoutlabs/encrypted-skin-cancer-detection', 'yytyvonne/DQN_agent_Chatbot', 'Kakoedlinnoeslovo/fairseq', 'overwindows/PALM', 'facebookresearch/GloRe', 'carlo-/sepconv-ios', 'zhusiling/UNets', 'zhongpeixiang/SemEval2019-Task3-EmotionDetection', 'euranova/CASS-dataset', 'yangliuy/NeuralResponseRanking', 'ybyangpku/CADGMs', 'KeqiangSun/FAB', 'yagyapandeya/CNN-with-Few-Data-VGGish-', 'RICE-EIC/FracTrain', 'zhengshou/AutoLoc', 'yzcjtr/GeoNet', 'ymcidence/Zero-Shot-Sketch-Image-Hashing', 'yule-BUAA/HGConv', 'yongbowin/pkuseg-python_annotation', 'sourabhdattawad/TabNet', 'ymirsky/KitNET-py', 'ymirsky/Kitsune-py', 'yumaloop/LSTMAutoEncoderOnMovingMNIST', 'overlapping-instances/MultiStar', 'yeefan1999/Explainable-Health-Prediction-with-Transfer-Learning', 'zy1998/inception_v3_flowerIdentify', 'zjZSTU/GoogLeNet', 'zzs1994/CVQN', 'yijie0710/GeoNet_pytorch', 'youngbin-ro/Multi2OIE', 'yky138495/awesome-matlab-rank-1000', 'mushfiqur11/SS-VideoCaptioning', 'yoomambo/BayesianOptimization_Tuned', 'code2k13/nlppipe', 'Carco-git/CW_Attack_on_MNIST', 'KangchengHou/gntk', 'dariush-salami/gcn-gesture-recognition', 'hszhao/PSPNet', 'zzxslp/CosRec', 'yongzx/SDEC-Keras', 'NanboLi/MulMON', 'zanyarz/NeuralTwinsTalk', 'yangsenius/TransPose', 'facebookresearch/EmpatheticDialogues', 'zhanglinfeng1997/Sentiment-Analysis-via-GCN', 'ReemHal/Browser-Based-Annotator', 'yogeshbalaji/robustOT', 'yuleiniu/vc', 'yoavnavon/GRU4REC-spotify', 'yxinjiang/Unet-for-foreground-segmentation', 'cocoxu/simplification', 'Stepphonwol/my_yowo', 'zgahhblhc/DialogueFairness', 'yaxingwang/Mix-and-match-networks', 'yamizi/FeatureNet', 'mgong2/DA_Infer', 'yurayli/image-caption-pytorch', 'cod3licious/conec', 'surafelml/improving-zeroshot-nmt', 'Sachin19/adversarial-classify', 'yurayli/stanford-cs224n-sol', 'yuji-roh/fr-train', 'NLPLearn/QANet', 'zhangjiong724/autoassist-exp', 'mohaseeb/wisture', 'yuzhimanhua/lm-lstm-crf', 'yuzhimanhua/Multi-BioNER', 'yshenaw/GNN-Resource-Management', 'yechengxi/deconvolution', 'shuohangwang/Cross-Thought', 'Nachwa/object_states', 'yinglunz/ROAI_ICML2020', 'darkreapyre/HaaS-dev', 'darkreapyre/HaaS-GitOps', 'yan-roo/SpineNet-Pytorch', 'darkreapyre/HaaS', 'yahoo/crow', 'ziqi92/Modof', 'zhangjy2008327/lane-detection-with-double-convgrus', 'wi-pi/GDPR', 'youngminPIL/rollback', 'zoj613/polya-gamma', 'yanfengliu/layered_embeddings', 'yfletberliac/adversarially-guided-actor-critic', 'KentonMurray/ProxGradPytorch', 'yahsieh37/Visual-Saliency-Prediction', 'yubowen-ph/JointER', 'zalkikar/BBOX_GradCAM', 'vinayprabhu/Kannada_MNIST', 'XinJCheng/CSPN', 'zyang-16/MCNS', 'joaoreis-feup/hyper_process_model', 'jpcreis/Hyper-Process-Model', 'yaxingwang/MineGAN', 'yaxingwang/DeepI2I', 'shubhamguptaiitd/GraphRNN', 'yihui-he/Estimated-Depth-Map-Helps-Image-Classification', 'SachinIchake/KALM', 'zygmuntz/hyperband', 'yueqiw/ncp-sort', 'drgriffis/Extrinsic-Evaluation-tasks', 'zhudanhao/g-gnn', 'zxok365/On-Demand-Ridesourcing-Project', 'liamcli/darts', 'yezhang-xiaofan/Rationale-CNN', 'zju-vipa/NetGraft', 'lianbin/VIOSLAM', 'CanCanZeng/LearnVIORB', 'ZuoJiaxing/Learn-ORB-VIO-Stereo-Mono', 'yuzhe630/adder-DSE', 'ychnlgy/DeepConsensus-experimental-FROZEN', 'carolinlawrence/nematus', 'zhengzx-nlp/past-and-future-nmt', 'zswang666/Stereo-LiDAR-CCVNorm', 'SuryanarayanaMK/PDE-STRIDE', 'zhangxiaoyu11/OmiEmbed', 'suvojit-0x55aa/A2S2K-ResNet', 'zhiyongc/Graph-Markov-Network', 'coastalcph/koepsala-parser', 'Nadavc220/DomainAdversarialTrainingOfNeuralNetworks', 'yujiapingyu/Deep-Hashing', 'SungjoonPark/KoreanWordVectors', 'xingyizhou/3DKeypoints-DA', 'vishal-burman/Neural-Machine-Translation', 'ykrmm/ICLR_2020', 'daphne12345/SummarizationRadiologyReports', 'belaalb/TI-DG', 'ianRDavies/LeMOL', 'yang-song/score_sde', 'yfreedomliTHU/mos-pytorch1.1', 'ybisk/charNMT-noise', 'StephanieWyt/RDGCN', 'zju-vipa/TransferbilityFromAttributionMaps', 'yehengchen/SmartCar-FaceRecognition', 'yehengchen/FaceRecognition-FaceNet', 'zhaolongkzz/human_motion', 'zth667/Diverse-Image-Synthesis-from-Semantic-Layout', 'yaohungt/GSTEG_CVPR_2019', 'yipersevere/text-sentiment-classification-with-deep-neural-networks', 'yipersevere/thesis', 'iamkucuk/DCGAN-Face-Generation', 'yzhu319/dlnd_face_generation_git', 'yujuezhao/AC-GAN', 'NadimKawwa/DCGAN_faces', 'yashyenugu/Anime-Face-GAN', 'virafpatrawala/DCGAN', 'suzana-ilic/DCGANs_pytorch', 'suzana-ilic/pytorch_DCGANs', 'toru34/li_emnlp_2017', 'ycccccccccc/Learning-unbiased-zero-shot-semantic-segmentation-networks-via-transductive-transfer', 'yunshengb/SimGNN', 'zhangzjn/DTVNet', 'yashkant/PNAS-Binarized-Neural-Networks', 'spikeeSakshu/CharacterRecognition', 'iamjanvijay/rnnt_decoder_cuda', 'zcyang/imageqa-san', 'zihangJiang/DR-Learning-for-3D-Face', 'zhengwang100/RECT', 'yqx7150/EASEL', 'yunzhusong/AAAI20-PORLHG', 'carlini/pixel-deflection', 'zion-king/Deep-Learning-for-Person-Re-identification', 'ayanc/rpcnn', 'XiaoxiaoGuo/fashion-retrieval', 'KamitaniLab/cnnpref', 'uber-research/FSDM', 'KelestZ/CondGen', 'ykiiiiii/CosmoVAE', 'mit-acl/clear', 'myagues/flax_nerf', 'yenchenlin/nerf-pytorch', 'yalharbi/StructuredNoiseInjection', 'zhangxiangxiao/glyph', 'songlab-cal/tape', 'xiangzhang1015/OATM', 'drimpossible/GDumb', 'yzjiao/Subg-Con', 'zhaofang0627/HPBTT', 'yuantiku/PoDA', 'zalanborsos/online-variance-reduction', 'yaxingwang/Transferring-GANs', 'MartinHahner88/FoggySynscapes', 'chuhang/SurfConv', 'StephenPauwels/edbn_ecmlpkdd', 'ds4dm/branch-search-trees', 'SSL92/hyperIQA', 'suyeecav/model-targeted-poisoning', 'XinGla/RCF', 'zengxianyu/jsws', 'zxlzr/RAN', 'zhengzx-nlp/dynamic-nmt', 'zhezh/adafuse-3d-human-pose', 'zhangboshen/A2J', 'zdou0830/DAFE', 'Xiangyi1996/PPNet-PyTorch', 'zoeyuchao/LFNet_modify', 'ypeleg/komplex', 'zenroad/modifypointnet', 'ycszen/TorchSeg', 'vinnik-dmitry07/PlaceRecognition', 'Xnsam/clothing_classification', 'mgonzalezrivero/reef_learning', 'carolgithubv1/convnets-keras', 'yuhuixu1993/Trained-Rank-Pruning', 'yahoo/object_relation_transformer', 'ymcui/Chinese-PreTrained-XLNet', 'zetayue/CPA', 'cruvadom/Logit_Separation', 'yogeshbalaji/Normalized-Wasserstein', 'carrenD/Med-CMDA', 'johanna-einsiedler/covid-19-air-pollution', 'benedekrozemberczki/APPNP', 'j96w/6-PACK', 'ziyin-dl/global-anchor-method', 'aaaasssddf/global-anchor-method', 'pbizopoulos/signal2image-modules-in-deep-neural-networks-for-eeg-classification', 'zhiweiuu/secs', 'coastalcph/Sequence_classification_with_human_attention', 'FuzhenZhuang/Transfer-Learning-Toolkit', 'zerohd4869/SLK-NER', 'yifan-h/CS-GNN', 'iamkissg/cpae-pytorch', 'yao8839836/text_gcn', 'selim-iitdu/STANCT', 'nithishkaviyan/Sentiment-Analysis-of-Yelp-Reviews', 'audqhsid/-Review-CNN-for-Sentence-Classification', 'yongjincho/cnn-text-classification-pytorch', 'sebastian-hofstaetter/neural-ranking-kd', 'yenchenlin/fid', 'yanx27/Pointnet', 'zgx0534/pointnet_win', 'y2kmz/pointnetv2', 'ytng001/sensemaking', 'ysenarath/hate-detection-icsc-2020', 'yitu-opensource/T2T-ViT', 'ysyushi/HyperMine', 'yatharthagarwal/x_ray', 'yongjie-lin/bert-opensesame', 'code-gen/cscg', 'code-gen/cgcs', 'TIXFeniks/neurips2019_intrus', 'yanx27/3DGNN_pytorch', 'gan3sh500/octaveconv-pytorch', 'yagyapandeya/Music_Source_Seperation_TF2', 'yoojungsun0/Psych239', 'jobdataexchange/competensor', 'zmd971202/IronyGeneration', 'zhaoyanpeng/vpcfg', 'iamgroot42/nelec', 'carljohanhoel/BayesianRLForAutonomousDriving', 'yyysbysb/al_obs_neurips19', 'ArashRahnama/Adversarial-Explanations-for-Artificial-Intelligence-Systems-AXAI', 'yixuan/cdtau', 'dhirajpatnaik16297/IMG-TXT-Generative-Adversarial-Network', 'htconquer/ddh', 'ayanc/edgeml.mdp', 'zekarias-tilahun/GAP', 'rochesterxugroup/HAM_dataset', 'WeijiaLau/MHCH-DAMI', 'yliu1021/HandGestureClassifierCNN', 'yujiali/ggnn', 'drsleep/nas-segm-pytorch', 'yiskw713/boundary_loss_for_remote_sensing', 'johanna-rock/imRICnn', 'dariopavllo/style-semantics', 'zhuoyang125/simple_classifier', 'benedekrozemberczki/AttentionWalk', 'yromano/fair_dummies', 'zalandoresearch/famos', 'vinojjayasundara/textcaps', 'violet-zct/DeMa-BWE', 'yangliuy/HybridNCM', 'rktamplayo/LeTraNets', 'yanrucheng/PINet-demo', 'zeyofu/EDL', 'zjunlp/DiagnoseRE', 'zhengdao-chen/GNN4CD', 'balbok0/bayes-nn-qsh', 'zphang/bert_on_stilts', 'ysharma1126/Split-Brain-Autoencoder', 'yanminglai/Malware-GAN', 'benedekrozemberczki/TENE', 'rktamplayo/DenoiseSum', 'yitianhoulai/ART', 'zhuchen03/FreeLB', 'sdyy6211/plant-segmentation', 'zhenxun-zhuang/SGD-Exponential-Stepsize', 'asprenger/keras_acgan', 'yongleex/AGT-ME', 'zhangtj1996/lottery-ticket-hypothesis-Mxnet', 'arnavdodiedo/DenseNet-MNIST', 'zhangweichen2006/iCAN', 'fsahli/MFclass', 'blablabananarama/ukiyoGAN', 'zhao-lab/kalidindi_dpgp_multi_vehicle_2019', 'zju3dv/pvnet', 'yumeng5/JoSH', 'zhaoxlpku/KnowledGPT', 'york2210/MedicalChatbot-HRL', 'cod3licious/simec', 'sourabhmadur/Neural-Style-Transfer', 'shizuo-kaji/StyleTransfer', 'kidach1/NeuralArtisticStyle', 'RyanWu2233/Style_Transfer', 'patconrey/ANN-Example', 'ialhashim/StyleGAN-Tensorflow2', 'tr1pzz/stylegan2-pytorch', 'xiangyue9607/BioNEV', 'zhyack/SCC', 'HongyuGong/Geometry-of-Compositionality', 'zychen423/KE-VIST', 'zomux/neuralcompressor', 'zhanxinrui/tracking_wo_bnw_fork', 'KhenAharon/Deep-Learning-SNLI-Residual-Stacked-Encoders', 'SharifAmit/OCT_Classification', 'zhawhjw/yolact-interpret', 'zhhchen4njit/yolact', 'ywang07/nmt_soft_prototype', 'j96w/DenseFusion', 'bayrameda/MrAP', 'XiangLiu0731/MFGNet', 'zxleong/GPRNet', 'belkakari/cellular-automata-pytorch', 'z-fabian/transfer_lowerbounds_arXiv', 'nithishkaviyan/Show-and-Tell-Neural-Network-Image-Caption-Generator-', 'zhaitongqing233/Backdoor-attack-against-speaker-verification', 'yuanyuanli85/Stacked_Hourglass_Network_Keras', 'zehuichen123/DSEBM', 'iamhankai/attribute-aware-attention', 'j-a-lin/DFANet_PyTorch', 'yongheng1991/qec_net', 'yfsong0709/RA-GCNv2', 'yzhan238/CGExpan', 'SaeedSharifiMa/AIF', 'yardstick17/AspectBasedSentimentAnalysis', 'XiaowanLi2018/TimeSeriesPrediction_BasedOnCNN', 'yuxi120407/DIB', 'Information-Fusion-Lab-Umass/causal_transfer_learning', 'yredwood/fewshot_blogpost', 'zuoxingdong/VIN_PyTorch_Visdom', 'yqian4/optuna', 'yuxi120407/semi-supervised_tensorflow2.0', 'yijiuzai/Matching-Networks-for-One-Shot-Learning', 'yumoh/speech-keras', 'yeeeqichen/Bert', 'yamad07/NeuralProcess', 'mireshghallah/shredder-v1', 'y0ast/Variational-Autoencoder', 'rmehta1987/CoZINB', 'yolu1055/conditional-glow', 'avinashsai/BERT-Aspect', 'yjparkLiCS/18-NIPS-APIAE', 'yechens/QiuZhao-ChongChongChong', 'yuanyu255/PCNN_C2SA', 'RElbers/region-mutual-information-pytorch', 'subhayanmukherjee/cnninsar', 'zekarias-tilahun/goat', 'pierreHmbt/Tensor_CDL', 'zh3nis/lstm-syl', 'nlpub/watset-java', 'yellowtownhz/STIGCN', 'ybayle/ReproducibleResearchCode', 'bmda-unibas/InverseLearningOfSymmetries', 'zhliping/Deep-Learning', 'yingtaomj/Iterative-Document-Representation-Learning-Towards-Summarization-with-Polishing', 'yikangli/video-rhythm', 'yougoforward/hlzhu_DANet_git', 'zhenxingsh/Pytorch_DANet', 'favae/favae_ijcai2019', 'jbarnesspain/blse', 'zetayue/MXMNet', 'nch08a/EDVizPhenotyping', 'yqx7150/IFR-Net-Code', 'yuzhimanhua/MetaCat', 'NLP-Discourse-SoochowU/t2d_discourseparser', 'umautobots/pixelwise-deblurring', 'youngryan1993/PrDA-Progressive-Domain-Adaptation-from-a-Source-Pre-trained-Model', 'youngryan1993/SFDA-Domain-Adaptation-without-Source-Data', 'IndustAI/risk-and-uncertainty', 'zhiyongc/Graph_Convolutional_LSTM', 'zhenpeiyang/RelativePose', 'zsef123/EfficientNets-PyTorch', 'zake7749/WSDM-Cup-2019', 'yftah89/TRL-PBLM', 'yumoxu/detnet', 'liernisestorain/zero-shot-dual-MT', 'yu20103983/FOTS', 'huangleiBuaa/OthogonalWN', 'mx54039q/cnn-visualizing', 'zidixiu/VIE', 'jmfacil/single-view-place-recognition', 'nikolamilosevic86/SerbianStemmer', 'pykao/ABCD-MICCAI2019', 'yasinyazici/Venn_GAN', 'tranc012/SMILE-Rep', 'bloodwass/mixout', 'zhangpur/SR-LSTM', 'zhangyu233/mvscode', 'zekunhao1995/PointFlowRenderer', 'yuriautsumi/PersonalizedGP', 'myaldiz/deep_violence_detection', 'yanqi1811/PWC-Net', 'zhengzhe97/yolactpaddle', 'Aoi-hosizora/FFDNet_pytorch', 'zhujiagang/gating-ConvNet-code', 'zhengwang100/RSDNE-python', 'zhenghuazx/BayesianLRPolicySearch', 'uber-research/D3G', 'vishalanand/MultiSeg', 'ynahshan/nn-quantization-pytorch', 'ovchinnikovdk/graph_clf', 'zchenry/ambiguity-comparison', 'belaalb/frameGAN', 'uber-research/DeepPruner', 'yli1/CGPS', 'SaeedNajafi/pytorch-ocd', 'SaeedNajafi/OCD-Learning', 'zhenngbolun/Learnbale_Bandpass_Filter', 'yzhangcs/crfpar', 'iamollas/Altruist', 'yaohungt/Capsules-Inverted-Attention-Routing', 'htanwar922/Language-Adversarial-Network', 'zhoujf620/Motif-based-inductive-GNN-training', 'amikael/ncdigraphs', 'yarotsky/voxelfeatures', 'fostiropoulos/dvq', 'yli1/CLCL', 'yahoo/maaf', 'codeRimoe/DL_for_RSIs', 'chuanraoCV/INQ-incremental-network-quantization-towards-lossless-CNNs-with-low-precision-weights', 'WeijiaZhang24/TEDVAE', 'yukang2017/RENAS', 'Nadav-Barak/AWP', 'mwray/Joint-Part-of-Speech-Embeddings', 'princetonvisualai/SPICE-U', 'jsgaobiao/superpoint_graph', 'ydecastro/lar_testing', 'rktamplayo/HCSC', 'ZurichNLP/ContraPro', 'Huangdebo/YOLOv4-MultiTask', 'ucals/cvae', 'violet-zct/pytorch-reorder-nmt', 'zaf11/xDeepFM-', 'carinanorre/Brain-Tumour-Segmentation-Dissertation', 'overshiki/unet-pytorch', 'zhugoldman/CNN-segmentation-for-Lung-cancer-OARs', 'Will-J-Gale/Self-Driving-Car-Vision', 'yassineAlouini/data-science-bowl-2018', 'SharifAmit/Fundus2Angio', 'black0017/3D-GAN-pytorch', 'ducha-aiki/LSUV-keras', 'yaoli/nade_k', 'tommoral/dicodile', 'yschroecker/universal_value_density_estimation', 'Ximilar-com/tf-image', 'zimengq/PyTorch-ReCode', 'zhezhaoa/neural_BOW_toolkit', 'benedekrozemberczki/SEAL-CI', 'zzd1992/Adversarial-Defense-by-Suppressing-High-Frequencies', 'zotrick/Pneumonia_classification_Xception', 'N0vel/weighted-hausdorff-distance-tensorflow-keras-loss', 'roccotrip/antisem', 'yaoqi-zd/SGAN', 'carpedm20/simulated-unsupervised-tensorflow', 'yeLer/fcn', 'zb12138/sph3d', 'yyyaoyuan/CWAN', 'yanivbl6/fixup', 'yifjiang/relative-depth-using-pytorch', 'yclavinas/ai_big_data_quantum_compution', 'zqwhu/SegDAwithBoundary', 'morningmoni/HiLAP', 'zerohd4869/HIN-SR', 'yaircarmon/semisup-adv', 'benedekrozemberczki/graph2vec', 'yinanzhu12/SegNet-keras', 'okn-yu/SegNet-A-Deep-Convolutional-Encoder-Decoder-Architecture-for-Image-Segmentation', 'yinanzhu12/SegNet-keras-implementation', 'georgeberry/role-action-embeddings', 'dariozanca/eymol', 'SSE-PT/SSE-PT', 'zju3dv/snake', 'yuvalpinter/m3gm', 'KanchiShimono/KGCN', 'benathi/word2gm', 'zhaobomin/pytorch-ocr', 'yunhai0920/company-name-id', 'tranbahien/CTPN-TensorFlow', 'zhenqifu/Twice-Mixing', 'Kanaderu/nlp_credibility', 'ziqizhang/semrerank', 'zengxianyu/crfill', 'Refefer/Dagger', 'ytsvetko/qvec', 'yaoshuwang/SelNet-Estimation', 'ucasir/NPRF', 'yueliukth/decoupling_breast_cancer_risk', 'corinadima/gWordcomp', 'benedekrozemberczki/BANE', 'yhchen12101/FGP-ICL', 'yang1fan2/Dota2-Prediction', 'ytsvetko/metaphor', 'xiangzhang1015/adversarial_seizure_detection', 'yuke93/RL-Restore', 'svakulenk0/semantic_coherence', 'aws-samples/amazon-sagemaker-visual-transformer', 'benathi/density-order-emb', 'yorkerlin/iBayesLRule', 'zhangmeishan/wordstructures', 'MIDA-group/sdt', 'zhd96/pi-vae', 'zihangdai/cegan_iclr2017', 'yuxiaochen1103/DG-STA', 'comicencyclo/TransferLearning_DiscriminativeFineTuning', 'yikeqicn/DeepErase', 'lcary/keras-program-induction', 'yjxiong/temporal-segment-networks', 'caroline171/content_based_recommendation', 'yccyenchicheng/p2pvg', 'pablovin/iCubUno', 'zhusiling/Pytorch-Encoding-boundary', 'ziyuan400/video_segmentation', 'swabhs/open-sesame', 'dssg/hiv-retention-public', 'zhanhaoliu09/auto_tv_denoise', 'zubair-irshad/imitation_learning', 'zhengjingwei/cluster_GCN', 'benedekrozemberczki/ClusterGCN', 'vinodkkurmi/PQG', 'yfsong0709/ResGCNv1', 'zbyte64/pytorch-dagsearch', 'yashkant/ENAS-Quantized-Neural-Networks', 'MINGUKKANG/PNU_Termproject_ENAS', 'www0wwwjs1/Matrix-Capsules-EM-Tensorflow', 'yashkalani/DRAW', 'rktamplayo/MCFA', 'yomnaa/AbsrtactiveApi', 'youngjie-cho/csci1470final', 'yougoforward/Fast_psaa', 'yougoforward/can', 'ywcmaike/TianchiVideoCharacterSegmentationPreliminary', 'zyasjtu/EAST', 'ydup/Anomaly-Detection-in-Time-Series-with-Triadic-Motif-Fields', 'yuhaozhang/tacred-relation', 'zhanjunlang/Span_OIE', 'zsef123/PGGAN-Pytorch', 'ANLGBOY/RealNVP-with-PyTorch', 'yanivbl6/quantized_meanfield', 'zi-lin/on-lstm-tensorflow', 'yikangshen/Ordered-Neurons', 'ben-ix/AdaptiveTPOT', 'zhling2020/RIS-GAN', 'mgermain/MADE', 'carpedm20/BEGAN-tensorflow', 'n-akram/SafeML', 'yuzhou-git/deep-casa', 'zsjdddhr/GraphRfi', 'yusuke0519/constrastive_predictive_coding', 'zjuym/chinese_cws_ner', 'DixinFan/st-gcn', 'yysijie/st-gcn', 'bpucla/latent-space-EBM-prior', 'laowang666888/ECSP1', 'zlai0/MAST', 'zh3nis/scrn', 'ranjanisubramanyan/Patient-data-representation', 'jsalsman/featex', 'ySalaun/LineSfM', 'zhanhuijing/ECC_PYCHARM'] not in index\""
     ]
    }
   ],
   "source": [
    "graphsage_data_train, graphsage_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "graphsage_data_train.X = repo_descriptions.loc[graph_data_train.repos]\n",
    "graphsage_data_test.X = repo_descriptions.loc[graph_data_test.repos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_records_df(sources, connected_vertices):\n",
    "    return pd.DataFrame.from_records(\n",
    "        [\n",
    "            {\"source\": src, \"destination\": dst, \"edge_type\": \"repo-file\"}\n",
    "            for (src, destinations) in zip(sources, connected_vertices)\n",
    "            for dst in destinations \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records_df = make_records_df(graphsage_data_train.repos, graph_data_train.X.fillna(\"\").str.split()).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertex_embeddings(wrapper, vertex_subset, model):\n",
    "    features = (\n",
    "        model.full_forward(\n",
    "            wrapper.dataset.x, wrapper.dataset.edge_index\n",
    "        )\n",
    "        .cpu()\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "    return features[wrapper.vertex_mapping.loc[vertex_subset]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_dependency_graph_wrapper = PygGraphWrapper(embeddings.FastTextVectorizer(fasttext_model).transform, non_root_dependency_records_df + make_records_df(graphsage_data_train.repos, graph_data_train.X.dropna().str.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_graph_wrapper.get_vertex_embeddings(graphsage_data_train.X.iloc[0].split(), graphsage_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_learner = RetrieverLearner(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    LambdaTransformer(lambda x: dependency_graph_wrapper.get_vertex_embeddings(x, graphsage_model)),\n",
    "    embeddings.FastTextVectorizer(fasttext_model)\n",
    ")\n",
    "graphsage_learner.fit_learner(graphsage_data_train)\n",
    "graphsage_learner.evaluate(graphsage_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graphsage_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graphsage_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation of repo, import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train, paired_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "paired_data_train.X = graph_data_train.X + \" \" + import_data_train.X\n",
    "paired_data_test.X = graph_data_test.X + \" \" + import_data_test.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    PairedKeyedVectors(python_word_embeddings.wv, graphsage_embeddings),\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "paired_learner.fit_learner(graph_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (learner, learner_name, test) in zip(\n",
    "    [import2vec_learner, prone_learner, paired_learner],\n",
    "    ['import2vec', 'prone', 'both'],\n",
    "    [X_test, repo_graph_terms_test, X_paired_test]\n",
    "):\n",
    "    accs = []\n",
    "    for k in [1, 3, 5, 10, 20]:\n",
    "        rec = get_retrieval_accuracy(learner, test, y_test, test_task_idxs, k=k)\n",
    "        accs.append(rec)\n",
    "    results.append(pd.Series(name=learner_name, data=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = [\"Accuracy@{}\".format(i) for i in [1, 3, 5, 10, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_markdown(open(\"metrics/zsl_results.md\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat metrics/zsl_results.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_distances = metrics.pairwise.cosine_distances(task_embeddings, task_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_embeddings = gensim.models.KeyedVectors.load('data/poincare5.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.wrappers.fasttext\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import typical_file_parts\n",
    "from mlutil import prototype_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lines_df = typical_file_parts.get_selected_lines_and_repos(python_files_df['repo_name'], python_files_df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting prototypical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_selector = prototype_selection.PrototypeSelector(fasttext_avg_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fasttext_prototypes = json.load(open('data/fasttext_prototypes.json', 'r'))\n",
    "except:\n",
    "    fasttext_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    fasttext_prototypes = fasttext_selector.prototypes\n",
    "    json.dump(fasttext_prototypes, open('data/fasttext_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_vectorizer = embeddings.TransformerVectorizer('microsoft/codebert-base', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector = prototype_selection.PrototypeSelector(codebert_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    codebert_prototypes = json.load(open('data/codebert_prototypes.json', 'r'))\n",
    "except:\n",
    "    codebert_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    codebert_prototypes = codebert_selector.prototypes\n",
    "    json.dump(codebert_prototypes, open('data/codebert_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_prototypes(vectorizer, prototypes):\n",
    "    prototype_aggregated_embeddings = {}\n",
    "    for key in prototypes.keys():\n",
    "        prototype_aggregated_embeddings[key] = np.mean(vectorizer.transform(prototypes[key]), axis=0)\n",
    "    return list(prototype_aggregated_embeddings.keys()), np.row_stack(prototype_aggregated_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in codebert_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in fasttext_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prototypes(repo_name):\n",
    "    return pd.DataFrame({\"codebert\": codebert_prototypes[repo_name], \"fasttext\": fasttext_prototypes[repo_name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"Recommenders-movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes['mmdetection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_repos, codebert_prototype_embeddings = vectorize_prototypes(codebert_vectorizer, codebert_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_repos, fasttext_prototype_embeddings = vectorize_prototypes(fasttext_avg_embedder, fasttext_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fasttext_prototype_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_tasks_series = paperswithcode_with_imports_df['most_common_task']\n",
    "paperswithcode_tasks_series.index = paperswithcode_with_imports_df['repo_name']\n",
    "#paperswithcode_tasks_series = paperswithcode_tasks_series[paperswithcode_tasks_series.index.isin(fasttext_repos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_tasks = paperswithcode_tasks_series.loc[fasttext_repos]\n",
    "fasttext_tasks_embeddings = task_embedder.transform(fasttext_tasks)\n",
    "codebert_tasks = paperswithcode_tasks_series.loc[codebert_repos]\n",
    "codebert_tasks_embeddings = task_embedder.transform(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner = zero_shot.ESZSLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(selected_lines_df['repo']))[3007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df = selected_lines_df[selected_lines_df['repo'] == 'auto_ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del codebert_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df['lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector.prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings = fasttext_avg_embedder.transform(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names = \n",
    "repo_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
