{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp matching_zsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import ast\n",
    "import tqdm\n",
    "import json\n",
    "import attr\n",
    "from operator import itemgetter\n",
    "from scipy.stats import hmean\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, metrics, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from mlutil.feature_extraction import embeddings\n",
    "import mlutil\n",
    "from scarce_learn import zero_shot\n",
    "from scarce_learn.zero_shot import devise_jax, devise_torch\n",
    "from github_search import paperswithcode_tasks, github_readmes, python_call_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "\n",
    "import_corpus_path = 'output/module_corpus.csv'\n",
    "word_vectors_filename = 'output/import2vec_module_vectors.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)\n",
    "import_corpus_df['imports'] = import_corpus_df['imports'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 30s, sys: 3.61 s, total: 3min 33s\n",
      "Wall time: 3min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "python_files_df = pd.read_csv('data/crawled_python_files.csv', encoding='latin-1')\n",
    "repo_names = python_files_df['repo_name']\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797972, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1749175, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   trangvu/ape-npi\n",
       "1                   trangvu/ape-npi\n",
       "2                   trangvu/ape-npi\n",
       "3                   trangvu/ape-npi\n",
       "4                   trangvu/ape-npi\n",
       "                     ...           \n",
       "1797967    vuanhtu1993/Keras-SRGANs\n",
       "1797968    vuanhtu1993/Keras-SRGANs\n",
       "1797969    vuanhtu1993/Keras-SRGANs\n",
       "1797970    vuanhtu1993/Keras-SRGANs\n",
       "1797971    vuanhtu1993/Keras-SRGANs\n",
       "Name: repo_name, Length: 1797972, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26999,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python_files_df['repo'] = python_files_df['repo_name'].str.split(\"/\").apply(itemgetter(1))  + '/' + python_files_df['repo_name']\n",
    "repo_names_tmp = python_files_df['repo_name']\n",
    "repo_names = repo_names_tmp.unique()\n",
    "python_files_df['repo_name'] = python_files_df['repo']\n",
    "python_files_df['repo'] = repo_names_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 0 ns, total: 13.2 ms\n",
      "Wall time: 85.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import2vec = gensim.models.KeyedVectors.load(word_vectors_filename)\n",
    "import2vec_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(import2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"3d reconstruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from github_search.paperswithcode_tasks import clean_task_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' reconstruction'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\d+d\", \"\", task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = pd.read_csv('output/papers_with_imports.csv')\n",
    "paperswithcode_with_imports_df['tasks'] = paperswithcode_with_imports_df['tasks'].apply(clean_task_name).apply(ast.literal_eval)\n",
    "paperswithcode_with_imports_df['imports'] = paperswithcode_with_imports_df['imports'].str.replace(\"set\\(\\)\", \"{}\").apply(ast.literal_eval)#str.replace(\"2d \", \"\").str.replace(\"3d \", \"\").str.replace(\"4d \", \"\").str.replace(\"6d \", \"\").str.lower().apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 26)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1                                       phnk/D7047E\n",
       "2                        Aiyoj/Thumbnail-Generation\n",
       "3                                   tzt101/MichiGAN\n",
       "4                               fairlearn/fairlearn\n",
       "5                                 hrlblab/CircleNet\n",
       "                            ...                    \n",
       "17380                       allenai/break-evaluator\n",
       "17381                        YeongHyeon/f-AnoGAN-TF\n",
       "17382                               LeeDoYup/AnoGAN\n",
       "17383                            tkwoo/anogan-keras\n",
       "17387    Kano-Wu/Domain-Adversarial-Neural-Networks\n",
       "Name: repo, Length: 14427, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports'] = paperswithcode_with_imports_df['imports'].apply(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports_with_embeddings'] = paperswithcode_with_imports_df['imports'].apply(lambda imps: len([imp in import2vec.vocab.keys() for imp in imps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.9 s, sys: 215 ms, total: 33.1 s\n",
      "Wall time: 33.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_embeddings = mlutil.feature_extraction.embeddings.load_gensim_embedding_model('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "fasttext_model = fasttext.load_model(\"output/python_files_fasttext_dim200.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "        \n",
    "class LossCallback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            dictionary learning\n",
       "1             sentiment analysis\n",
       "2                region proposal\n",
       "3               image generation\n",
       "4                       fairness\n",
       "                  ...           \n",
       "17383          anomaly detection\n",
       "17384             style transfer\n",
       "17385             style transfer\n",
       "17386             style transfer\n",
       "17387    representation learning\n",
       "Name: most_common_task, Length: 17388, dtype: object"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task'][:None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:40:50: loading wv recursively from output/abstract_readme_w2v200.bin.wv.* with mmap=None\n",
      "INFO - 20:40:50: loading vectors from output/abstract_readme_w2v200.bin.wv.vectors.npy with mmap=None\n",
      "INFO - 20:40:50: setting ignored attribute vectors_norm to None\n",
      "INFO - 20:40:50: loading vocabulary recursively from output/abstract_readme_w2v200.bin.vocabulary.* with mmap=None\n",
      "INFO - 20:40:50: loading trainables recursively from output/abstract_readme_w2v200.bin.trainables.* with mmap=None\n",
      "INFO - 20:40:50: loading syn1neg from output/abstract_readme_w2v200.bin.trainables.syn1neg.npy with mmap=None\n",
      "INFO - 20:40:50: setting ignored attribute cum_table to None\n",
      "INFO - 20:40:50: loaded output/abstract_readme_w2v200.bin\n"
     ]
    }
   ],
   "source": [
    "python_word_embeddings = gensim.models.Word2Vec.load('output/abstract_readme_w2v200.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "@attr.s\n",
    "class RepoTaskData:\n",
    "    \n",
    "    tasks = attr.ib()\n",
    "    repos = attr.ib()\n",
    "    X = attr.ib()\n",
    "    all_tasks = attr.ib()\n",
    "    y = attr.ib()\n",
    "    \n",
    "    def split_tasks(area_grouped_tasks, test_size=0.2):\n",
    "        tasks_train, tasks_test = model_selection.train_test_split(area_grouped_tasks['task'], stratify=area_grouped_tasks['area'], test_size=test_size, random_state=0)\n",
    "        return tasks_train, tasks_test\n",
    "    \n",
    "    def create_split(tasks_train, all_tasks, paperswithcode_with_features_df, X_repr):\n",
    "        train_indicator = paperswithcode_with_features_df['most_common_task'].isin(tasks_train)\n",
    "        repos_train = paperswithcode_with_features_df['repo'][train_indicator]\n",
    "        repos_test = paperswithcode_with_features_df['repo'][~train_indicator]\n",
    "        X_repr = X_repr.apply(lambda x: \" \".join(x))\n",
    "        X_train = X_repr[train_indicator]\n",
    "        X_test = X_repr[~train_indicator]\n",
    "        all_tasks_train = all_tasks[train_indicator]\n",
    "        all_tasks_test = all_tasks[~train_indicator]\n",
    "        y_train = paperswithcode_with_features_df[train_indicator]['most_common_task'].str.lower().apply(clean_task_name)\n",
    "        y_test = paperswithcode_with_features_df[~train_indicator]['most_common_task'].str.lower().apply(clean_task_name)\n",
    "        \n",
    "        return (\n",
    "            RepoTaskData(tasks_train, repos_train, X_train, all_tasks_train, y_train),\n",
    "            RepoTaskData(tasks_test, repos_test, X_test, all_tasks_test, y_test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_first_vocab_entry(vocab):\n",
    "    return list(itertools.islice(vocab.items(), 1))[0][0] \n",
    "\n",
    "\n",
    "class PairedKeyedVectors:\n",
    "    \n",
    "    @attr.s\n",
    "    class wv:\n",
    "        vocab = attr.ib()\n",
    "    \n",
    "    def __init__(self, kv1, kv2):\n",
    "        self.kv1 = kv1\n",
    "        self.kv2 = kv2\n",
    "        self.vocab = {**kv1.vocab, **kv2.vocab} \n",
    "        self.dim1 = len(kv1[get_first_vocab_entry(kv1.vocab)])\n",
    "        self.dim2 = len(kv2[get_first_vocab_entry(kv2.vocab)])\n",
    "        self.wv= PairedKeyedVectors.wv(self.vocab)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not item in self.kv1.vocab.keys():\n",
    "            return np.concatenate([np.zeros(self.dim1), self.kv2[item]])\n",
    "        elif not item in self.kv2.vocab.keys():\n",
    "            return np.concatenate([self.kv1[item], np.zeros(self.dim2)])\n",
    "        else:\n",
    "            return np.concatenate([self.kv1[item], self.kv2[item]])\n",
    "    \n",
    "\n",
    "\n",
    "@attr.s\n",
    "class RetrieverLearner:\n",
    "    \n",
    "    zs_learner: zero_shot.ZeroShotClassifier = attr.ib()\n",
    "    input_embedder: embeddings.EmbeddingVectorizer = attr.ib() \n",
    "    y_embedder: embeddings.EmbeddingVectorizer = attr.ib()\n",
    "    input_embedder_kwargs = attr.ib(default=dict())\n",
    "        \n",
    "    @staticmethod\n",
    "    def create(\n",
    "        zs_learner: zero_shot.ZeroShotClassifier,\n",
    "        input_embeddings: gensim.models.KeyedVectors,\n",
    "        target_embeddings: gensim.models.KeyedVectors,\n",
    "        input_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        y_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        input_embedder_kwargs=dict()\n",
    "    ):\n",
    "        input_embedder = input_embedding_method(input_embeddings, **input_embedder_kwargs) \n",
    "        y_embedder = y_embedding_method(target_embeddings)\n",
    "        return RetrieverLearner(zs_learner, input_embedder, y_embedder)\n",
    "    \n",
    "    def get_target_embeddings(self, y):\n",
    "        unique_y = pd.Series(y.unique())\n",
    "        y_embeddings = self.y_embedder.transform(unique_y)\n",
    "        return unique_y, y_embeddings\n",
    "    \n",
    "    def fit_learner(self, data, **kwargs):\n",
    "        self.input_embedder.fit(data.X)\n",
    "        X_embeddings = self.input_embedder.transform(data.X)\n",
    "        self.y_embedder.fit(data.y)\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        self.zs_learner.fit(np.array(X_embeddings), np.array(input_y_idxs), np.array(y_embeddings), **kwargs)\n",
    "        \n",
    "    def predict_idxs(self, X, y_embeddings):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        return self.zs_learner.predict(X_embeddings, y_embeddings)\n",
    "    \n",
    "    def predict_topk(self, X, y_embeddings, target_names, k=5, similarity=metrics.pairwise.cosine_similarity):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        predictions = self.zs_learner.predict_raw(X_embeddings)\n",
    "        target_similarities = similarity(predictions, y_embeddings)\n",
    "        targets = [target_names[row[:k]] for row in (-target_similarities).argsort(axis=1)]\n",
    "        return targets\n",
    "        \n",
    "    def evaluate(self, data, metric):\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        predicted_idxs = self.predict_idxs(data.X, y_embeddings)\n",
    "        return metric(input_y_idxs, predicted_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_accuracy(learner, X, y, y_names, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    input_embeddings = learner.input_embedder.transform(X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    target_similarities = similarity(predictions, y_embeddings)\n",
    "    target_idxs = (-target_similarities).argsort(axis=1)\n",
    "    targets = [y_names.iloc[row[:k]] for row in target_idxs]\n",
    "\n",
    "    accuracies = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        true_tasks = set(all_tasks_test.iloc[i])\n",
    "        accuracies[i] = len(true_tasks.intersection(set(targets[i].values))) / min(len(true_tasks), k)\n",
    "    return accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "graph = pickle.load(open('output/call_igraph.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.get_vertex_dataframe().iloc[graph.neighborhood(vertices=[\"<ROOT>\"])[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get repos that are in graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes = graph.get_vertex_dataframe()['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 897 ms, sys: 63.9 ms, total: 961 ms\n",
      "Wall time: 966 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paperswithcode_with_features_df = paperswithcode_with_imports_df[\n",
    "    paperswithcode_with_imports_df['repo'].isin(graph.get_vertex_dataframe()['name']) |\n",
    "    paperswithcode_with_imports_df['repo'].apply(lambda s: s.split(\"/\")[1]).isin(graph.get_vertex_dataframe()['name'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(paperswithcode_with_features_df['repo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task'] = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = tasks.apply(clean_task_name)\n",
    "all_tasks = paperswithcode_with_features_df['tasks'].apply(lambda s: [clean_task_name(t) for t in s])\n",
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = all_tasks.explode().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          dictionary learning\n",
       "1                     named entity recognition\n",
       "1                           sentiment analysis\n",
       "2                              region proposal\n",
       "2        user constrained thumbnail generation\n",
       "                         ...                  \n",
       "17209     image compression artifact reduction\n",
       "17233      multi modal document classification\n",
       "17280                      geometry perception\n",
       "17311                       split and rephrase\n",
       "17322      one shot image to image translation\n",
       "Name: tasks, Length: 1311, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_area_grouped_tasks(paperswithcode_tasks_path='data/paperswithcode_tasks.csv'):\n",
    "    area_grouped_tasks = pd.read_csv('data/paperswithcode_tasks.csv').dropna()\n",
    "    area_grouped_tasks['task'] = area_grouped_tasks['task'].apply(clean_task_name)\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['task'].isin(tasks)]\n",
    "    area_counts = area_grouped_tasks['area'].value_counts()\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['area'].isin(area_counts.index[area_counts > 1])]\n",
    "    return area_grouped_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:40:57: Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO - 20:40:57: NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "computer-vision                316\n",
       "miscellaneous                  296\n",
       "natural-language-processing    223\n",
       "methodology                    108\n",
       "medical                         72\n",
       "speech                          36\n",
       "time-series                     34\n",
       "graphs                          33\n",
       "playing-games                   23\n",
       "robots                          20\n",
       "computer-code                   15\n",
       "knowledge-base                  15\n",
       "music                           12\n",
       "audio                           12\n",
       "reasoning                       10\n",
       "adversarial                      6\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_area_grouped_tasks()['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_grouped_tasks = get_area_grouped_tasks()\n",
    "area_grouped_tasks['task'] = area_grouped_tasks['task'].apply(clean_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_train, tasks_test = RepoTaskData.split_tasks(area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "984"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_test.str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            dictionary learning\n",
       "1             sentiment analysis\n",
       "2                region proposal\n",
       "3               image generation\n",
       "4                       fairness\n",
       "                  ...           \n",
       "17383          anomaly detection\n",
       "17384             style transfer\n",
       "17385             style transfer\n",
       "17386             style transfer\n",
       "17387    representation learning\n",
       "Name: most_common_task, Length: 17388, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4139"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task'].isin(tasks_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readme_summaries(upstream, product, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, paperswithcode_with_features_df['repo']))\n",
    "    readmes = pd.Series(raw_readmes).apply(github_readmes.try_decode)\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readmes(df, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, df['repo']))\n",
    "    readmes = list(map(github_readmes.try_decode, raw_readmes))\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'paper_url', 'arxiv_id', 'title', 'abstract', 'url_abs',\n",
       "       'url_pdf', 'proceeding', 'authors', 'tasks', 'date', 'methods',\n",
       "       'framework', 'mentioned_in_github', 'mentioned_in_paper',\n",
       "       'paper_arxiv_id', 'paper_title', 'paper_url_abs', 'paper_url_pdf',\n",
       "       'repo', 'repo_url', 'most_common_task', 'imports', 'n_imports',\n",
       "       'n_imports_with_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17388, 25)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "readmes = get_readmes(paperswithcode_with_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_keywords(text):\n",
    "    return python_call_graph.try_run(gensim.summarization.keywords)(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "readme_keywords = pd.Series(pool.map(try_keywords, readmes)).str.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df = pd.read_csv('output/processed_dependency_records.csv').dropna()#.iloc[:1000000]\n",
    "non_root_dependency_records_df = dependency_records_df[\n",
    "    (dependency_records_df['source'] != \"<ROOT>\") &\n",
    "    (dependency_records_df['edge_type'] != 'repo-repo')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_outgoing_edges(graph, node):\n",
    "    #idx = pd.Index(graph.names).get_loc(node)\n",
    "    #outgoing_edges_idx = np.where(graph.mat[idx].todense())[1]\n",
    "    return graph.get_vertex_dataframe().iloc[graph.successors(node)]['name']\n",
    "    #return graph.names[outgoing_edges_idx]\n",
    "\n",
    "\n",
    "def get_repo_functions(graph, repo):\n",
    "    return ' '.join(get_outgoing_edges(graph, repo).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_records = pd.read_csv('output/dependency_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def prepare_task_train_test_split(upstream, area_grouped_tasks_path, product):\n",
    "    area_grouped_tasks = get_area_grouped_tasks(area_grouped_tasks_path)\n",
    "    tasks_train, tasks_test = RepoTaskData.split_tasks(area_grouped_tasks)\n",
    "    tasks_train.to_csv(product['train'], index=None)\n",
    "    tasks_test.to_csv(product['test'], index=None)\n",
    "\n",
    "\n",
    "def prepare_graph_repo_task_data(upstream, product):\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "    graph_data_train.X = graph_data_train.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    graph_data_test.X = graph_data_test.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    pickle.dump((graph_data_train, graph_data_test), open(str(product), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.82 ms, sys: 16.3 ms, total: 21.1 ms\n",
      "Wall time: 95.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(\"output/tmp_graph_data.pkl\"):\n",
    "    (graph_data_train, graph_data_test) = pickle.load(open(\"output/tmp_graph_data.pkl\", \"rb\"))\n",
    "else:\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "    graph_data_train.X = graph_data_train.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    graph_data_test.X = graph_data_test.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    pickle.dump((graph_data_train, graph_data_test), open(\"output/tmp_graph_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertex ID\n",
       "627616                                  plot\n",
       "635979    canbakiskan/neuro-inspired-defense\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outgoing_edges(graph, get_outgoing_edges(graph, graph_data_train.repos.iloc[0]).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14350"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_data_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graph_data_train.X)):\n",
    "    graph_data_train.X.iloc[i] = graph_data_train.X.iloc[i].replace(graph_data_train.repos.iloc[i], \"\")\n",
    "for i in range(len(graph_data_test.X)):\n",
    "    graph_data_test.X.iloc[i] = graph_data_test.X.iloc[i].replace(graph_data_test.repos.iloc[i], \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.X = graph_data_train.X.str.replace(\":\", \" \")\n",
    "graph_data_train.X = graph_data_train.X.str.replace(\"<ROOT>\", \" \")\n",
    "graph_data_test.X = graph_data_test.X.str.replace(\":\", \" \")\n",
    "graph_data_test.X = graph_data_test.X.str.replace(\"<ROOT>\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computer-vision                316\n",
       "miscellaneous                  296\n",
       "natural-language-processing    223\n",
       "methodology                    108\n",
       "medical                         72\n",
       "speech                          36\n",
       "time-series                     34\n",
       "graphs                          33\n",
       "playing-games                   23\n",
       "robots                          20\n",
       "computer-code                   15\n",
       "knowledge-base                  15\n",
       "music                           12\n",
       "audio                           12\n",
       "reasoning                       10\n",
       "adversarial                      6\n",
       "Name: area, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_grouped_tasks['area'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maybe_get_ndarray_elem(arr, idx, default=-1):\n",
    "    if len(arr) <= idx:\n",
    "        return default\n",
    "    else:\n",
    "        return arr[idx]\n",
    "    \n",
    "    \n",
    "def get_retrieval_results(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "\n",
    "    X_recalled = [\n",
    "        np.argsort(-input_target_similarities[:,y_idx])[:k]\n",
    "        for (y_idx, __) in enumerate(y_names)\n",
    "    ]\n",
    "    return X_recalled\n",
    "\n",
    "\n",
    "def get_retrieval_accuracies(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    retrieved_X = get_retrieval_results(learner, data, k=k, similarity=similarity)\n",
    "    retrieved_X_actual_labels = [data.all_tasks.iloc[idxs_recalled].explode().values for idxs_recalled in retrieved_X]\n",
    "    retrieved_idxs = [\n",
    "        np.where(retrieved_X_actual_labels[y_idx] == y_name)[0]\n",
    "        for (y_idx, y_name) in enumerate(y_names)\n",
    "    ]\n",
    "    num_recalled = [len(r) for r in retrieved_idxs]\n",
    "    pos_recalled = [maybe_get_ndarray_elem(r, 0) for r in retrieved_idxs] \n",
    "    accurately_recalled = [r > -1 for r in pos_recalled]\n",
    "    return pd.DataFrame({\"retrieved_labels\": retrieved_X_actual_labels, \"num_recalled\": num_recalled, \"recalled\": accurately_recalled, \"position\": pos_recalled}, index=y_names)\n",
    "\n",
    "\n",
    "def get_retrieval_accuracy(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    return np.mean(get_retrieval_accuracies(learner, data, k, similarity)['recalled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pd.Series([1,2,3]).values == 2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def run_learner_experiment(\n",
    "    retriever_learner,\n",
    "    data_train, data_test\n",
    "):\n",
    "    retriever_learner.fit_learner(data_train)\n",
    "    \n",
    "    accuracy_train = retriever_learner.evaluate(data_train, metrics.accuracy_score)\n",
    "    accuracy_test = retriever_learner.evaluate(data_test, metrics.accuracy_score)\n",
    "    top10_accuracy_train = get_retrieval_accuracy(retriever_learner, data_train, k=10)\n",
    "    top10_accuracy_test = get_retrieval_accuracy(retriever_learner, data_test, k=10)\n",
    "    \n",
    "    return dict(\n",
    "        accuracy_train=accuracy_train,\n",
    "        accuracy_test=accuracy_test,\n",
    "        top10_accuracy_train=top10_accuracy_train,\n",
    "        top10_accuracy_test=top10_accuracy_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Deep Neural Networks (DNNs) are vulnerable to ...\n",
       "1        Word2Vec is a prominent model for natural lang...\n",
       "2        Thumbnails are widely used all over the world ...\n",
       "3        Despite the recent success of face image gener...\n",
       "4        We present a systematic approach for achieving...\n",
       "                               ...                        \n",
       "17383    Obtaining models that capture imaging markers ...\n",
       "17384    Gatys et al. recently introduced a neural algo...\n",
       "17385    Gatys et al. recently introduced a neural algo...\n",
       "17386    Gatys et al. recently introduced a neural algo...\n",
       "17387    We introduce a new representation learning alg...\n",
       "Name: abstract, Length: 17388, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_abstract = ~paperswithcode_with_imports_df['abstract'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url_abs</th>\n",
       "      <th>url_pdf</th>\n",
       "      <th>proceeding</th>\n",
       "      <th>authors</th>\n",
       "      <th>tasks</th>\n",
       "      <th>...</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>most_common_task</th>\n",
       "      <th>imports</th>\n",
       "      <th>n_imports</th>\n",
       "      <th>n_imports_with_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://paperswithcode.com/paper/a-neuro-inspi...</td>\n",
       "      <td>2011.10867</td>\n",
       "      <td>A Neuro-Inspired Autoencoding Defense Against ...</td>\n",
       "      <td>Deep Neural Networks (DNNs) are vulnerable to ...</td>\n",
       "      <td>https://arxiv.org/abs/2011.10867v2</td>\n",
       "      <td>https://arxiv.org/pdf/2011.10867v2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Can Bakiskan', 'Metehan Cekic', 'Ahmet Dunda...</td>\n",
       "      <td>[dictionary learning]</td>\n",
       "      <td>...</td>\n",
       "      <td>2011.10867</td>\n",
       "      <td>A Neuro-Inspired Autoencoding Defense Against ...</td>\n",
       "      <td>https://arxiv.org/abs/2011.10867v2</td>\n",
       "      <td>https://arxiv.org/pdf/2011.10867v2.pdf</td>\n",
       "      <td>canbakiskan/neuro-inspired-defense</td>\n",
       "      <td>https://github.com/canbakiskan/neuro-inspired-...</td>\n",
       "      <td>dictionary learning</td>\n",
       "      <td>{sklearn, namers, sys, torchvision, train_test...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>https://paperswithcode.com/paper/word2vec-opti...</td>\n",
       "      <td>2003.11645</td>\n",
       "      <td>Word2Vec: Optimal Hyper-Parameters and Their I...</td>\n",
       "      <td>Word2Vec is a prominent model for natural lang...</td>\n",
       "      <td>https://arxiv.org/abs/2003.11645v2</td>\n",
       "      <td>https://arxiv.org/pdf/2003.11645v2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Tosin P. Adewumi', 'Foteini Liwicki', 'Marcu...</td>\n",
       "      <td>[named entity recognition, sentiment analysis]</td>\n",
       "      <td>...</td>\n",
       "      <td>2003.11645</td>\n",
       "      <td>Word2Vec: Optimal Hyper-Parameters and Their I...</td>\n",
       "      <td>https://arxiv.org/abs/2003.11645v2</td>\n",
       "      <td>https://arxiv.org/pdf/2003.11645v2.pdf</td>\n",
       "      <td>phnk/D7047E</td>\n",
       "      <td>https://github.com/phnk/D7047E</td>\n",
       "      <td>sentiment analysis</td>\n",
       "      <td>{sklearn, copy, sigopt, tempfile, urllib, sys,...</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://paperswithcode.com/paper/user-constrai...</td>\n",
       "      <td>1810.13054</td>\n",
       "      <td>User Constrained Thumbnail Generation using Ad...</td>\n",
       "      <td>Thumbnails are widely used all over the world ...</td>\n",
       "      <td>http://arxiv.org/abs/1810.13054v3</td>\n",
       "      <td>http://arxiv.org/pdf/1810.13054v3.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Perla Sai Raj Kishore', 'Ayan Kumar Bhunia',...</td>\n",
       "      <td>[region proposal, user constrained thumbnail g...</td>\n",
       "      <td>...</td>\n",
       "      <td>1810.13054</td>\n",
       "      <td>User Constrained Thumbnail Generation using Ad...</td>\n",
       "      <td>http://arxiv.org/abs/1810.13054v3</td>\n",
       "      <td>http://arxiv.org/pdf/1810.13054v3.pdf</td>\n",
       "      <td>Aiyoj/Thumbnail-Generation</td>\n",
       "      <td>https://github.com/Aiyoj/Thumbnail-Generation</td>\n",
       "      <td>region proposal</td>\n",
       "      <td>{tensorflow, custom_vgg19, pandas, numpy, re, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>https://paperswithcode.com/paper/michigan-mult...</td>\n",
       "      <td>2010.16417</td>\n",
       "      <td>MichiGAN: Multi-Input-Conditioned Hair Image G...</td>\n",
       "      <td>Despite the recent success of face image gener...</td>\n",
       "      <td>https://arxiv.org/abs/2010.16417v1</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16417v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Zhentao Tan', 'Menglei Chai', 'Dongdong Chen...</td>\n",
       "      <td>[conditional image generation, image generation]</td>\n",
       "      <td>...</td>\n",
       "      <td>2010.16417</td>\n",
       "      <td>MichiGAN: Multi-Input-Conditioned Hair Image G...</td>\n",
       "      <td>https://arxiv.org/abs/2010.16417v1</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16417v1.pdf</td>\n",
       "      <td>tzt101/MichiGAN</td>\n",
       "      <td>https://github.com/tzt101/MichiGAN</td>\n",
       "      <td>image generation</td>\n",
       "      <td>{sys, PyQt5, threading, trainers, importlib, t...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>https://paperswithcode.com/paper/a-reductions-...</td>\n",
       "      <td>1803.02453</td>\n",
       "      <td>A Reductions Approach to Fair Classification</td>\n",
       "      <td>We present a systematic approach for achieving...</td>\n",
       "      <td>http://arxiv.org/abs/1803.02453v3</td>\n",
       "      <td>http://arxiv.org/pdf/1803.02453v3.pdf</td>\n",
       "      <td>ICML 2018 7</td>\n",
       "      <td>['Alekh Agarwal', 'Alina Beygelzimer', 'Mirosl...</td>\n",
       "      <td>[fairness]</td>\n",
       "      <td>...</td>\n",
       "      <td>1803.02453</td>\n",
       "      <td>A Reductions Approach to Fair Classification</td>\n",
       "      <td>http://arxiv.org/abs/1803.02453v3</td>\n",
       "      <td>http://arxiv.org/pdf/1803.02453v3.pdf</td>\n",
       "      <td>fairlearn/fairlearn</td>\n",
       "      <td>https://github.com/fairlearn/fairlearn</td>\n",
       "      <td>fairness</td>\n",
       "      <td>{copy, _mean_predictions, subprocess, time, co...</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17383</th>\n",
       "      <td>30798</td>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>Obtaining models that capture imaging markers ...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thomas Schlegl', 'Philipp Seebck', 'Sebasti...</td>\n",
       "      <td>[anomaly detection, unsupervised anomaly detec...</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>tkwoo/anogan-keras</td>\n",
       "      <td>https://github.com/tkwoo/anogan-keras</td>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>{tensorflow, matplotlib, sklearn, numpy, cv2, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>30799</td>\n",
       "      <td>https://paperswithcode.com/paper/arbitrary-sty...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>Gatys et al. recently introduced a neural algo...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ICCV 2017 10</td>\n",
       "      <td>['Xun Huang', 'Serge Belongie']</td>\n",
       "      <td>[style transfer]</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ptran1203/style_transfer</td>\n",
       "      <td>https://github.com/ptran1203/style_transfer</td>\n",
       "      <td>style transfer</td>\n",
       "      <td>{tensorflow, matplotlib, sklearn, collections,...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17385</th>\n",
       "      <td>30800</td>\n",
       "      <td>https://paperswithcode.com/paper/arbitrary-sty...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>Gatys et al. recently introduced a neural algo...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ICCV 2017 10</td>\n",
       "      <td>['Xun Huang', 'Serge Belongie']</td>\n",
       "      <td>[style transfer]</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>gs18113/AdaIN-TensorFlow2</td>\n",
       "      <td>https://github.com/gs18113/AdaIN-TensorFlow2</td>\n",
       "      <td>style transfer</td>\n",
       "      <td>{tensorflow, data, functions, os, model, glob,...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17386</th>\n",
       "      <td>30801</td>\n",
       "      <td>https://paperswithcode.com/paper/arbitrary-sty...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>Gatys et al. recently introduced a neural algo...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ICCV 2017 10</td>\n",
       "      <td>['Xun Huang', 'Serge Belongie']</td>\n",
       "      <td>[style transfer]</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>Jwrede/neural_style_transfer</td>\n",
       "      <td>https://github.com/Jwrede/neural_style_transfer</td>\n",
       "      <td>style transfer</td>\n",
       "      <td>{pandas, matplotlib, torch, numpy, cv2, test_f...</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17387</th>\n",
       "      <td>30803</td>\n",
       "      <td>https://paperswithcode.com/paper/domain-advers...</td>\n",
       "      <td>1412.4446</td>\n",
       "      <td>Domain-Adversarial Neural Networks</td>\n",
       "      <td>We introduce a new representation learning alg...</td>\n",
       "      <td>http://arxiv.org/abs/1412.4446v2</td>\n",
       "      <td>http://arxiv.org/pdf/1412.4446v2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hana Ajakan', 'Pascal Germain', 'Hugo Laroch...</td>\n",
       "      <td>[denoising, domain adaptation, representation ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1412.4446</td>\n",
       "      <td>Domain-Adversarial Neural Networks</td>\n",
       "      <td>http://arxiv.org/abs/1412.4446v2</td>\n",
       "      <td>http://arxiv.org/pdf/1412.4446v2.pdf</td>\n",
       "      <td>Kano-Wu/Domain-Adversarial-Neural-Networks</td>\n",
       "      <td>https://github.com/Kano-Wu/Domain-Adversarial-...</td>\n",
       "      <td>representation learning</td>\n",
       "      <td>{tensorflow, sklearn, DANN, numpy, sys, utils,...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17327 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          paper_url  \\\n",
       "0               0  https://paperswithcode.com/paper/a-neuro-inspi...   \n",
       "1               3  https://paperswithcode.com/paper/word2vec-opti...   \n",
       "2               4  https://paperswithcode.com/paper/user-constrai...   \n",
       "3               5  https://paperswithcode.com/paper/michigan-mult...   \n",
       "4               6  https://paperswithcode.com/paper/a-reductions-...   \n",
       "...           ...                                                ...   \n",
       "17383       30798  https://paperswithcode.com/paper/unsupervised-...   \n",
       "17384       30799  https://paperswithcode.com/paper/arbitrary-sty...   \n",
       "17385       30800  https://paperswithcode.com/paper/arbitrary-sty...   \n",
       "17386       30801  https://paperswithcode.com/paper/arbitrary-sty...   \n",
       "17387       30803  https://paperswithcode.com/paper/domain-advers...   \n",
       "\n",
       "         arxiv_id                                              title  \\\n",
       "0      2011.10867  A Neuro-Inspired Autoencoding Defense Against ...   \n",
       "1      2003.11645  Word2Vec: Optimal Hyper-Parameters and Their I...   \n",
       "2      1810.13054  User Constrained Thumbnail Generation using Ad...   \n",
       "3      2010.16417  MichiGAN: Multi-Input-Conditioned Hair Image G...   \n",
       "4      1803.02453       A Reductions Approach to Fair Classification   \n",
       "...           ...                                                ...   \n",
       "17383  1703.05921  Unsupervised Anomaly Detection with Generative...   \n",
       "17384  1703.06868  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17385  1703.06868  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17386  1703.06868  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17387   1412.4446                 Domain-Adversarial Neural Networks   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      Deep Neural Networks (DNNs) are vulnerable to ...   \n",
       "1      Word2Vec is a prominent model for natural lang...   \n",
       "2      Thumbnails are widely used all over the world ...   \n",
       "3      Despite the recent success of face image gener...   \n",
       "4      We present a systematic approach for achieving...   \n",
       "...                                                  ...   \n",
       "17383  Obtaining models that capture imaging markers ...   \n",
       "17384  Gatys et al. recently introduced a neural algo...   \n",
       "17385  Gatys et al. recently introduced a neural algo...   \n",
       "17386  Gatys et al. recently introduced a neural algo...   \n",
       "17387  We introduce a new representation learning alg...   \n",
       "\n",
       "                                  url_abs  \\\n",
       "0      https://arxiv.org/abs/2011.10867v2   \n",
       "1      https://arxiv.org/abs/2003.11645v2   \n",
       "2       http://arxiv.org/abs/1810.13054v3   \n",
       "3      https://arxiv.org/abs/2010.16417v1   \n",
       "4       http://arxiv.org/abs/1803.02453v3   \n",
       "...                                   ...   \n",
       "17383   http://arxiv.org/abs/1703.05921v1   \n",
       "17384   http://arxiv.org/abs/1703.06868v2   \n",
       "17385   http://arxiv.org/abs/1703.06868v2   \n",
       "17386   http://arxiv.org/abs/1703.06868v2   \n",
       "17387    http://arxiv.org/abs/1412.4446v2   \n",
       "\n",
       "                                      url_pdf    proceeding  \\\n",
       "0      https://arxiv.org/pdf/2011.10867v2.pdf           NaN   \n",
       "1      https://arxiv.org/pdf/2003.11645v2.pdf           NaN   \n",
       "2       http://arxiv.org/pdf/1810.13054v3.pdf           NaN   \n",
       "3      https://arxiv.org/pdf/2010.16417v1.pdf           NaN   \n",
       "4       http://arxiv.org/pdf/1803.02453v3.pdf   ICML 2018 7   \n",
       "...                                       ...           ...   \n",
       "17383   http://arxiv.org/pdf/1703.05921v1.pdf           NaN   \n",
       "17384   http://arxiv.org/pdf/1703.06868v2.pdf  ICCV 2017 10   \n",
       "17385   http://arxiv.org/pdf/1703.06868v2.pdf  ICCV 2017 10   \n",
       "17386   http://arxiv.org/pdf/1703.06868v2.pdf  ICCV 2017 10   \n",
       "17387    http://arxiv.org/pdf/1412.4446v2.pdf           NaN   \n",
       "\n",
       "                                                 authors  \\\n",
       "0      ['Can Bakiskan', 'Metehan Cekic', 'Ahmet Dunda...   \n",
       "1      ['Tosin P. Adewumi', 'Foteini Liwicki', 'Marcu...   \n",
       "2      ['Perla Sai Raj Kishore', 'Ayan Kumar Bhunia',...   \n",
       "3      ['Zhentao Tan', 'Menglei Chai', 'Dongdong Chen...   \n",
       "4      ['Alekh Agarwal', 'Alina Beygelzimer', 'Mirosl...   \n",
       "...                                                  ...   \n",
       "17383  ['Thomas Schlegl', 'Philipp Seebck', 'Sebasti...   \n",
       "17384                    ['Xun Huang', 'Serge Belongie']   \n",
       "17385                    ['Xun Huang', 'Serge Belongie']   \n",
       "17386                    ['Xun Huang', 'Serge Belongie']   \n",
       "17387  ['Hana Ajakan', 'Pascal Germain', 'Hugo Laroch...   \n",
       "\n",
       "                                                   tasks  ... paper_arxiv_id  \\\n",
       "0                                  [dictionary learning]  ...     2011.10867   \n",
       "1         [named entity recognition, sentiment analysis]  ...     2003.11645   \n",
       "2      [region proposal, user constrained thumbnail g...  ...     1810.13054   \n",
       "3       [conditional image generation, image generation]  ...     2010.16417   \n",
       "4                                             [fairness]  ...     1803.02453   \n",
       "...                                                  ...  ...            ...   \n",
       "17383  [anomaly detection, unsupervised anomaly detec...  ...     1703.05921   \n",
       "17384                                   [style transfer]  ...     1703.06868   \n",
       "17385                                   [style transfer]  ...     1703.06868   \n",
       "17386                                   [style transfer]  ...     1703.06868   \n",
       "17387  [denoising, domain adaptation, representation ...  ...      1412.4446   \n",
       "\n",
       "                                             paper_title  \\\n",
       "0      A Neuro-Inspired Autoencoding Defense Against ...   \n",
       "1      Word2Vec: Optimal Hyper-Parameters and Their I...   \n",
       "2      User Constrained Thumbnail Generation using Ad...   \n",
       "3      MichiGAN: Multi-Input-Conditioned Hair Image G...   \n",
       "4           A Reductions Approach to Fair Classification   \n",
       "...                                                  ...   \n",
       "17383  Unsupervised Anomaly Detection with Generative...   \n",
       "17384  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17385  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17386  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "17387                 Domain-Adversarial Neural Networks   \n",
       "\n",
       "                            paper_url_abs  \\\n",
       "0      https://arxiv.org/abs/2011.10867v2   \n",
       "1      https://arxiv.org/abs/2003.11645v2   \n",
       "2       http://arxiv.org/abs/1810.13054v3   \n",
       "3      https://arxiv.org/abs/2010.16417v1   \n",
       "4       http://arxiv.org/abs/1803.02453v3   \n",
       "...                                   ...   \n",
       "17383   http://arxiv.org/abs/1703.05921v1   \n",
       "17384   http://arxiv.org/abs/1703.06868v2   \n",
       "17385   http://arxiv.org/abs/1703.06868v2   \n",
       "17386   http://arxiv.org/abs/1703.06868v2   \n",
       "17387    http://arxiv.org/abs/1412.4446v2   \n",
       "\n",
       "                                paper_url_pdf  \\\n",
       "0      https://arxiv.org/pdf/2011.10867v2.pdf   \n",
       "1      https://arxiv.org/pdf/2003.11645v2.pdf   \n",
       "2       http://arxiv.org/pdf/1810.13054v3.pdf   \n",
       "3      https://arxiv.org/pdf/2010.16417v1.pdf   \n",
       "4       http://arxiv.org/pdf/1803.02453v3.pdf   \n",
       "...                                       ...   \n",
       "17383   http://arxiv.org/pdf/1703.05921v1.pdf   \n",
       "17384   http://arxiv.org/pdf/1703.06868v2.pdf   \n",
       "17385   http://arxiv.org/pdf/1703.06868v2.pdf   \n",
       "17386   http://arxiv.org/pdf/1703.06868v2.pdf   \n",
       "17387    http://arxiv.org/pdf/1412.4446v2.pdf   \n",
       "\n",
       "                                             repo  \\\n",
       "0              canbakiskan/neuro-inspired-defense   \n",
       "1                                     phnk/D7047E   \n",
       "2                      Aiyoj/Thumbnail-Generation   \n",
       "3                                 tzt101/MichiGAN   \n",
       "4                             fairlearn/fairlearn   \n",
       "...                                           ...   \n",
       "17383                          tkwoo/anogan-keras   \n",
       "17384                    ptran1203/style_transfer   \n",
       "17385                   gs18113/AdaIN-TensorFlow2   \n",
       "17386                Jwrede/neural_style_transfer   \n",
       "17387  Kano-Wu/Domain-Adversarial-Neural-Networks   \n",
       "\n",
       "                                                repo_url  \\\n",
       "0      https://github.com/canbakiskan/neuro-inspired-...   \n",
       "1                         https://github.com/phnk/D7047E   \n",
       "2          https://github.com/Aiyoj/Thumbnail-Generation   \n",
       "3                     https://github.com/tzt101/MichiGAN   \n",
       "4                 https://github.com/fairlearn/fairlearn   \n",
       "...                                                  ...   \n",
       "17383              https://github.com/tkwoo/anogan-keras   \n",
       "17384        https://github.com/ptran1203/style_transfer   \n",
       "17385       https://github.com/gs18113/AdaIN-TensorFlow2   \n",
       "17386    https://github.com/Jwrede/neural_style_transfer   \n",
       "17387  https://github.com/Kano-Wu/Domain-Adversarial-...   \n",
       "\n",
       "              most_common_task  \\\n",
       "0          dictionary learning   \n",
       "1           sentiment analysis   \n",
       "2              region proposal   \n",
       "3             image generation   \n",
       "4                     fairness   \n",
       "...                        ...   \n",
       "17383        anomaly detection   \n",
       "17384           style transfer   \n",
       "17385           style transfer   \n",
       "17386           style transfer   \n",
       "17387  representation learning   \n",
       "\n",
       "                                                 imports n_imports  \\\n",
       "0      {sklearn, namers, sys, torchvision, train_test...        30   \n",
       "1      {sklearn, copy, sigopt, tempfile, urllib, sys,...        76   \n",
       "2      {tensorflow, custom_vgg19, pandas, numpy, re, ...        15   \n",
       "3      {sys, PyQt5, threading, trainers, importlib, t...        40   \n",
       "4      {copy, _mean_predictions, subprocess, time, co...        82   \n",
       "...                                                  ...       ...   \n",
       "17383  {tensorflow, matplotlib, sklearn, numpy, cv2, ...        12   \n",
       "17384  {tensorflow, matplotlib, sklearn, collections,...        12   \n",
       "17385  {tensorflow, data, functions, os, model, glob,...        10   \n",
       "17386  {pandas, matplotlib, torch, numpy, cv2, test_f...        14   \n",
       "17387  {tensorflow, sklearn, DANN, numpy, sys, utils,...         9   \n",
       "\n",
       "      n_imports_with_embeddings  \n",
       "0                            30  \n",
       "1                            76  \n",
       "2                            15  \n",
       "3                            40  \n",
       "4                            82  \n",
       "...                         ...  \n",
       "17383                        12  \n",
       "17384                        12  \n",
       "17385                        10  \n",
       "17386                        14  \n",
       "17387                         9  \n",
       "\n",
       "[17327 rows x 25 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_train[has_abstract]\n",
    "paperswithcode_with_features_df[has_abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_data_train, abstract_data_test = RepoTaskData.create_split(tasks_train[has_abstract], all_tasks[has_abstract], paperswithcode_with_features_df[has_abstract], paperswithcode_with_features_df[has_abstract]['abstract'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarce_learn.zero_shot import devise_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "abstract_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.5326790561703905,\n",
       " 'accuracy_test': 0.13952702702702702,\n",
       " 'top10_accuracy_train': 0.8793103448275862,\n",
       " 'top10_accuracy_test': 0.7355371900826446}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(abstract_learner, abstract_data_train, abstract_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract model using fasttext trained on Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "abstract_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4578548061529895,\n",
       " 'accuracy_test': 0.07128378378378378,\n",
       " 'top10_accuracy_train': 0.6344827586206897,\n",
       " 'top10_accuracy_test': 0.4297520661157025}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(abstract_fasttext_learner, abstract_data_train, abstract_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec model on READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_readmes_df = pd.read_csv(\"output/papers_with_readmes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['readme'] = paperswithcode_with_readmes_df['readme'] \n",
    "paperswithcode_with_features_df['readme'] = paperswithcode_with_readmes_df['readme'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_readme = ~paperswithcode_with_imports_df['readme'].isna()\n",
    "\n",
    "readme_data_train, readme_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], paperswithcode_with_features_df[has_readme]['readme'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['tasks'].apply(\" \".join).str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_train[has_readme].str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks[has_readme].apply(\" \".join).str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_test.y.str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_test.all_tasks.apply(\" \".join).str.contains(\"-\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'paper_url', 'arxiv_id', 'title', 'abstract', 'url_abs',\n",
       "       'url_pdf', 'proceeding', 'authors', 'tasks', 'date', 'methods',\n",
       "       'framework', 'mentioned_in_github', 'mentioned_in_paper',\n",
       "       'paper_arxiv_id', 'paper_title', 'paper_url_abs', 'paper_url_pdf',\n",
       "       'repo', 'repo_url', 'most_common_task', 'imports', 'n_imports',\n",
       "       'n_imports_with_embeddings', 'readme'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 100),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "readme_learner.fit_learner(readme_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.3888042650418888,\n",
       " 'accuracy_test': 0.059114735002912054,\n",
       " 'top10_accuracy_train': 0.8235294117647058,\n",
       " 'top10_accuracy_test': 0.6204379562043796}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(readme_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext on READMEs - worse than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.27722772277227725,\n",
       " 'accuracy_test': 0.028246942341292953,\n",
       " 'top10_accuracy_train': 0.5625,\n",
       " 'top10_accuracy_test': 0.39416058394160586}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(readme_fasttext_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme_keywords_data_train, readme_keywords_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], readme_keywords[has_readme].str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_keywords_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(10, 10),\n",
    "    word_embeddings,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(readme_keywords_learner, readme_keywords_data_train, readme_keywords_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_data_train, import_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_imports_df, paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.5151515151515151,\n",
       " 'accuracy_test': 0.0019014693171996544,\n",
       " 'top10_accuracy_train': 1.0,\n",
       " 'top10_accuracy_test': 0.0297029702970297}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "import2vec_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(lmbda=100.0, gamma=10.0),\n",
    "    import2vec,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(import2vec_learner, import_data_train, import_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRoNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:45:55: loading Word2VecKeyedVectors object from data/prone_embeddings.bin\n",
      "INFO - 20:45:58: loading vectors from data/prone_embeddings.bin.vectors.npy with mmap=None\n",
      "INFO - 20:45:59: setting ignored attribute vectors_norm to None\n",
      "INFO - 20:45:59: loaded data/prone_embeddings.bin\n"
     ]
    }
   ],
   "source": [
    "prone_embeddings = gensim.models.KeyedVectors.load(\"data/prone_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using repo embedding from node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.1716376306620209,\n",
       " 'accuracy_test': 0.012179065174456879,\n",
       " 'top10_accuracy_train': 0.4793103448275862,\n",
       " 'top10_accuracy_test': 0.1557377049180328}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prone_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    prone_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(prone_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregating vertex embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_kv_file =\"output/graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:46:05: loading Word2VecKeyedVectors object from output/graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin\n",
      "INFO - 20:46:08: loading vectors from output/graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin.vectors.npy with mmap=None\n",
      "INFO - 20:46:09: setting ignored attribute vectors_norm to None\n",
      "INFO - 20:46:09: loaded output/graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin\n"
     ]
    }
   ],
   "source": [
    "graphsage_embeddings = gensim.models.KeyedVectors.load(graphsage_kv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coincidence'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graphsage_embeddings.vocab)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_list = list(graphsage_embeddings.vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = graph_data_train.X[150].strip().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True, True, True, True, True, True, True, True, True]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[token in vocab_list for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.1616724738675958,\n",
       " 'accuracy_test': 0.01053324555628703,\n",
       " 'top10_accuracy_train': 0.5241379310344828,\n",
       " 'top10_accuracy_test': 0.12295081967213115}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "graphsage_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    graphsage_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(graphsage_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "prone_results = run_learner_experiment(prone_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_results = run_learner_experiment(abstract_learner, abstract_data_train, abstract_data_test)\n",
    "readme_results = run_learner_experiment(readme_learner, readme_data_train, readme_data_test)\n",
    "graphsage_results = run_learner_experiment(graphsage_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records([abstract_results, readme_results, prone_results, graphsage_results])\n",
    "results_df['method'] = ['abstract', 'readme', 'prone', 'graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>top10_accuracy_train</th>\n",
       "      <th>top10_accuracy_test</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.532679</td>\n",
       "      <td>0.139527</td>\n",
       "      <td>0.879310</td>\n",
       "      <td>0.735537</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.388804</td>\n",
       "      <td>0.059115</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.620438</td>\n",
       "      <td>readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.171638</td>\n",
       "      <td>0.009875</td>\n",
       "      <td>0.479310</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.165523</td>\n",
       "      <td>0.013509</td>\n",
       "      <td>0.441379</td>\n",
       "      <td>0.297521</td>\n",
       "      <td>graphsage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  accuracy_test  top10_accuracy_train  top10_accuracy_test  \\\n",
       "0        0.532679       0.139527              0.879310             0.735537   \n",
       "1        0.388804       0.059115              0.823529             0.620438   \n",
       "2        0.171638       0.009875              0.479310             0.100000   \n",
       "3        0.165523       0.013509              0.441379             0.297521   \n",
       "\n",
       "      method  \n",
       "0   abstract  \n",
       "1     readme  \n",
       "2      prone  \n",
       "3  graphsage  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using GraphSAGE model for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class LambdaTransformer:\n",
    "    \n",
    "    def __init__(self, transform_fn):\n",
    "        self.transform = transform_fn\n",
    "        \n",
    "    def fit(self, X, **kwargs):\n",
    "        return self\n",
    "    \n",
    "    \n",
    "class PyGGraphModelTransformer:\n",
    "    \n",
    "    def __init__(self, model, dependency_graph_wrapper):\n",
    "        self.model = model\n",
    "        self.dependency_graph_wrapper = dependency_graph_wrapper\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return self.dependency_graph_wrapper.get_vertex_embeddings(x, self.model)\n",
    "    \n",
    "    def fit(self, X, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.pytorch_geometric_data import PygGraphWrapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embedder = embeddings.FastTextVectorizer(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 43.9 s, sys: 3.86 s, total: 47.7 s\n",
      "Wall time: 43.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dependency_graph_wrapper = PygGraphWrapper(fasttext_embedder, non_root_dependency_records_df, \"source\", \"destination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 kuba kuba 166280 pa  7 19:44 output/graphsage_model.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 166283 pa  7 20:19 output/residual_graphsage_model.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 166282 pa 10 12:41 output/graphsage_model_no_root.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 809626 pa 10 21:24 output/graphsage_model_50_dim200_layers3.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 166283 pa 11 13:04 output/graphsage_model_100_dim100_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 246219 pa 11 14:24 output/graphsage_model_50_dim100_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 647053 pa 29 22:16 output/graphsage_model_60_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646987 pa 30 20:12 output/graphsage_model_2_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646988 pa 30 20:40 output/graphsage_model_40_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646987 pa 31 10:22 output/graphsage_model_100_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646986 pa 31 12:58 output/graphsage_model_200_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646987 lis  9 19:38 output/graphsage_model_11_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646988 lis  9 19:45 output/graphsage_model_1_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646988 lis  9 19:47 output/graphsage_model_21_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 646987 lis  9 19:54 output/graphsage_model_51_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 647051 gru 30 13:00 output/graphsage_model_10_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 647052 sty  2 12:51 output/graphsage_model_50_dim200_layers2.pth\r\n",
      "-rw-rw-r-- 1 kuba kuba 647052 sty  2 22:06 output/graphsage_model_20_dim200_layers2.pth\r\n"
     ]
    }
   ],
   "source": [
    "!ls -ltr output/*graphsage*pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_model = torch.load(\"output/graphsage_model_20_dim200_layers2.pth\").cpu()\n",
    "graphsage_model.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_data_train, graphsage_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df.repo.apply(lambda s: [s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_test.y = graph_data_test.y.apply(clean_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_test.y.str.contains(\"-\").mean()#= graph_data_test.y.apply(clean_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_test.all_tasks.apply(\" \".join).str.contains(\"-\").mean()#= graph_data_test.y.apply(clean_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def make_records_df(sources, connected_vertices):\n",
    "    return pd.DataFrame.from_records(\n",
    "        [\n",
    "            {\"source\": src, \"destination\": dst, \"edge_type\": \"repo-file\"}\n",
    "            for (src, destinations) in zip(sources, connected_vertices)\n",
    "            for dst in destinations \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records_df = make_records_df(graphsage_data_train.repos, graph_data_train.X.fillna(\"\").str.split()).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_vertex_embeddings(wrapper, vertex_subset, model):\n",
    "    features = (\n",
    "        model.full_forward(\n",
    "            wrapper.dataset.x, wrapper.dataset.edge_index\n",
    "        )\n",
    "        #.cpu()\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "    return features[wrapper.vertex_mapping.loc[vertex_subset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_records_df = make_records_df(graphsage_data_train.repos, graph_data_train.X.dropna().str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_graph_df = pd.concat([non_root_dependency_records_df, make_records_df(graphsage_data_train.repos, graph_data_train.X.dropna().str.split())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.9 s, sys: 3.98 s, total: 48.9 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extended_dependency_graph_wrapper = PygGraphWrapper(embeddings.FastTextVectorizer(fasttext_model), dep_graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extended_dependency_graph_wrapper.dataset.x.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pathlib\n",
    "\n",
    "\n",
    "\n",
    "def make_pyggraph_retriever_learner(zs_learner, dependency_graph_wrapper, model):\n",
    "    \n",
    "    lambda_transformer = PyGGraphModelTransformer(model, dependency_graph_wrapper)\n",
    "    return RetrieverLearner(\n",
    "        zs_learner,\n",
    "        lambda_transformer,\n",
    "        dependency_graph_wrapper.featurizer\n",
    "    )\n",
    "\n",
    "\n",
    "def save_pyggraph_retriever_learner(pyggraph_retriever_learner, directory):\n",
    "    p = pathlib.Path(directory)\n",
    "    p.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_learner = make_pyggraph_retriever_learner(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    dependency_graph_wrapper,\n",
    "    graphsage_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    }
   ],
   "source": [
    "graphsage_results = run_learner_experiment(graphsage_learner, graphsage_data_train, graphsage_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'zero shot learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dictionary learning', 'natural language inference',\n",
       "       'facial landmark detection', 'q learning', 'reconstruction',\n",
       "       'knowledge distillation', 'task oriented dialogue systems',\n",
       "       'outlier detection', 'meta learning', 'super resolution',\n",
       "       'image to image translation', 'neural architecture search',\n",
       "       'style transfer', 'text summarization',\n",
       "       'interpretable machine learning', 'natural language understanding',\n",
       "       'policy gradient methods', 'multi agent reinforcement learning',\n",
       "       'self supervised learning', 'self driving cars',\n",
       "       'sentence classification', 'reading comprehension',\n",
       "       'object detection', 'speaker verification', 'multi armed bandits',\n",
       "       'scene text', 'image inpainting', 'network embedding',\n",
       "       'demosaicking', 'person re identification',\n",
       "       'out of distribution detection', 'robust classification',\n",
       "       'link prediction', 'few shot learning', 'network pruning',\n",
       "       'multi task learning', 'edge computing', 'audio classification',\n",
       "       'session based recommendations', 'image dehazing',\n",
       "       'density estimation', 'activity recognition',\n",
       "       'hate speech detection', 'part segmentation', 'two sample testing',\n",
       "       'document classification', 'scene understanding',\n",
       "       'chinese word segmentation', 'graph classification',\n",
       "       'semantic parsing', 'multi class classification',\n",
       "       'incremental learning', 'covid 19 diagnosis', 'text to sql',\n",
       "       'human pose estimation', 'lesion segmentation',\n",
       "       'one shot learning', 'multi object tracking', 'edge detection',\n",
       "       'general reinforcement learning', 'text to speech synthesis',\n",
       "       'video prediction', 'speech enhancement',\n",
       "       'multi label classification', 'zero shot learning',\n",
       "       'learning to rank', 'part of speech tagging',\n",
       "       'mortality prediction', 'cross lingual transfer',\n",
       "       'fraud detection', 'human object interaction detection',\n",
       "       'openai gym', 'neural network compression', 'question generation',\n",
       "       'image stylization', 'point cloud classification',\n",
       "       'transliteration', 'unsupervised image to image translation',\n",
       "       'object reconstruction', 'multimodal sentiment analysis',\n",
       "       'data visualization', 'real time object detection',\n",
       "       'cross modal retrieval', 'click through rate prediction',\n",
       "       'unsupervised pre training', 'conversational response generation',\n",
       "       'graph construction', 'pose estimation',\n",
       "       'multi goal reinforcement learning', 'paraphrase identification',\n",
       "       'aspect based sentiment analysis', 'word sense disambiguation',\n",
       "       'omniglot', 'saliency detection', 'speaker identification',\n",
       "       'rectification', 'linguistic acceptability',\n",
       "       'relation classification', 'fine grained image classification',\n",
       "       'extractive text summarization',\n",
       "       'semi supervised image classification', 'text style transfer',\n",
       "       'video recognition', 'face reconstruction', 'multi human parsing',\n",
       "       'self supervised image classification',\n",
       "       'inductive logic programming', 'meta reinforcement learning',\n",
       "       'homography estimation', 'data to text generation',\n",
       "       'ad hoc information retrieval',\n",
       "       'retinal oct disease classification',\n",
       "       'chinese named entity recognition', 'shape reconstruction',\n",
       "       'video object segmentation', 'multi tissue nucleus segmentation',\n",
       "       'real time strategy games', 'time series classification',\n",
       "       'few shot image classification', 'image super resolution',\n",
       "       'conditional image generation'], dtype=object)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_test.y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dictionary learning', 'answer selection',\n",
       "       'natural language inference', 'paraphrase identification',\n",
       "       'facial landmark detection', 'combinatorial optimization',\n",
       "       'q learning', 'continuous control', 'autonomous driving',\n",
       "       'reconstruction', 'knowledge distillation', 'topic models',\n",
       "       'task oriented dialogue systems',\n",
       "       'abnormal event detection in video', 'outlier detection', 'automl',\n",
       "       'meta learning', 'deblurring', 'image super resolution',\n",
       "       'super resolution', 'image manipulation',\n",
       "       'image to image translation',\n",
       "       'multimodal unsupervised image to image translation',\n",
       "       'style transfer', 'unsupervised image to image translation',\n",
       "       'automated feature engineering', 'hyperparameter optimization',\n",
       "       'neural architecture search',\n",
       "       'hyperspectral image super resolution',\n",
       "       'extractive text summarization', 'text summarization',\n",
       "       'interpretable machine learning', 'l2 regularization',\n",
       "       'stochastic optimization', 'natural language understanding',\n",
       "       'chatbot', 'dialogue generation', 'policy gradient methods',\n",
       "       'multi agent reinforcement learning', 'starcraft ii',\n",
       "       'face generation', 'video generation', 'openai gym', 'starcraft',\n",
       "       'self supervised learning', 'speaker verification',\n",
       "       'voice conversion', 'self driving cars', 'visual localization',\n",
       "       'visual navigation', 'sentence classification',\n",
       "       'sentence embeddings', 'machine reading comprehension',\n",
       "       'reading comprehension', 'depth estimation', 'object detection',\n",
       "       'text dependent speaker verification', 'ssim',\n",
       "       'video super resolution', 'multi armed bandits', 'patch matching',\n",
       "       'optical character recognition', 'scene text',\n",
       "       'scene text recognition', 'image inpainting',\n",
       "       'multi class classification', 'network embedding',\n",
       "       'node clustering', 'demosaicking', 'image forensics',\n",
       "       'rectification', 'code search', 'person re identification',\n",
       "       'image morphing', 'video frame interpolation', 'human parsing',\n",
       "       'semantic parsing', 'multi frame super resolution',\n",
       "       'optical flow estimation', 'image quality assessment',\n",
       "       'no reference image quality assessment', 'medical diagnosis',\n",
       "       'out of distribution detection', 'board games',\n",
       "       'brain tumor segmentation', 'tumor segmentation',\n",
       "       'robust classification', 'auxiliary learning', 'few shot learning',\n",
       "       'knowledge base completion', 'link prediction', 'network pruning',\n",
       "       'inductive logic programming', 'relational reasoning',\n",
       "       'systematic generalization', 'multi task learning',\n",
       "       'program induction', 'fps games', 'general reinforcement learning',\n",
       "       'edge computing', 'denoising', 'image denoising',\n",
       "       'hierarchical structure', 'omniglot', 'document summarization',\n",
       "       'turning point identification', 'audio classification',\n",
       "       'audio tagging', 'environmental sound classification',\n",
       "       'emotion recognition', 'speech emotion recognition',\n",
       "       'session based recommendations', 'image dehazing',\n",
       "       'single image dehazing', 'scene text editing',\n",
       "       'density estimation', 'few shot imitation learning',\n",
       "       'imitation learning', 'metric learning', 'activity recognition',\n",
       "       'dota 2', 'imputation', 'hate speech detection',\n",
       "       'object classification', 'part segmentation',\n",
       "       'cube engraving classification', 'deep clustering',\n",
       "       'survival analysis', 'two sample testing', 'graph embedding',\n",
       "       'knowledge graph embedding', 'dialogue state tracking',\n",
       "       'document classification', 'medical code prediction',\n",
       "       'lane detection', 'video inpainting',\n",
       "       'simultaneous localization and mapping',\n",
       "       'abstractive text summarization', 'curriculum learning',\n",
       "       'trajectory forecasting', 'trajectory prediction',\n",
       "       'scene understanding', 'chinese word segmentation',\n",
       "       'continual learning', 'computed tomography (ct)',\n",
       "       'covid 19 diagnosis', 'graph classification', 'ucca parsing',\n",
       "       'structured prediction', 'graph sampling', 'node classification',\n",
       "       'abuse detection', 'abusive language', 'incremental learning',\n",
       "       'one shot learning', 'quantization', 'medical image generation',\n",
       "       'image reconstruction', 'semantic role labeling',\n",
       "       'speaker identification', 'speaker recognition',\n",
       "       'few shot regression', 'variational inference', 'video prediction',\n",
       "       'text to sql', 'human pose estimation', 'human reconstruction',\n",
       "       'shape generation', 'shape modeling', 'compressive sensing',\n",
       "       'fake news detection', 'automatic liver and tumor segmentation',\n",
       "       'lesion segmentation', 'multi object tracking',\n",
       "       'object detection from stereo images', 'edge detection',\n",
       "       'visual odometry', 'knowledge graph completion',\n",
       "       'knowledge graph embeddings', 'knowledge graphs',\n",
       "       'indoor localization', 'minecraft', 'multiple sequence alignment',\n",
       "       'safe exploration', 'text to speech synthesis',\n",
       "       'conditional image generation', 'model selection',\n",
       "       'object localization', 'weakly supervised object localization',\n",
       "       'speech enhancement', 'speech synthesis',\n",
       "       'query based extractive summarization',\n",
       "       'text independent speaker verification',\n",
       "       'hierarchical reinforcement learning', 'graph matching',\n",
       "       'meta reinforcement learning', 'feature engineering',\n",
       "       'multi label classification', 'person search', 'video retrieval',\n",
       "       'speaker diarization', 'zero shot learning', 'active learning',\n",
       "       'crowd counting', 'learning to rank', 'model compression',\n",
       "       'program synthesis', 'novel view synthesis', 'plane detection',\n",
       "       'smac', 'graph mining', 'music genre transfer',\n",
       "       'synthetic data generation', 'question generation',\n",
       "       'real to cartoon translation', 'game of doom',\n",
       "       'driver attention monitoring', 'misinformation',\n",
       "       'rumour detection', 'image retrieval', 'semantic similarity',\n",
       "       'semantic textual similarity', 'image enhancement',\n",
       "       'image restoration', 'pedestrian detection',\n",
       "       'part of speech tagging', 'unsupervised part of speech tagging',\n",
       "       'mortality prediction', 'readmission prediction',\n",
       "       'cross lingual transfer', 'scene reconstruction', 'colorization',\n",
       "       'eeg', 'video understanding', 'fine grained image classification',\n",
       "       'fine grained visual recognition', 'scene text detection',\n",
       "       'video based person re identification', 'hypergraph embedding',\n",
       "       'fraud detection', 'image compression', 'ms ssim',\n",
       "       'human object interaction detection', 'noise estimation',\n",
       "       'card games', 'game of poker', 'multi goal reinforcement learning',\n",
       "       'chinese reading comprehension', 'text style transfer',\n",
       "       'vision and language navigation', 'malware detection',\n",
       "       'traffic classification', 'lemmatization', 'tokenization',\n",
       "       'efficient exploration', 'shape reconstruction',\n",
       "       'shape reconstruction from a single  image',\n",
       "       'shape representation', 'handwriting recognition',\n",
       "       'license plate recognition', 'autonomous vehicles',\n",
       "       'federated learning', 'neural network compression',\n",
       "       'graph clustering', 'medical imaging segmentation',\n",
       "       'automatic machine learning model selection',\n",
       "       'breast cancer detection',\n",
       "       'breast mass segmentation in whole mammograms',\n",
       "       'breast tumour classification', 'mathematical proofs',\n",
       "       'medical image retrieval', 'probabilistic deep learning',\n",
       "       'fact verification', 'indoor scene understanding',\n",
       "       'point cloud super resolution', 'single view  reconstruction',\n",
       "       'bayesian optimisation', 'object reconstruction',\n",
       "       'image stylization', 'rain removal', 'intent classification',\n",
       "       'language identification', 'slot filling',\n",
       "       'point cloud classification', 'document embedding',\n",
       "       'sentence embedding', 'text matching', 'text based games',\n",
       "       'video captioning', 'morphological inflection', 'transliteration',\n",
       "       'normalising flows', 'mri reconstruction', 'dqn replay dataset',\n",
       "       'offline rl', 'face hallucination', 'cross lingual ner',\n",
       "       'dependency parsing', 'document ranking', 'point cloud generation',\n",
       "       'multimodal emotion recognition', 'multimodal sentiment analysis',\n",
       "       'data visualization', 'car racing', 'motion compensation',\n",
       "       'covid 19 image segmentation', 'object detection in aerial images',\n",
       "       'one shot object detection', 'real time object detection',\n",
       "       'music generation', 'text generation', 'feature selection',\n",
       "       'lesion classification', 'cross modal retrieval',\n",
       "       'domain generalization', 'relation extraction',\n",
       "       'quantum approximate optimization', 'quantum machine learning',\n",
       "       'graph representation learning', 'single image haze removal',\n",
       "       'seizure detection', 'data summarization',\n",
       "       'extreme multi label classification', 'multi label learning',\n",
       "       'texture synthesis', 'click through rate prediction',\n",
       "       'predict future video frames', 'image captioning',\n",
       "       'low light image enhancement', 'few shot image classification',\n",
       "       'bilevel optimization', 'speech recognition', 'graph generation',\n",
       "       'scene graph generation', 'adversarial attack',\n",
       "       'coreference resolution', 'unsupervised pre training',\n",
       "       'conversational response generation', 'graph construction',\n",
       "       'amr parsing', 'sentence compression',\n",
       "       'open information extraction', 'sketch based image retrieval',\n",
       "       'pose estimation', 'aspect based sentiment analysis',\n",
       "       'motion estimation', 'font style transfer',\n",
       "       'next basket recommendation', 'acute stroke lesion segmentation',\n",
       "       'ischemic stroke lesion segmentation',\n",
       "       'outcome prediction in multimodal mri', 'recommendation systems',\n",
       "       'structure from motion', 'object recognition',\n",
       "       'community detection', 'word sense disambiguation',\n",
       "       'lexical simplification', 'distractor generation',\n",
       "       'contour detection', 'saliency detection', 'gaussian processes',\n",
       "       'keyword extraction', 'sound event detection',\n",
       "       'feature importance', 'action recognition',\n",
       "       'medical image segmentation', 'temporal action localization',\n",
       "       'unsupervised person re identification', 'matrix completion',\n",
       "       'temporal knowledge graph completion', 'binarization',\n",
       "       'latent variable models', 'traffic prediction',\n",
       "       'facial expression translation', 'entity extraction using gan',\n",
       "       'information plane', 'mutual information estimation',\n",
       "       'shadow removal', 'speech denoising', 'caricature',\n",
       "       'dimensionality reduction', 'multi label zero shot learning',\n",
       "       'video style transfer', 'small data image classification',\n",
       "       'sentence summarization', 'information retrieval',\n",
       "       'music style transfer', 'multiobjective optimization',\n",
       "       'facial inpainting', 'graph learning', 'graph regression',\n",
       "       'language acquisition', 'linguistic acceptability',\n",
       "       'object reconstruction from a single image', 'lexical entailment',\n",
       "       'relation classification', 'adversarial text', 'face detection',\n",
       "       'face verification', 'fundus to angiography generation',\n",
       "       'topological data analysis', 'emotion classification',\n",
       "       'future prediction', 'chunking', 'text simplification',\n",
       "       'rf based pose estimation', 'facial expression recognition',\n",
       "       'lossy compression artifact reduction', 'object discovery',\n",
       "       'image text removal', 'multi label text classification',\n",
       "       'entity alignment', 'graph similarity', 'deep attention',\n",
       "       'video restoration', 'accuracy metrics', 'sentence rewriting',\n",
       "       'multiple affordance detection',\n",
       "       'semi supervised image classification',\n",
       "       'point cloud reconstruction', 'bayesian inference',\n",
       "       'adversarial defense', 'music source separation',\n",
       "       'common sense reasoning', 'visual dialog',\n",
       "       'self supervised image classification', 'fairness', 'epidemiology',\n",
       "       'electron microscopy', 'dialogue understanding',\n",
       "       'face age editing', 'word embeddings', 'data to text generation',\n",
       "       'text categorization', 'video recognition',\n",
       "       'transform a video into a comics', 'single image deraining',\n",
       "       'triple classification', 'point set upsampling',\n",
       "       'meeting summarization', 'explainable artificial intelligence',\n",
       "       'reasoning chain explanations', 'eye tracking',\n",
       "       'face reconstruction', 'talking head generation',\n",
       "       'fine grained image recognition',\n",
       "       'photometric redshift estimation', 'multi human parsing',\n",
       "       'human motion prediction', 'multi future trajectory prediction',\n",
       "       'gaze estimation', 'motion capture', 'legged robots',\n",
       "       'unsupervised domain adaptation', 'one shot segmentation',\n",
       "       'face recognition', 'grammatical error detection',\n",
       "       'saliency prediction', 'scanpath prediction',\n",
       "       'sequential skip prediction', 'open domain dialog',\n",
       "       'decision making', 'fine grained visual categorization',\n",
       "       'image to video person re identification',\n",
       "       'text attribute transfer', 'code generation',\n",
       "       'nuclear segmentation', 'homography estimation', 'rgb t tracking',\n",
       "       'dynamic link prediction', 'point processes', 'motion detection',\n",
       "       'vehicle re identification', 'brain decoding',\n",
       "       'multi view learning', 'anomaly detection',\n",
       "       'unsupervised anomaly detection', 'robot navigation',\n",
       "       'network congestion control', 'instance segmentation',\n",
       "       'human detection', 'open set learning',\n",
       "       'ad hoc information retrieval', 'irregular text recognition',\n",
       "       'acoustic scene classification',\n",
       "       'few shot relation classification',\n",
       "       'rgb d salient object detection', 'depth completion',\n",
       "       'monocular depth estimation',\n",
       "       'inductive knowledge graph completion', 'typeface completion',\n",
       "       'complex word identification',\n",
       "       'retinal oct disease classification',\n",
       "       'large scale person re identification', 'multiple people tracking',\n",
       "       'object tracking', 'online multi object tracking',\n",
       "       'visual relationship detection', 'boundary detection',\n",
       "       'chinese named entity recognition',\n",
       "       'cross lingual document classification', 'classification',\n",
       "       'action detection', 'activity detection',\n",
       "       'fine grained vehicle classification', 'entity linking',\n",
       "       'fine grained image inpainting', 'face alignment',\n",
       "       'image outpainting', 'relational pattern learning', '',\n",
       "       'entity embeddings', 'value prediction',\n",
       "       'semi supervised video object segmentation',\n",
       "       'video object segmentation', 'video segmentation',\n",
       "       'visual object tracking', 'stereo matching',\n",
       "       'stereo matching hand', 'activity prediction',\n",
       "       'motion forecasting', 'unsupervised facial landmark detection',\n",
       "       'keyword spotting', 'point cloud registration', 'intent detection',\n",
       "       'colorectal gland segmentation:',\n",
       "       'multi tissue nucleus segmentation', 'face sketch synthesis',\n",
       "       'discourse parsing', 'drs parsing', 'news classification',\n",
       "       'real time strategy games', 'bird view synthesis',\n",
       "       'cross view image to image translation', 'text spotting',\n",
       "       'argument mining', 'word alignment', 'variable selection',\n",
       "       'arrhythmia detection', 'ecg classification',\n",
       "       'time series classification', 'lung cancer diagnosis',\n",
       "       'unsupervised mnist', 'model extraction', 'hand pose estimation',\n",
       "       'multiple object tracking', 'real time multi object tracking',\n",
       "       'speaker separation', 'speech separation',\n",
       "       'video instance segmentation', 'intrinsic image decomposition',\n",
       "       'generalized few shot classification', 'point cloud matching',\n",
       "       'surface generation', 'one class classifier',\n",
       "       'object super resolution', 'end to end speech recognition',\n",
       "       'color image denoising', 'semantic composition',\n",
       "       'named entity recognition', 'temporal information extraction',\n",
       "       'cross modal  person re identification',\n",
       "       'traveling salesman problem', 'game of chess', 'game of go',\n",
       "       'game of shogi', 'video deinterlacing',\n",
       "       'knowledge base question answering', 'extended summarization',\n",
       "       'temporal logic', 'face model', 'person identification',\n",
       "       'distributional reinforcement learning',\n",
       "       'unsupervised text style transfer',\n",
       "       'generalizable person re identification', 'point cloud completion',\n",
       "       'fine grained opinion analysis', 'junction detection',\n",
       "       'line segment detection', 'object skeleton detection',\n",
       "       'knowledge base population', 'open knowledge base completion',\n",
       "       'cross domain few shot', 'scene classification',\n",
       "       'scene recognition', 'distributed optimization',\n",
       "       'disaster response', 'timex normalization', 'decipherment',\n",
       "       'person retrieval', 'complimentary image retrieval',\n",
       "       'intrusion detection', 'material recognition', 'rotated mnist',\n",
       "       'curved text detection', 'shadow detection',\n",
       "       'multimodal abstractive text summarization', 'video denoising',\n",
       "       'video enhancement', 'long tail learning',\n",
       "       'long tail learning with class descriptors',\n",
       "       'emotion cause extraction', 'emotion cause pair extraction',\n",
       "       'pose prediction', 'pose estimation using rgb',\n",
       "       'image compression artifact reduction', 'audio generation',\n",
       "       'audio super resolution', 'pneumonia detection',\n",
       "       'one shot image to image translation', 'face swapping'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_test.all_tasks.explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records([abstract_results, readme_results, prone_results, graphsage_results])\n",
    "results_df['method'] = ['abstract', 'readme', 'prone', 'graphsage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>top10_accuracy_train</th>\n",
       "      <th>top10_accuracy_test</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.736</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.620</td>\n",
       "      <td>readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.172</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.100</td>\n",
       "      <td>prone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.298</td>\n",
       "      <td>graphsage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  accuracy_test  top10_accuracy_train  top10_accuracy_test  \\\n",
       "0           0.533          0.140                 0.879                0.736   \n",
       "1           0.389          0.059                 0.824                0.620   \n",
       "2           0.172          0.010                 0.479                0.100   \n",
       "3           0.166          0.014                 0.441                0.298   \n",
       "\n",
       "      method  \n",
       "0   abstract  \n",
       "1     readme  \n",
       "2      prone  \n",
       "3  graphsage  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>top10_accuracy_train</th>\n",
       "      <th>top10_accuracy_test</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.533</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.736</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.389</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.620</td>\n",
       "      <td>readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.166</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.298</td>\n",
       "      <td>graphsage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  accuracy_test  top10_accuracy_train  top10_accuracy_test  \\\n",
       "0           0.533          0.140                 0.879                0.736   \n",
       "1           0.389          0.059                 0.824                0.620   \n",
       "2           0.166          0.014                 0.441                0.298   \n",
       "\n",
       "      method  \n",
       "0   abstract  \n",
       "1     readme  \n",
       "2  graphsage  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_records([abstract_results, readme_results, graphsage_results])\n",
    "results_df['method'] = ['abstract', 'readme', 'graphsage']\n",
    "results_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_csv(\"output/retrieval_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_query_level_results(\n",
    "    retriever_learner,\n",
    "    data_test\n",
    "):\n",
    "    \n",
    "    accuracy_test = retriever_learner.evaluate(data_test, metrics.accuracy_score)\n",
    "    results = get_retrieval_accuracies(retriever_learner, data_test, k=10)\n",
    "    results['position'] = results['position'].replace(-1, np.inf)\n",
    "    \n",
    "    return accuracy_test, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_idx_or_inf(xs, a):\n",
    "    idxs = np.where(xs == a)[0].astype(int)\n",
    "    if len(idxs) == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return idxs[0]\n",
    "    \n",
    "\n",
    "def get_areas(area_grouped_tasks, tasks):\n",
    "    return tasks.apply(\n",
    "        lambda ts:\n",
    "        area_grouped_tasks['area'][\n",
    "            area_grouped_tasks['task'].isin(ts)\n",
    "        ].unique()\n",
    "    )\n",
    "\n",
    "\n",
    "def analyze_query_level_results(query_level_results, area_grouped_tasks):\n",
    "    retrieval_results_with_area_test = area_grouped_tasks.merge(query_level_results, left_on='task', right_index=True)\n",
    "    for tasks in retrieval_results_with_area_test['retrieved_labels'].values:\n",
    "        for task in tasks:\n",
    "            try:\n",
    "                partial(get_areas, area_grouped_tasks)([task])\n",
    "            except:\n",
    "                print(task)\n",
    "    retrieved_areas = get_areas(area_grouped_tasks, retrieval_results_with_area_test['retrieved_labels'])#apply(partial(get_areas, area_grouped_tasks))\n",
    "    retrieval_results_with_area_test['retrieved_areas'] = retrieved_areas\n",
    "    is_area_retrieved = retrieval_results_with_area_test.apply(lambda row: row['area'] in row['retrieved_areas'][:10], axis=1)\n",
    "    num_area_retrieved = retrieval_results_with_area_test.apply(lambda row: len(np.where(row['area'] == np.array(row['retrieved_areas'])[:10])[0]), axis=1)\n",
    "    area_idx = retrieval_results_with_area_test.apply(lambda row: get_idx_or_inf(np.array(row['retrieved_areas']), row['area']), axis=1)\n",
    "    retrieval_results_with_area_test['area_recalled'] = is_area_retrieved\n",
    "    retrieval_results_with_area_test['area_position'] = area_idx\n",
    "    retrieval_results_with_area_test['num_area_recalled'] = num_area_retrieved\n",
    "    query_level_results = retrieval_results_with_area_test.groupby('area').agg(\n",
    "        {\n",
    "            \"recalled\": \"mean\",\n",
    "            \"num_recalled\": \"mean\",\n",
    "            \"position\": [\"median\", \"mean\"],\n",
    "            \"area_recalled\": \"mean\",\n",
    "            \"num_area_recalled\": \"mean\",\n",
    "            \"area_position\": [\"median\", \"mean\"],\n",
    "        }\n",
    "    )\n",
    "    query_level_results['count'] = retrieval_results_with_area_test['area'].value_counts()#groupby('area').agg('count')\n",
    "    return query_level_results \n",
    "    \n",
    "def get_analyzed_query_level_results(retriever_learner, data_test, area_grouped_tasks):\n",
    "    detailed_results_all = get_query_level_results(retriever_learner, data_test)\n",
    "    retrieval_results_with_area_test = analyze_query_level_results(query_level_results, area_grouped_tasks)\n",
    "    return retrieval_results_with_area_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-200-73bd4eb12c0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadme_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_readme_area_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_query_level_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadme_learner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadme_data_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-130-54feebe979cb>\u001b[0m in \u001b[0;36mget_query_level_results\u001b[0;34m(retriever_learner, data_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m ):\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0maccuracy_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_retrieval_accuracies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretriever_learner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'position'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-3b4cd466f6ad>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, data, metric)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0munique_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0minput_y_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munique_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munique_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mpredicted_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_y_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-3b4cd466f6ad>\u001b[0m in \u001b[0;36mpredict_idxs\u001b[0;34m(self, X, y_embeddings)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mX_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzs_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/mlutil/mlutil/feature_extraction/embeddings.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0manalyzed_docs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manalyzed_docs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/mlutil/mlutil/feature_extraction/embeddings.py\u001b[0m in \u001b[0;36m_embed_texts\u001b[0;34m(self, texts, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/mlutil/mlutil/feature_extraction/embeddings.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage_embeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/mlutil/mlutil/feature_extraction/embeddings.py\u001b[0m in \u001b[0;36m_embed_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         embeddings = [\n\u001b[0m\u001b[1;32m    237\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/mlutil/mlutil/feature_extraction/embeddings.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_embed_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         embeddings = [\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mnew_func1\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1454\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mnew_func1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1456\u001b[0;31m                 warnings.warn(\n\u001b[0m\u001b[1;32m   1457\u001b[0m                     \u001b[0mfmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1458\u001b[0m                     \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "readme_accuracy, raw_readme_area_results = get_query_level_results(readme_learner, readme_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_accuracy, raw_graphsage_area_results = get_query_level_results(graphsage_learner, graphsage_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059114735002912054"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               dictionary learning\n",
       "6        natural language inference\n",
       "7        natural language inference\n",
       "8        natural language inference\n",
       "9        natural language inference\n",
       "                    ...            \n",
       "17378    neural network compression\n",
       "17379    neural network compression\n",
       "17384                style transfer\n",
       "17385                style transfer\n",
       "17386                style transfer\n",
       "Name: most_common_task, Length: 3434, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_test.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013508949679162444"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieved_labels</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th>recalled</th>\n",
       "      <th>position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dictionary learning</th>\n",
       "      <td>[incremental learning, knowledge distillation,...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural language inference</th>\n",
       "      <td>[abstractive text summarization, text summariz...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facial landmark detection</th>\n",
       "      <td>[face alignment, face recognition, face recons...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q learning</th>\n",
       "      <td>[atari games, q learning, multi goal reinforce...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reconstruction</th>\n",
       "      <td>[image compression, ms ssim, neural architectu...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real time strategy games</th>\n",
       "      <td>[link prediction, atari games, q learning, wea...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time series classification</th>\n",
       "      <td>[audio classification, weather forecasting, li...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>few shot image classification</th>\n",
       "      <td>[interpretable machine learning, image to imag...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image super resolution</th>\n",
       "      <td>[image super resolution, super resolution, ima...</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conditional image generation</th>\n",
       "      <td>[image manipulation, super resolution, image s...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                retrieved_labels  \\\n",
       "dictionary learning            [incremental learning, knowledge distillation,...   \n",
       "natural language inference     [abstractive text summarization, text summariz...   \n",
       "facial landmark detection      [face alignment, face recognition, face recons...   \n",
       "q learning                     [atari games, q learning, multi goal reinforce...   \n",
       "reconstruction                 [image compression, ms ssim, neural architectu...   \n",
       "...                                                                          ...   \n",
       "real time strategy games       [link prediction, atari games, q learning, wea...   \n",
       "time series classification     [audio classification, weather forecasting, li...   \n",
       "few shot image classification  [interpretable machine learning, image to imag...   \n",
       "image super resolution         [image super resolution, super resolution, ima...   \n",
       "conditional image generation   [image manipulation, super resolution, image s...   \n",
       "\n",
       "                               num_recalled  recalled  position  \n",
       "dictionary learning                       1      True       2.0  \n",
       "natural language inference                3      True       2.0  \n",
       "facial landmark detection                 0     False       inf  \n",
       "q learning                                3      True       1.0  \n",
       "reconstruction                            1      True      16.0  \n",
       "...                                     ...       ...       ...  \n",
       "real time strategy games                  0     False       inf  \n",
       "time series classification                0     False       inf  \n",
       "few shot image classification             0     False       inf  \n",
       "image super resolution                   10      True       0.0  \n",
       "conditional image generation              0     False       inf  \n",
       "\n",
       "[137 rows x 4 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_readme_area_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-f5280c44466b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ras' is not defined"
     ]
    }
   ],
   "source": [
    "ras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"  \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['lidar semantic segmentation', 'self supervised video retrieval',\n",
       "       'the semantic segmentation of remote sensing imagery',\n",
       "       'persian sentiment analysis', 'few shot semantic segmentation',\n",
       "       'node clustering', 'image morphing',\n",
       "       'no reference image quality assessment', 'landmark recognition',\n",
       "       'interestingness detection', 'extreme summarization',\n",
       "       'few shot text classification', 'cube engraving classification',\n",
       "       'video quality assessment', 'multi label zero shot learning',\n",
       "       'portrait segmentation', 'unsupervised sentence compression',\n",
       "       'indoor scene understanding',\n",
       "       'logical reasoning question answering',\n",
       "       'covid 19 image segmentation', 'nonhomogeneous image dehazing',\n",
       "       'text segmentation', 'jpeg compression artifact reduction',\n",
       "       'single view  reconstruction', 'volumetric reconstruction',\n",
       "       'cryogenic electron microscopy (cryo em)',\n",
       "       'spinal cord gray matter   segmentation', 'music genre transfer',\n",
       "       'driver attention monitoring', 'ad hoc video search',\n",
       "       'cross domain few shot', 'cross domain few shot learning',\n",
       "       'drawing pictures', 'face animation', '', 'thai word segmentation',\n",
       "       'chinese reading comprehension', 'x ray diffraction (xrd)',\n",
       "       'on the fly sketch based image retrieval',\n",
       "       'zero shot segmentation', 'medical object detection',\n",
       "       'image paragraph captioning', 'video forensics', 'person reposing',\n",
       "       'pose guided image generation', 'line art colorization',\n",
       "       'crop yield prediction',\n",
       "       'multi label classification of biomedical texts',\n",
       "       'classification of hyperspectral images',\n",
       "       'camouflage segmentation', 'video generation from a single image',\n",
       "       'hierarchical text classification of blurbs (germeval 2019)',\n",
       "       'sentence segmentation', 'drone based object tracking', 'gpr',\n",
       "       'micro expression recognition',\n",
       "       'scientific document summarization', 'layout to image generation',\n",
       "       'facial expression translation', 'multiple people tracking',\n",
       "       'music style transfer', 'cross lingual sentiment classification',\n",
       "       'object reconstruction from a single image', 'missing elements',\n",
       "       'egocentric pose estimation', 'sentence rewriting',\n",
       "       'histopathological segmentation', 'materials screening',\n",
       "       'action generation', 'human action generation', 'motion detection',\n",
       "       'art analysis', 'ancient text restoration',\n",
       "       'transform a video into a comics',\n",
       "       'multi person pose estimation (absolute)',\n",
       "       'multi person pose estimation (root relative)',\n",
       "       'root joint localization', 'medical visual question answering',\n",
       "       'entity cross document coreference resolution',\n",
       "       'event cross document coreference resolution',\n",
       "       'text line extraction', 'reasoning chain explanations',\n",
       "       'supervised video summarization',\n",
       "       'unsupervised video summarization', 'eeg 4 classes',\n",
       "       'eeg left/right hand', 'talking head generation',\n",
       "       'noun phrase canonicalization', 'image instance retrieval',\n",
       "       'self supervised audio classification', 'road segementation',\n",
       "       'drone pose estimation', 'hyperspectral image segmentation',\n",
       "       'hypergraph representations', 'amr to text generation',\n",
       "       'style generalization', 'table recognition',\n",
       "       'chinese sentence pair classification',\n",
       "       'chinese sentiment analysis', 'dense video captioning',\n",
       "       'instrument recognition', 'text image retrieval',\n",
       "       'fine grained vehicle classification',\n",
       "       'generalized zero shot object detection', 'image outpainting',\n",
       "       'unconstrained lip synchronization',\n",
       "       'vision based navigation with language based assistance',\n",
       "       'age invariant face recognition', 'face sketch synthesis',\n",
       "       'bird view synthesis', 'co salient object detection',\n",
       "       'relationship extraction (distant supervised)',\n",
       "       'sequential sentence segmentation',\n",
       "       'intubation support prediction',\n",
       "       'cross domain document classification',\n",
       "       'generalized few shot classification', 'video matting',\n",
       "       'image stitching', 'real time  semantic segmentation',\n",
       "       'pill classification', 'pill classification (both sides)',\n",
       "       'cross modal  person re identification',\n",
       "       'semantic contour prediction', 'commonsense reasoning for rl',\n",
       "       'extended summarization', 'multi label image retrieval',\n",
       "       'generalizable person re identification',\n",
       "       'object skeleton detection', 'shape from texture',\n",
       "       'image imputation', 'plane instance segmentation',\n",
       "       'disaster response', 'visual sentiment prediction',\n",
       "       'optic disc segmentation', 'complimentary image retrieval',\n",
       "       'audio question answering',\n",
       "       'one shot unsupervised domain adaptation',\n",
       "       'lip to speech synthesis', 'vector graphics',\n",
       "       'vector graphics animation',\n",
       "       'semantic role labeling (predicted predicates)',\n",
       "       'multi modal document classification', 'geometry perception',\n",
       "       'split and rephrase'], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks_tasks = all_tasks.explode().unique()\n",
    "\n",
    "all_tasks_tasks[~pd.Series(all_tasks_tasks).isin(area_grouped_tasks['task'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_raw_tasks = raw_graphsage_area_results.retrieved_labels.explode().drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['multi label zero shot learning', '', 'object skeleton detection',\n",
       "       'indoor scene understanding', 'bird view synthesis',\n",
       "       'music genre transfer', 'single view  reconstruction',\n",
       "       'disaster response', 'music style transfer'], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_raw_tasks[~pd.Series(all_raw_tasks).isin(area_grouped_tasks['task'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "isin() missing 1 required positional argument: 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-b55186b6bef5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marea_grouped_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: isin() missing 1 required positional argument: 'values'"
     ]
    }
   ],
   "source": [
    "area_grouped_tasks['task'].isin() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>adversarial defense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>inference attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adversarial</td>\n",
       "      <td>data poisoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>lexical entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>classification consistency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>foveation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>unsupervised video object segmentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>miscellaneous</td>\n",
       "      <td>video question answering</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1231 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               area                                    task\n",
       "0       adversarial                        adversarial text\n",
       "1       adversarial                      adversarial attack\n",
       "2       adversarial                     adversarial defense\n",
       "3       adversarial                        inference attack\n",
       "4       adversarial                          data poisoning\n",
       "...             ...                                     ...\n",
       "1875  miscellaneous                      lexical entailment\n",
       "1877  miscellaneous              classification consistency\n",
       "1878  miscellaneous                               foveation\n",
       "1879  miscellaneous  unsupervised video object segmentation\n",
       "1883  miscellaneous                video question answering\n",
       "\n",
       "[1231 rows x 2 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "area_grouped_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       [adversarial defense, adversarial defense, sel...\n",
       "22      [interpretable machine learning, image to imag...\n",
       "25      [audio generation, speech synthesis, style tra...\n",
       "42      [dependency parsing, semantic parsing, atari g...\n",
       "88      [q learning, atari games, board games, multi t...\n",
       "                              ...                        \n",
       "1768    [image to image translation, image to image tr...\n",
       "1776    [meta learning, multi agent reinforcement lear...\n",
       "1780    [face identification, face recognition, face v...\n",
       "1784    [depth estimation, super resolution, image sup...\n",
       "1803    [fine grained opinion analysis, multi task lea...\n",
       "Name: retrieved_labels, Length: 148, dtype: object"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_results_with_area_test['retrieved_labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1           adversarial\n",
       " 2           adversarial\n",
       " 169     computer-vision\n",
       " 224     computer-vision\n",
       " 564     computer-vision\n",
       " 923         methodology\n",
       " 1470      playing-games\n",
       " 1541             speech\n",
       " 1550             speech\n",
       " 1586             speech\n",
       " 1741      miscellaneous\n",
       " 1783      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 2           adversarial\n",
       " 22                audio\n",
       " 225     computer-vision\n",
       " 716             medical\n",
       " 800             medical\n",
       " 958         methodology\n",
       " 1541             speech\n",
       " 1550             speech\n",
       " 1586             speech\n",
       " 1678      miscellaneous\n",
       " 1741      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 25                audio\n",
       " 112     computer-vision\n",
       " 225     computer-vision\n",
       " 297     computer-vision\n",
       " 431     computer-vision\n",
       " 477     computer-vision\n",
       " 481     computer-vision\n",
       " 571     computer-vision\n",
       " 756             medical\n",
       " 1554             speech\n",
       " 1559             speech\n",
       " 1585             speech\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1768      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 42                    computer-code\n",
       " 867                     methodology\n",
       " 1169    natural-language-processing\n",
       " 1190    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1470                  playing-games\n",
       " 1646                  miscellaneous\n",
       " 1650                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 90      computer-vision\n",
       " 123     computer-vision\n",
       " 296     computer-vision\n",
       " 431     computer-vision\n",
       " 537     computer-vision\n",
       " 716             medical\n",
       " 867         methodology\n",
       " 878         methodology\n",
       " 942         methodology\n",
       " 967         methodology\n",
       " 1458      playing-games\n",
       " 1470      playing-games\n",
       " 1648      miscellaneous\n",
       " 1664      miscellaneous\n",
       " 1828      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 90                  computer-vision\n",
       " 225                 computer-vision\n",
       " 296                 computer-vision\n",
       " 405                 computer-vision\n",
       " 537                 computer-vision\n",
       " 716                         medical\n",
       " 756                         medical\n",
       " 811                         medical\n",
       " 828                         medical\n",
       " 841                     methodology\n",
       " 934                     methodology\n",
       " 961                     methodology\n",
       " 1062                  miscellaneous\n",
       " 1230    natural-language-processing\n",
       " 1642                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " 1741                  miscellaneous\n",
       " 1784                  miscellaneous\n",
       " 1826                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 90                  computer-vision\n",
       " 225                 computer-vision\n",
       " 296                 computer-vision\n",
       " 405                 computer-vision\n",
       " 537                 computer-vision\n",
       " 716                         medical\n",
       " 756                         medical\n",
       " 811                         medical\n",
       " 828                         medical\n",
       " 841                     methodology\n",
       " 934                     methodology\n",
       " 961                     methodology\n",
       " 1062                  miscellaneous\n",
       " 1230    natural-language-processing\n",
       " 1642                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " 1741                  miscellaneous\n",
       " 1784                  miscellaneous\n",
       " 1826                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 147     computer-vision\n",
       " 174     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 518     computer-vision\n",
       " 537     computer-vision\n",
       " 1612        time-series\n",
       " 1710      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1787      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 147     computer-vision\n",
       " 174     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 518     computer-vision\n",
       " 537     computer-vision\n",
       " 1612        time-series\n",
       " 1710      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1787      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 192     computer-vision\n",
       " 199     computer-vision\n",
       " 219     computer-vision\n",
       " 431     computer-vision\n",
       " 537     computer-vision\n",
       " 884         methodology\n",
       " 934         methodology\n",
       " 953         methodology\n",
       " 1062      miscellaneous\n",
       " 1642      miscellaneous\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1693      miscellaneous\n",
       " 1694      miscellaneous\n",
       " 1731      miscellaneous\n",
       " 1846      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 94                  computer-vision\n",
       " 169                 computer-vision\n",
       " 184                 computer-vision\n",
       " 224                 computer-vision\n",
       " 412                 computer-vision\n",
       " 431                 computer-vision\n",
       " 848                     methodology\n",
       " 1007                  miscellaneous\n",
       " 1195    natural-language-processing\n",
       " 1648                  miscellaneous\n",
       " 1832                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 147     computer-vision\n",
       " 174     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 335     computer-vision\n",
       " 518     computer-vision\n",
       " 1728      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 915         methodology\n",
       " 967         methodology\n",
       " 1532             robots\n",
       " 1648      miscellaneous\n",
       " 1653      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 915         methodology\n",
       " 967         methodology\n",
       " 1532             robots\n",
       " 1648      miscellaneous\n",
       " 1653      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 915         methodology\n",
       " 967         methodology\n",
       " 1532             robots\n",
       " 1648      miscellaneous\n",
       " 1653      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 431     computer-vision\n",
       " 537     computer-vision\n",
       " 615              graphs\n",
       " 716             medical\n",
       " 878         methodology\n",
       " 898         methodology\n",
       " 934         methodology\n",
       " 958         methodology\n",
       " 1062      miscellaneous\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 611              graphs\n",
       " 1532             robots\n",
       " 1653      miscellaneous\n",
       " 1667      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1780      miscellaneous\n",
       " 1863      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 611              graphs\n",
       " 1532             robots\n",
       " 1653      miscellaneous\n",
       " 1667      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1780      miscellaneous\n",
       " 1863      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 611              graphs\n",
       " 1532             robots\n",
       " 1653      miscellaneous\n",
       " 1667      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1780      miscellaneous\n",
       " 1863      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 209     computer-vision\n",
       " 297     computer-vision\n",
       " 449     computer-vision\n",
       " 878         methodology\n",
       " 1550             speech\n",
       " 1554             speech\n",
       " 1555             speech\n",
       " 1556             speech\n",
       " 1569             speech\n",
       " 1689      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169    computer-vision\n",
       " 224    computer-vision\n",
       " 605             graphs\n",
       " 848        methodology\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 231     computer-vision\n",
       " 431     computer-vision\n",
       " 515     computer-vision\n",
       " 542     computer-vision\n",
       " 558     computer-vision\n",
       " 898         methodology\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 201     computer-vision\n",
       " 256     computer-vision\n",
       " 300     computer-vision\n",
       " 564     computer-vision\n",
       " 811             medical\n",
       " 828             medical\n",
       " 852         methodology\n",
       " 878         methodology\n",
       " 898         methodology\n",
       " 943         methodology\n",
       " 958         methodology\n",
       " 1470      playing-games\n",
       " 1646      miscellaneous\n",
       " 1669      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1826      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 107     computer-vision\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 225     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 1532             robots\n",
       " 1653      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 147     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 278     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 445     computer-vision\n",
       " 537     computer-vision\n",
       " 866         methodology\n",
       " 915         methodology\n",
       " 1612        time-series\n",
       " 1646      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1787      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 167     computer-vision\n",
       " 297     computer-vision\n",
       " 449     computer-vision\n",
       " 1658      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 201     computer-vision\n",
       " 245     computer-vision\n",
       " 454     computer-vision\n",
       " 716             medical\n",
       " 811             medical\n",
       " 828             medical\n",
       " 878         methodology\n",
       " 898         methodology\n",
       " 943         methodology\n",
       " 958         methodology\n",
       " 1470      playing-games\n",
       " 1646      miscellaneous\n",
       " 1669      miscellaneous\n",
       " 1826      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224     computer-vision\n",
       " 297     computer-vision\n",
       " 306     computer-vision\n",
       " 716             medical\n",
       " 836         methodology\n",
       " 852         methodology\n",
       " 861         methodology\n",
       " 874         methodology\n",
       " 932         methodology\n",
       " 947         methodology\n",
       " 958         methodology\n",
       " 1687      miscellaneous\n",
       " 1784      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 159     computer-vision\n",
       " 169     computer-vision\n",
       " 292     computer-vision\n",
       " 322     computer-vision\n",
       " 327     computer-vision\n",
       " 337     computer-vision\n",
       " 431     computer-vision\n",
       " 537     computer-vision\n",
       " 587              graphs\n",
       " 607              graphs\n",
       " 878         methodology\n",
       " 915         methodology\n",
       " 1648      miscellaneous\n",
       " 1671      miscellaneous\n",
       " 1793      miscellaneous\n",
       " 1811      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 115     computer-vision\n",
       " 147     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 443     computer-vision\n",
       " 537     computer-vision\n",
       " 1612        time-series\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " 1691      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1752      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 115     computer-vision\n",
       " 147     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 443     computer-vision\n",
       " 537     computer-vision\n",
       " 1612        time-series\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " 1691      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1752      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 115     computer-vision\n",
       " 147     computer-vision\n",
       " 224     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 443     computer-vision\n",
       " 537     computer-vision\n",
       " 1612        time-series\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " 1691      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1752      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 431     computer-vision\n",
       " 515     computer-vision\n",
       " 756             medical\n",
       " 1533             robots\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1694      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 245    computer-vision\n",
       " 454    computer-vision\n",
       " Name: area, dtype: object,\n",
       " 100                 computer-vision\n",
       " 123                 computer-vision\n",
       " 146                 computer-vision\n",
       " 169                 computer-vision\n",
       " 186                 computer-vision\n",
       " 224                 computer-vision\n",
       " 249                 computer-vision\n",
       " 283                 computer-vision\n",
       " 297                 computer-vision\n",
       " 449                 computer-vision\n",
       " 557                 computer-vision\n",
       " 613                          graphs\n",
       " 879                     methodology\n",
       " 1137    natural-language-processing\n",
       " 1393    natural-language-processing\n",
       " 1644                  miscellaneous\n",
       " 1664                  miscellaneous\n",
       " 1739                  miscellaneous\n",
       " 1740                  miscellaneous\n",
       " 1752                  miscellaneous\n",
       " 1754                  miscellaneous\n",
       " 1809                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 2           adversarial\n",
       " 22                audio\n",
       " 146     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 306     computer-vision\n",
       " 431     computer-vision\n",
       " 449     computer-vision\n",
       " 841         methodology\n",
       " 862         methodology\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1656      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1741      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 583             graphs\n",
       " 602             graphs\n",
       " 603             graphs\n",
       " 607             graphs\n",
       " 629     knowledge-base\n",
       " 769            medical\n",
       " 837        methodology\n",
       " 848        methodology\n",
       " 861        methodology\n",
       " 864        methodology\n",
       " 926        methodology\n",
       " 947        methodology\n",
       " 1591       time-series\n",
       " 1645     miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 231     computer-vision\n",
       " 297     computer-vision\n",
       " 431     computer-vision\n",
       " 515     computer-vision\n",
       " 537     computer-vision\n",
       " 542     computer-vision\n",
       " 756             medical\n",
       " 1533             robots\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1694      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 278                 computer-vision\n",
       " 406                 computer-vision\n",
       " 557                 computer-vision\n",
       " 657                         medical\n",
       " 673                         medical\n",
       " 724                         medical\n",
       " 866                     methodology\n",
       " 878                     methodology\n",
       " 915                     methodology\n",
       " 1323    natural-language-processing\n",
       " 1633                    time-series\n",
       " 1875                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 564     computer-vision\n",
       " 837         methodology\n",
       " 850         methodology\n",
       " 861         methodology\n",
       " 932         methodology\n",
       " 947         methodology\n",
       " 962         methodology\n",
       " 1467      playing-games\n",
       " 1487      playing-games\n",
       " 1645      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1746      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 587                          graphs\n",
       " 592                          graphs\n",
       " 597                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 846                     methodology\n",
       " 848                     methodology\n",
       " 860                     methodology\n",
       " 947                     methodology\n",
       " 1348    natural-language-processing\n",
       " Name: area, dtype: object,\n",
       " 123                 computer-vision\n",
       " 583                          graphs\n",
       " 596                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 637                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 848                     methodology\n",
       " 861                     methodology\n",
       " 864                     methodology\n",
       " 875                     methodology\n",
       " 891                     methodology\n",
       " 922                     methodology\n",
       " 947                     methodology\n",
       " 1165    natural-language-processing\n",
       " 1269    natural-language-processing\n",
       " 1323    natural-language-processing\n",
       " 1365    natural-language-processing\n",
       " 1666                  miscellaneous\n",
       " 1724                  miscellaneous\n",
       " 1875                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123                 computer-vision\n",
       " 583                          graphs\n",
       " 596                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 637                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 848                     methodology\n",
       " 861                     methodology\n",
       " 864                     methodology\n",
       " 875                     methodology\n",
       " 891                     methodology\n",
       " 922                     methodology\n",
       " 947                     methodology\n",
       " 1165    natural-language-processing\n",
       " 1269    natural-language-processing\n",
       " 1323    natural-language-processing\n",
       " 1365    natural-language-processing\n",
       " 1666                  miscellaneous\n",
       " 1724                  miscellaneous\n",
       " 1875                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 306                 computer-vision\n",
       " 576                          graphs\n",
       " 583                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 638                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 864                     methodology\n",
       " 900                     methodology\n",
       " 947                     methodology\n",
       " 968                     methodology\n",
       " 1250    natural-language-processing\n",
       " 1299    natural-language-processing\n",
       " 1645                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 306                 computer-vision\n",
       " 576                          graphs\n",
       " 583                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 638                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 864                     methodology\n",
       " 900                     methodology\n",
       " 947                     methodology\n",
       " 968                     methodology\n",
       " 1250    natural-language-processing\n",
       " 1299    natural-language-processing\n",
       " 1645                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 431     computer-vision\n",
       " 454     computer-vision\n",
       " 594              graphs\n",
       " 607              graphs\n",
       " 615              graphs\n",
       " 716             medical\n",
       " 861         methodology\n",
       " 947         methodology\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1725      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 169     computer-vision\n",
       " 613              graphs\n",
       " 850         methodology\n",
       " 867         methodology\n",
       " 879         methodology\n",
       " 953         methodology\n",
       " 954         methodology\n",
       " 1646      miscellaneous\n",
       " 1666      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 564     computer-vision\n",
       " 716             medical\n",
       " 820             medical\n",
       " 878         methodology\n",
       " 1665      miscellaneous\n",
       " 1670      miscellaneous\n",
       " 1692      miscellaneous\n",
       " 1823      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 602                          graphs\n",
       " 629                  knowledge-base\n",
       " 638                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 741                         medical\n",
       " 841                     methodology\n",
       " 958                     methodology\n",
       " 1165    natural-language-processing\n",
       " 1365    natural-language-processing\n",
       " 1470                  playing-games\n",
       " Name: area, dtype: object,\n",
       " 123                 computer-vision\n",
       " 716                         medical\n",
       " 820                         medical\n",
       " 1365    natural-language-processing\n",
       " 1670                  miscellaneous\n",
       " 1823                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 256     computer-vision\n",
       " 716             medical\n",
       " 837         methodology\n",
       " 878         methodology\n",
       " 898         methodology\n",
       " 927         methodology\n",
       " 956         methodology\n",
       " 1645      miscellaneous\n",
       " 1746      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 841       methodology\n",
       " 884       methodology\n",
       " 934       methodology\n",
       " 1062    miscellaneous\n",
       " 1105            music\n",
       " 1539           speech\n",
       " 1552           speech\n",
       " 1554           speech\n",
       " 1646    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 850       methodology\n",
       " 867       methodology\n",
       " 1469    playing-games\n",
       " 1470    playing-games\n",
       " 1487    playing-games\n",
       " 1489    playing-games\n",
       " Name: area, dtype: object,\n",
       " 306     computer-vision\n",
       " 861         methodology\n",
       " 879         methodology\n",
       " 947         methodology\n",
       " 962         methodology\n",
       " 1051      miscellaneous\n",
       " 1470      playing-games\n",
       " 1645      miscellaneous\n",
       " 1753      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 852       methodology\n",
       " 861       methodology\n",
       " 867       methodology\n",
       " 879       methodology\n",
       " 885       methodology\n",
       " 932       methodology\n",
       " 947       methodology\n",
       " 962       methodology\n",
       " 1015    miscellaneous\n",
       " 1470    playing-games\n",
       " 1645    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 850                     methodology\n",
       " 855                     methodology\n",
       " 867                     methodology\n",
       " 879                     methodology\n",
       " 917                     methodology\n",
       " 947                     methodology\n",
       " 1182    natural-language-processing\n",
       " 1457                  playing-games\n",
       " 1467                  playing-games\n",
       " 1470                  playing-games\n",
       " 1487                  playing-games\n",
       " 1489                  playing-games\n",
       " 1777                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224                 computer-vision\n",
       " 576                          graphs\n",
       " 602                          graphs\n",
       " 629                  knowledge-base\n",
       " 631                  knowledge-base\n",
       " 638                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 847                     methodology\n",
       " 851                     methodology\n",
       " 855                     methodology\n",
       " 861                     methodology\n",
       " 878                     methodology\n",
       " 893                     methodology\n",
       " 898                     methodology\n",
       " 947                     methodology\n",
       " 1182    natural-language-processing\n",
       " 1645                  miscellaneous\n",
       " 1687                  miscellaneous\n",
       " 1777                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 306     computer-vision\n",
       " 850         methodology\n",
       " 852         methodology\n",
       " 861         methodology\n",
       " 867         methodology\n",
       " 879         methodology\n",
       " 932         methodology\n",
       " 947         methodology\n",
       " 962         methodology\n",
       " 1469      playing-games\n",
       " 1470      playing-games\n",
       " 1487      playing-games\n",
       " 1489      playing-games\n",
       " 1645      miscellaneous\n",
       " 1753      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 297                 computer-vision\n",
       " 583                          graphs\n",
       " 596                          graphs\n",
       " 613                          graphs\n",
       " 836                     methodology\n",
       " 864                     methodology\n",
       " 875                     methodology\n",
       " 884                     methodology\n",
       " 891                     methodology\n",
       " 898                     methodology\n",
       " 958                     methodology\n",
       " 1269    natural-language-processing\n",
       " 1646                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 613            graphs\n",
       " 862       methodology\n",
       " 867       methodology\n",
       " 875       methodology\n",
       " 898       methodology\n",
       " 947       methodology\n",
       " 1469    playing-games\n",
       " 1646    miscellaneous\n",
       " 1753    miscellaneous\n",
       " 1777    miscellaneous\n",
       " 1825    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1           adversarial\n",
       " 224     computer-vision\n",
       " 225     computer-vision\n",
       " 848         methodology\n",
       " 861         methodology\n",
       " 915         methodology\n",
       " 932         methodology\n",
       " 947         methodology\n",
       " 1076      miscellaneous\n",
       " 1550             speech\n",
       " 1648      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1659      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 850       methodology\n",
       " 867       methodology\n",
       " 947       methodology\n",
       " 1469    playing-games\n",
       " 1470    playing-games\n",
       " 1487    playing-games\n",
       " 1489    playing-games\n",
       " 1746    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 95      computer-vision\n",
       " 225     computer-vision\n",
       " 245     computer-vision\n",
       " 515     computer-vision\n",
       " 564     computer-vision\n",
       " 837         methodology\n",
       " 844         methodology\n",
       " 878         methodology\n",
       " 962         methodology\n",
       " 967         methodology\n",
       " 1072      miscellaneous\n",
       " 1105              music\n",
       " 1539             speech\n",
       " 1552             speech\n",
       " 1554             speech\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1692      miscellaneous\n",
       " 1731      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169                 computer-vision\n",
       " 583                          graphs\n",
       " 596                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 613                          graphs\n",
       " 629                  knowledge-base\n",
       " 848                     methodology\n",
       " 861                     methodology\n",
       " 864                     methodology\n",
       " 875                     methodology\n",
       " 878                     methodology\n",
       " 891                     methodology\n",
       " 947                     methodology\n",
       " 1208    natural-language-processing\n",
       " 1269    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1470                  playing-games\n",
       " 1683                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 431     computer-vision\n",
       " 615              graphs\n",
       " 841         methodology\n",
       " 852         methodology\n",
       " 862         methodology\n",
       " 884         methodology\n",
       " 958         methodology\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 199     computer-vision\n",
       " 249     computer-vision\n",
       " 297     computer-vision\n",
       " 431     computer-vision\n",
       " 449     computer-vision\n",
       " 528     computer-vision\n",
       " 537     computer-vision\n",
       " 884         methodology\n",
       " 1554             speech\n",
       " 1645      miscellaneous\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1693      miscellaneous\n",
       " 1694      miscellaneous\n",
       " 1832      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 199     computer-vision\n",
       " 249     computer-vision\n",
       " 297     computer-vision\n",
       " 431     computer-vision\n",
       " 449     computer-vision\n",
       " 528     computer-vision\n",
       " 537     computer-vision\n",
       " 884         methodology\n",
       " 1554             speech\n",
       " 1645      miscellaneous\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1693      miscellaneous\n",
       " 1694      miscellaneous\n",
       " 1832      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 54                    computer-code\n",
       " 169                 computer-vision\n",
       " 850                     methodology\n",
       " 852                     methodology\n",
       " 861                     methodology\n",
       " 867                     methodology\n",
       " 947                     methodology\n",
       " 1007                  miscellaneous\n",
       " 1028                  miscellaneous\n",
       " 1068                  miscellaneous\n",
       " 1195    natural-language-processing\n",
       " 1467                  playing-games\n",
       " 1470                  playing-games\n",
       " 1487                  playing-games\n",
       " Name: area, dtype: object,\n",
       " 855                     methodology\n",
       " 861                     methodology\n",
       " 878                     methodology\n",
       " 893                     methodology\n",
       " 917                     methodology\n",
       " 947                     methodology\n",
       " 962                     methodology\n",
       " 1051                  miscellaneous\n",
       " 1182    natural-language-processing\n",
       " 1470                  playing-games\n",
       " 1645                  miscellaneous\n",
       " 1742                  miscellaneous\n",
       " 1777                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224                 computer-vision\n",
       " 583                          graphs\n",
       " 596                          graphs\n",
       " 602                          graphs\n",
       " 610                          graphs\n",
       " 616                          graphs\n",
       " 629                  knowledge-base\n",
       " 642                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 837                     methodology\n",
       " 852                     methodology\n",
       " 864                     methodology\n",
       " 891                     methodology\n",
       " 927                     methodology\n",
       " 935                     methodology\n",
       " 947                     methodology\n",
       " 948                     methodology\n",
       " 956                     methodology\n",
       " 1165    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1269    natural-language-processing\n",
       " 1510                      reasoning\n",
       " Name: area, dtype: object,\n",
       " 306                 computer-vision\n",
       " 852                     methodology\n",
       " 855                     methodology\n",
       " 861                     methodology\n",
       " 879                     methodology\n",
       " 932                     methodology\n",
       " 947                     methodology\n",
       " 953                     methodology\n",
       " 962                     methodology\n",
       " 1182    natural-language-processing\n",
       " 1645                  miscellaneous\n",
       " 1777                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225                 computer-vision\n",
       " 477                 computer-vision\n",
       " 571                 computer-vision\n",
       " 613                          graphs\n",
       " 756                         medical\n",
       " 861                     methodology\n",
       " 947                     methodology\n",
       " 1038                  miscellaneous\n",
       " 1143    natural-language-processing\n",
       " 1156    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1194    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1445    natural-language-processing\n",
       " 1645                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 861       methodology\n",
       " 879       methodology\n",
       " 932       methodology\n",
       " 947       methodology\n",
       " 962       methodology\n",
       " 1470    playing-games\n",
       " 1645    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 105     computer-vision\n",
       " 123     computer-vision\n",
       " 146     computer-vision\n",
       " 197     computer-vision\n",
       " 225     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 449     computer-vision\n",
       " 531     computer-vision\n",
       " 1653      miscellaneous\n",
       " 1660      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1714      miscellaneous\n",
       " 1780      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 431                 computer-vision\n",
       " 515                 computer-vision\n",
       " 615                          graphs\n",
       " 852                     methodology\n",
       " 867                     methodology\n",
       " 875                     methodology\n",
       " 958                     methodology\n",
       " 979                   miscellaneous\n",
       " 1081                  miscellaneous\n",
       " 1169    natural-language-processing\n",
       " 1190    natural-language-processing\n",
       " 1470                  playing-games\n",
       " 1646                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " 1678                  miscellaneous\n",
       " 1692                  miscellaneous\n",
       " 1741                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 245     computer-vision\n",
       " 454     computer-vision\n",
       " 867         methodology\n",
       " 875         methodology\n",
       " 898         methodology\n",
       " 934         methodology\n",
       " 1062      miscellaneous\n",
       " 1646      miscellaneous\n",
       " 1784      miscellaneous\n",
       " 1825      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 94                  computer-vision\n",
       " 169                 computer-vision\n",
       " 184                 computer-vision\n",
       " 224                 computer-vision\n",
       " 297                 computer-vision\n",
       " 564                 computer-vision\n",
       " 837                     methodology\n",
       " 879                     methodology\n",
       " 934                     methodology\n",
       " 1016                  miscellaneous\n",
       " 1062                  miscellaneous\n",
       " 1210    natural-language-processing\n",
       " 1223    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1450    natural-language-processing\n",
       " Name: area, dtype: object,\n",
       " 837       methodology\n",
       " 850       methodology\n",
       " 947       methodology\n",
       " 1028    miscellaneous\n",
       " 1742    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 454                 computer-vision\n",
       " 613                          graphs\n",
       " 861                     methodology\n",
       " 932                     methodology\n",
       " 986                   miscellaneous\n",
       " 1023                  miscellaneous\n",
       " 1031                  miscellaneous\n",
       " 1230    natural-language-processing\n",
       " 1450    natural-language-processing\n",
       " 1665                  miscellaneous\n",
       " 1678                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225                 computer-vision\n",
       " 613                          graphs\n",
       " 878                     methodology\n",
       " 1164    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1254    natural-language-processing\n",
       " 1290    natural-language-processing\n",
       " 1303    natural-language-processing\n",
       " 1333    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1378    natural-language-processing\n",
       " 1433    natural-language-processing\n",
       " 1678                  miscellaneous\n",
       " 1768                  miscellaneous\n",
       " 1858                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225                 computer-vision\n",
       " 875                     methodology\n",
       " 879                     methodology\n",
       " 898                     methodology\n",
       " 915                     methodology\n",
       " 958                     methodology\n",
       " 1016                  miscellaneous\n",
       " 1076                  miscellaneous\n",
       " 1223    natural-language-processing\n",
       " 1450    natural-language-processing\n",
       " 1550                         speech\n",
       " 1646                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " 1670                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 515                 computer-vision\n",
       " 921                     methodology\n",
       " 1117    natural-language-processing\n",
       " 1199    natural-language-processing\n",
       " 1223    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1344    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1646                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " 1650                  miscellaneous\n",
       " 1722                  miscellaneous\n",
       " 1796                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224     computer-vision\n",
       " 225     computer-vision\n",
       " 414     computer-vision\n",
       " 852         methodology\n",
       " 878         methodology\n",
       " 908         methodology\n",
       " 934         methodology\n",
       " 947         methodology\n",
       " 1062      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1117    natural-language-processing\n",
       " 1137    natural-language-processing\n",
       " 1253    natural-language-processing\n",
       " 1259    natural-language-processing\n",
       " 1344    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1366    natural-language-processing\n",
       " 1740                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 861                     methodology\n",
       " 874                     methodology\n",
       " 878                     methodology\n",
       " 947                     methodology\n",
       " 1143    natural-language-processing\n",
       " 1197    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1348    natural-language-processing\n",
       " 1508                      reasoning\n",
       " 1665                  miscellaneous\n",
       " 1750                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 405     computer-vision\n",
       " 431     computer-vision\n",
       " 756             medical\n",
       " 878         methodology\n",
       " 1105              music\n",
       " 1539             speech\n",
       " 1544             speech\n",
       " 1550             speech\n",
       " 1552             speech\n",
       " 1554             speech\n",
       " 1556             speech\n",
       " 1558             speech\n",
       " 1569             speech\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1689      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 616                          graphs\n",
       " 639                  knowledge-base\n",
       " 642                  knowledge-base\n",
       " 986                   miscellaneous\n",
       " 1113    natural-language-processing\n",
       " 1117    natural-language-processing\n",
       " 1143    natural-language-processing\n",
       " 1145    natural-language-processing\n",
       " 1156    natural-language-processing\n",
       " 1194    natural-language-processing\n",
       " 1195    natural-language-processing\n",
       " 1213    natural-language-processing\n",
       " 1215    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1323    natural-language-processing\n",
       " 1365    natural-language-processing\n",
       " 1433    natural-language-processing\n",
       " 1875                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 90                  computer-vision\n",
       " 123                 computer-vision\n",
       " 169                 computer-vision\n",
       " 296                 computer-vision\n",
       " 564                 computer-vision\n",
       " 716                         medical\n",
       " 817                         medical\n",
       " 878                     methodology\n",
       " 953                     methodology\n",
       " 1169    natural-language-processing\n",
       " 1665                  miscellaneous\n",
       " 1692                  miscellaneous\n",
       " 1705                  miscellaneous\n",
       " 1848                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169                 computer-vision\n",
       " 898                     methodology\n",
       " 937                     methodology\n",
       " 967                     methodology\n",
       " 979                   miscellaneous\n",
       " 1169    natural-language-processing\n",
       " 1190    natural-language-processing\n",
       " 1199    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1457                  playing-games\n",
       " 1650                  miscellaneous\n",
       " 1678                  miscellaneous\n",
       " 1685                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 105                 computer-vision\n",
       " 493                 computer-vision\n",
       " 850                     methodology\n",
       " 1155    natural-language-processing\n",
       " 1167    natural-language-processing\n",
       " 1195    natural-language-processing\n",
       " 1199    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1301    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1489                  playing-games\n",
       " 1642                  miscellaneous\n",
       " 1650                  miscellaneous\n",
       " 1657                  miscellaneous\n",
       " 1678                  miscellaneous\n",
       " 1685                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169                 computer-vision\n",
       " 613                          graphs\n",
       " 850                     methodology\n",
       " 867                     methodology\n",
       " 878                     methodology\n",
       " 898                     methodology\n",
       " 937                     methodology\n",
       " 1028                  miscellaneous\n",
       " 1129    natural-language-processing\n",
       " 1210    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1458                  playing-games\n",
       " Name: area, dtype: object,\n",
       " 878                     methodology\n",
       " 1117    natural-language-processing\n",
       " 1141    natural-language-processing\n",
       " 1145    natural-language-processing\n",
       " 1167    natural-language-processing\n",
       " 1185    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1649                  miscellaneous\n",
       " 1658                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 711                         medical\n",
       " 879                     methodology\n",
       " 1016                  miscellaneous\n",
       " 1223    natural-language-processing\n",
       " 1228    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1365    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1450    natural-language-processing\n",
       " 1722                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169                 computer-vision\n",
       " 716                         medical\n",
       " 841                     methodology\n",
       " 862                     methodology\n",
       " 958                     methodology\n",
       " 1230    natural-language-processing\n",
       " 1646                  miscellaneous\n",
       " 1746                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 167                 computer-vision\n",
       " 837                     methodology\n",
       " 878                     methodology\n",
       " 1117    natural-language-processing\n",
       " 1122    natural-language-processing\n",
       " 1164    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1202    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1286    natural-language-processing\n",
       " 1303    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1378    natural-language-processing\n",
       " 1456    natural-language-processing\n",
       " 1658                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 878                     methodology\n",
       " 967                     methodology\n",
       " 1117    natural-language-processing\n",
       " 1141    natural-language-processing\n",
       " 1145    natural-language-processing\n",
       " 1167    natural-language-processing\n",
       " 1185    natural-language-processing\n",
       " 1199    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1649                  miscellaneous\n",
       " 1658                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 25                            audio\n",
       " 112                 computer-vision\n",
       " 225                 computer-vision\n",
       " 937                     methodology\n",
       " 1253    natural-language-processing\n",
       " 1255    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1366    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1415    natural-language-processing\n",
       " 1567                         speech\n",
       " 1678                  miscellaneous\n",
       " 1768                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 112                 computer-vision\n",
       " 613                          graphs\n",
       " 837                     methodology\n",
       " 878                     methodology\n",
       " 1016                  miscellaneous\n",
       " 1119    natural-language-processing\n",
       " 1143    natural-language-processing\n",
       " 1159    natural-language-processing\n",
       " 1164    natural-language-processing\n",
       " 1171    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1262    natural-language-processing\n",
       " 1378    natural-language-processing\n",
       " 1455    natural-language-processing\n",
       " 1678                  miscellaneous\n",
       " 1685                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 169                 computer-vision\n",
       " 878                     methodology\n",
       " 1145    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1252    natural-language-processing\n",
       " 1323    natural-language-processing\n",
       " 1333    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1372    natural-language-processing\n",
       " 1378    natural-language-processing\n",
       " 1433    natural-language-processing\n",
       " 1436    natural-language-processing\n",
       " 1439    natural-language-processing\n",
       " Name: area, dtype: object,\n",
       " 986                   miscellaneous\n",
       " 1122    natural-language-processing\n",
       " 1143    natural-language-processing\n",
       " 1194    natural-language-processing\n",
       " 1202    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1303    natural-language-processing\n",
       " 1323    natural-language-processing\n",
       " 1433    natural-language-processing\n",
       " 1875                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146                 computer-vision\n",
       " 297                 computer-vision\n",
       " 431                 computer-vision\n",
       " 449                 computer-vision\n",
       " 594                          graphs\n",
       " 602                          graphs\n",
       " 629                  knowledge-base\n",
       " 638                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 716                         medical\n",
       " 769                         medical\n",
       " 870                     methodology\n",
       " 884                     methodology\n",
       " 900                     methodology\n",
       " 926                     methodology\n",
       " 947                     methodology\n",
       " 1143    natural-language-processing\n",
       " 1165    natural-language-processing\n",
       " 1194    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1299    natural-language-processing\n",
       " 1591                    time-series\n",
       " 1645                  miscellaneous\n",
       " 1646                  miscellaneous\n",
       " 1648                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 209                 computer-vision\n",
       " 613                          graphs\n",
       " 878                     methodology\n",
       " 879                     methodology\n",
       " 947                     methodology\n",
       " 1016                  miscellaneous\n",
       " 1223    natural-language-processing\n",
       " 1228    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1450    natural-language-processing\n",
       " 1722                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1228    natural-language-processing\n",
       " 1230    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1378    natural-language-processing\n",
       " 1722                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 54                    computer-code\n",
       " 613                          graphs\n",
       " 861                     methodology\n",
       " 986                   miscellaneous\n",
       " 1031                  miscellaneous\n",
       " 1155    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1366    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " Name: area, dtype: object,\n",
       " 306                 computer-vision\n",
       " 716                         medical\n",
       " 848                     methodology\n",
       " 852                     methodology\n",
       " 861                     methodology\n",
       " 862                     methodology\n",
       " 947                     methodology\n",
       " 958                     methodology\n",
       " 1230    natural-language-processing\n",
       " 1646                  miscellaneous\n",
       " 1746                  miscellaneous\n",
       " 1784                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1199    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1650                  miscellaneous\n",
       " 1857                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 878       methodology\n",
       " 1550           speech\n",
       " 1554           speech\n",
       " 1556           speech\n",
       " 1558           speech\n",
       " 1559           speech\n",
       " 1569           speech\n",
       " 1585           speech\n",
       " 1645    miscellaneous\n",
       " 1678    miscellaneous\n",
       " 1689    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 22               audio\n",
       " 602             graphs\n",
       " 629     knowledge-base\n",
       " 867        methodology\n",
       " 878        methodology\n",
       " 965        methodology\n",
       " 986      miscellaneous\n",
       " 1068     miscellaneous\n",
       " 1470     playing-games\n",
       " 1657     miscellaneous\n",
       " 1680     miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224     computer-vision\n",
       " 850         methodology\n",
       " 867         methodology\n",
       " 937         methodology\n",
       " 947         methodology\n",
       " 1457      playing-games\n",
       " 1458      playing-games\n",
       " 1464      playing-games\n",
       " 1470      playing-games\n",
       " 1519             robots\n",
       " 1835      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1         adversarial\n",
       " 850       methodology\n",
       " 867       methodology\n",
       " 937       methodology\n",
       " 965       methodology\n",
       " 1457    playing-games\n",
       " 1469    playing-games\n",
       " 1470    playing-games\n",
       " 1477    playing-games\n",
       " Name: area, dtype: object,\n",
       " 848       methodology\n",
       " 850       methodology\n",
       " 861       methodology\n",
       " 867       methodology\n",
       " 901       methodology\n",
       " 946       methodology\n",
       " 947       methodology\n",
       " 1469    playing-games\n",
       " 1511           robots\n",
       " 1517           robots\n",
       " Name: area, dtype: object,\n",
       " 224     computer-vision\n",
       " 848         methodology\n",
       " 861         methodology\n",
       " 878         methodology\n",
       " 915         methodology\n",
       " 1541             speech\n",
       " 1550             speech\n",
       " 1558             speech\n",
       " 1586             speech\n",
       " Name: area, dtype: object,\n",
       " 405     computer-vision\n",
       " 431     computer-vision\n",
       " 756             medical\n",
       " 878         methodology\n",
       " 1105              music\n",
       " 1539             speech\n",
       " 1550             speech\n",
       " 1552             speech\n",
       " 1554             speech\n",
       " 1558             speech\n",
       " 1585             speech\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 19              audio\n",
       " 878       methodology\n",
       " 953       methodology\n",
       " 1550           speech\n",
       " 1554           speech\n",
       " 1558           speech\n",
       " 1562           speech\n",
       " 1585           speech\n",
       " 1678    miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 224     computer-vision\n",
       " 249     computer-vision\n",
       " 297     computer-vision\n",
       " 306     computer-vision\n",
       " 449     computer-vision\n",
       " 848         methodology\n",
       " 861         methodology\n",
       " 878         methodology\n",
       " 915         methodology\n",
       " 947         methodology\n",
       " 1541             speech\n",
       " 1550             speech\n",
       " 1586             speech\n",
       " 1645      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 583                          graphs\n",
       " 587                          graphs\n",
       " 602                          graphs\n",
       " 607                          graphs\n",
       " 629                  knowledge-base\n",
       " 864                     methodology\n",
       " 898                     methodology\n",
       " 922                     methodology\n",
       " 967                     methodology\n",
       " 1199    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1650                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 22                audio\n",
       " 25                audio\n",
       " 209     computer-vision\n",
       " 602              graphs\n",
       " 629      knowledge-base\n",
       " 837         methodology\n",
       " 898         methodology\n",
       " 1068      miscellaneous\n",
       " 1746      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 245     computer-vision\n",
       " 454     computer-vision\n",
       " 867         methodology\n",
       " 1469      playing-games\n",
       " 1477      playing-games\n",
       " 1644      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 224     computer-vision\n",
       " 878         methodology\n",
       " 884         methodology\n",
       " 947         methodology\n",
       " 1550             speech\n",
       " 1573             speech\n",
       " 1645      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 79      computer-vision\n",
       " 86      computer-vision\n",
       " 105     computer-vision\n",
       " 431     computer-vision\n",
       " 615              graphs\n",
       " 849         methodology\n",
       " 1007      miscellaneous\n",
       " 1554             speech\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 431                 computer-vision\n",
       " 602                          graphs\n",
       " 629                  knowledge-base\n",
       " 644                  knowledge-base\n",
       " 878                     methodology\n",
       " 947                     methodology\n",
       " 948                     methodology\n",
       " 1164    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1190    natural-language-processing\n",
       " 1197    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1286    natural-language-processing\n",
       " 1461                  playing-games\n",
       " 1465                  playing-games\n",
       " 1470                  playing-games\n",
       " 1492                  playing-games\n",
       " 1648                  miscellaneous\n",
       " 1772                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 1155    natural-language-processing\n",
       " 1199    natural-language-processing\n",
       " 1341    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1650                  miscellaneous\n",
       " 1857                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 201     computer-vision\n",
       " 225     computer-vision\n",
       " 306     computer-vision\n",
       " 431     computer-vision\n",
       " 615              graphs\n",
       " 716             medical\n",
       " 811             medical\n",
       " 828             medical\n",
       " 841         methodology\n",
       " 862         methodology\n",
       " 958         methodology\n",
       " 1646      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1746      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1826      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 167     computer-vision\n",
       " 209     computer-vision\n",
       " 297     computer-vision\n",
       " 449     computer-vision\n",
       " 1550             speech\n",
       " 1569             speech\n",
       " 1656      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1688      miscellaneous\n",
       " 1706      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 24                            audio\n",
       " 35                            audio\n",
       " 167                 computer-vision\n",
       " 301                 computer-vision\n",
       " 416                 computer-vision\n",
       " 445                 computer-vision\n",
       " 837                     methodology\n",
       " 878                     methodology\n",
       " 1155    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1254    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1658                  miscellaneous\n",
       " 1659                  miscellaneous\n",
       " 1678                  miscellaneous\n",
       " 1685                  miscellaneous\n",
       " 1812                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 209     computer-vision\n",
       " 564     computer-vision\n",
       " 613              graphs\n",
       " 741             medical\n",
       " 837         methodology\n",
       " 878         methodology\n",
       " 1026      miscellaneous\n",
       " 1087      miscellaneous\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1665      miscellaneous\n",
       " 1692      miscellaneous\n",
       " 1739      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 143     computer-vision\n",
       " 225     computer-vision\n",
       " 330     computer-vision\n",
       " 431     computer-vision\n",
       " 477     computer-vision\n",
       " 558     computer-vision\n",
       " 571     computer-vision\n",
       " 756             medical\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1764      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 146     computer-vision\n",
       " 165     computer-vision\n",
       " 167     computer-vision\n",
       " 245     computer-vision\n",
       " 297     computer-vision\n",
       " 322     computer-vision\n",
       " 449     computer-vision\n",
       " 454     computer-vision\n",
       " 488     computer-vision\n",
       " 542     computer-vision\n",
       " 1649      miscellaneous\n",
       " 1658      miscellaneous\n",
       " 1709      miscellaneous\n",
       " 1763      miscellaneous\n",
       " 1801      miscellaneous\n",
       " 1811      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 255     computer-vision\n",
       " 431     computer-vision\n",
       " 756             medical\n",
       " 852         methodology\n",
       " 947         methodology\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1685      miscellaneous\n",
       " 1686      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 472                 computer-vision\n",
       " 602                          graphs\n",
       " 629                  knowledge-base\n",
       " 878                     methodology\n",
       " 925                     methodology\n",
       " 937                     methodology\n",
       " 947                     methodology\n",
       " 953                     methodology\n",
       " 1155    natural-language-processing\n",
       " 1255    natural-language-processing\n",
       " 1369    natural-language-processing\n",
       " 1415    natural-language-processing\n",
       " 1458                  playing-games\n",
       " 1461                  playing-games\n",
       " 1465                  playing-games\n",
       " 1470                  playing-games\n",
       " 1492                  playing-games\n",
       " 1567                         speech\n",
       " 1650                  miscellaneous\n",
       " 1720                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 42                    computer-code\n",
       " 255                 computer-vision\n",
       " 861                     methodology\n",
       " 878                     methodology\n",
       " 1119    natural-language-processing\n",
       " 1138    natural-language-processing\n",
       " 1145    natural-language-processing\n",
       " 1303    natural-language-processing\n",
       " 1357    natural-language-processing\n",
       " 1366    natural-language-processing\n",
       " 1411    natural-language-processing\n",
       " 1678                  miscellaneous\n",
       " 1685                  miscellaneous\n",
       " 1686                  miscellaneous\n",
       " 1724                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 17                audio\n",
       " 35                audio\n",
       " 147     computer-vision\n",
       " 169     computer-vision\n",
       " 224     computer-vision\n",
       " 245     computer-vision\n",
       " 261     computer-vision\n",
       " 335     computer-vision\n",
       " 337     computer-vision\n",
       " 454     computer-vision\n",
       " 562     computer-vision\n",
       " 602              graphs\n",
       " 629      knowledge-base\n",
       " 644      knowledge-base\n",
       " 878         methodology\n",
       " 1671      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 183     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 611              graphs\n",
       " 1532             robots\n",
       " 1653      miscellaneous\n",
       " 1667      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1780      miscellaneous\n",
       " 1863      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 716                         medical\n",
       " 852                     methodology\n",
       " 861                     methodology\n",
       " 878                     methodology\n",
       " 879                     methodology\n",
       " 932                     methodology\n",
       " 947                     methodology\n",
       " 962                     methodology\n",
       " 1365    natural-language-processing\n",
       " 1470                  playing-games\n",
       " 1645                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 309     computer-vision\n",
       " 344     computer-vision\n",
       " 405     computer-vision\n",
       " 431     computer-vision\n",
       " 542     computer-vision\n",
       " 615              graphs\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1731      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 2           adversarial\n",
       " 209     computer-vision\n",
       " 841         methodology\n",
       " 898         methodology\n",
       " 958         methodology\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1739      miscellaneous\n",
       " 1741      miscellaneous\n",
       " 1746      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 850       methodology\n",
       " 867       methodology\n",
       " 947       methodology\n",
       " 1457    playing-games\n",
       " 1467    playing-games\n",
       " 1470    playing-games\n",
       " 1487    playing-games\n",
       " 1489    playing-games\n",
       " Name: area, dtype: object,\n",
       " 100     computer-vision\n",
       " 123     computer-vision\n",
       " 183     computer-vision\n",
       " 219     computer-vision\n",
       " 297     computer-vision\n",
       " 359     computer-vision\n",
       " 449     computer-vision\n",
       " 537     computer-vision\n",
       " 1532             robots\n",
       " 1678      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1743      miscellaneous\n",
       " 1754      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 947                     methodology\n",
       " 958                     methodology\n",
       " 1028                  miscellaneous\n",
       " 1365    natural-language-processing\n",
       " 1550                         speech\n",
       " 1687                  miscellaneous\n",
       " 1746                  miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 431     computer-vision\n",
       " 477     computer-vision\n",
       " 515     computer-vision\n",
       " 537     computer-vision\n",
       " 571     computer-vision\n",
       " 756             medical\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 147     computer-vision\n",
       " 224     computer-vision\n",
       " 249     computer-vision\n",
       " 261     computer-vision\n",
       " 322     computer-vision\n",
       " 335     computer-vision\n",
       " 449     computer-vision\n",
       " 878         methodology\n",
       " 1076      miscellaneous\n",
       " 1622        time-series\n",
       " 1646      miscellaneous\n",
       " 1728      miscellaneous\n",
       " 1752      miscellaneous\n",
       " 1856      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 197     computer-vision\n",
       " 277     computer-vision\n",
       " 288     computer-vision\n",
       " 297     computer-vision\n",
       " 322     computer-vision\n",
       " 361     computer-vision\n",
       " 424     computer-vision\n",
       " 449     computer-vision\n",
       " 454     computer-vision\n",
       " 531     computer-vision\n",
       " 540     computer-vision\n",
       " 573     computer-vision\n",
       " 1524             robots\n",
       " 1526             robots\n",
       " 1653      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1714      miscellaneous\n",
       " 1751      miscellaneous\n",
       " 1763      miscellaneous\n",
       " 1780      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 405     computer-vision\n",
       " 431     computer-vision\n",
       " 477     computer-vision\n",
       " 537     computer-vision\n",
       " 571     computer-vision\n",
       " 756             medical\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1731      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 225     computer-vision\n",
       " 231     computer-vision\n",
       " 431     computer-vision\n",
       " 477     computer-vision\n",
       " 515     computer-vision\n",
       " 542     computer-vision\n",
       " 571     computer-vision\n",
       " 756             medical\n",
       " 898         methodology\n",
       " 1642      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1678      miscellaneous\n",
       " 1768      miscellaneous\n",
       " 1858      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 850       methodology\n",
       " 867       methodology\n",
       " 947       methodology\n",
       " 1002    miscellaneous\n",
       " 1470    playing-games\n",
       " 1477    playing-games\n",
       " 1487    playing-games\n",
       " 1489    playing-games\n",
       " Name: area, dtype: object,\n",
       " 123     computer-vision\n",
       " 146     computer-vision\n",
       " 225     computer-vision\n",
       " 277     computer-vision\n",
       " 297     computer-vision\n",
       " 322     computer-vision\n",
       " 361     computer-vision\n",
       " 424     computer-vision\n",
       " 449     computer-vision\n",
       " 454     computer-vision\n",
       " 488     computer-vision\n",
       " 540     computer-vision\n",
       " 573     computer-vision\n",
       " 1526             robots\n",
       " 1653      miscellaneous\n",
       " 1699      miscellaneous\n",
       " 1751      miscellaneous\n",
       " 1780      miscellaneous\n",
       " 1864      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 146     computer-vision\n",
       " 249     computer-vision\n",
       " 256     computer-vision\n",
       " 297     computer-vision\n",
       " 300     computer-vision\n",
       " 431     computer-vision\n",
       " 449     computer-vision\n",
       " 540     computer-vision\n",
       " 564     computer-vision\n",
       " 867         methodology\n",
       " 906         methodology\n",
       " 923         methodology\n",
       " 962         methodology\n",
       " 1642      miscellaneous\n",
       " 1645      miscellaneous\n",
       " 1648      miscellaneous\n",
       " 1731      miscellaneous\n",
       " 1751      miscellaneous\n",
       " Name: area, dtype: object,\n",
       " 42                    computer-code\n",
       " 613                          graphs\n",
       " 878                     methodology\n",
       " 1119    natural-language-processing\n",
       " 1137    natural-language-processing\n",
       " 1138    natural-language-processing\n",
       " 1159    natural-language-processing\n",
       " 1167    natural-language-processing\n",
       " 1169    natural-language-processing\n",
       " 1213    natural-language-processing\n",
       " 1224    natural-language-processing\n",
       " 1250    natural-language-processing\n",
       " 1333    natural-language-processing\n",
       " 1370    natural-language-processing\n",
       " 1372    natural-language-processing\n",
       " 1411    natural-language-processing\n",
       " 1436    natural-language-processing\n",
       " Name: area, dtype: object]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "[area_grouped_tasks['area'][\n",
    "        area_grouped_tasks['task'].isin(ts)]\n",
    "    for ts in retrieval_results_with_area_test['retrieved_labels']\n",
    "    ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-9d00c8c9805a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mretrieval_results_with_area_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marea_grouped_tasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_query_level_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'task'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mretrieved_areas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretrieval_results_with_area_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retrieved_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_areas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marea_grouped_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mretrieved_areas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#retrieval_results_with_area_test['retrieved_areas'] = retrieved_areas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-201-a280375c2241>\u001b[0m in \u001b[0;36mget_areas\u001b[0;34m(area_grouped_tasks, tasks)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_areas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marea_grouped_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     return tasks.apply(\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         area_grouped_tasks['area'][\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "_query_level_results = raw_readme_area_results\n",
    "retrieval_results_with_area_test = area_grouped_tasks.merge(_query_level_results, left_on='task', right_index=True)\n",
    "\n",
    "retrieved_areas = retrieval_results_with_area_test['retrieved_labels'].apply(partial(get_areas, area_grouped_tasks))\n",
    "retrieved_areas\n",
    "#retrieval_results_with_area_test['retrieved_areas'] = retrieved_areas\n",
    "#is_area_retrieved = retrieval_results_with_area_test.apply(lambda row: row['area'] in row['retrieved_areas'][:10], axis=1)\n",
    "#num_area_retrieved = retrieval_results_with_area_test.apply(lambda row: len(np.where(row['area'] == np.array(row['retrieved_areas'])[:10])[0]), axis=1)\n",
    "#area_idx = retrieval_results_with_area_test.apply(lambda row: get_idx_or_inf(np.array(row['retrieved_areas']), row['area']), axis=1)\n",
    "#retrieval_results_with_area_test['area_recalled'] = is_area_retrieved\n",
    "#retrieval_results_with_area_test['area_position'] = area_idx\n",
    "#retrieval_results_with_area_test['num_area_recalled'] = num_area_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adversarial defense\n",
      "adversarial defense\n",
      "self supervised learning\n",
      "adversarial defense\n",
      "adversarial defense\n",
      "adversarial defense\n",
      "robust classification\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speaker verification\n",
      "adversarial attack\n",
      "person re identification\n",
      "adversarial attack\n",
      "image retrieval\n",
      "atari games\n",
      "efficient exploration\n",
      "binarization\n",
      "robust classification\n",
      "interpretable machine learning\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "audio classification\n",
      "adversarial defense\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speaker verification\n",
      "noise estimation\n",
      "robust classification\n",
      "lesion segmentation\n",
      "two sample testing\n",
      "two sample testing\n",
      "style transfer\n",
      "audio generation\n",
      "speech synthesis\n",
      "style transfer\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "text to speech synthesis\n",
      "image captioning\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "speech enhancement\n",
      "style transfer\n",
      "speech enhancement\n",
      "face recognition\n",
      "heterogeneous face recognition\n",
      "dependency parsing\n",
      "semantic parsing\n",
      "atari games\n",
      "q learning\n",
      "extractive text summarization\n",
      "text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "neural architecture search\n",
      "neural architecture search\n",
      "neural architecture search\n",
      "natural language inference\n",
      "natural language understanding\n",
      "semantic parsing\n",
      "text to sql\n",
      "text to sql\n",
      "q learning\n",
      "atari games\n",
      "board games\n",
      "multi task learning\n",
      "reconstruction\n",
      "classification\n",
      "point cloud classification\n",
      "reconstruction\n",
      "image super resolution\n",
      "super resolution\n",
      "image inpainting\n",
      "crowd counting\n",
      "density estimation\n",
      "multi task learning\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "point cloud classification\n",
      "robust classification\n",
      "sentence classification\n",
      "sentence classification\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "nuclear segmentation\n",
      "denoising\n",
      "image inpainting\n",
      "image restoration\n",
      "image to image translation\n",
      "super resolution\n",
      "accuracy metrics\n",
      "neural network compression\n",
      "rectification\n",
      "network pruning\n",
      "network pruning\n",
      "lesion segmentation\n",
      "point cloud classification\n",
      "robust classification\n",
      "sentence classification\n",
      "sentence classification\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "nuclear segmentation\n",
      "denoising\n",
      "image inpainting\n",
      "image restoration\n",
      "image to image translation\n",
      "super resolution\n",
      "accuracy metrics\n",
      "neural network compression\n",
      "rectification\n",
      "network pruning\n",
      "network pruning\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "contour detection\n",
      "edge detection\n",
      "multi object tracking\n",
      "object detection from stereo images\n",
      "multi object tracking\n",
      "large scale person re identification\n",
      "multi object tracking\n",
      "multiple people tracking\n",
      "object tracking\n",
      "online multi object tracking\n",
      "person re identification\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "contour detection\n",
      "edge detection\n",
      "multi object tracking\n",
      "object detection from stereo images\n",
      "multi object tracking\n",
      "large scale person re identification\n",
      "multi object tracking\n",
      "multiple people tracking\n",
      "object tracking\n",
      "online multi object tracking\n",
      "person re identification\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "compressive sensing\n",
      "denoising\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "dictionary learning\n",
      "mri reconstruction\n",
      "image inpainting\n",
      "reconstruction\n",
      "shape representation\n",
      "image denoising\n",
      "model compression\n",
      "neural network compression\n",
      "metric learning\n",
      "person re identification\n",
      "content based image retrieval\n",
      "image retrieval\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "text matching\n",
      "text matching\n",
      "image retrieval\n",
      "structure from motion\n",
      "cross modal retrieval\n",
      "image retrieval\n",
      "on the fly sketch based image retrieval\n",
      "sketch based image retrieval\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multi object tracking\n",
      "multiple people tracking\n",
      "object tracking\n",
      "online multi object tracking\n",
      "person re identification\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "face alignment\n",
      "super resolution\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "density estimation\n",
      "outlier detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "style transfer\n",
      "face alignment\n",
      "super resolution\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "density estimation\n",
      "outlier detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "style transfer\n",
      "face alignment\n",
      "super resolution\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "density estimation\n",
      "outlier detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "style transfer\n",
      "lesion segmentation\n",
      "hyperparameter optimization\n",
      "multi task learning\n",
      "neural network compression\n",
      "neural architecture search\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image inpainting\n",
      "interpretable machine learning\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "two sample testing\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "human pose estimation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "human pose estimation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "human pose estimation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "activity recognition\n",
      "emotion recognition\n",
      "multi task learning\n",
      "speech emotion recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "speech denoising\n",
      "speech enhancement\n",
      "speaker verification\n",
      "text independent speaker verification\n",
      "person re identification\n",
      "person re identification\n",
      "graph matching\n",
      "person re identification\n",
      "person re identification\n",
      "metric learning\n",
      "person re identification\n",
      "person re identification\n",
      "person re identification\n",
      "person re identification\n",
      "person re identification\n",
      "image retrieval\n",
      "metric learning\n",
      "person re identification\n",
      "style transfer\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "hyperparameter optimization\n",
      "style transfer\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "style transfer\n",
      "deblurring\n",
      "denoising\n",
      "image reconstruction\n",
      "image super resolution\n",
      "lossy compression artifact reduction\n",
      "super resolution\n",
      "hyperparameter optimization\n",
      "image manipulation\n",
      "style transfer\n",
      "self supervised image classification\n",
      "self supervised learning\n",
      "semi supervised image classification\n",
      "interpretable machine learning\n",
      "atari games\n",
      "two sample testing\n",
      "two sample testing\n",
      "multi task learning\n",
      "combinatorial optimization\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "traveling salesman problem\n",
      "one shot learning\n",
      "neural architecture search\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "rotated mnist\n",
      "face alignment\n",
      "face recognition\n",
      "face reconstruction\n",
      "face to face translation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "facial expression translation\n",
      "image to image translation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "contour detection\n",
      "edge detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "abnormal event detection in video\n",
      "outlier detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "scene text\n",
      "scene text recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "interpretable machine learning\n",
      "lane detection\n",
      "self driving cars\n",
      "multi task learning\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "rotated mnist\n",
      "lesion segmentation\n",
      "interpretable machine learning\n",
      "atari games\n",
      "combinatorial optimization\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "traveling salesman problem\n",
      "one shot learning\n",
      "dimensionality reduction\n",
      "face recognition\n",
      "few shot learning\n",
      "few shot regression\n",
      "meta learning\n",
      "variational inference\n",
      "few shot learning\n",
      "meta learning\n",
      "omniglot\n",
      "omniglot\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "rectification\n",
      "person re identification\n",
      "interpretable machine learning\n",
      "lesion segmentation\n",
      "image inpainting\n",
      "image super resolution\n",
      "super resolution\n",
      "community detection\n",
      "graph classification\n",
      "image retrieval\n",
      "loop closure detection\n",
      "simultaneous localization and mapping\n",
      "outlier detection\n",
      "multi task learning\n",
      "shadow detection\n",
      "shadow removal\n",
      "image inpainting\n",
      "boundary detection\n",
      "edge detection\n",
      "boundary detection\n",
      "edge detection\n",
      "boundary detection\n",
      "edge detection\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "edge computing\n",
      "human object interaction detection\n",
      "object detection in aerial images\n",
      "one shot object detection\n",
      "real time object detection\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "scene text\n",
      "scene text detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "edge computing\n",
      "human object interaction detection\n",
      "object detection in aerial images\n",
      "one shot object detection\n",
      "real time object detection\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "scene text\n",
      "scene text detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "image inpainting\n",
      "imputation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "edge computing\n",
      "human object interaction detection\n",
      "object detection in aerial images\n",
      "one shot object detection\n",
      "real time object detection\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "scene text\n",
      "scene text detection\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "image reconstruction\n",
      "image super resolution\n",
      "super resolution\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "human object interaction detection\n",
      "object reconstruction\n",
      "reconstruction\n",
      "object reconstruction\n",
      "face detection\n",
      "face recognition\n",
      "question generation\n",
      "visual dialog\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "car racing\n",
      "saliency detection\n",
      "small data image classification\n",
      "zero shot learning\n",
      "crowd counting\n",
      "image retrieval\n",
      "learning to rank\n",
      "fine grained image classification\n",
      "semantic composition\n",
      "person re identification\n",
      "person search\n",
      "video retrieval\n",
      "omniglot\n",
      "video classification\n",
      "network pruning\n",
      "adversarial defense\n",
      "robust classification\n",
      "image super resolution\n",
      "super resolution\n",
      "audio classification\n",
      "facial landmark detection\n",
      "distributed optimization\n",
      "neural architecture search\n",
      "style transfer\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "eeg\n",
      "knowledge distillation\n",
      "seizure detection\n",
      "graph classification\n",
      "graph classification\n",
      "multi label classification\n",
      "graph classification\n",
      "graph classification\n",
      "few shot learning\n",
      "meta learning\n",
      "graph classification\n",
      "metric learning\n",
      "graph clustering\n",
      "graph embedding\n",
      "link prediction\n",
      "graph classification\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image inpainting\n",
      "scene text\n",
      "scene text detection\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "face recognition\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "deblurring\n",
      "denoising\n",
      "image reconstruction\n",
      "image super resolution\n",
      "lossy compression artifact reduction\n",
      "super resolution\n",
      "saliency detection\n",
      "abnormal event detection in video\n",
      "outlier detection\n",
      "saliency detection\n",
      "rgb d salient object detection\n",
      "saliency detection\n",
      "lexical entailment\n",
      "relation classification\n",
      "saliency detection\n",
      "arrhythmia detection\n",
      "ecg classification\n",
      "time series classification\n",
      "saliency detection\n",
      "outlier detection\n",
      "multi task learning\n",
      "pneumonia detection\n",
      "multi label classification\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "self supervised learning\n",
      "multi label classification\n",
      "few shot image classification\n",
      "few shot learning\n",
      "generalized few shot classification\n",
      "meta learning\n",
      "two sample testing\n",
      "multi agent reinforcement learning\n",
      "starcraft\n",
      "starcraft ii\n",
      "super resolution\n",
      "few shot image classification\n",
      "few shot learning\n",
      "generalized few shot classification\n",
      "meta learning\n",
      "meta learning\n",
      "graph classification\n",
      "graph classification\n",
      "metric learning\n",
      "graph classification\n",
      "link prediction\n",
      "community detection\n",
      "graph classification\n",
      "meta learning\n",
      "relation extraction\n",
      "graph classification\n",
      "graph similarity\n",
      "meta learning\n",
      "stochastic optimization\n",
      "graph classification\n",
      "graph regression\n",
      "graph classification\n",
      "matrix completion\n",
      "graph classification\n",
      "metric learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "relational pattern learning\n",
      "relational reasoning\n",
      "graph classification\n",
      "automl\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "link prediction\n",
      "few shot learning\n",
      "meta learning\n",
      "network embedding\n",
      "multi class classification\n",
      "network embedding\n",
      "node clustering\n",
      "lexical entailment\n",
      "relation classification\n",
      "reconstruction\n",
      "patch matching\n",
      "document classification\n",
      "graph classification\n",
      "metric learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "relational pattern learning\n",
      "relational reasoning\n",
      "graph classification\n",
      "automl\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "link prediction\n",
      "few shot learning\n",
      "meta learning\n",
      "network embedding\n",
      "multi class classification\n",
      "network embedding\n",
      "node clustering\n",
      "lexical entailment\n",
      "relation classification\n",
      "reconstruction\n",
      "patch matching\n",
      "document classification\n",
      "graph embedding\n",
      "link prediction\n",
      "node clustering\n",
      "graph construction\n",
      "knowledge graph completion\n",
      "link prediction\n",
      "meta learning\n",
      "natural language inference\n",
      "sentence embeddings\n",
      "knowledge distillation\n",
      "knowledge distillation\n",
      "knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "omniglot\n",
      "link prediction\n",
      "graph classification\n",
      "entity embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "graph embedding\n",
      "link prediction\n",
      "node clustering\n",
      "graph construction\n",
      "knowledge graph completion\n",
      "link prediction\n",
      "meta learning\n",
      "natural language inference\n",
      "sentence embeddings\n",
      "knowledge distillation\n",
      "knowledge distillation\n",
      "knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "omniglot\n",
      "link prediction\n",
      "graph classification\n",
      "entity embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "two sample testing\n",
      "two sample testing\n",
      "graph classification\n",
      "few shot learning\n",
      "meta learning\n",
      "lesion segmentation\n",
      "pedestrian detection\n",
      "self driving cars\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "graph classification\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "neural architecture search\n",
      "node classification\n",
      "reconstruction\n",
      "patch matching\n",
      "q learning\n",
      "learning to rank\n",
      "q learning\n",
      "neural architecture search\n",
      "variable selection\n",
      "multi agent reinforcement learning\n",
      "image retrieval\n",
      "dictionary learning\n",
      "zero shot learning\n",
      "learning to rank\n",
      "lesion segmentation\n",
      "lesion classification\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "medical diagnosis\n",
      "out of distribution detection\n",
      "lesion classification\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "reconstruction\n",
      "lesion segmentation\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "mortality prediction\n",
      "interpretable machine learning\n",
      "interpretable machine learning\n",
      "knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "relational reasoning\n",
      "atari games\n",
      "document classification\n",
      "network pruning\n",
      "network pruning\n",
      "atari games\n",
      "knowledge graphs\n",
      "link prediction\n",
      "document classification\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "lesion segmentation\n",
      "lesion classification\n",
      "lesion segmentation\n",
      "lesion classification\n",
      "lesion segmentation\n",
      "reconstruction\n",
      "document classification\n",
      "medical diagnosis\n",
      "out of distribution detection\n",
      "multi task learning\n",
      "two sample testing\n",
      "two sample testing\n",
      "extreme multi label classification\n",
      "multi label classification\n",
      "multi label learning\n",
      "knowledge distillation\n",
      "hyperparameter optimization\n",
      "lesion segmentation\n",
      "semi supervised image classification\n",
      "hyperparameter optimization\n",
      "semi supervised image classification\n",
      "network pruning\n",
      "neural architecture search\n",
      "neural network compression\n",
      "network pruning\n",
      "model compression\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "neural network compression\n",
      "model compression\n",
      "model compression\n",
      "network pruning\n",
      "neural architecture search\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "atari games\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "fairness\n",
      "few shot learning\n",
      "meta learning\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "zero shot learning\n",
      "atari games\n",
      "few shot learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "hierarchical structure\n",
      "meta learning\n",
      "omniglot\n",
      "few shot learning\n",
      "meta learning\n",
      "omniglot\n",
      "incremental learning\n",
      "zero shot learning\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "one shot learning\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "continual learning\n",
      "meta learning\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "q learning\n",
      "q learning\n",
      "zero shot learning\n",
      "atari games\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "atari games\n",
      "q learning\n",
      "multi goal reinforcement learning\n",
      "multi goal reinforcement learning\n",
      "active learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "starcraft ii\n",
      "zero shot learning\n",
      "dota 2\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "starcraft\n",
      "multi agent reinforcement learning\n",
      "starcraft ii\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "auxiliary learning\n",
      "few shot learning\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "auxiliary learning\n",
      "meta learning\n",
      "multi task learning\n",
      "federated learning\n",
      "multi task learning\n",
      "federated learning\n",
      "knowledge distillation\n",
      "person re identification\n",
      "bayesian inference\n",
      "meta learning\n",
      "variational inference\n",
      "active learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "inductive knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "graph construction\n",
      "knowledge graph completion\n",
      "link prediction\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "person re identification\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "atari games\n",
      "atari games\n",
      "one shot learning\n",
      "continuous control\n",
      "q learning\n",
      "one shot learning\n",
      "few shot learning\n",
      "meta learning\n",
      "omniglot\n",
      "hierarchical structure\n",
      "meta learning\n",
      "omniglot\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "automl\n",
      "neural architecture search\n",
      "model compression\n",
      "model compression\n",
      "learning to rank\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "interpretable machine learning\n",
      "dimensionality reduction\n",
      "face recognition\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "model compression\n",
      "model compression\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "hierarchical structure\n",
      "meta learning\n",
      "neural architecture search\n",
      "continuous control\n",
      "q learning\n",
      "distributed computing\n",
      "distributed optimization\n",
      "hyperparameter optimization\n",
      "distributed computing\n",
      "hyperparameter optimization\n",
      "distributed computing\n",
      "hyperparameter optimization\n",
      "automl\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "learning to rank\n",
      "outlier detection\n",
      "outlier detection\n",
      "image to image translation\n",
      "super resolution\n",
      "fraud detection\n",
      "meta learning\n",
      "metric learning\n",
      "person re identification\n",
      "scene text\n",
      "scene text detection\n",
      "adversarial attack\n",
      "person re identification\n",
      "speaker verification\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "meta learning\n",
      "meta learning\n",
      "atari games\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "two sample testing\n",
      "multi agent reinforcement learning\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "computed tomography (ct)\n",
      "image reconstruction\n",
      "super resolution\n",
      "super resolution\n",
      "incremental learning\n",
      "speech enhancement\n",
      "lane detection\n",
      "multi task learning\n",
      "style transfer\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "music style transfer\n",
      "self supervised learning\n",
      "style transfer\n",
      "image to image translation\n",
      "multi label classification\n",
      "density estimation\n",
      "model selection\n",
      "photometric redshift estimation\n",
      "image denoising\n",
      "physical attribute prediction\n",
      "few shot learning\n",
      "meta learning\n",
      "automl\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "link prediction\n",
      "learning to rank\n",
      "image retrieval\n",
      "metric learning\n",
      "graph classification\n",
      "metric learning\n",
      "part of speech tagging\n",
      "unsupervised part of speech tagging\n",
      "atari games\n",
      "montezuma's revenge\n",
      "meta learning\n",
      "multi task learning\n",
      "image retrieval\n",
      "interpretable machine learning\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "interpretable machine learning\n",
      "two sample testing\n",
      "two sample testing\n",
      "network pruning\n",
      "distributed optimization\n",
      "neural architecture search\n",
      "one shot learning\n",
      "model compression\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "face detection\n",
      "face identification\n",
      "face recognition\n",
      "knowledge distillation\n",
      "model compression\n",
      "speech enhancement\n",
      "model compression\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face anti spoofing\n",
      "face recognition\n",
      "image inpainting\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "face detection\n",
      "face identification\n",
      "face recognition\n",
      "knowledge distillation\n",
      "model compression\n",
      "speech enhancement\n",
      "model compression\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face anti spoofing\n",
      "face recognition\n",
      "image inpainting\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "image compression\n",
      "ms ssim\n",
      "neural architecture search\n",
      "ssim\n",
      "cross modal retrieval\n",
      "image retrieval\n",
      "text matching\n",
      "one shot learning\n",
      "multi agent reinforcement learning\n",
      "starcraft\n",
      "starcraft ii\n",
      "meta learning\n",
      "weather forecasting\n",
      "atari games\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "few shot learning\n",
      "program induction\n",
      "multi armed bandits\n",
      "active learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "federated learning\n",
      "multi task learning\n",
      "few shot learning\n",
      "meta learning\n",
      "atari games\n",
      "fairness\n",
      "few shot learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi goal reinforcement learning\n",
      "inductive logic programming\n",
      "extreme multi label classification\n",
      "multi label classification\n",
      "multi label learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "link prediction\n",
      "inductive logic programming\n",
      "natural language understanding\n",
      "relational reasoning\n",
      "systematic generalization\n",
      "graph embedding\n",
      "knowledge base completion\n",
      "knowledge graph embedding\n",
      "knowledge graph embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "knowledge base completion\n",
      "natural language inference\n",
      "meta learning\n",
      "person re identification\n",
      "one shot learning\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "dictionary learning\n",
      "one shot learning\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "omniglot\n",
      "one shot learning\n",
      "omniglot\n",
      "one shot learning\n",
      "omniglot\n",
      "one shot learning\n",
      "few shot learning\n",
      "meta learning\n",
      "active learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "zero shot learning\n",
      "meta learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "word sense disambiguation\n",
      "meta learning\n",
      "recommendation systems\n",
      "knowledge distillation\n",
      "open domain dialog\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "semantic parsing\n",
      "meta learning\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "learning to rank\n",
      "atari games\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "meta learning\n",
      "few shot image classification\n",
      "meta learning\n",
      "incremental learning\n",
      "incremental learning\n",
      "few shot learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "zero shot learning\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "human pose estimation\n",
      "gaze estimation\n",
      "pose estimation\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "reconstruction\n",
      "single view  reconstruction\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "dependency parsing\n",
      "semantic parsing\n",
      "atari games\n",
      "q learning\n",
      "data visualization\n",
      "style transfer\n",
      "interpretable machine learning\n",
      "automl\n",
      "neural architecture search\n",
      "computed tomography (ct)\n",
      "image reconstruction\n",
      "super resolution\n",
      "open set learning\n",
      "robust classification\n",
      "one shot learning\n",
      "lane detection\n",
      "self driving cars\n",
      "automl\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "neural network compression\n",
      "distributed computing\n",
      "hyperparameter optimization\n",
      "q learning\n",
      "rectification\n",
      "distributed computing\n",
      "hyperparameter optimization\n",
      "distributed computing\n",
      "hyperparameter optimization\n",
      "q learning\n",
      "q learning\n",
      "cross modal  person re identification\n",
      "person re identification\n",
      "image retrieval\n",
      "structure from motion\n",
      "image retrieval\n",
      "structure from motion\n",
      "information retrieval\n",
      "self supervised learning\n",
      "zero shot learning\n",
      "multi label classification\n",
      "natural language understanding\n",
      "fake news detection\n",
      "misinformation\n",
      "rumour detection\n",
      "zero shot learning\n",
      "neural network compression\n",
      "content based image retrieval\n",
      "image retrieval\n",
      "face recognition\n",
      "multi armed bandits\n",
      "multi armed bandits\n",
      "multi armed bandits\n",
      "meta learning\n",
      "multi armed bandits\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi label classification\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "multi armed bandits\n",
      "session based recommendations\n",
      "learning to rank\n",
      "fake news detection\n",
      "sentence classification\n",
      "click through rate prediction\n",
      "click through rate prediction\n",
      "self driving cars\n",
      "style transfer\n",
      "covid 19 diagnosis\n",
      "covid 19 image segmentation\n",
      "next basket recommendation\n",
      "session based recommendations\n",
      "few shot image classification\n",
      "few shot learning\n",
      "fine grained opinion analysis\n",
      "multi task learning\n",
      "learning to rank\n",
      "lemmatization\n",
      "multi task learning\n",
      "tokenization\n",
      "chinese word segmentation\n",
      "task oriented dialogue systems\n",
      "part of speech tagging\n",
      "natural language inference\n",
      "natural language understanding\n",
      "grammatical error detection\n",
      "sentence classification\n",
      "morphological inflection\n",
      "transliteration\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "outlier detection\n",
      "fraud detection\n",
      "speaker verification\n",
      "image to image translation\n",
      "super resolution\n",
      "outlier detection\n",
      "hyperparameter optimization\n",
      "automl\n",
      "neural architecture search\n",
      "interpretable machine learning\n",
      "fake news detection\n",
      "misinformation\n",
      "rumour detection\n",
      "zero shot learning\n",
      "out of distribution detection\n",
      "reading comprehension\n",
      "face hallucination\n",
      "image reconstruction\n",
      "super resolution\n",
      "neural architecture search\n",
      "distractor generation\n",
      "reading comprehension\n",
      "distractor generation\n",
      "reading comprehension\n",
      "stance detection\n",
      "reading comprehension\n",
      "rumour detection\n",
      "stance classification\n",
      "stance detection\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "unsupervised pre training\n",
      "cross modal  person re identification\n",
      "person re identification\n",
      "fine grained visual categorization\n",
      "meta learning\n",
      "style transfer\n",
      "image to image translation\n",
      "neural network compression\n",
      "meta learning\n",
      "one shot learning\n",
      "domain generalization\n",
      "meta learning\n",
      "multi task learning\n",
      "person re identification\n",
      "question generation\n",
      "question generation\n",
      "distractor generation\n",
      "reading comprehension\n",
      "distractor generation\n",
      "reading comprehension\n",
      "dialogue understanding\n",
      "reading comprehension\n",
      "dialogue state tracking\n",
      "task oriented dialogue systems\n",
      "question generation\n",
      "reading comprehension\n",
      "conversational response generation\n",
      "question generation\n",
      "visual dialog\n",
      "coreference resolution\n",
      "natural language understanding\n",
      "natural language inference\n",
      "natural language inference\n",
      "natural language understanding\n",
      "entity extraction using gan\n",
      "multi task learning\n",
      "relation extraction\n",
      "stance detection\n",
      "few shot learning\n",
      "few shot regression\n",
      "meta learning\n",
      "multi task learning\n",
      "covid 19 diagnosis\n",
      "decision making\n",
      "natural language inference\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speaker verification\n",
      "text independent speaker verification\n",
      "multi task learning\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "speaker verification\n",
      "speaker diarization\n",
      "speaker verification\n",
      "speech enhancement\n",
      "denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "emotion recognition\n",
      "multi task learning\n",
      "speech emotion recognition\n",
      "click through rate prediction\n",
      "knowledge base completion\n",
      "knowledge base population\n",
      "natural language inference\n",
      "open information extraction\n",
      "open knowledge base completion\n",
      "reading comprehension\n",
      "document classification\n",
      "lexical entailment\n",
      "relation classification\n",
      "word sense disambiguation\n",
      "grammatical error detection\n",
      "sentence classification\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "hate speech detection\n",
      "ad hoc information retrieval\n",
      "text matching\n",
      "semantic parsing\n",
      "image retrieval\n",
      "image retrieval\n",
      "dictionary learning\n",
      "material recognition\n",
      "dictionary learning\n",
      "material recognition\n",
      "image retrieval\n",
      "point cloud classification\n",
      "automatic liver and tumor segmentation\n",
      "lesion segmentation\n",
      "tumor segmentation\n",
      "reconstruction\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "image retrieval\n",
      "task oriented dialogue systems\n",
      "style transfer\n",
      "style transfer\n",
      "text style transfer\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "dota 2\n",
      "policy gradient methods\n",
      "data visualization\n",
      "density estimation\n",
      "dependency parsing\n",
      "semantic parsing\n",
      "hyperparameter optimization\n",
      "text matching\n",
      "video generation\n",
      "video prediction\n",
      "stance detection\n",
      "denoising\n",
      "style transfer\n",
      "text generation\n",
      "text style transfer\n",
      "video recognition\n",
      "document summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "turning point identification\n",
      "abstractive text summarization\n",
      "natural language inference\n",
      "text summarization\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "text summarization\n",
      "text summarization\n",
      "learning to rank\n",
      "learning to rank\n",
      "multi armed bandits\n",
      "document ranking\n",
      "multi task learning\n",
      "document ranking\n",
      "information retrieval\n",
      "natural language understanding\n",
      "image retrieval\n",
      "hyperparameter optimization\n",
      "board games\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "policy gradient methods\n",
      "q learning\n",
      "optical character recognition\n",
      "scene text\n",
      "hate speech detection\n",
      "natural language understanding\n",
      "natural language inference\n",
      "natural language understanding\n",
      "machine reading comprehension\n",
      "reading comprehension\n",
      "multi task learning\n",
      "natural language inference\n",
      "multi task learning\n",
      "natural language inference\n",
      "natural language understanding\n",
      "data to text generation\n",
      "natural language inference\n",
      "text generation\n",
      "aspect based sentiment analysis\n",
      "aspect based sentiment analysis\n",
      "aspect based sentiment analysis\n",
      "stance classification\n",
      "stance detection\n",
      "aspect based sentiment analysis\n",
      "text summarization\n",
      "document classification\n",
      "medical code prediction\n",
      "sentence classification\n",
      "sentence classification\n",
      "fake news detection\n",
      "misinformation\n",
      "rumour detection\n",
      "zero shot learning\n",
      "two sample testing\n",
      "two sample testing\n",
      "interpretable machine learning\n",
      "sentence classification\n",
      "sentence classification\n",
      "image retrieval\n",
      "network pruning\n",
      "network pruning\n",
      "distributed optimization\n",
      "neural architecture search\n",
      "lesion segmentation\n",
      "multi label classification\n",
      "scene text\n",
      "scene text recognition\n",
      "entity linking\n",
      "reading comprehension\n",
      "chinese word segmentation\n",
      "intent classification\n",
      "natural language understanding\n",
      "slot filling\n",
      "intent classification\n",
      "natural language understanding\n",
      "slot filling\n",
      "lemmatization\n",
      "multi task learning\n",
      "tokenization\n",
      "natural language understanding\n",
      "temporal information extraction\n",
      "part of speech tagging\n",
      "semantic parsing\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "natural language inference\n",
      "density estimation\n",
      "natural language inference\n",
      "hate speech detection\n",
      "natural language understanding\n",
      "machine reading comprehension\n",
      "reading comprehension\n",
      "multi task learning\n",
      "optical character recognition\n",
      "scene text\n",
      "data to text generation\n",
      "natural language inference\n",
      "text generation\n",
      "task oriented dialogue systems\n",
      "chatbot\n",
      "dialogue generation\n",
      "policy gradient methods\n",
      "chatbot\n",
      "dialogue generation\n",
      "policy gradient methods\n",
      "chatbot\n",
      "dialogue generation\n",
      "policy gradient methods\n",
      "text summarization\n",
      "conversational response generation\n",
      "image captioning\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "dialogue state tracking\n",
      "task oriented dialogue systems\n",
      "audio generation\n",
      "style transfer\n",
      "natural language understanding\n",
      "semantic role labeling\n",
      "image captioning\n",
      "style transfer\n",
      "text attribute transfer\n",
      "text style transfer\n",
      "paraphrase identification\n",
      "fact verification\n",
      "misinformation\n",
      "natural language inference\n",
      "cross lingual transfer\n",
      "lemmatization\n",
      "multi task learning\n",
      "tokenization\n",
      "multi label classification\n",
      "natural language understanding\n",
      "learning to rank\n",
      "style transfer\n",
      "text simplification\n",
      "part of speech tagging\n",
      "tokenization\n",
      "hate speech detection\n",
      "fine grained opinion analysis\n",
      "multi task learning\n",
      "relation classification\n",
      "image retrieval\n",
      "sentence classification\n",
      "grammatical error detection\n",
      "sentence classification\n",
      "decipherment\n",
      "part of speech tagging\n",
      "chunking\n",
      "multi task learning\n",
      "discourse parsing\n",
      "drs parsing\n",
      "natural language understanding\n",
      "chinese word segmentation\n",
      "click through rate prediction\n",
      "grammatical error detection\n",
      "sentence classification\n",
      "chinese word segmentation\n",
      "chinese word segmentation\n",
      "lexical entailment\n",
      "relation classification\n",
      "intent classification\n",
      "natural language understanding\n",
      "slot filling\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "chinese word segmentation\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "eeg\n",
      "knowledge distillation\n",
      "seizure detection\n",
      "lesion segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "relational reasoning\n",
      "model compression\n",
      "neural architecture search\n",
      "node classification\n",
      "graph representation learning\n",
      "natural language inference\n",
      "sentence embeddings\n",
      "meta learning\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "fake news detection\n",
      "misinformation\n",
      "rumour detection\n",
      "zero shot learning\n",
      "stance detection\n",
      "fake news detection\n",
      "sentence classification\n",
      "sentence classification\n",
      "meta learning\n",
      "activity recognition\n",
      "multi task learning\n",
      "stance classification\n",
      "stance detection\n",
      "learning to rank\n",
      "aspect based sentiment analysis\n",
      "aspect based sentiment analysis\n",
      "sentence classification\n",
      "aspect based sentiment analysis\n",
      "aspect based sentiment analysis\n",
      "stance classification\n",
      "stance detection\n",
      "sentence classification\n",
      "sentence classification\n",
      "aspect based sentiment analysis\n",
      "part of speech tagging\n",
      "tokenization\n",
      "sentence classification\n",
      "semantic parsing\n",
      "few shot learning\n",
      "program induction\n",
      "dialogue state tracking\n",
      "task oriented dialogue systems\n",
      "task oriented dialogue systems\n",
      "task oriented dialogue systems\n",
      "task oriented dialogue systems\n",
      "document summarization\n",
      "text summarization\n",
      "click through rate prediction\n",
      "session based recommendations\n",
      "learning to rank\n",
      "lesion segmentation\n",
      "sentence classification\n",
      "sentence classification\n",
      "interpretable machine learning\n",
      "rectification\n",
      "few shot learning\n",
      "metric learning\n",
      "omniglot\n",
      "one shot learning\n",
      "two sample testing\n",
      "two sample testing\n",
      "distributed optimization\n",
      "neural architecture search\n",
      "few shot learning\n",
      "meta learning\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "text summarization\n",
      "text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "stance detection\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "abstractive text summarization\n",
      "sentence summarization\n",
      "text summarization\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "natural language understanding\n",
      "text summarization\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speech enhancement\n",
      "speaker verification\n",
      "text independent speaker verification\n",
      "emotion recognition\n",
      "multi task learning\n",
      "speech emotion recognition\n",
      "text to speech synthesis\n",
      "style transfer\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "text to speech synthesis\n",
      "multi task learning\n",
      "text to speech synthesis\n",
      "link prediction\n",
      "atari games\n",
      "q learning\n",
      "weather forecasting\n",
      "hierarchical reinforcement learning\n",
      "q learning\n",
      "audio classification\n",
      "video recognition\n",
      "video understanding\n",
      "q learning\n",
      "multi task learning\n",
      "q learning\n",
      "click through rate prediction\n",
      "atari games\n",
      "q learning\n",
      "board games\n",
      "multi agent reinforcement learning\n",
      "atari games\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "person re identification\n",
      "video based person re identification\n",
      "atari games\n",
      "q learning\n",
      "text based games\n",
      "legged robots\n",
      "meta learning\n",
      "atari games\n",
      "q learning\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "openai gym\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "atari games\n",
      "hierarchical reinforcement learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "adversarial attack\n",
      "atari games\n",
      "atari games\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "few shot imitation learning\n",
      "few shot learning\n",
      "imitation learning\n",
      "meta learning\n",
      "metric learning\n",
      "q learning\n",
      "q learning\n",
      "industrial robots\n",
      "robotic grasping\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speaker verification\n",
      "outlier detection\n",
      "metric learning\n",
      "person re identification\n",
      "few shot learning\n",
      "few shot learning\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speaker verification\n",
      "multi task learning\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speech enhancement\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speech enhancement\n",
      "denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "text to speech synthesis\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "multi task learning\n",
      "speech enhancement\n",
      "speech enhancement\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "speech enhancement\n",
      "text to speech synthesis\n",
      "multi task learning\n",
      "speech enhancement\n",
      "style transfer\n",
      "voice conversion\n",
      "dictionary learning\n",
      "dictionary learning\n",
      "multi task learning\n",
      "speech enhancement\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speaker identification\n",
      "speaker recognition\n",
      "metric learning\n",
      "person re identification\n",
      "speaker verification\n",
      "outlier detection\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face detection\n",
      "face identification\n",
      "face recognition\n",
      "knowledge distillation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "few shot learning\n",
      "meta learning\n",
      "omniglot\n",
      "community detection\n",
      "graph embedding\n",
      "network embedding\n",
      "community detection\n",
      "graph classification\n",
      "graph embedding\n",
      "graph embedding\n",
      "graph classification\n",
      "link prediction\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "hyperparameter optimization\n",
      "graph embedding\n",
      "density estimation\n",
      "audio classification\n",
      "weather forecasting\n",
      "link prediction\n",
      "hyperparameter optimization\n",
      "audio generation\n",
      "weather forecasting\n",
      "multi label classification\n",
      "two sample testing\n",
      "weather forecasting\n",
      "activity recognition\n",
      "car racing\n",
      "continuous control\n",
      "openai gym\n",
      "q learning\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "knowledge distillation\n",
      "knowledge distillation\n",
      "knowledge distillation\n",
      "person re identification\n",
      "model compression\n",
      "knowledge distillation\n",
      "knowledge distillation\n",
      "meta learning\n",
      "speech recognition\n",
      "multi task learning\n",
      "speaker verification\n",
      "neural architecture search\n",
      "neural architecture search\n",
      "cross modal retrieval\n",
      "neural architecture search\n",
      "quantization\n",
      "neural architecture search\n",
      "quantization\n",
      "neural architecture search\n",
      "neural architecture search\n",
      "speech enhancement\n",
      "image super resolution\n",
      "motion compensation\n",
      "super resolution\n",
      "video generation\n",
      "video super resolution\n",
      "image morphing\n",
      "style transfer\n",
      "video frame interpolation\n",
      "super resolution\n",
      "natural language inference\n",
      "coreference resolution\n",
      "multi task learning\n",
      "image super resolution\n",
      "super resolution\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "inductive logic programming\n",
      "dependency parsing\n",
      "lemmatization\n",
      "semantic parsing\n",
      "atari games\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "meta learning\n",
      "natural language understanding\n",
      "temporal information extraction\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "abstractive text summarization\n",
      "sentence summarization\n",
      "text summarization\n",
      "stance detection\n",
      "document summarization\n",
      "text summarization\n",
      "text summarization\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "text summarization\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "two sample testing\n",
      "two sample testing\n",
      "lesion segmentation\n",
      "interpretable machine learning\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "rotated mnist\n",
      "omniglot\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "network pruning\n",
      "distributed optimization\n",
      "neural architecture search\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "scene text\n",
      "scene text recognition\n",
      "speaker verification\n",
      "text independent speaker verification\n",
      "action detection\n",
      "activity detection\n",
      "activity recognition\n",
      "video classification\n",
      "action detection\n",
      "activity detection\n",
      "activity recognition\n",
      "video classification\n",
      "activity recognition\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "scene text\n",
      "scene text detection\n",
      "scene text recognition\n",
      "text spotting\n",
      "transliteration\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "document summarization\n",
      "text summarization\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "acoustic scene classification\n",
      "audio tagging\n",
      "multi label classification\n",
      "scene classification\n",
      "scene recognition\n",
      "semantic parsing\n",
      "style transfer\n",
      "text style transfer\n",
      "disaster response\n",
      "multi task learning\n",
      "mortality prediction\n",
      "mortality prediction\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "multi label classification\n",
      "neural architecture search\n",
      "multi label classification\n",
      "deep clustering\n",
      "self supervised learning\n",
      "survival analysis\n",
      "learning to rank\n",
      "activity recognition\n",
      "edge computing\n",
      "small data image classification\n",
      "image manipulation\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image dehazing\n",
      "single image haze removal\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "electron microscopy\n",
      "image to image translation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "reconstruction\n",
      "indoor localization\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "boundary detection\n",
      "edge detection\n",
      "object classification\n",
      "scene understanding\n",
      "lane detection\n",
      "self driving cars\n",
      "deblurring\n",
      "scene understanding\n",
      "optical character recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "lane detection\n",
      "self driving cars\n",
      "homography estimation\n",
      "style transfer\n",
      "text style transfer\n",
      "unsupervised text style transfer\n",
      "style transfer\n",
      "style transfer\n",
      "style transfer\n",
      "style transfer\n",
      "texture synthesis\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "meta learning\n",
      "one shot learning\n",
      "talking head generation\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "style transfer\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "atari games\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "dictionary learning\n",
      "eye tracking\n",
      "text summarization\n",
      "document summarization\n",
      "text summarization\n",
      "link prediction\n",
      "atari games\n",
      "board games\n",
      "chatbot\n",
      "dialogue generation\n",
      "policy gradient methods\n",
      "extractive text summarization\n",
      "meta learning\n",
      "quantum approximate optimization\n",
      "quantum machine learning\n",
      "multi task learning\n",
      "style transfer\n",
      "text style transfer\n",
      "unsupervised text style transfer\n",
      "style transfer\n",
      "texture synthesis\n",
      "dialogue state tracking\n",
      "task oriented dialogue systems\n",
      "style transfer\n",
      "hate speech detection\n",
      "multi class classification\n",
      "chinese word segmentation\n",
      "argument mining\n",
      "cross lingual transfer\n",
      "multi task learning\n",
      "word alignment\n",
      "multi task learning\n",
      "few shot learning\n",
      "text to sql\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "image retrieval\n",
      "loop closure detection\n",
      "simultaneous localization and mapping\n",
      "link prediction\n",
      "autonomous vehicles\n",
      "multi task learning\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "knowledge graphs\n",
      "link prediction\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "gaze estimation\n",
      "human pose estimation\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "one shot learning\n",
      "zero shot learning\n",
      "lesion segmentation\n",
      "atari games\n",
      "meta learning\n",
      "incremental learning\n",
      "knowledge distillation\n",
      "atari games\n",
      "document classification\n",
      "multi task learning\n",
      "meta learning\n",
      "few shot learning\n",
      "meta learning\n",
      "denoising\n",
      "image denoising\n",
      "image super resolution\n",
      "super resolution\n",
      "denoising\n",
      "image denoising\n",
      "image restoration\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "denoising\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "deblurring\n",
      "denoising\n",
      "image super resolution\n",
      "activity recognition\n",
      "edge computing\n",
      "small data image classification\n",
      "neural architecture search\n",
      "interpretable machine learning\n",
      "network pruning\n",
      "hyperparameter optimization\n",
      "hyperparameter optimization\n",
      "robust classification\n",
      "two sample testing\n",
      "adversarial defense\n",
      "two sample testing\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "starcraft\n",
      "starcraft ii\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "dota 2\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "starcraft\n",
      "multi agent reinforcement learning\n",
      "atari games\n",
      "human pose estimation\n",
      "object reconstruction from a single image\n",
      "shape reconstruction\n",
      "reconstruction\n",
      "reconstruction\n",
      "shape representation\n",
      "style transfer\n",
      "reconstruction\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "reconstruction\n",
      "single view  reconstruction\n",
      "object reconstruction\n",
      "reconstruction\n",
      "object reconstruction\n",
      "image inpainting\n",
      "face reconstruction\n",
      "face recognition\n",
      "face reconstruction\n",
      "face verification\n",
      "document classification\n",
      "document classification\n",
      "document classification\n",
      "speaker verification\n",
      "interpretable machine learning\n",
      "document classification\n",
      "two sample testing\n",
      "multi armed bandits\n",
      "two sample testing\n",
      "meta learning\n",
      "variational inference\n",
      "image inpainting\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "image reconstruction\n",
      "style transfer\n",
      "style transfer\n",
      "style transfer\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "style transfer\n",
      "style transfer\n",
      "style transfer\n",
      "human object interaction detection\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "human object interaction detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "edge computing\n",
      "fraud detection\n",
      "human object interaction detection\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "homography estimation\n",
      "gaze estimation\n",
      "human pose estimation\n",
      "depth estimation\n",
      "object detection\n",
      "self driving cars\n",
      "edge detection\n",
      "visual odometry\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "pose estimation\n",
      "self driving cars\n",
      "visual localization\n",
      "visual navigation\n",
      "image super resolution\n",
      "super resolution\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image super resolution\n",
      "super resolution\n",
      "image inpainting\n",
      "image super resolution\n",
      "super resolution\n",
      "denoising\n",
      "image denoising\n",
      "image restoration\n",
      "super resolution\n",
      "denoising\n",
      "image denoising\n",
      "image restoration\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "deblurring\n",
      "denoising\n",
      "image reconstruction\n",
      "image super resolution\n",
      "lossy compression artifact reduction\n",
      "super resolution\n",
      "hyperparameter optimization\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "atari games\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "network congestion control\n",
      "openai gym\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "gaze estimation\n",
      "gaze estimation\n",
      "human pose estimation\n",
      "face alignment\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "facial landmark detection\n",
      "edge detection\n",
      "visual odometry\n",
      "gaze estimation\n",
      "reconstruction\n",
      "scene reconstruction\n",
      "scene understanding\n",
      "depth estimation\n",
      "object detection\n",
      "self driving cars\n",
      "gaze estimation\n",
      "image to image translation\n",
      "depth estimation\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "efficient exploration\n",
      "q learning\n",
      "self supervised image classification\n",
      "self supervised learning\n",
      "semi supervised image classification\n",
      "face identification\n",
      "face recognition\n",
      "face verification\n",
      "feature selection\n",
      "image super resolution\n",
      "super resolution\n",
      "face detection\n",
      "face identification\n",
      "face recognition\n",
      "knowledge distillation\n",
      "incremental learning\n",
      "denoising\n",
      "image denoising\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "fine grained opinion analysis\n",
      "multi task learning\n",
      "semantic parsing\n",
      "natural language inference\n",
      "question generation\n",
      "text generation\n",
      "argument mining\n",
      "cross lingual transfer\n",
      "multi task learning\n",
      "word alignment\n",
      "natural language understanding\n",
      "semantic role labeling\n",
      "learning to rank\n",
      "discourse parsing\n",
      "drs parsing\n",
      "natural language understanding\n",
      "part of speech tagging\n",
      "natural language inference\n",
      "natural language understanding\n",
      "open information extraction\n",
      "semantic parsing\n",
      "text to sql\n"
     ]
    }
   ],
   "source": [
    "readme_area_results = analyze_query_level_results(raw_readme_area_results, area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recalled</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th colspan=\"2\" halign=\"left\">position</th>\n",
       "      <th>area_recalled</th>\n",
       "      <th>num_area_recalled</th>\n",
       "      <th colspan=\"2\" halign=\"left\">area_position</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1.56</td>\n",
       "      <td>7.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-vision</th>\n",
       "      <td>0.58</td>\n",
       "      <td>2.03</td>\n",
       "      <td>15.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural-language-processing</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1.69</td>\n",
       "      <td>10.5</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.88</td>\n",
       "      <td>3.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodology</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1.88</td>\n",
       "      <td>5.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graphs</th>\n",
       "      <td>0.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>0.67</td>\n",
       "      <td>2.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing-games</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time-series</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversarial</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-code</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge-base</th>\n",
       "      <td>1.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            recalled num_recalled position         \\\n",
       "                                mean         mean   median   mean   \n",
       "area                                                                \n",
       "miscellaneous                   0.54         1.56      7.0    inf   \n",
       "computer-vision                 0.58         2.03     15.0    inf   \n",
       "natural-language-processing     0.58         1.69     10.5    inf   \n",
       "methodology                     0.62         1.88      5.0    inf   \n",
       "graphs                          0.80         2.00      3.0    inf   \n",
       "speech                          1.00         2.50      0.5   0.75   \n",
       "medical                         0.67         2.33      0.0    inf   \n",
       "playing-games                   0.67         1.67      4.0    inf   \n",
       "audio                           1.00         1.00      2.5   2.50   \n",
       "robots                          1.00         1.50      7.5   7.50   \n",
       "time-series                     0.00         0.00      inf    inf   \n",
       "adversarial                     1.00         5.00      0.0   0.00   \n",
       "computer-code                   1.00         2.00     14.0  14.00   \n",
       "knowledge-base                  1.00         5.00      1.0   1.00   \n",
       "\n",
       "                            area_recalled num_area_recalled area_position  \\\n",
       "                                     mean              mean        median   \n",
       "area                                                                        \n",
       "miscellaneous                        0.95              0.95           3.0   \n",
       "computer-vision                      0.97              0.97           0.0   \n",
       "natural-language-processing          0.88              0.88           3.0   \n",
       "methodology                          0.96              0.96           1.0   \n",
       "graphs                               1.00              1.00           1.0   \n",
       "speech                               1.00              1.00           2.0   \n",
       "medical                              1.00              1.00           1.0   \n",
       "playing-games                        1.00              1.00           2.0   \n",
       "audio                                1.00              1.00           0.5   \n",
       "robots                               1.00              1.00           2.0   \n",
       "time-series                          0.00              0.00           inf   \n",
       "adversarial                          1.00              1.00           0.0   \n",
       "computer-code                        1.00              1.00           0.0   \n",
       "knowledge-base                       1.00              1.00           2.0   \n",
       "\n",
       "                                  count  \n",
       "                             mean        \n",
       "area                                     \n",
       "miscellaneous                 inf    41  \n",
       "computer-vision               inf    33  \n",
       "natural-language-processing   inf    26  \n",
       "methodology                   inf    24  \n",
       "graphs                       0.80     5  \n",
       "speech                       2.50     4  \n",
       "medical                      1.33     3  \n",
       "playing-games                3.00     3  \n",
       "audio                        0.50     2  \n",
       "robots                       2.00     2  \n",
       "time-series                   inf     2  \n",
       "adversarial                  0.00     1  \n",
       "computer-code                0.00     1  \n",
       "knowledge-base               2.00     1  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_area_results.round(2).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "recalled           mean       0.746257\n",
       "num_recalled       mean       2.154185\n",
       "position           median          inf\n",
       "                   mean            inf\n",
       "area_recalled      mean       0.911705\n",
       "num_area_recalled  mean       0.911705\n",
       "area_position      median          inf\n",
       "                   mean            inf\n",
       "count                        10.571429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_area_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word sense disambiguation\n",
      "feature selection\n",
      "image inpainting\n",
      "audio classification\n",
      "policy gradient methods\n",
      "image retrieval\n",
      "metric learning\n",
      "person re identification\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "scene text\n",
      "scene text recognition\n",
      "semi supervised image classification\n",
      "image super resolution\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "self supervised learning\n",
      "autonomous vehicles\n",
      "federated learning\n",
      "meta learning\n",
      "multi task learning\n",
      "style transfer\n",
      "openai gym\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "image inpainting\n",
      "image super resolution\n",
      "super resolution\n",
      "optical character recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "multi agent reinforcement learning\n",
      "autonomous driving\n",
      "multi task learning\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "brain tumor segmentation\n",
      "lesion segmentation\n",
      "tumor segmentation\n",
      "omniglot\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "decision making\n",
      "few shot learning\n",
      "meta learning\n",
      "few shot learning\n",
      "self driving cars\n",
      "self supervised learning\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "omniglot\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "reconstruction\n",
      "style transfer\n",
      "network pruning\n",
      "neural network compression\n",
      "unsupervised pre training\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "q learning\n",
      "text based games\n",
      "one shot learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "learning to rank\n",
      "deblurring\n",
      "denoising\n",
      "image super resolution\n",
      "style transfer\n",
      "network pruning\n",
      "neural network compression\n",
      "unsupervised pre training\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "q learning\n",
      "text based games\n",
      "one shot learning\n",
      "bilevel optimization\n",
      "meta learning\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "learning to rank\n",
      "deblurring\n",
      "denoising\n",
      "image super resolution\n",
      "edge detection\n",
      "scene understanding\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "image reconstruction\n",
      "mri reconstruction\n",
      "unsupervised image to image translation\n",
      "multi agent reinforcement learning\n",
      "image inpainting\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "knowledge distillation\n",
      "edge detection\n",
      "scene understanding\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "image reconstruction\n",
      "mri reconstruction\n",
      "unsupervised image to image translation\n",
      "multi agent reinforcement learning\n",
      "image inpainting\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "hyperparameter optimization\n",
      "neural architecture search\n",
      "knowledge distillation\n",
      "reconstruction\n",
      "reconstruction\n",
      "computed tomography (ct)\n",
      "image reconstruction\n",
      "super resolution\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "zero shot learning\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "scene reconstruction\n",
      "scene understanding\n",
      "covid 19 diagnosis\n",
      "scene understanding\n",
      "edge detection\n",
      "visual odometry\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "speaker verification\n",
      "lane detection\n",
      "self driving cars\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "multi task learning\n",
      "multi class classification\n",
      "multi label text classification\n",
      "multi task learning\n",
      "super resolution\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "reconstruction\n",
      "face hallucination\n",
      "image reconstruction\n",
      "super resolution\n",
      "speaker identification\n",
      "neural architecture search\n",
      "quantization\n",
      "image to image translation\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "object reconstruction\n",
      "reconstruction\n",
      "reconstruction\n",
      "scene reconstruction\n",
      "scene understanding\n",
      "super resolution\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "reconstruction\n",
      "face hallucination\n",
      "image reconstruction\n",
      "super resolution\n",
      "speaker identification\n",
      "neural architecture search\n",
      "quantization\n",
      "image to image translation\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "object reconstruction\n",
      "reconstruction\n",
      "reconstruction\n",
      "scene reconstruction\n",
      "scene understanding\n",
      "super resolution\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "reconstruction\n",
      "face hallucination\n",
      "image reconstruction\n",
      "super resolution\n",
      "speaker identification\n",
      "neural architecture search\n",
      "quantization\n",
      "image to image translation\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "object reconstruction\n",
      "reconstruction\n",
      "reconstruction\n",
      "scene reconstruction\n",
      "scene understanding\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "person re identification\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "q learning\n",
      "text based games\n",
      "image super resolution\n",
      "super resolution\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "zero shot learning\n",
      "continuous control\n",
      "q learning\n",
      "unsupervised pre training\n",
      "natural language understanding\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "indoor localization\n",
      "person re identification\n",
      "person retrieval\n",
      "network pruning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "image inpainting\n",
      "reconstruction\n",
      "shape representation\n",
      "activity recognition\n",
      "autonomous driving\n",
      "q learning\n",
      "natural language understanding\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "indoor localization\n",
      "person re identification\n",
      "person retrieval\n",
      "network pruning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "image inpainting\n",
      "reconstruction\n",
      "shape representation\n",
      "activity recognition\n",
      "autonomous driving\n",
      "q learning\n",
      "natural language understanding\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "indoor localization\n",
      "person re identification\n",
      "person retrieval\n",
      "network pruning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "image inpainting\n",
      "reconstruction\n",
      "shape representation\n",
      "activity recognition\n",
      "autonomous driving\n",
      "q learning\n",
      "speaker identification\n",
      "speaker recognition\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "natural language inference\n",
      "natural language understanding\n",
      "few shot learning\n",
      "long tail learning\n",
      "long tail learning with class descriptors\n",
      "open set learning\n",
      "natural language inference\n",
      "speaker identification\n",
      "speaker recognition\n",
      "real time strategy games\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "activity recognition\n",
      "multi task learning\n",
      "multi task learning\n",
      "style transfer\n",
      "voice conversion\n",
      "hypergraph embedding\n",
      "knowledge graphs\n",
      "link prediction\n",
      "multi agent reinforcement learning\n",
      "multi label classification\n",
      "person re identification\n",
      "person retrieval\n",
      "multi agent reinforcement learning\n",
      "starcraft ii\n",
      "density estimation\n",
      "person re identification\n",
      "person search\n",
      "video retrieval\n",
      "reading comprehension\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "conditional image generation\n",
      "image to image translation\n",
      "colorization\n",
      "self supervised image classification\n",
      "style transfer\n",
      "image to image translation\n",
      "style transfer\n",
      "image inpainting\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "continuous control\n",
      "q learning\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "person re identification\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "semi supervised image classification\n",
      "document embedding\n",
      "extractive text summarization\n",
      "sentence embedding\n",
      "sentence embeddings\n",
      "text summarization\n",
      "covid 19 diagnosis\n",
      "speaker identification\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "facial landmark detection\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "face hallucination\n",
      "image reconstruction\n",
      "super resolution\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "person re identification\n",
      "acoustic scene classification\n",
      "self driving cars\n",
      "sound event detection\n",
      "video prediction\n",
      "colorization\n",
      "image restoration\n",
      "image to image translation\n",
      "image super resolution\n",
      "super resolution\n",
      "dependency parsing\n",
      "named entity recognition\n",
      "natural language inference\n",
      "semantic role labeling\n",
      "word embeddings\n",
      "face alignment\n",
      "super resolution\n",
      "object detection in aerial images\n",
      "one shot object detection\n",
      "real time object detection\n",
      "continuous control\n",
      "q learning\n",
      "object reconstruction\n",
      "object super resolution\n",
      "depth estimation\n",
      "object reconstruction\n",
      "super resolution\n",
      "face swapping\n",
      "multi task learning\n",
      "click through rate prediction\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "person re identification\n",
      "covid 19 diagnosis\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "image inpainting\n",
      "continuous control\n",
      "q learning\n",
      "video prediction\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "few shot learning\n",
      "zero shot learning\n",
      "rectification\n",
      "scene text\n",
      "scene text recognition\n",
      "q learning\n",
      "openai gym\n",
      "q learning\n",
      "few shot learning\n",
      "meta learning\n",
      "two sample testing\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "dictionary learning\n",
      "continuous control\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "robust classification\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "network pruning\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "fake news detection\n",
      "natural language inference\n",
      "news classification\n",
      "super resolution\n",
      "point cloud classification\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "semantic parsing\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "person re identification\n",
      "video based person re identification\n",
      "image inpainting\n",
      "imputation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "self supervised image classification\n",
      "semi supervised image classification\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "facial landmark detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "transliteration\n",
      "covid 19 diagnosis\n",
      "out of distribution detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "contour detection\n",
      "edge detection\n",
      "multimodal emotion recognition\n",
      "multimodal sentiment analysis\n",
      "hate speech detection\n",
      "outlier detection\n",
      "facial landmark detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "transliteration\n",
      "covid 19 diagnosis\n",
      "out of distribution detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "contour detection\n",
      "edge detection\n",
      "multimodal emotion recognition\n",
      "multimodal sentiment analysis\n",
      "hate speech detection\n",
      "outlier detection\n",
      "facial landmark detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "transliteration\n",
      "covid 19 diagnosis\n",
      "out of distribution detection\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "contour detection\n",
      "edge detection\n",
      "multimodal emotion recognition\n",
      "multimodal sentiment analysis\n",
      "hate speech detection\n",
      "outlier detection\n",
      "font style transfer\n",
      "style transfer\n",
      "density estimation\n",
      "deblurring\n",
      "self supervised learning\n",
      "image super resolution\n",
      "motion compensation\n",
      "super resolution\n",
      "video generation\n",
      "video super resolution\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "image to image translation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "meta reinforcement learning\n",
      "visual navigation\n",
      "incremental learning\n",
      "person re identification\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "graph classification\n",
      "topological data analysis\n",
      "q learning\n",
      "lane detection\n",
      "self driving cars\n",
      "natural language understanding\n",
      "continuous control\n",
      "q learning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "activity recognition\n",
      "image inpainting\n",
      "semantic parsing\n",
      "semantic parsing\n",
      "multi agent reinforcement learning\n",
      "learning to rank\n",
      "imitation learning\n",
      "q learning\n",
      "scene understanding\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "person re identification\n",
      "click through rate prediction\n",
      "super resolution\n",
      "video deinterlacing\n",
      "document embedding\n",
      "extractive text summarization\n",
      "sentence embedding\n",
      "sentence embeddings\n",
      "text summarization\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "omniglot\n",
      "one shot learning\n",
      "multiobjective optimization\n",
      "speaker verification\n",
      "text independent speaker verification\n",
      "person re identification\n",
      "video based person re identification\n",
      "dota 2\n",
      "policy gradient methods\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "text summarization\n",
      "openai gym\n",
      "q learning\n",
      "few shot learning\n",
      "long tail learning\n",
      "long tail learning with class descriptors\n",
      "open set learning\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "reconstruction\n",
      "indoor localization\n",
      "word sense disambiguation\n",
      "image to image translation\n",
      "q learning\n",
      "text based games\n",
      "deblurring\n",
      "self supervised learning\n",
      "image inpainting\n",
      "computed tomography (ct)\n",
      "image to image translation\n",
      "medical image generation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "image to image translation\n",
      "image enhancement\n",
      "low light image enhancement\n",
      "self supervised learning\n",
      "style transfer\n",
      "density estimation\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "point cloud classification\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "image super resolution\n",
      "super resolution\n",
      "anomaly detection\n",
      "continual learning\n",
      "meta learning\n",
      "one class classifier\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "graph classification\n",
      "lane detection\n",
      "self driving cars\n",
      "fake news detection\n",
      "misinformation\n",
      "rumour detection\n",
      "zero shot learning\n",
      "face detection\n",
      "face verification\n",
      "multi task learning\n",
      "medical imaging segmentation\n",
      "action recognition\n",
      "medical image segmentation\n",
      "neural architecture search\n",
      "scene understanding\n",
      "temporal action localization\n",
      "meta learning\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "q learning\n",
      "image super resolution\n",
      "super resolution\n",
      "meta learning\n",
      "q learning\n",
      "sentence classification\n",
      "reconstruction\n",
      "shape representation\n",
      "continuous control\n",
      "q learning\n",
      "style transfer\n",
      "knowledge distillation\n",
      "meta learning\n",
      "relation extraction\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "interpretable machine learning\n",
      "density estimation\n",
      "multi label classification\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "natural language inference\n",
      "neural architecture search\n",
      "dictionary learning\n",
      "image super resolution\n",
      "super resolution\n",
      "graph classification\n",
      "reconstruction\n",
      "crowd counting\n",
      "meta learning\n",
      "openai gym\n",
      "q learning\n",
      "cross lingual transfer\n",
      "morphological inflection\n",
      "deblurring\n",
      "image super resolution\n",
      "super resolution\n",
      "text to sql\n",
      "knowledge distillation\n",
      "learning to rank\n",
      "image super resolution\n",
      "super resolution\n",
      "graph classification\n",
      "reconstruction\n",
      "crowd counting\n",
      "meta learning\n",
      "openai gym\n",
      "q learning\n",
      "cross lingual transfer\n",
      "morphological inflection\n",
      "deblurring\n",
      "image super resolution\n",
      "super resolution\n",
      "text to sql\n",
      "knowledge distillation\n",
      "learning to rank\n",
      "video prediction\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "link prediction\n",
      "object reconstruction\n",
      "reconstruction\n",
      "object reconstruction\n",
      "natural language inference\n",
      "active learning\n",
      "few shot learning\n",
      "graph classification\n",
      "word sense disambiguation\n",
      "bird view synthesis\n",
      "cross view image to image translation\n",
      "image to image translation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "meta learning\n",
      "q learning\n",
      "knowledge distillation\n",
      "video prediction\n",
      "dota 2\n",
      "policy gradient methods\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "graph classification\n",
      "graph regression\n",
      "meta learning\n",
      "graph classification\n",
      "metric learning\n",
      "multi task learning\n",
      "lesion segmentation\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "omniglot\n",
      "scene text\n",
      "scene text recognition\n",
      "continuous control\n",
      "q learning\n",
      "automatic liver and tumor segmentation\n",
      "lesion segmentation\n",
      "tumor segmentation\n",
      "lesion segmentation\n",
      "incremental learning\n",
      "omniglot\n",
      "plane detection\n",
      "reconstruction\n",
      "multi label classification\n",
      "reading comprehension\n",
      "metric learning\n",
      "person re identification\n",
      "video based person re identification\n",
      "learning to rank\n",
      "document embedding\n",
      "extractive text summarization\n",
      "sentence embedding\n",
      "sentence embeddings\n",
      "text summarization\n",
      "zero shot learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "person re identification\n",
      "unsupervised person re identification\n",
      "openai gym\n",
      "q learning\n",
      "image super resolution\n",
      "super resolution\n",
      "density estimation\n",
      "multi task learning\n",
      "pneumonia detection\n",
      "image inpainting\n",
      "imputation\n",
      "image super resolution\n",
      "super resolution\n",
      "omniglot\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "knowledge graph completion\n",
      "multi label classification\n",
      "lane detection\n",
      "self driving cars\n",
      "continuous control\n",
      "policy gradient methods\n",
      "q learning\n",
      "automatic liver and tumor segmentation\n",
      "lesion segmentation\n",
      "tumor segmentation\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "q learning\n",
      "text based games\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "meta learning\n",
      "word sense disambiguation\n",
      "document embedding\n",
      "extractive text summarization\n",
      "sentence embedding\n",
      "sentence embeddings\n",
      "text summarization\n",
      "person re identification\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "bird view synthesis\n",
      "cross view image to image translation\n",
      "image to image translation\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "network pruning\n",
      "slot filling\n",
      "text to sql\n",
      "open set learning\n",
      "robust classification\n",
      "graph classification\n",
      "neural architecture search\n",
      "point cloud classification\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi label classification\n",
      "natural language inference\n",
      "stochastic optimization\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "continuous control\n",
      "q learning\n",
      "meta reinforcement learning\n",
      "visual navigation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "legged robots\n",
      "meta learning\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "meta learning\n",
      "q learning\n",
      "continual learning\n",
      "few shot learning\n",
      "meta learning\n",
      "image super resolution\n",
      "super resolution\n",
      "few shot learning\n",
      "meta learning\n",
      "word sense disambiguation\n",
      "meta learning\n",
      "neural architecture search\n",
      "continual learning\n",
      "few shot learning\n",
      "video prediction\n",
      "continuous control\n",
      "q learning\n",
      "continual learning\n",
      "few shot learning\n",
      "continual learning\n",
      "few shot learning\n",
      "meta learning\n",
      "meta learning\n",
      "neural architecture search\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "robust classification\n",
      "q learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "video prediction\n",
      "learning to rank\n",
      "zero shot learning\n",
      "legged robots\n",
      "meta learning\n",
      "meta learning\n",
      "graph classification\n",
      "metric learning\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "knowledge distillation\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "meta learning\n",
      "meta learning\n",
      "neural architecture search\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "q learning\n",
      "q learning\n",
      "style transfer\n",
      "continuous control\n",
      "q learning\n",
      "graph classification\n",
      "metric learning\n",
      "meta learning\n",
      "image super resolution\n",
      "super resolution\n",
      "meta learning\n",
      "q learning\n",
      "meta learning\n",
      "computed tomography (ct)\n",
      "covid 19 diagnosis\n",
      "multi task learning\n",
      "self supervised learning\n",
      "video prediction\n",
      "continuous control\n",
      "q learning\n",
      "meta learning\n",
      "speech recognition\n",
      "dota 2\n",
      "policy gradient methods\n",
      "learning to rank\n",
      "few shot learning\n",
      "meta learning\n",
      "word sense disambiguation\n",
      "image super resolution\n",
      "super resolution\n",
      "speaker verification\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "anomaly detection\n",
      "continual learning\n",
      "meta learning\n",
      "one class classifier\n",
      "denoising\n",
      "image denoising\n",
      "image restoration\n",
      "super resolution\n",
      "fraud detection\n",
      "outlier detection\n",
      "semantic parsing\n",
      "multi class classification\n",
      "multi label text classification\n",
      "outlier detection\n",
      "multi agent reinforcement learning\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "continuous control\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "legged robots\n",
      "meta learning\n",
      "q learning\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "inductive logic programming\n",
      "video prediction\n",
      "image super resolution\n",
      "super resolution\n",
      "style transfer\n",
      "image super resolution\n",
      "super resolution\n",
      "two sample testing\n",
      "q learning\n",
      "multi label classification\n",
      "multi label classification\n",
      "continuous control\n",
      "q learning\n",
      "meta learning\n",
      "relation extraction\n",
      "link prediction\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "neural architecture search\n",
      "inductive logic programming\n",
      "density estimation\n",
      "crowd counting\n",
      "meta learning\n",
      "q learning\n",
      "human object interaction detection\n",
      "few shot learning\n",
      "model selection\n",
      "object localization\n",
      "weakly supervised object localization\n",
      "image retrieval\n",
      "metric learning\n",
      "person re identification\n",
      "image super resolution\n",
      "super resolution\n",
      "semi supervised image classification\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "continuous control\n",
      "q learning\n",
      "image inpainting\n",
      "few shot learning\n",
      "zero shot learning\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "video generation\n",
      "video prediction\n",
      "openai gym\n",
      "density estimation\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "multi label classification\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "meta learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "multi armed bandits\n",
      "video generation\n",
      "video prediction\n",
      "openai gym\n",
      "density estimation\n",
      "color image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "multi label classification\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "meta learning\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "multi armed bandits\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "dota 2\n",
      "policy gradient methods\n",
      "zero shot learning\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "openai gym\n",
      "dimensionality reduction\n",
      "link prediction\n",
      "\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "meta learning\n",
      "meta learning\n",
      "neural architecture search\n",
      "link prediction\n",
      "matrix completion\n",
      "recommendation systems\n",
      "video prediction\n",
      "graph classification\n",
      "graph regression\n",
      "meta learning\n",
      "car racing\n",
      "continuous control\n",
      "openai gym\n",
      "q learning\n",
      "inductive logic programming\n",
      "domain generalization\n",
      "meta learning\n",
      "text to sql\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "density estimation\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "meta learning\n",
      "saliency detection\n",
      "saliency prediction\n",
      "scanpath prediction\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "meta learning\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "meta learning\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "meta learning\n",
      "neural architecture search\n",
      "video prediction\n",
      "q learning\n",
      "intrusion detection\n",
      "omniglot\n",
      "one shot learning\n",
      "q learning\n",
      "text to sql\n",
      "graph classification\n",
      "metric learning\n",
      "sentence classification\n",
      "q learning\n",
      "lexical entailment\n",
      "relation classification\n",
      "continuous control\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "meta learning\n",
      "openai gym\n",
      "q learning\n",
      "dimensionality reduction\n",
      "link prediction\n",
      "learning to rank\n",
      "q learning\n",
      "meta learning\n",
      "legged robots\n",
      "meta learning\n",
      "reconstruction\n",
      "shape representation\n",
      "continuous control\n",
      "q learning\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "dota 2\n",
      "policy gradient methods\n",
      "chatbot\n",
      "dialogue generation\n",
      "policy gradient methods\n",
      "image inpainting\n",
      "knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "natural language understanding\n",
      "activity recognition\n",
      "openai gym\n",
      "few shot image classification\n",
      "autonomous driving\n",
      "q learning\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "zero shot learning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "lane detection\n",
      "self driving cars\n",
      "multi agent reinforcement learning\n",
      "self supervised learning\n",
      "image to image translation\n",
      "colorization\n",
      "self supervised image classification\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "inductive logic programming\n",
      "multi task learning\n",
      "session based recommendations\n",
      "reconstruction\n",
      "indoor localization\n",
      "reconstruction\n",
      "novel view synthesis\n",
      "single view  reconstruction\n",
      "super resolution\n",
      "multi label classification\n",
      "car racing\n",
      "continuous control\n",
      "openai gym\n",
      "q learning\n",
      "network pruning\n",
      "meta learning\n",
      "recommendation systems\n",
      "image super resolution\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "inductive logic programming\n",
      "denoising\n",
      "image denoising\n",
      "image restoration\n",
      "neural architecture search\n",
      "rain removal\n",
      "multi task learning\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "image super resolution\n",
      "super resolution\n",
      "knowledge distillation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "q learning\n",
      "mortality prediction\n",
      "readmission prediction\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "crowd counting\n",
      "meta learning\n",
      "mortality prediction\n",
      "openai gym\n",
      "q learning\n",
      "game of chess\n",
      "game of go\n",
      "game of shogi\n",
      "general reinforcement learning\n",
      "meta reinforcement learning\n",
      "visual navigation\n",
      "openai gym\n",
      "dota 2\n",
      "policy gradient methods\n",
      "lane detection\n",
      "self driving cars\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "human motion prediction\n",
      "multi future trajectory prediction\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "automl\n",
      "meta learning\n",
      "q learning\n",
      "session based recommendations\n",
      "saliency detection\n",
      "saliency prediction\n",
      "scanpath prediction\n",
      "automl\n",
      "meta learning\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "abuse detection\n",
      "abusive language\n",
      "multi class classification\n",
      "lane detection\n",
      "self driving cars\n",
      "knowledge distillation\n",
      "information retrieval\n",
      "reading comprehension\n",
      "anomaly detection\n",
      "continual learning\n",
      "meta learning\n",
      "one class classifier\n",
      "speaker verification\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "fraud detection\n",
      "activity recognition\n",
      "image super resolution\n",
      "super resolution\n",
      "multi class classification\n",
      "autonomous vehicles\n",
      "multi task learning\n",
      "hate speech detection\n",
      "natural language understanding\n",
      "super resolution\n",
      "learning to rank\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "image dehazing\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "q learning\n",
      "text based games\n",
      "imitation learning\n",
      "q learning\n",
      "scene text\n",
      "scene text detection\n",
      "continuous control\n",
      "q learning\n",
      "semantic parsing\n",
      "self supervised learning\n",
      "vision and language navigation\n",
      "visual navigation\n",
      "mortality prediction\n",
      "readmission prediction\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "meta learning\n",
      "knowledge graph embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "semantic parsing\n",
      "feature importance\n",
      "interpretable machine learning\n",
      "entity embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "fps games\n",
      "game of doom\n",
      "q learning\n",
      "self driving cars\n",
      "natural language inference\n",
      "natural language understanding\n",
      "question generation\n",
      "natural language understanding\n",
      "question generation\n",
      "reading comprehension\n",
      "few shot learning\n",
      "distractor generation\n",
      "reading comprehension\n",
      "amr parsing\n",
      "semantic parsing\n",
      "question generation\n",
      "reading comprehension\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "self supervised learning\n",
      "link prediction\n",
      "multi task learning\n",
      "relation extraction\n",
      "semantic parsing\n",
      "image to image translation\n",
      "end to end speech recognition\n",
      "graph sampling\n",
      "neural architecture search\n",
      "speech recognition\n",
      "active learning\n",
      "crowd counting\n",
      "image quality assessment\n",
      "learning to rank\n",
      "self supervised learning\n",
      "entity embeddings\n",
      "knowledge graphs\n",
      "link prediction\n",
      "mortality prediction\n",
      "readmission prediction\n",
      "hate speech detection\n",
      "automl\n",
      "model compression\n",
      "neural architecture search\n",
      "style transfer\n",
      "voice conversion\n",
      "scene text\n",
      "scene text detection\n",
      "image super resolution\n",
      "super resolution\n",
      "style transfer\n",
      "semantic parsing\n",
      "text to sql\n",
      "reading comprehension\n",
      "human parsing\n",
      "multi human parsing\n",
      "document classification\n",
      "image inpainting\n",
      "image super resolution\n",
      "super resolution\n",
      "self supervised learning\n",
      "vision and language navigation\n",
      "visual navigation\n",
      "two sample testing\n",
      "self supervised learning\n",
      "text to sql\n",
      "end to end speech recognition\n",
      "graph sampling\n",
      "neural architecture search\n",
      "speech recognition\n",
      "few shot learning\n",
      "document classification\n",
      "few shot learning\n",
      "multi task learning\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "feature engineering\n",
      "natural language inference\n",
      "relation classification\n",
      "relation extraction\n",
      "text categorization\n",
      "reconstruction\n",
      "multi task learning\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "omniglot\n",
      "multi object tracking\n",
      "object detection from stereo images\n",
      "multi object tracking\n",
      "lesion segmentation\n",
      "interpretable machine learning\n",
      "graph embedding\n",
      "link prediction\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "image to image translation\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "reconstruction\n",
      "novel view synthesis\n",
      "single view  reconstruction\n",
      "inductive knowledge graph completion\n",
      "knowledge graphs\n",
      "link prediction\n",
      "natural language inference\n",
      "natural language understanding\n",
      "conversational response generation\n",
      "super resolution\n",
      "semantic parsing\n",
      "density estimation\n",
      "multi agent reinforcement learning\n",
      "activity recognition\n",
      "image to image translation\n",
      "inductive logic programming\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "multi label classification\n",
      "multi task learning\n",
      "graph classification\n",
      "deblurring\n",
      "image super resolution\n",
      "super resolution\n",
      "multi task learning\n",
      "natural language inference\n",
      "natural language understanding\n",
      "unsupervised pre training\n",
      "semantic parsing\n",
      "ucca parsing\n",
      "interpretable machine learning\n",
      "conversational response generation\n",
      "super resolution\n",
      "speech synthesis\n",
      "style transfer\n",
      "task oriented dialogue systems\n",
      "aspect based sentiment analysis\n",
      "natural language understanding\n",
      "link prediction\n",
      "self supervised learning\n",
      "mortality prediction\n",
      "readmission prediction\n",
      "cross lingual transfer\n",
      "morphological inflection\n",
      "multi label classification\n",
      "link prediction\n",
      "matrix completion\n",
      "recommendation systems\n",
      "metric learning\n",
      "person re identification\n",
      "video based person re identification\n",
      "few shot learning\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi task learning\n",
      "link prediction\n",
      "natural language inference\n",
      "natural language understanding\n",
      "sentence classification\n",
      "sentence classification\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "extractive text summarization\n",
      "text summarization\n",
      "semantic parsing\n",
      "text summarization\n",
      "multi label classification\n",
      "auxiliary learning\n",
      "few shot learning\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "audio classification\n",
      "part of speech tagging\n",
      "natural language understanding\n",
      "semantic parsing\n",
      "natural language inference\n",
      "natural language understanding\n",
      "learning to rank\n",
      "disaster response\n",
      "multi task learning\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "style transfer\n",
      "text style transfer\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "abstractive text summarization\n",
      "natural language inference\n",
      "text summarization\n",
      "rectification\n",
      "scene text\n",
      "scene text recognition\n",
      "semantic parsing\n",
      "ucca parsing\n",
      "density estimation\n",
      "interpretable machine learning\n",
      "person re identification\n",
      "unsupervised person re identification\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "scene text\n",
      "scene text detection\n",
      "scene text recognition\n",
      "text spotting\n",
      "conversational response generation\n",
      "human object interaction detection\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "aspect based sentiment analysis\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "super resolution\n",
      "natural language inference\n",
      "natural language understanding\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "natural language understanding\n",
      "zero shot learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "text summarization\n",
      "graph classification\n",
      "amr parsing\n",
      "semantic parsing\n",
      "text summarization\n",
      "arrhythmia detection\n",
      "ecg classification\n",
      "time series classification\n",
      "scene text\n",
      "scene text recognition\n",
      "federated learning\n",
      "natural language understanding\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "music genre transfer\n",
      "style transfer\n",
      "synthetic data generation\n",
      "end to end speech recognition\n",
      "graph sampling\n",
      "neural architecture search\n",
      "speech recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "multi class classification\n",
      "natural language inference\n",
      "link prediction\n",
      "fps games\n",
      "game of doom\n",
      "q learning\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi task learning\n",
      "policy gradient methods\n",
      "q learning\n",
      "self supervised learning\n",
      "graph clustering\n",
      "graph embedding\n",
      "link prediction\n",
      "cross lingual transfer\n",
      "morphological inflection\n",
      "image to image translation\n",
      "discourse parsing\n",
      "drs parsing\n",
      "natural language understanding\n",
      "natural language inference\n",
      "natural language understanding\n",
      "feature engineering\n",
      "natural language inference\n",
      "relation classification\n",
      "relation extraction\n",
      "text categorization\n",
      "next basket recommendation\n",
      "session based recommendations\n",
      "reconstruction\n",
      "shape reconstruction\n",
      "multi object tracking\n",
      "object detection from stereo images\n",
      "multi object tracking\n",
      "text to speech synthesis\n",
      "indoor scene understanding\n",
      "scene understanding\n",
      "scene text\n",
      "scene text detection\n",
      "few shot learning\n",
      "image retrieval\n",
      "semantic similarity\n",
      "semantic textual similarity\n",
      "abstractive text summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "deep attention\n",
      "semantic parsing\n",
      "text to sql\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "information retrieval\n",
      "link prediction\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "eeg\n",
      "knowledge distillation\n",
      "seizure detection\n",
      "lesion segmentation\n",
      "part of speech tagging\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "density estimation\n",
      "normalising flows\n",
      "graph classification\n",
      "multi task learning\n",
      "multi label classification\n",
      "abstractive text summarization\n",
      "natural language inference\n",
      "text summarization\n",
      "link prediction\n",
      "mortality prediction\n",
      "readmission prediction\n",
      "interpretable machine learning\n",
      "image to image translation\n",
      "openai gym\n",
      "q learning\n",
      "natural language inference\n",
      "natural language understanding\n",
      "dota 2\n",
      "policy gradient methods\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "multi label zero shot learning\n",
      "zero shot learning\n",
      "graph classification\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "multi task learning\n",
      "learning to rank\n",
      "domain generalization\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "feature importance\n",
      "interpretable machine learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "human motion prediction\n",
      "multi future trajectory prediction\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "sentence classification\n",
      "sentence classification\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "lesion segmentation\n",
      "few shot learning\n",
      "meta learning\n",
      "word sense disambiguation\n",
      "eeg\n",
      "knowledge distillation\n",
      "seizure detection\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "brain decoding\n",
      "multi class classification\n",
      "multi view learning\n",
      "extractive text summarization\n",
      "text summarization\n",
      "few shot learning\n",
      "optical character recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "federated learning\n",
      "natural language understanding\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "abstractive text summarization\n",
      "hierarchical structure\n",
      "meeting summarization\n",
      "text summarization\n",
      "scene text\n",
      "scene text detection\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "answer selection\n",
      "reading comprehension\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "acoustic scene classification\n",
      "audio tagging\n",
      "multi label classification\n",
      "scene classification\n",
      "scene recognition\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "natural language inference\n",
      "natural language inference\n",
      "natural language understanding\n",
      "speaker identification\n",
      "speaker recognition\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "speaker identification\n",
      "speaker recognition\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "scene text\n",
      "scene text detection\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "human motion prediction\n",
      "multi future trajectory prediction\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "lane detection\n",
      "self driving cars\n",
      "multi armed bandits\n",
      "openai gym\n",
      "multi agent reinforcement learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "meta reinforcement learning\n",
      "visual navigation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "real time strategy games\n",
      "reading comprehension\n",
      "self supervised learning\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "image to image translation\n",
      "natural language inference\n",
      "eeg\n",
      "self supervised learning\n",
      "natural language inference\n",
      "speaker identification\n",
      "speaker recognition\n",
      "speaker identification\n",
      "speaker recognition\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "natural language inference\n",
      "natural language understanding\n",
      "audio generation\n",
      "audio super resolution\n",
      "super resolution\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "acoustic scene classification\n",
      "audio tagging\n",
      "multi label classification\n",
      "scene classification\n",
      "scene recognition\n",
      "denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "task oriented dialogue systems\n",
      "natural language inference\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "multi agent reinforcement learning\n",
      "smac\n",
      "starcraft\n",
      "super resolution\n",
      "denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "speaker identification\n",
      "speaker recognition\n",
      "acoustic scene classification\n",
      "audio tagging\n",
      "multi label classification\n",
      "scene classification\n",
      "scene recognition\n",
      "self driving cars\n",
      "video prediction\n",
      "domain generalization\n",
      "meta learning\n",
      "real time strategy games\n",
      "image to image translation\n",
      "natural language inference\n",
      "natural language understanding\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "optical character recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "natural language inference\n",
      "face hallucination\n",
      "image super resolution\n",
      "super resolution\n",
      "acoustic scene classification\n",
      "audio tagging\n",
      "multi label classification\n",
      "scene classification\n",
      "scene recognition\n",
      "natural language inference\n",
      "natural language understanding\n",
      "knowledge distillation\n",
      "feature engineering\n",
      "q learning\n",
      "dependency parsing\n",
      "semantic parsing\n",
      "link prediction\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "meta learning\n",
      "relation extraction\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "knowledge graphs\n",
      "link prediction\n",
      "semantic parsing\n",
      "two sample testing\n",
      "multi task learning\n",
      "density estimation\n",
      "deblurring\n",
      "denoising\n",
      "image reconstruction\n",
      "image super resolution\n",
      "lossy compression artifact reduction\n",
      "super resolution\n",
      "multi task learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "feature importance\n",
      "interpretable machine learning\n",
      "combinatorial optimization\n",
      "program synthesis\n",
      "semantic parsing\n",
      "structured prediction\n",
      "breast tumour classification\n",
      "colorectal gland segmentation:\n",
      "multi tissue nucleus segmentation\n",
      "nuclear segmentation\n",
      "feature selection\n",
      "image inpainting\n",
      "document classification\n",
      "continuous control\n",
      "q learning\n",
      "image inpainting\n",
      "image super resolution\n",
      "super resolution\n",
      "speaker verification\n",
      "activity recognition\n",
      "natural language inference\n",
      "question generation\n",
      "text generation\n",
      "knowledge distillation\n",
      "meta learning\n",
      "bayesian inference\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi task learning\n",
      "curriculum learning\n",
      "image super resolution\n",
      "ssim\n",
      "super resolution\n",
      "video generation\n",
      "video prediction\n",
      "graph classification\n",
      "openai gym\n",
      "q learning\n",
      "image super resolution\n",
      "super resolution\n",
      "interpretable machine learning\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "multi task learning\n",
      "multi label classification\n",
      "incremental learning\n",
      "optical character recognition\n",
      "dota 2\n",
      "policy gradient methods\n",
      "continuous control\n",
      "q learning\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "lane detection\n",
      "self driving cars\n",
      "lane detection\n",
      "self driving cars\n",
      "density estimation\n",
      "chinese word segmentation\n",
      "density estimation\n",
      "optical character recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "abstractive text summarization\n",
      "hierarchical structure\n",
      "meeting summarization\n",
      "text summarization\n",
      "scene text\n",
      "scene text detection\n",
      "few shot learning\n",
      "abstractive text summarization\n",
      "text summarization\n",
      "answer selection\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "federated learning\n",
      "natural language understanding\n",
      "answer selection\n",
      "reading comprehension\n",
      "question generation\n",
      "natural language inference\n",
      "paraphrase identification\n",
      "natural language inference\n",
      "few shot learning\n",
      "long tail learning\n",
      "long tail learning with class descriptors\n",
      "open set learning\n",
      "knowledge distillation\n",
      "speech synthesis\n",
      "real time strategy games\n",
      "style transfer\n",
      "audio classification\n",
      "speaker verification\n",
      "text dependent speaker verification\n",
      "speaker identification\n",
      "speaker recognition\n",
      "scene text\n",
      "scene text recognition\n",
      "neural architecture search\n",
      "quantization\n",
      "image inpainting\n",
      "fraud detection\n",
      "real time strategy games\n",
      "multi agent reinforcement learning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "multi class classification\n",
      "stereo matching\n",
      "stereo matching hand\n",
      "image dehazing\n",
      "single image dehazing\n",
      "continuous control\n",
      "q learning\n",
      "activity recognition\n",
      "curved text detection\n",
      "scene text\n",
      "scene text detection\n",
      "multi task learning\n",
      "pneumonia detection\n",
      "image to image translation\n",
      "openai gym\n",
      "q learning\n",
      "audio classification\n",
      "semantic parsing\n",
      "text simplification\n",
      "multi object tracking\n",
      "object detection from stereo images\n",
      "multi object tracking\n",
      "activity recognition\n",
      "omniglot\n",
      "one shot learning\n",
      "q learning\n",
      "text based games\n",
      "dota 2\n",
      "policy gradient methods\n",
      "saliency detection\n",
      "image stylization\n",
      "image super resolution\n",
      "super resolution\n",
      "music style transfer\n",
      "self supervised learning\n",
      "style transfer\n",
      "image super resolution\n",
      "motion compensation\n",
      "super resolution\n",
      "video generation\n",
      "video super resolution\n",
      "style transfer\n",
      "image inpainting\n",
      "style transfer\n",
      "text generation\n",
      "text style transfer\n",
      "robust classification\n",
      "multi agent reinforcement learning\n",
      "open set learning\n",
      "robust classification\n",
      "dictionary learning\n",
      "eye tracking\n",
      "edge detection\n",
      "neural architecture search\n",
      "object skeleton detection\n",
      "covid 19 diagnosis\n",
      "covid 19 diagnosis\n",
      "extractive text summarization\n",
      "query based extractive summarization\n",
      "text summarization\n",
      "reconstruction\n",
      "simultaneous localization and mapping\n",
      "continuous control\n",
      "meta learning\n",
      "meta reinforcement learning\n",
      "openai gym\n",
      "scene understanding\n",
      "image super resolution\n",
      "super resolution\n",
      "video prediction\n",
      "few shot learning\n",
      "model selection\n",
      "object localization\n",
      "weakly supervised object localization\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "image super resolution\n",
      "super resolution\n",
      "image restoration\n",
      "image super resolution\n",
      "super resolution\n",
      "document summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "turning point identification\n",
      "dota 2\n",
      "policy gradient methods\n",
      "omniglot\n",
      "one shot learning\n",
      "fine grained image classification\n",
      "knowledge graphs\n",
      "link prediction\n",
      "triple classification\n",
      "semi supervised image classification\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "semi supervised image classification\n",
      "style transfer\n",
      "scene text\n",
      "scene text detection\n",
      "two sample testing\n",
      "human object interaction detection\n",
      "automl\n",
      "model compression\n",
      "neural architecture search\n",
      "document summarization\n",
      "extractive text summarization\n",
      "text summarization\n",
      "turning point identification\n",
      "image inpainting\n",
      "image reconstruction\n",
      "image super resolution\n",
      "super resolution\n",
      "speaker verification\n",
      "edge detection\n",
      "visual odometry\n",
      "neural network compression\n",
      "multi class classification\n",
      "multi label text classification\n",
      "scene understanding\n",
      "reconstruction\n",
      "junction detection\n",
      "line segment detection\n",
      "anomaly detection\n",
      "continual learning\n",
      "meta learning\n",
      "one class classifier\n",
      "super resolution\n",
      "natural language understanding\n",
      "person re identification\n",
      "person retrieval\n",
      "image super resolution\n",
      "super resolution\n",
      "reconstruction\n",
      "indoor localization\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "activity recognition\n",
      "image inpainting\n",
      "autonomous driving\n",
      "q learning\n",
      "network pruning\n",
      "reconstruction\n",
      "shape representation\n",
      "bird view synthesis\n",
      "cross view image to image translation\n",
      "image to image translation\n",
      "covid 19 diagnosis\n",
      "eeg\n",
      "knowledge distillation\n",
      "seizure detection\n",
      "style transfer\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "meta learning\n",
      "meta learning\n",
      "omniglot\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "object reconstruction\n",
      "reconstruction\n",
      "object reconstruction\n",
      "large scale person re identification\n",
      "multiple object tracking\n",
      "object tracking\n",
      "person re identification\n",
      "video instance segmentation\n",
      "person re identification\n",
      "document classification\n",
      "multi task learning\n",
      "text summarization\n",
      "density estimation\n",
      "latent variable models\n",
      "normalising flows\n",
      "image retrieval\n",
      "metric learning\n",
      "person re identification\n",
      "denoising\n",
      "image denoising\n",
      "image super resolution\n",
      "super resolution\n",
      "q learning\n",
      "one shot learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "legged robots\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "hyperparameter optimization\n",
      "meta learning\n",
      "multi agent reinforcement learning\n",
      "multi agent reinforcement learning\n",
      "reconstruction\n",
      "computed tomography (ct)\n",
      "image reconstruction\n",
      "super resolution\n",
      "super resolution\n",
      "eeg\n",
      "multi task learning\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "saliency detection\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "reconstruction\n",
      "denoising\n",
      "image denoising\n",
      "image enhancement\n",
      "image super resolution\n",
      "super resolution\n",
      "music style transfer\n",
      "self supervised learning\n",
      "style transfer\n",
      "interpretable machine learning\n",
      "inductive logic programming\n",
      "image to image translation\n",
      "intent classification\n",
      "natural language understanding\n",
      "slot filling\n",
      "multi label classification\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "dota 2\n",
      "policy gradient methods\n",
      "continuous control\n",
      "q learning\n",
      "image super resolution\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "super resolution\n",
      "style transfer\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "deblurring\n",
      "self supervised learning\n",
      "image inpainting\n",
      "reconstruction\n",
      "structure from motion\n",
      "image inpainting\n",
      "style transfer\n",
      "density estimation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image enhancement\n",
      "low light image enhancement\n",
      "self supervised learning\n",
      "style transfer\n",
      "video style transfer\n",
      "speaker verification\n",
      "self driving cars\n",
      "trajectory forecasting\n",
      "trajectory prediction\n",
      "text to sql\n",
      "multi class classification\n",
      "semantic parsing\n",
      "density estimation\n",
      "model selection\n",
      "photometric redshift estimation\n",
      "multi class classification\n",
      "multi label text classification\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "plane detection\n",
      "reconstruction\n",
      "density estimation\n",
      "model selection\n",
      "photometric redshift estimation\n",
      "network pruning\n",
      "natural language understanding\n",
      "reconstruction\n",
      "indoor localization\n",
      "image inpainting\n",
      "classification\n",
      "point cloud classification\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "few shot image classification\n",
      "few shot learning\n",
      "meta learning\n",
      "zero shot learning\n",
      "reconstruction\n",
      "shape representation\n",
      "knowledge distillation\n",
      "reconstruction\n",
      "simultaneous localization and mapping\n",
      "image to image translation\n",
      "human pose estimation\n",
      "hand pose estimation\n",
      "motion capture\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "style transfer\n",
      "multi agent reinforcement learning\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "image to image translation\n",
      "real to cartoon translation\n",
      "computed tomography (ct)\n",
      "image to image translation\n",
      "medical image generation\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image enhancement\n",
      "low light image enhancement\n",
      "self supervised learning\n",
      "image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "unsupervised image to image translation\n",
      "few shot learning\n",
      "zero shot learning\n",
      "continuous control\n",
      "q learning\n",
      "adversarial text\n",
      "style transfer\n",
      "text generation\n",
      "cross view image to image translation\n",
      "fundus to angiography generation\n",
      "image to image translation\n",
      "nuclear segmentation\n",
      "image super resolution\n",
      "super resolution\n",
      "video super resolution\n",
      "image super resolution\n",
      "image to image translation\n",
      "super resolution\n",
      "image to image translation\n",
      "multimodal unsupervised image to image translation\n",
      "style transfer\n",
      "unsupervised image to image translation\n",
      "image super resolution\n",
      "multi frame super resolution\n",
      "super resolution\n",
      "continuous control\n",
      "q learning\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "meta learning\n",
      "continuous control\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "legged robots\n",
      "meta learning\n",
      "q learning\n",
      "multi agent reinforcement learning\n",
      "q learning\n",
      "two sample testing\n",
      "q learning\n",
      "face hallucination\n",
      "image denoising\n",
      "image restoration\n",
      "image super resolution\n",
      "combinatorial optimization\n",
      "q learning\n",
      "dota 2\n",
      "policy gradient methods\n",
      "music source separation\n",
      "speaker separation\n",
      "speech enhancement\n",
      "speech separation\n",
      "rectification\n",
      "rectification\n",
      "scene text\n",
      "scene text recognition\n",
      "hate speech detection\n",
      "zero shot learning\n",
      "graph embedding\n",
      "knowledge graph embedding\n",
      "knowledge graphs\n",
      "link prediction\n",
      "reconstruction\n",
      "simultaneous localization and mapping\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "q learning\n",
      "text based games\n",
      "natural language understanding\n",
      "entity extraction using gan\n",
      "multi task learning\n",
      "relation extraction\n",
      "multi task learning\n",
      "edge computing\n",
      "deblurring\n",
      "image super resolution\n",
      "super resolution\n",
      "face generation\n",
      "image to image translation\n",
      "video generation\n",
      "neural architecture search\n"
     ]
    }
   ],
   "source": [
    "graphsage_area_results = analyze_query_level_results(raw_graphsage_area_results, area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recalled</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th colspan=\"2\" halign=\"left\">position</th>\n",
       "      <th>area_recalled</th>\n",
       "      <th>num_area_recalled</th>\n",
       "      <th colspan=\"2\" halign=\"left\">area_position</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>mean</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.23</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-vision</th>\n",
       "      <td>0.34</td>\n",
       "      <td>0.59</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural-language-processing</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodology</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.81</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.95</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graphs</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing-games</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time-series</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-code</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge-base</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            recalled num_recalled position      area_recalled  \\\n",
       "                                mean         mean   median mean          mean   \n",
       "area                                                                            \n",
       "miscellaneous                   0.17         0.23      inf  inf          0.91   \n",
       "computer-vision                 0.34         0.59      inf  inf          1.00   \n",
       "natural-language-processing     0.25         0.46      inf  inf          0.96   \n",
       "methodology                     0.38         0.81      inf  inf          1.00   \n",
       "graphs                          0.25         0.25      inf  inf          0.75   \n",
       "speech                          0.50         0.50      inf  inf          1.00   \n",
       "medical                         0.33         1.00      inf  inf          0.67   \n",
       "playing-games                   0.00         0.00      inf  inf          1.00   \n",
       "time-series                     0.00         0.00      inf  inf          0.00   \n",
       "audio                           1.00         1.00      3.0  3.0          1.00   \n",
       "computer-code                   0.00         0.00      inf  inf          0.00   \n",
       "knowledge-base                  0.00         0.00      inf  inf          0.00   \n",
       "robots                          0.00         0.00      inf  inf          0.00   \n",
       "\n",
       "                            num_area_recalled area_position       count  \n",
       "                                         mean        median  mean        \n",
       "area                                                                     \n",
       "miscellaneous                            0.91           3.0   inf    35  \n",
       "computer-vision                          1.00           0.0  0.12    32  \n",
       "natural-language-processing              0.96           4.0   inf    24  \n",
       "methodology                              1.00           2.0  1.95    21  \n",
       "graphs                                   0.75           1.5   inf     4  \n",
       "speech                                   1.00           5.0  4.75     4  \n",
       "medical                                  0.67           2.0   inf     3  \n",
       "playing-games                            1.00           2.0  2.00     2  \n",
       "time-series                              0.00           inf   inf     2  \n",
       "audio                                    1.00           0.0  0.00     1  \n",
       "computer-code                            0.00           inf   inf     1  \n",
       "knowledge-base                           0.00           inf   inf     1  \n",
       "robots                                   0.00           inf   inf     1  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_area_results.round(2).sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_area_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_readme_results = analyze_query_level_results(rea, area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_readme_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_graphsage_results = analyze_query_level_results(detailed_results_graphsage_all, area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analyzed_readme_results.sort_values(('recalled','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_graphsage_results.sort_values(('recalled','mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_grouped_tasks['task'] == [detailed_results_readme['top10_accuracy_test'].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_results_readme['top10_accuracy_test'].groupby(area_grouped_tasks['task'].loc[detailed_results_readme['top10_accuracy_test'].index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(readme_data_test, open(\"output/readme_data_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graphsage_data_test, open(\"output/graphsage_data_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graphsage_learner, open(\"output/graphsage_learner.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(readme_learner, open(\"output/readme_learner.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_retriever = Retriever.from_retriever_learner(readme_learner)\n",
    "readme_retriever.set_embeddings(readme_data_train.repos, readme_data_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever = Retriever.from_retriever_learner(graphsage_learner)\n",
    "graphsage_retriever.set_embeddings(graphsage_data_train.repos, graphsage_data_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metric_learning_results = readme_retriever.retrieve_query_results(\"metric learning\", k=5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "metric_learning_results_graphsage = graphsage_retriever.retrieve_query_results(\"metric learning\", k=5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_learning_results = readme_retriever.retrieve_query_results(\"distance learning\", k=5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_learning_results_graphsage = graphsage_retriever.retrieve_query_results(\"distance learning\", k=5).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_learning_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_learning_results_graphsage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "readme_retriever.retrieve_query_results(\"video text detection\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever.retrieve_query_results(\"video text detection\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_retriever.retrieve_query_results(\"context recommender systems\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever.retrieve_query_results(\"context recommender systems\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_retriever.retrieve_query_results(\"bayesian optimization\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever.retrieve_query_results(\"bayesian optimization\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_retriever.retrieve_query_results(\"evolutionary methods\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever.retrieve_query_results(\"evolutionary methods\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_retriever.retrieve_query_results(\"painting\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_retriever.retrieve_query_results(\"painting\", k=10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "retrieve_query_results(graphsage_learner, graphsage_data_train.repos, graphsage_data_train.X, \"distance learning\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_query_results(graphsage_learner, graphsage_data_train.X, \"distance learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation of repo, import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train, paired_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "paired_data_train.X = graph_data_train.X + \" \" + import_data_train.X\n",
    "paired_data_test.X = graph_data_test.X + \" \" + import_data_test.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    PairedKeyedVectors(python_word_embeddings.wv, graphsage_embeddings),\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "paired_learner.fit_learner(graph_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (learner, learner_name, test) in zip(\n",
    "    [import2vec_learner, prone_learner, paired_learner],\n",
    "    ['import2vec', 'prone', 'both'],\n",
    "    [X_test, repo_graph_terms_test, X_paired_test]\n",
    "):\n",
    "    accs = []\n",
    "    for k in [1, 3, 5, 10, 20]:\n",
    "        rec = get_retrieval_accuracy(learner, test, y_test, test_task_idxs, k=k)\n",
    "        accs.append(rec)\n",
    "    results.append(pd.Series(name=learner_name, data=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = [\"Accuracy@{}\".format(i) for i in [1, 3, 5, 10, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_markdown(open(\"metrics/zsl_results.md\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat metrics/zsl_results.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_distances = metrics.pairwise.cosine_distances(task_embeddings, task_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_embeddings = gensim.models.KeyedVectors.load('data/poincare5.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.wrappers.fasttext\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import typical_file_parts\n",
    "from mlutil import prototype_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lines_df = typical_file_parts.get_selected_lines_and_repos(python_files_df['repo_name'], python_files_df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting prototypical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_selector = prototype_selection.PrototypeSelector(fasttext_avg_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fasttext_prototypes = json.load(open('data/fasttext_prototypes.json', 'r'))\n",
    "except:\n",
    "    fasttext_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    fasttext_prototypes = fasttext_selector.prototypes\n",
    "    json.dump(fasttext_prototypes, open('data/fasttext_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_vectorizer = embeddings.TransformerVectorizer('microsoft/codebert-base', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector = prototype_selection.PrototypeSelector(codebert_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    codebert_prototypes = json.load(open('data/codebert_prototypes.json', 'r'))\n",
    "except:\n",
    "    codebert_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    codebert_prototypes = codebert_selector.prototypes\n",
    "    json.dump(codebert_prototypes, open('data/codebert_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_prototypes(vectorizer, prototypes):\n",
    "    prototype_aggregated_embeddings = {}\n",
    "    for key in prototypes.keys():\n",
    "        prototype_aggregated_embeddings[key] = np.mean(vectorizer.transform(prototypes[key]), axis=0)\n",
    "    return list(prototype_aggregated_embeddings.keys()), np.row_stack(prototype_aggregated_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in codebert_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in fasttext_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prototypes(repo_name):\n",
    "    return pd.DataFrame({\"codebert\": codebert_prototypes[repo_name], \"fasttext\": fasttext_prototypes[repo_name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"Recommenders-movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes['mmdetection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_repos, codebert_prototype_embeddings = vectorize_prototypes(codebert_vectorizer, codebert_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_repos, fasttext_prototype_embeddings = vectorize_prototypes(fasttext_avg_embedder, fasttext_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fasttext_prototype_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_tasks_series = paperswithcode_with_imports_df['most_common_task']\n",
    "paperswithcode_tasks_series.index = paperswithcode_with_imports_df['repo_name']\n",
    "#paperswithcode_tasks_series = paperswithcode_tasks_series[paperswithcode_tasks_series.index.isin(fasttext_repos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_tasks = paperswithcode_tasks_series.loc[fasttext_repos]\n",
    "fasttext_tasks_embeddings = task_embedder.transform(fasttext_tasks)\n",
    "codebert_tasks = paperswithcode_tasks_series.loc[codebert_repos]\n",
    "codebert_tasks_embeddings = task_embedder.transform(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner = zero_shot.ESZSLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(selected_lines_df['repo']))[3007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df = selected_lines_df[selected_lines_df['repo'] == 'auto_ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del codebert_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df['lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector.prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings = fasttext_avg_embedder.transform(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names = \n",
    "repo_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
