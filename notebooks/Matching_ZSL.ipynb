{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp matching_zsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import ast\n",
    "import tqdm\n",
    "import json\n",
    "import attr\n",
    "from operator import itemgetter\n",
    "from scipy.stats import hmean\n",
    "import logging\n",
    "\n",
    "import concurrent.futures\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, metrics, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from mlutil.feature_extraction import embeddings\n",
    "import mlutil\n",
    "from scarce_learn import zero_shot\n",
    "from scarce_learn.zero_shot import devise_jax, devise_torch\n",
    "from github_search import (\n",
    "    paperswithcode_tasks,\n",
    "    github_readmes,\n",
    "    python_call_graph,\n",
    "    data_utils,\n",
    ")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.pytorch_geometric_data import PygGraphWrapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from github_search.paperswithcode_tasks import clean_task_name\n",
    "import fasttext\n",
    "import pickle\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "\n",
    "import_corpus_path = \"output/module_corpus.csv\"\n",
    "word_vectors_filename = \"output/import2vec_module_vectors.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)\n",
    "import_corpus_df['imports'] = import_corpus_df['imports'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "#python_files_df = pd.read_csv('data/crawled_python_files.csv', encoding='latin-1')\n",
    "#repo_names = python_files_df['repo_name']\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python_files_df['repo'] = python_files_df['repo_name'].str.split(\"/\").apply(itemgetter(1))  + '/' + python_files_df['repo_name']\n",
    "repo_names_tmp = python_files_df['repo_name']\n",
    "repo_names = repo_names_tmp.unique()\n",
    "python_files_df['repo_name'] = python_files_df['repo']\n",
    "python_files_df['repo'] = repo_names_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 17:24:12,219 - gensim.utils - INFO - loading Word2VecKeyedVectors object from output/import2vec_module_vectors.bin\n",
      "2022-03-14 17:24:12,234 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2022-03-14 17:24:12,235 - gensim.utils - INFO - loaded output/import2vec_module_vectors.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 ms, sys: 811 Âµs, total: 13.6 ms\n",
      "Wall time: 16.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import2vec = gensim.models.KeyedVectors.load(word_vectors_filename)\n",
    "import2vec_embedder = (\n",
    "    mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(import2vec)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"3d reconstruction\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-2f5edfe6165f>:1: DtypeWarning: Columns (2,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  paperswithcode_with_imports_df = pd.read_csv('output/papers_with_imports.csv')\n",
      "<ipython-input-10-2f5edfe6165f>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  paperswithcode_with_imports_df['imports'] = paperswithcode_with_imports_df['imports'].str.replace(\"set\\(\\)\", \"{}\").apply(ast.literal_eval)\n"
     ]
    }
   ],
   "source": [
    "paperswithcode_with_imports_df = pd.read_csv(\"output/papers_with_imports.csv\")\n",
    "paperswithcode_with_imports_df[\"tasks\"] = (\n",
    "    paperswithcode_with_imports_df[\"tasks\"]\n",
    "    .apply(clean_task_name)\n",
    "    .apply(ast.literal_eval)\n",
    ")\n",
    "paperswithcode_with_imports_df[\"imports\"] = (\n",
    "    paperswithcode_with_imports_df[\"imports\"]\n",
    "    .str.replace(\"set\\(\\)\", \"{}\")\n",
    "    .apply(ast.literal_eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36209, 23)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df[\"n_imports\"] = paperswithcode_with_imports_df[\n",
    "    \"imports\"\n",
    "].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df[\n",
    "    \"n_imports_with_embeddings\"\n",
    "] = paperswithcode_with_imports_df[\"imports\"].apply(\n",
    "    lambda imps: len([imp in import2vec.vocab.keys() for imp in imps])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36209"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df[\"repo\"].unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 17:24:15,327 - gensim.models.utils_any2vec - INFO - loading projection weights from /home/kuba/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2022-03-14 17:24:50,418 - gensim.models.utils_any2vec - INFO - loaded (400000, 300) matrix from /home/kuba/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 381 ms, total: 34.9 s\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_embeddings = mlutil.feature_extraction.embeddings.load_gensim_embedding_model(\n",
    "    \"glove-wiki-gigaword-300\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = fasttext.load_model(\"output/python_files_fasttext_dim200.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "\n",
    "\n",
    "class LossCallback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print(\"Loss after epoch {}: {}\".format(self.epoch, loss))\n",
    "        else:\n",
    "            print(\n",
    "                \"Loss after epoch {}: {}\".format(\n",
    "                    self.epoch, loss - self.loss_previous_step\n",
    "                )\n",
    "            )\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 17:25:14,363 - gensim.utils - INFO - loading Word2Vec object from output/abstract_readme_w2v200.bin\n",
      "2022-03-14 17:25:14,758 - gensim.utils - INFO - loading wv recursively from output/abstract_readme_w2v200.bin.wv.* with mmap=None\n",
      "2022-03-14 17:25:14,759 - gensim.utils - INFO - loading vectors from output/abstract_readme_w2v200.bin.wv.vectors.npy with mmap=None\n",
      "2022-03-14 17:25:14,787 - gensim.utils - INFO - setting ignored attribute vectors_norm to None\n",
      "2022-03-14 17:25:14,788 - gensim.utils - INFO - loading vocabulary recursively from output/abstract_readme_w2v200.bin.vocabulary.* with mmap=None\n",
      "2022-03-14 17:25:14,788 - gensim.utils - INFO - loading trainables recursively from output/abstract_readme_w2v200.bin.trainables.* with mmap=None\n",
      "2022-03-14 17:25:14,788 - gensim.utils - INFO - loading syn1neg from output/abstract_readme_w2v200.bin.trainables.syn1neg.npy with mmap=None\n",
      "2022-03-14 17:25:14,811 - gensim.utils - INFO - setting ignored attribute cum_table to None\n",
      "2022-03-14 17:25:14,812 - gensim.utils - INFO - loaded output/abstract_readme_w2v200.bin\n"
     ]
    }
   ],
   "source": [
    "python_word_embeddings = gensim.models.Word2Vec.load(\n",
    "    \"output/abstract_readme_w2v200.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class RepoTaskData:\n",
    "\n",
    "    tasks = attr.ib()\n",
    "    repos = attr.ib()\n",
    "    X = attr.ib()\n",
    "    all_tasks = attr.ib()\n",
    "    y = attr.ib()\n",
    "\n",
    "    def split_tasks(area_grouped_tasks, test_size=0.2):\n",
    "        tasks_train, tasks_test = model_selection.train_test_split(\n",
    "            area_grouped_tasks[\"task\"],\n",
    "            stratify=area_grouped_tasks[\"area\"],\n",
    "            test_size=test_size,\n",
    "            random_state=0,\n",
    "        )\n",
    "        return tasks_train, tasks_test\n",
    "\n",
    "    def create_split(\n",
    "        tasks_test,\n",
    "        all_tasks,\n",
    "        paperswithcode_with_features_df,\n",
    "        X_repr,\n",
    "        y_col=\"least_common_task\",\n",
    "    ):\n",
    "        train_indicator = paperswithcode_with_features_df[\"tasks\"].apply(\n",
    "            lambda ts: not (any([t in list(tasks_test) for t in ts]))\n",
    "        )\n",
    "        repos_train = paperswithcode_with_features_df[\"repo\"][train_indicator]\n",
    "        repos_test = paperswithcode_with_features_df[\"repo\"][~train_indicator]\n",
    "        X_repr = X_repr.apply(lambda x: \" \".join(x))\n",
    "        X_train = X_repr[train_indicator]\n",
    "        X_test = X_repr[~train_indicator]\n",
    "        all_tasks_train = all_tasks[train_indicator]\n",
    "        all_tasks_test = all_tasks[~train_indicator]\n",
    "        y_train = (\n",
    "            paperswithcode_with_features_df[train_indicator][y_col]\n",
    "            .str.lower()\n",
    "            .apply(clean_task_name)\n",
    "        )\n",
    "        y_test = (\n",
    "            paperswithcode_with_features_df[~train_indicator][y_col]\n",
    "            .str.lower()\n",
    "            .apply(clean_task_name)\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            RepoTaskData(tasks_train, repos_train, X_train, all_tasks_train, y_train),\n",
    "            RepoTaskData(tasks_test, repos_test, X_test, all_tasks_test, y_test),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_first_vocab_entry(vocab):\n",
    "    return list(itertools.islice(vocab.items(), 1))[0][0]\n",
    "\n",
    "\n",
    "class PairedKeyedVectors:\n",
    "    @attr.s\n",
    "    class wv:\n",
    "        vocab = attr.ib()\n",
    "\n",
    "    def __init__(self, kv1, kv2):\n",
    "        self.kv1 = kv1\n",
    "        self.kv2 = kv2\n",
    "        self.vocab = {**kv1.vocab, **kv2.vocab}\n",
    "        self.dim1 = len(kv1[get_first_vocab_entry(kv1.vocab)])\n",
    "        self.dim2 = len(kv2[get_first_vocab_entry(kv2.vocab)])\n",
    "        self.wv = PairedKeyedVectors.wv(self.vocab)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if not item in self.kv1.vocab.keys():\n",
    "            return np.concatenate([np.zeros(self.dim1), self.kv2[item]])\n",
    "        elif not item in self.kv2.vocab.keys():\n",
    "            return np.concatenate([self.kv1[item], np.zeros(self.dim2)])\n",
    "        else:\n",
    "            return np.concatenate([self.kv1[item], self.kv2[item]])\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class RetrieverLearner:\n",
    "\n",
    "    zs_learner: zero_shot.ZeroShotClassifier = attr.ib()\n",
    "    input_embedder: embeddings.EmbeddingVectorizer = attr.ib()\n",
    "    y_embedder: embeddings.EmbeddingVectorizer = attr.ib()\n",
    "    input_embedder_kwargs = attr.ib(default=dict())\n",
    "\n",
    "    @staticmethod\n",
    "    def create(\n",
    "        zs_learner: zero_shot.ZeroShotClassifier,\n",
    "        input_embeddings: gensim.models.KeyedVectors,\n",
    "        target_embeddings: gensim.models.KeyedVectors,\n",
    "        input_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        y_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        input_embedder_kwargs=dict(),\n",
    "    ):\n",
    "        input_embedder = input_embedding_method(\n",
    "            input_embeddings, **input_embedder_kwargs\n",
    "        )\n",
    "        y_embedder = y_embedding_method(target_embeddings)\n",
    "        return RetrieverLearner(zs_learner, input_embedder, y_embedder)\n",
    "\n",
    "    def get_target_embeddings(self, y):\n",
    "        unique_y = pd.Series(y.unique())\n",
    "        y_embeddings = self.y_embedder.transform(unique_y)\n",
    "        return unique_y, y_embeddings\n",
    "\n",
    "    def fit_learner(self, data, **kwargs):\n",
    "        self.input_embedder.fit(data.X)\n",
    "        X_embeddings = self.input_embedder.transform(data.X)\n",
    "        self.y_embedder.fit(data.y)\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        self.zs_learner.fit(\n",
    "            np.array(X_embeddings),\n",
    "            np.array(input_y_idxs),\n",
    "            np.array(y_embeddings),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def predict_idxs(self, X, y_embeddings):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        return self.zs_learner.predict(X_embeddings, y_embeddings)\n",
    "\n",
    "    def predict_topk(\n",
    "        self,\n",
    "        X,\n",
    "        y_embeddings,\n",
    "        target_names,\n",
    "        k=5,\n",
    "        similarity=metrics.pairwise.cosine_similarity,\n",
    "    ):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        predictions = self.zs_learner.predict_raw(X_embeddings)\n",
    "        target_similarities = similarity(predictions, y_embeddings)\n",
    "        targets = [\n",
    "            target_names[row[:k]] for row in (-target_similarities).argsort(axis=1)\n",
    "        ]\n",
    "        return targets\n",
    "\n",
    "    def evaluate(self, data, metric):\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        predicted_idxs = self.predict_idxs(data.X, y_embeddings)\n",
    "        return metric(input_y_idxs, predicted_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(\"output/call_igraph.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53700"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.get_vertex_dataframe().iloc[graph.neighborhood(vertices=[\"<ROOT>\"])[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get repos that are in graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36208"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df[\"repo\"].isin(graph.get_vertex_dataframe()[\"name\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes = graph.get_vertex_dataframe()[\"name\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600597"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_tasks_df = (\n",
    "    pd.read_csv(\"output/papers_with_readmes.csv\")\n",
    "    .dropna(subset=[\"least_common_task\"])\n",
    "    .dropna(subset=[\"readme\", \"abstract\"])\n",
    ")\n",
    "paperswithcode_with_tasks_df[\"tasks\"] = paperswithcode_with_tasks_df[\"tasks\"].apply(\n",
    "    ast.literal_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39848,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_tasks_df[\"readme\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df = pd.read_csv(\"output/processed_dependency_records.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def filter_smaller_tasks(paperswithcode_with_tasks_df, min_task_count=10):\n",
    "    task_counts = paperswithcode_with_tasks_df[\"least_common_task\"].value_counts()\n",
    "    return paperswithcode_with_tasks_df[\n",
    "        paperswithcode_with_tasks_df[\"least_common_task\"].isin(\n",
    "            task_counts[task_counts >= min_task_count].index\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "def prepare_paperswithcode_with_features_df(\n",
    "    paperswithcode_with_tasks_df, dependency_records_df, min_task_count\n",
    "):\n",
    "    paperswithcode_with_features_df = paperswithcode_with_tasks_df[\n",
    "        paperswithcode_with_tasks_df[\"repo\"].isin(graph.get_vertex_dataframe()[\"name\"])\n",
    "        | paperswithcode_with_tasks_df[\"repo\"]\n",
    "        .apply(lambda s: s.split(\"/\")[1])\n",
    "        .isin(graph.get_vertex_dataframe()[\"name\"])\n",
    "    ]\n",
    "    paperswithcode_with_features_df = paperswithcode_with_features_df.dropna(\n",
    "        subset=[\"readme\", \"abstract\"]\n",
    "    )\n",
    "    tasks = paperswithcode_with_features_df[\"least_common_task\"].str.lower()\n",
    "\n",
    "    per_repo_dependency_records = data_utils.get_repo_records(\n",
    "        paperswithcode_with_features_df[\"repo\"], dependency_records_df\n",
    "    )\n",
    "    per_repo_dependency_records = per_repo_dependency_records.reset_index()\n",
    "    per_repo_dependency_records.columns = [\"source\", \"dependency_records\"]\n",
    "    paperswithcode_with_features_df = paperswithcode_with_features_df.merge(\n",
    "        per_repo_dependency_records.reset_index(), left_on=\"repo\", right_on=\"source\"\n",
    "    )\n",
    "    all_tasks = paperswithcode_with_features_df[\"tasks\"]\n",
    "    is_valid_record = all_tasks.apply(len) > 0\n",
    "    paperswithcode_with_features_df = filter_smaller_tasks(\n",
    "        paperswithcode_with_features_df[is_valid_record], min_task_count\n",
    "    )\n",
    "    all_tasks = paperswithcode_with_features_df[\"tasks\"]\n",
    "    all_task_counts = all_tasks.explode().value_counts()\n",
    "    valid_tasks = all_task_counts[all_task_counts >= min_task_count].index\n",
    "    paperswithcode_with_features_df[\"tasks\"] = paperswithcode_with_features_df[\n",
    "        \"tasks\"\n",
    "    ].apply(lambda ts: [t for t in ts if t in valid_tasks])\n",
    "    return paperswithcode_with_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_features_df = prepare_paperswithcode_with_features_df(\n",
    "    paperswithcode_with_tasks_df, dependency_records_df, min_task_count=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = paperswithcode_with_imports_df[\n",
    "    paperswithcode_with_imports_df[\"repo\"].isin(paperswithcode_with_features_df[\"repo\"])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = paperswithcode_with_features_df[\n",
    "    \"tasks\"\n",
    "]  # .apply(lambda tasks: [t for t in tasks if t in valid_tasks.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = all_tasks.explode().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image classification             1765\n",
       "object detection                 1085\n",
       "language modelling                800\n",
       "domain adaptation                 766\n",
       "data augmentation                 696\n",
       "                                 ... \n",
       "code summarization                 10\n",
       "synthetic data generation          10\n",
       "handwritten digit recognition      10\n",
       "discourse parsing                  10\n",
       "automatic post editing             10\n",
       "Name: least_common_task, Length: 429, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df[\"least_common_task\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32815, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_grouped_tasks = get_area_grouped_tasks()\n",
    "area_grouped_tasks[\"task\"] = area_grouped_tasks[\"task\"].apply(clean_task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_area_grouped_tasks = pd.read_csv(\"data/paperswithcode_tasks.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_area_grouped_tasks[\"task\"] = all_area_grouped_tasks[\"task\"].str.replace(\"-\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_train, tasks_test = RepoTaskData.split_tasks(all_area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readme_summaries(upstream, product, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(\n",
    "        pool.map(github_readmes.get_readme, paperswithcode_with_features_df[\"repo\"])\n",
    "    )\n",
    "    readmes = pd.Series(raw_readmes).apply(github_readmes.try_decode)\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readmes(df, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, df[\"repo\"]))\n",
    "    readmes = list(map(github_readmes.try_decode, raw_readmes))\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'paper_url', 'paper_title',\n",
       "       'paper_arxiv_id', 'paper_url_abs', 'paper_url_pdf', 'repo_url',\n",
       "       'mentioned_in_paper', 'mentioned_in_github', 'framework', 'repo',\n",
       "       'title', 'abstract', 'tasks', 'least_common_task', 'readme', 'index',\n",
       "       'source', 'dependency_records'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32815, 20)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "readmes = get_readmes(paperswithcode_with_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_keywords(text):\n",
    "    return python_call_graph.try_run(gensim.summarization.keywords)(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(\n",
    "    word_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_outgoing_edges(graph, node):\n",
    "    # idx = pd.Index(graph.names).get_loc(node)\n",
    "    # outgoing_edges_idx = np.where(graph.mat[idx].todense())[1]\n",
    "    return graph.get_vertex_dataframe().iloc[graph.successors(node)][\"name\"]\n",
    "    # return graph.names[outgoing_edges_idx]\n",
    "\n",
    "\n",
    "def get_repo_functions(graph_records, repo):\n",
    "    return \" \".join(set(get_outgoing_edges(graph, repo).values)).replace(repo + \":\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def prepare_task_train_test_split(upstream, product):\n",
    "    area_grouped_tasks = pd.read_csv(str(upstream[\"prepare_area_grouped_tasks\"]))\n",
    "    tasks_train, tasks_test = RepoTaskData.split_tasks(area_grouped_tasks)\n",
    "    tasks_train.to_csv(product[\"train\"], index=None)\n",
    "    tasks_test.to_csv(product[\"test\"], index=None)\n",
    "\n",
    "\n",
    "def prepare_graph_repo_task_data(upstream, product):\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(\n",
    "        tasks_train,\n",
    "        all_tasks,\n",
    "        paperswithcode_with_features_df,\n",
    "        paperswithcode_with_imports_df[\"imports\"],\n",
    "    )\n",
    "    graph_data_train.X = graph_data_train.repos.apply(\n",
    "        lambda x: get_repo_functions(graph, x)\n",
    "    )\n",
    "    graph_data_test.X = graph_data_test.repos.apply(\n",
    "        lambda x: get_repo_functions(graph, x)\n",
    "    )\n",
    "    pickle.dump((graph_data_train, graph_data_test), open(str(product), \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_data_train, readme_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    paperswithcode_with_features_df[\"tasks\"],\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_features_df[\"readme\"].str.split(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_test.to_csv(\"output/test_tasks.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718665244552796"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_train.X.shape[0] / paperswithcode_with_features_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.718665244552796"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_train.X.shape[0] / paperswithcode_with_features_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train, graph_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    paperswithcode_with_features_df[\"tasks\"],\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_features_df[\"repo\"].apply(lambda t: [t]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'is_valid_record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_valid_record' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(\"output/tmp_graph_data.pkl\"):\n",
    "    (graph_data_train, graph_data_test) = pickle.load(\n",
    "        open(\"output/tmp_graph_data.pkl\", \"rb\")\n",
    "    )\n",
    "else:\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(\n",
    "        tasks_test,\n",
    "        all_tasks[is_valid_record],\n",
    "        paperswithcode_with_features_df[is_valid_record],\n",
    "        paperswithcode_with_features_df[is_valid_record][\"readme\"].str.split(),\n",
    "    )\n",
    "\n",
    "    graph_records_train_X = pd.Series(\n",
    "        [\n",
    "            get_repo_functions(graph, x)\n",
    "            for x in tqdm.notebook.tqdm(graph_data_train.repos)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    graph_records_test_X = pd.Series(\n",
    "        [\n",
    "            get_repo_functions(graph, x)\n",
    "            for x in tqdm.notebook.tqdm(graph_data_test.repos)\n",
    "        ]\n",
    "    )\n",
    "    graph_data_train.X = graph_records_train_X\n",
    "    graph_data_test.X = graph_records_test_X\n",
    "    pickle.dump(\n",
    "        (graph_data_train, graph_data_test), open(\"output/tmp_graph_data.pkl\", \"wb\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graph_data_train.X)):\n",
    "    graph_data_train.X.iloc[i] = graph_data_train.X.iloc[i].replace(\n",
    "        graph_data_train.repos.iloc[i], \"\"\n",
    "    )\n",
    "for i in range(len(graph_data_test.X)):\n",
    "    graph_data_test.X.iloc[i] = graph_data_test.X.iloc[i].replace(\n",
    "        graph_data_test.repos.iloc[i], \"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.X = graph_data_train.X.str.replace(\":\", \" \")\n",
    "graph_data_train.X = graph_data_train.X.str.replace(\"<ROOT>\", \" \")\n",
    "graph_data_test.X = graph_data_test.X.str.replace(\":\", \" \")\n",
    "graph_data_test.X = graph_data_test.X.str.replace(\"<ROOT>\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def maybe_get_ndarray_elem(arr, idx, default=-1):\n",
    "    if len(arr) <= idx:\n",
    "        return default\n",
    "    else:\n",
    "        return arr[idx]\n",
    "\n",
    "\n",
    "def get_retrieval_results(\n",
    "    learner, data, queried_tasks, k=10, similarity=metrics.pairwise.cosine_similarity\n",
    "):\n",
    "    if queried_tasks == \"all\":\n",
    "        tasks = data.all_tasks.explode().drop_duplicates()\n",
    "    elif queried_tasks == \"target\":\n",
    "        tasks = data.y.drop_duplicates()\n",
    "    else:\n",
    "        tasks = queried_tasks\n",
    "    y_names, __ = learner.get_target_embeddings(tasks)\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "\n",
    "    X_recalled = [\n",
    "        np.argsort(-input_target_similarities[:, y_idx])[:k]\n",
    "        for (y_idx, __) in enumerate(y_names)\n",
    "    ]\n",
    "    return y_names, X_recalled\n",
    "\n",
    "\n",
    "def get_retrieval_metrics(\n",
    "    learner,\n",
    "    data,\n",
    "    k=10,\n",
    "    similarity=metrics.pairwise.cosine_similarity,\n",
    "    queried_tasks=\"all\",\n",
    "):\n",
    "    y_names, retrieved_X = get_retrieval_results(\n",
    "        learner, data, k=k, similarity=similarity, queried_tasks=queried_tasks\n",
    "    )\n",
    "    retrieved_X_actual_labels = [\n",
    "        data.all_tasks.iloc[idxs_recalled].explode().values\n",
    "        for idxs_recalled in retrieved_X\n",
    "    ]\n",
    "    retrieved_idxs = [\n",
    "        np.where(retrieved_X_actual_labels[y_idx] == y_name)[0]\n",
    "        for (y_idx, y_name) in enumerate(y_names)\n",
    "    ]\n",
    "    num_recalled = [len(r) for r in retrieved_idxs]\n",
    "    pos_recalled = [maybe_get_ndarray_elem(r, 0) for r in retrieved_idxs]\n",
    "    accurately_recalled = [r > -1 for r in pos_recalled]\n",
    "    return pd.DataFrame(\n",
    "        {\n",
    "            \"retrieved_labels\": retrieved_X_actual_labels,\n",
    "            \"num_recalled\": num_recalled,\n",
    "            \"recalled\": accurately_recalled,\n",
    "            \"position\": pos_recalled,\n",
    "        },\n",
    "        index=y_names,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_retrieval_accuracy(\n",
    "    learner,\n",
    "    data,\n",
    "    k=10,\n",
    "    similarity=metrics.pairwise.cosine_similarity,\n",
    "    queried_tasks=None,\n",
    "):\n",
    "    return np.mean(\n",
    "        get_retrieval_metrics(learner, data, k, similarity, queried_tasks)[\"recalled\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def run_learner_experiment(\n",
    "    retriever_learner, data_train, data_test, queried_tasks=\"all\", fit_learner=True\n",
    "):\n",
    "    if fit_learner:\n",
    "        retriever_learner.fit_learner(data_train)\n",
    "\n",
    "    accuracy_train = retriever_learner.evaluate(data_train, metrics.accuracy_score)\n",
    "    accuracy_test = retriever_learner.evaluate(data_test, metrics.accuracy_score)\n",
    "    top10_accuracy_train = get_retrieval_accuracy(\n",
    "        retriever_learner, data_train, queried_tasks=queried_tasks, k=10\n",
    "    )\n",
    "    top10_accuracy_test = get_retrieval_accuracy(\n",
    "        retriever_learner, data_test, queried_tasks=queried_tasks, k=10\n",
    "    )\n",
    "\n",
    "    return dict(\n",
    "        accuracy_train=accuracy_train,\n",
    "        accuracy_test=accuracy_test,\n",
    "        top10_accuracy_train=top10_accuracy_train,\n",
    "        top10_accuracy_test=top10_accuracy_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 20:47:25,999 - faiss.loader - INFO - Loading faiss with AVX2 support.\n",
      "2022-03-14 20:47:26,000 - faiss.loader - INFO - Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "2022-03-14 20:47:26,000 - faiss.loader - INFO - Loading faiss.\n",
      "2022-03-14 20:47:26,014 - faiss.loader - INFO - Successfully loaded faiss.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import models as sbert_models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "word_embedding_model = sbert_models.Transformer(\n",
    "    model_name, max_seq_length=64, do_lower_case=True\n",
    ")\n",
    "pooling_model = sbert_models.Pooling(\n",
    "    word_embedding_model.get_word_embedding_dimension(), \"cls\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 20:48:01,925 - sentence_transformers.SentenceTransformer - INFO - Load pretrained SentenceTransformer: output/sbert/lstm_sts_512x2/\n",
      "2022-03-14 20:48:02,231 - sentence_transformers.SentenceTransformer - INFO - Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "sbert_model = SentenceTransformer(\"output/sbert/lstm_sts_512x2/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_data_train, abstract_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    paperswithcode_with_features_df[\"tasks\"],\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_features_df[\"abstract\"].str.split(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarce_learn.zero_shot import devise_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_objective_impl(zslearner_kwargs, embedding_kwargs, data_train, data_test):\n",
    "    zs_learner = zero_shot.ESZSLearner(**zslearner_kwargs)\n",
    "    learner = RetrieverLearner.create(zs_learner, **embedding_kwargs)\n",
    "    exp_results = run_learner_experiment(\n",
    "        learner, abstract_data_train, abstract_data_test\n",
    "    )\n",
    "    print(exp_results)\n",
    "    return exp_results[\"top10_accuracy_test\"]\n",
    "\n",
    "\n",
    "def retrieval_objective(trial):\n",
    "    lmbda = trial.suggest_float(\"lmbda\", 1, 1000, log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\", 1, 1000, log=True)\n",
    "    zslearner_kwargs = dict(lmbda=lmbda, gamma=gamma)\n",
    "    embedding_kwargs = dict(\n",
    "        input_embeddings=python_word_embeddings,\n",
    "        target_embeddings=python_word_embeddings,\n",
    "        input_embedding_method=embeddings.AverageWordEmbeddingsVectorizer,\n",
    "        y_embedding_method=embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    )\n",
    "    return retriever_learner_trial_impl(\n",
    "        zslearner_kwargs, embedding_kwargs, abstract_data_train, abstract_data_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 913 ms, total: 15.8 s\n",
      "Wall time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "abstract_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    ")\n",
    "\n",
    "abstract_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4836958826273163,\n",
       " 'accuracy_test': 0.13572357019064124,\n",
       " 'top10_accuracy_train': 0.9285714285714286,\n",
       " 'top10_accuracy_test': 0.8142414860681114}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(\n",
    "    abstract_learner,\n",
    "    abstract_data_train,\n",
    "    abstract_data_test,\n",
    "    fit_learner=False,\n",
    "    queried_tasks=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4836958826273163,\n",
       " 'accuracy_test': 0.13572357019064124,\n",
       " 'top10_accuracy_train': 0.8232558139534883,\n",
       " 'top10_accuracy_test': 0.7375478927203065}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(\n",
    "    abstract_learner,\n",
    "    abstract_data_train,\n",
    "    abstract_data_test,\n",
    "    fit_learner=False,\n",
    "    queried_tasks=\"all\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class SBertModelWrapper:\n",
    "\n",
    "    model = attr.ib()\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.model.encode(X.values)\n",
    "\n",
    "\n",
    "sbert_wrapper = SBertModelWrapper(sbert_model)\n",
    "abstract_sbert_learner = RetrieverLearner(\n",
    "    zero_shot.ESZSLearner(100, 100),\n",
    "    embeddings.AverageWordEmbeddingsVectorizer(python_word_embeddings),\n",
    "    sbert_wrapper,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_learner_experiment(\n",
    "    abstract_sbert_learner, abstract_data_train, abstract_data_test, queried_tasks=\"all\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract model using fasttext trained on Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "abstract_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 100),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_learner_experiment(\n",
    "    abstract_fasttext_learner, abstract_data_train, abstract_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vec model on READMEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "paperswithcode_with_readmes_df = pd.read_csv(\"output/papers_with_readmes.csv\")\n",
    "paperswithcode_with_imports_df['readme'] = paperswithcode_with_readmes_df['readme'] \n",
    "paperswithcode_with_features_df['readme'] = readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_data_train, readme_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    all_tasks,\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_features_df[\"readme\"].str.split(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    ")\n",
    "\n",
    "readme_learner.fit_learner(readme_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_learner_experiment(\n",
    "    readme_learner, readme_data_train, readme_data_test, fit_learner=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_learner_experiment(\n",
    "    readme_learner,\n",
    "    readme_data_train,\n",
    "    readme_data_test,\n",
    "    fit_learner=False,\n",
    "    queried_tasks=\"target\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_sbert_learner = RetrieverLearner(\n",
    "    zero_shot.ESZSLearner(100, 100), sbert_wrapper, sbert_wrapper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc60ee51b27d493aa4d2f45b90a239f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/911 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 6.50 GiB (GPU 0; 23.70 GiB total capacity; 3.12 GiB already allocated; 1.43 GiB free; 3.51 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-292-2e3fc0b9e20b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_learner_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadme_sbert_learner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadme_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadme_data_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-221074800703>\u001b[0m in \u001b[0;36mrun_learner_experiment\u001b[0;34m(retriever_learner, data_train, data_test, queried_tasks, fit_learner)\u001b[0m\n\u001b[1;32m      9\u001b[0m ):\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_learner\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mretriever_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0maccuracy_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mretriever_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-82ef777978f8>\u001b[0m in \u001b[0;36mfit_learner\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mX_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0munique_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-289-5a50b1129137>\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/forks/sentence-transformers/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0moutput_value\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/forks/sentence-transformers/sentence_transformers/models/LSTM.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0munpack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'token_embeddings'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0m\u001b[1;32m    665\u001b[0m                               self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[1;32m    666\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 6.50 GiB (GPU 0; 23.70 GiB total capacity; 3.12 GiB already allocated; 1.43 GiB free; 3.51 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "run_learner_experiment(readme_sbert_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext on READMEs - worse than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "run_learner_experiment(readme_fasttext_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "readme_keywords_data_train, readme_keywords_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], readme_keywords[has_readme].str.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_keywords_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(10, 10),\n",
    "    word_embeddings,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(readme_keywords_learner, readme_keywords_data_train, readme_keywords_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-7ef81096c892>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimport_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_data_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRepoTaskData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_valid_record\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_valid_record\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaperswithcode_with_features_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_valid_record\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaperswithcode_with_features_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mis_valid_record\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'imports'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2374\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m             raise IndexingError(\n\u001b[0m\u001b[1;32m   2377\u001b[0m                 \u001b[0;34m\"Unalignable boolean Series provided as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                 \u001b[0;34m\"indexer (index of the boolean Series and of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "import_data_train, import_data_test = RepoTaskData.create_split(\n",
    "    tasks_test[is_valid_record],\n",
    "    all_tasks[is_valid_record],\n",
    "    paperswithcode_with_features_df[is_valid_record],\n",
    "    paperswithcode_with_features_df[is_valid_record][\"imports\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "import2vec_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(lmbda=100.0, gamma=10.0),\n",
    "    import2vec,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    ")\n",
    "\n",
    "run_learner_experiment(import2vec_learner, import_data_train, import_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRoNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prone_embeddings = gensim.models.KeyedVectors.load(\"data/prone_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using repo embedding from node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prone_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    prone_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    ")\n",
    "\n",
    "run_learner_experiment(prone_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregating vertex embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_kv_file = (\n",
    "    \"output/graphsage_embeddings_fasttext_dim200_epochs20_dim200_layers2.bin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graphsage_kv_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-125-d2b2f6a31725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgraphsage_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphsage_kv_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'graphsage_kv_file' is not defined"
     ]
    }
   ],
   "source": [
    "graphsage_embeddings = gensim.models.KeyedVectors.load(graphsage_kv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using GraphSAGE model for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class LambdaTransformer:\n",
    "    def __init__(self, transform_fn):\n",
    "        self.transform = transform_fn\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        return self\n",
    "\n",
    "\n",
    "class PyGGraphModelTransformer:\n",
    "    def __init__(self, model, dependency_graph_wrapper):\n",
    "        self.model = model\n",
    "        self.dependency_graph_wrapper = dependency_graph_wrapper\n",
    "\n",
    "    def transform(self, x):\n",
    "        return self.dependency_graph_wrapper.get_vertex_embeddings(x, self.model)\n",
    "\n",
    "    def fit(self, X, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.pytorch_geometric_data import PygGraphWrapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAGE(\n",
       "  (convs): ModuleList(\n",
       "    (0): SAGEConv(200, 200)\n",
       "    (1): SAGEConv(200, 200)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_model = torch.load(\"output/graphsage_model_100_dim200_layers2.pth\").cpu()\n",
    "graphsage_model.eval()  # = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-08 23:34:32,014 - root - INFO - creating dependency nodes\n",
      "2022-03-08 23:34:34,796 - root - INFO - loading dependency records\n",
      "2022-03-08 23:34:35,088 - root - INFO - creating dependency dataframe\n",
      "2022-03-08 23:34:36,217 - root - INFO - creating dependency graph wrapper\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    }
   ],
   "source": [
    "dependency_graph_wrapper = data_utils.make_extended_dependency_wrapper(\n",
    "    repos=pd.concat([readme_data_train.repos, readme_data_test.repos]),\n",
    "    dependency_records_df=dependency_records_df[\n",
    "        dependency_records_df[\"edge_type\"] == \"repo-file\"\n",
    "    ],\n",
    "    fasttext_model=fasttext_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_vertex_embeddings(wrapper, vertex_subset, model):\n",
    "    features = (\n",
    "        model.full_forward(wrapper.dataset.x, wrapper.dataset.edge_index)\n",
    "        .cpu()\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "    return features[wrapper.vertex_mapping.loc[vertex_subset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_data_test.repos.isin(dependency_graph_wrapper.records_df[\"source\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def make_pyggraph_retriever_learner(\n",
    "    zs_learner, dependency_graph_wrapper, model, y_embedder\n",
    "):\n",
    "\n",
    "    lambda_transformer = PyGGraphModelTransformer(model, dependency_graph_wrapper)\n",
    "    return RetrieverLearner(zs_learner, lambda_transformer, y_embedder)\n",
    "\n",
    "\n",
    "def save_pyggraph_retriever_learner(pyggraph_retriever_learner, directory):\n",
    "    p = pathlib.Path(directory)\n",
    "    p.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_data_train, graphsage_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    all_tasks,\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_features_df[\"repo\"].apply(lambda s: [s]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_learner = make_pyggraph_retriever_learner(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    dependency_graph_wrapper,\n",
    "    graphsage_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer(python_word_embeddings),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 53s, sys: 54.8 s, total: 3min 47s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "graphsage_results = run_learner_experiment(\n",
    "    graphsage_learner, graphsage_data_train, graphsage_data_test, fit_learner=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.11401542715761898,\n",
       " 'accuracy_test': 0.035801312089971886,\n",
       " 'top10_accuracy_train': 0.34991119005328597,\n",
       " 'top10_accuracy_test': 0.21584699453551912}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 30s, sys: 22.5 s, total: 4min 52s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "abstract_results = run_learner_experiment(\n",
    "    abstract_learner, abstract_data_train, abstract_data_test, fit_learner=False\n",
    ")\n",
    "readme_results = run_learner_experiment(\n",
    "    readme_learner, readme_data_train, readme_data_test, fit_learner=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import2vec_results = run_learner_experiment(\n",
    "    import2vec_learner, import_data_train, import_data_test, fit_learner=False\n",
    ")\n",
    "prone_results = run_learner_experiment(\n",
    "    prone_learner, graph_data_train, graph_data_test, fit_learner=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame.from_records(\n",
    "    [abstract_results, readme_results, graphsage_results]\n",
    ")\n",
    "results_df[\"method\"] = [\"abstract\", \"readme\", \"graphsage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>top10_accuracy_train</th>\n",
       "      <th>top10_accuracy_test</th>\n",
       "      <th>method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.502</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.658</td>\n",
       "      <td>abstract</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.303</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.590</td>\n",
       "      <td>readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.114</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.216</td>\n",
       "      <td>graphsage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy_train  accuracy_test  top10_accuracy_train  top10_accuracy_test  \\\n",
       "0           0.502          0.248                  0.75                0.658   \n",
       "1           0.303          0.167                  0.70                0.590   \n",
       "2           0.114          0.036                  0.35                0.216   \n",
       "\n",
       "      method  \n",
       "0   abstract  \n",
       "1     readme  \n",
       "2  graphsage  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_csv(\"output/retrieval_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>top10_accuracy_train</th>\n",
       "      <th>top10_accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>readme</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>graphsage</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      method  top10_accuracy_train  top10_accuracy_test\n",
       "0   abstract                  0.75                0.658\n",
       "1     readme                  0.70                0.590\n",
       "2  graphsage                  0.35                0.216"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[[\"method\", \"top10_accuracy_train\", \"top10_accuracy_test\"]].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_query_level_results(retriever_learner, data_test, k=10):\n",
    "\n",
    "    accuracy_test = retriever_learner.evaluate(data_test, metrics.accuracy_score)\n",
    "    results = get_retrieval_metrics(retriever_learner, data_test, k=k)\n",
    "    results[\"position\"] = results[\"position\"].replace(-1, np.inf)\n",
    "\n",
    "    return accuracy_test, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_idx_or_inf(xs, a):\n",
    "    idxs = np.where(xs == a)[0].astype(int)\n",
    "    if len(idxs) == 0:\n",
    "        return np.inf\n",
    "    else:\n",
    "        return idxs[0]\n",
    "\n",
    "\n",
    "def get_areas(area_grouped_tasks, tasks):\n",
    "    return tasks.apply(\n",
    "        lambda ts: area_grouped_tasks[\"area\"][\n",
    "            area_grouped_tasks[\"task\"].isin(ts)\n",
    "        ].unique()\n",
    "    )\n",
    "\n",
    "\n",
    "erroneous_area_tasks = []\n",
    "\n",
    "\n",
    "def analyze_query_level_results(\n",
    "    query_level_results, area_grouped_tasks, erroneous_area_tasks=erroneous_area_tasks\n",
    "):\n",
    "    retrieval_results_with_area_test = area_grouped_tasks.merge(\n",
    "        query_level_results, left_on=\"task\", right_index=True\n",
    "    )\n",
    "    for tasks in retrieval_results_with_area_test[\"retrieved_labels\"].values:\n",
    "        for task in tasks:\n",
    "            try:\n",
    "                partial(get_areas, area_grouped_tasks)(pd.Series([[task]]))\n",
    "            except:\n",
    "                erroneous_area_tasks.append(task)\n",
    "    retrieved_areas = get_areas(\n",
    "        area_grouped_tasks, retrieval_results_with_area_test[\"retrieved_labels\"]\n",
    "    )  # apply(partial(get_areas, area_grouped_tasks))\n",
    "    retrieval_results_with_area_test[\"retrieved_areas\"] = retrieved_areas\n",
    "    is_area_retrieved = retrieval_results_with_area_test.apply(\n",
    "        lambda row: row[\"area\"] in row[\"retrieved_areas\"][:10], axis=1\n",
    "    )\n",
    "    num_area_retrieved = retrieval_results_with_area_test.apply(\n",
    "        lambda row: len(\n",
    "            np.where(row[\"area\"] == np.array(row[\"retrieved_areas\"])[:10])[0]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "    area_idx = retrieval_results_with_area_test.apply(\n",
    "        lambda row: get_idx_or_inf(np.array(row[\"retrieved_areas\"]), row[\"area\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    retrieval_results_with_area_test[\"area_recalled\"] = is_area_retrieved\n",
    "    retrieval_results_with_area_test[\"area_recalled_position\"] = area_idx\n",
    "    retrieval_results_with_area_test[\"num_area_recalled\"] = num_area_retrieved\n",
    "    query_level_results = retrieval_results_with_area_test.groupby(\"area\").agg(\n",
    "        {\n",
    "            \"recalled\": \"mean\",\n",
    "            \"num_recalled\": \"mean\",\n",
    "            # \"position\": [\"median\", \"mean\"],\n",
    "            \"area_recalled\": \"mean\",\n",
    "            \"num_area_recalled\": \"mean\",\n",
    "            \"area_recalled_position\": [\"median\"],\n",
    "        }\n",
    "    )\n",
    "    query_level_results[\"count\"] = retrieval_results_with_area_test[\n",
    "        \"area\"\n",
    "    ].value_counts()  # groupby('area').agg('count')\n",
    "    return query_level_results\n",
    "\n",
    "\n",
    "def get_analyzed_query_level_results(retriever_learner, data_test, area_grouped_tasks):\n",
    "    detailed_results_all = get_query_level_results(retriever_learner, data_test)\n",
    "    retrieval_results_with_area_test = analyze_query_level_results(\n",
    "        query_level_results, area_grouped_tasks\n",
    "    )\n",
    "    return retrieval_results_with_area_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.1 s, sys: 4.03 s, total: 27.2 s\n",
      "Wall time: 21.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readme_accuracy, raw_readme_area_results = get_query_level_results(\n",
    "    readme_learner, readme_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n",
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    }
   ],
   "source": [
    "graphsage_accuracy, raw_graphsage_area_results = get_query_level_results(\n",
    "    graphsage_learner, graphsage_data_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1670103092783505"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (87,200) into shape (87,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-38e97f8a942a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreadme_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_topk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreadme_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadme_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_data_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-82ef777978f8>\u001b[0m in \u001b[0;36mpredict_topk\u001b[0;34m(self, X, y_embeddings, target_names, k, similarity)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mX_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzs_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mtarget_similarities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtarget_similarities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_return_float_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"check_pairwise_arrays\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_return_float_dtype\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mY_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mY_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order, like)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (87,200) into shape (87,)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "representation learning    390\n",
       "continuous control         378\n",
       "image retrieval            213\n",
       "keypoint detection         205\n",
       "meta learning              189\n",
       "                          ... \n",
       "video retrieval             17\n",
       "neural rendering            17\n",
       "decipherment                17\n",
       "argument mining             17\n",
       "foveation                   16\n",
       "Name: least_common_task, Length: 67, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_test.y.value_counts()[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_area_results = analyze_query_level_results(\n",
    "    raw_readme_area_results, area_grouped_tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recalled</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th>area_recalled</th>\n",
       "      <th>num_area_recalled</th>\n",
       "      <th>area_recalled_position</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>computer-vision</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.51</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>3.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodology</th>\n",
       "      <td>0.65</td>\n",
       "      <td>2.35</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural-language-processing</th>\n",
       "      <td>0.48</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graphs</th>\n",
       "      <td>0.70</td>\n",
       "      <td>2.45</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time-series</th>\n",
       "      <td>0.47</td>\n",
       "      <td>2.47</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.79</td>\n",
       "      <td>1.5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.69</td>\n",
       "      <td>1.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing-games</th>\n",
       "      <td>0.55</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>0.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>inf</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-code</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge-base</th>\n",
       "      <td>0.75</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.75</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversarial</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            recalled num_recalled area_recalled  \\\n",
       "                                mean         mean          mean   \n",
       "area                                                              \n",
       "computer-vision                 0.54         1.93          0.99   \n",
       "miscellaneous                   0.51         1.88          0.96   \n",
       "methodology                     0.65         2.35          1.00   \n",
       "natural-language-processing     0.48         1.95          0.98   \n",
       "graphs                          0.70         2.45          0.95   \n",
       "time-series                     0.47         2.47          0.73   \n",
       "medical                         0.50         1.79          0.79   \n",
       "speech                          0.69         1.54          1.00   \n",
       "playing-games                   0.55         2.09          1.00   \n",
       "robots                          0.57         1.00          0.86   \n",
       "reasoning                       0.00         0.00          0.17   \n",
       "computer-code                   0.25         0.25          0.50   \n",
       "knowledge-base                  0.75         1.75          1.00   \n",
       "music                           0.75         2.50          1.00   \n",
       "adversarial                     1.00         1.67          1.00   \n",
       "audio                           1.00         1.00          1.00   \n",
       "\n",
       "                            num_area_recalled area_recalled_position count  \n",
       "                                         mean                 median        \n",
       "area                                                                        \n",
       "computer-vision                          0.99                    0.0   114  \n",
       "miscellaneous                            0.96                    3.0   113  \n",
       "methodology                              1.00                    1.0    66  \n",
       "natural-language-processing              0.98                    2.0    60  \n",
       "graphs                                   0.95                    0.0    20  \n",
       "time-series                              0.73                    2.0    15  \n",
       "medical                                  0.79                    1.5    14  \n",
       "speech                                   1.00                    3.0    13  \n",
       "playing-games                            1.00                    2.0    11  \n",
       "robots                                   0.86                    4.0     7  \n",
       "reasoning                                0.17                    inf     6  \n",
       "computer-code                            0.50                    inf     4  \n",
       "knowledge-base                           1.00                    1.0     4  \n",
       "music                                    1.00                    3.0     4  \n",
       "adversarial                              1.00                    0.0     3  \n",
       "audio                                    1.00                    0.0     2  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readme_area_results.round(2).sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_tasks = graphsage_data_train.all_tasks.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-99-a15f09509351>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  readme_area_results.round(2).sort_values('count', ascending=False).to_latex(open(\"output/readme_area_results.tex\", \"w\"))\n"
     ]
    }
   ],
   "source": [
    "readme_area_results.round(2).sort_values(\"count\", ascending=False).to_latex(\n",
    "    open(\"output/readme_area_results.tex\", \"w\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "graphsage_area_results = analyze_query_level_results(\n",
    "    raw_graphsage_area_results, area_grouped_tasks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recalled</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th>area_recalled</th>\n",
       "      <th>num_area_recalled</th>\n",
       "      <th>area_recalled_position</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>computer-vision</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodology</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural-language-processing</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graphs</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time-series</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>inf</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.23</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing-games</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.29</td>\n",
       "      <td>inf</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.17</td>\n",
       "      <td>inf</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-code</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge-base</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversarial</th>\n",
       "      <td>0.67</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            recalled num_recalled area_recalled  \\\n",
       "                                mean         mean          mean   \n",
       "area                                                              \n",
       "computer-vision                 0.23         0.60          0.99   \n",
       "miscellaneous                   0.17         0.58          0.96   \n",
       "methodology                     0.30         0.59          1.00   \n",
       "natural-language-processing     0.17         0.32          0.92   \n",
       "graphs                          0.25         0.45          0.85   \n",
       "time-series                     0.00         0.00          0.20   \n",
       "medical                         0.29         0.57          0.86   \n",
       "speech                          0.23         0.38          0.77   \n",
       "playing-games                   0.00         0.00          0.91   \n",
       "robots                          0.14         0.14          0.29   \n",
       "reasoning                       0.00         0.00          0.17   \n",
       "computer-code                   0.00         0.00          0.25   \n",
       "knowledge-base                  0.50         0.75          0.75   \n",
       "music                           0.00         0.00          0.00   \n",
       "adversarial                     0.67         1.33          1.00   \n",
       "audio                           0.00         0.00          0.00   \n",
       "\n",
       "                            num_area_recalled area_recalled_position count  \n",
       "                                         mean                 median        \n",
       "area                                                                        \n",
       "computer-vision                          0.99                    0.0   114  \n",
       "miscellaneous                            0.96                    4.0   113  \n",
       "methodology                              1.00                    2.0    66  \n",
       "natural-language-processing              0.92                    3.5    60  \n",
       "graphs                                   0.85                    1.0    20  \n",
       "time-series                              0.20                    inf    15  \n",
       "medical                                  0.86                    2.0    14  \n",
       "speech                                   0.77                    5.0    13  \n",
       "playing-games                            0.91                    3.0    11  \n",
       "robots                                   0.29                    inf     7  \n",
       "reasoning                                0.17                    inf     6  \n",
       "computer-code                            0.25                    inf     4  \n",
       "knowledge-base                           0.75                    2.5     4  \n",
       "music                                    0.00                    inf     4  \n",
       "adversarial                              1.00                    0.0     3  \n",
       "audio                                    0.00                    inf     2  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_area_results.round(2).sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-102-ffd3490da1f6>:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  graphsage_area_results.round(2).sort_values('count', ascending=False).to_latex(open(\"output/graphsage_area_results.tex\", \"w\"))\n"
     ]
    }
   ],
   "source": [
    "graphsage_area_results.round(2).sort_values(\"count\", ascending=False).to_latex(\n",
    "    open(\"output/graphsage_area_results.tex\", \"w\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>recalled</th>\n",
       "      <th>num_recalled</th>\n",
       "      <th>area_recalled</th>\n",
       "      <th>num_area_recalled</th>\n",
       "      <th>area_recalled_position</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>computer-vision</th>\n",
       "      <td>0.228070</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.991228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscellaneous</th>\n",
       "      <td>0.168142</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>0.964602</td>\n",
       "      <td>4.0</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>methodology</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural-language-processing</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>3.5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>graphs</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time-series</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>inf</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>medical</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speech</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>playing-games</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robots</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>inf</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reasoning</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>inf</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>computer-code</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knowledge-base</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>music</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adversarial</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audio</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>inf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             recalled num_recalled area_recalled  \\\n",
       "                                 mean         mean          mean   \n",
       "area                                                               \n",
       "computer-vision              0.228070     0.596491      0.991228   \n",
       "miscellaneous                0.168142     0.575221      0.964602   \n",
       "methodology                  0.303030     0.590909      1.000000   \n",
       "natural-language-processing  0.166667     0.316667      0.916667   \n",
       "graphs                       0.250000     0.450000      0.850000   \n",
       "time-series                  0.000000     0.000000      0.200000   \n",
       "medical                      0.285714     0.571429      0.857143   \n",
       "speech                       0.230769     0.384615      0.769231   \n",
       "playing-games                0.000000     0.000000      0.909091   \n",
       "robots                       0.142857     0.142857      0.285714   \n",
       "reasoning                    0.000000     0.000000      0.166667   \n",
       "computer-code                0.000000     0.000000      0.250000   \n",
       "knowledge-base               0.500000     0.750000      0.750000   \n",
       "music                        0.000000     0.000000      0.000000   \n",
       "adversarial                  0.666667     1.333333      1.000000   \n",
       "audio                        0.000000     0.000000      0.000000   \n",
       "\n",
       "                            num_area_recalled area_recalled_position count  \n",
       "                                         mean                 median        \n",
       "area                                                                        \n",
       "computer-vision                      0.991228                    0.0   114  \n",
       "miscellaneous                        0.964602                    4.0   113  \n",
       "methodology                          1.000000                    2.0    66  \n",
       "natural-language-processing          0.916667                    3.5    60  \n",
       "graphs                               0.850000                    1.0    20  \n",
       "time-series                          0.200000                    inf    15  \n",
       "medical                              0.857143                    2.0    14  \n",
       "speech                               0.769231                    5.0    13  \n",
       "playing-games                        0.909091                    3.0    11  \n",
       "robots                               0.285714                    inf     7  \n",
       "reasoning                            0.166667                    inf     6  \n",
       "computer-code                        0.250000                    inf     4  \n",
       "knowledge-base                       0.750000                    2.5     4  \n",
       "music                                0.000000                    inf     4  \n",
       "adversarial                          1.000000                    0.0     3  \n",
       "audio                                0.000000                    inf     2  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_area_results.sort_values(\"count\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tasks_all = graph_data_train.all_tasks.explode().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07815275310834814"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(graph_data_train.all_tasks.explode().value_counts() < 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47540983606557374"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(graphsage_data_test.all_tasks.explode().value_counts() < 10).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "364"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_data_train.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_data_test.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(graph_data_test.y.unique()).intersection(train_tasks_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_data_test.y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat output/graphsage_area_results.tex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(readme_data_test, open(\"output/readme_data_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(graphsage_data_test, open(\"output/graphsage_data_test.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'fasttext_pybind.fasttext' object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-6ca487fee6e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphsage_learner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output/graphsage_learner.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot pickle 'fasttext_pybind.fasttext' object"
     ]
    }
   ],
   "source": [
    "pickle.dump(graphsage_learner, open(\"output/graphsage_learner.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(readme_learner, open(\"output/readme_learner.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation of repo, import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train, paired_data_test = RepoTaskData.create_split(\n",
    "    tasks_test,\n",
    "    all_tasks,\n",
    "    paperswithcode_with_features_df,\n",
    "    paperswithcode_with_imports_df[\"imports\"],\n",
    ")\n",
    "paired_data_train.X = graph_data_train.X + \" \" + import_data_train.X\n",
    "paired_data_test.X = graph_data_test.X + \" \" + import_data_test.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    PairedKeyedVectors(python_word_embeddings.wv, graphsage_embeddings),\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer,\n",
    ")\n",
    "\n",
    "paired_learner.fit_learner(graph_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (learner, learner_name, test) in zip(\n",
    "    [import2vec_learner, prone_learner, paired_learner],\n",
    "    [\"import2vec\", \"prone\", \"both\"],\n",
    "    [X_test, repo_graph_terms_test, X_paired_test],\n",
    "):\n",
    "    accs = []\n",
    "    for k in [1, 3, 5, 10, 20]:\n",
    "        rec = get_retrieval_accuracy(learner, test, y_test, test_task_idxs, k=k)\n",
    "        accs.append(rec)\n",
    "    results.append(pd.Series(name=learner_name, data=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = [\"Accuracy@{}\".format(i) for i in [1, 3, 5, 10, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_markdown(open(\"metrics/zsl_results.md\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat metrics/zsl_results.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_distances = metrics.pairwise.cosine_distances(task_embeddings, task_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_embeddings = gensim.models.KeyedVectors.load(\"data/poincare5.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.wrappers.fasttext\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import typical_file_parts\n",
    "from mlutil import prototype_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lines_df = typical_file_parts.get_selected_lines_and_repos(\n",
    "    python_files_df[\"repo_name\"], python_files_df[\"content\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
