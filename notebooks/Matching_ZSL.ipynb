{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp matching_zsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import ast\n",
    "import tqdm\n",
    "import json\n",
    "import attr\n",
    "from operator import itemgetter\n",
    "\n",
    "from scarce_learn import zero_shot\n",
    "from mlutil.feature_extraction import embeddings\n",
    "import itertools\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, metrics, model_selection\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "\n",
    "from github_search import paperswithcode_tasks\n",
    "\n",
    "import mlutil\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from scarce_learn.zero_shot import devise_jax, devise_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=false\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upstream\n",
    "\n",
    "import_corpus_path = 'output/module_corpus.csv'\n",
    "word_vectors_filename = 'output/import2vec_module_vectors.bin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%time\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)\n",
    "import_corpus_df['imports'] = import_corpus_df['imports'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 50s, sys: 3.2 s, total: 2min 53s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "python_files_df = pd.read_csv('data/crawled_python_files.csv', encoding='latin-1')\n",
    "repo_names = python_files_df['repo_name']\n",
    "import_corpus_df = pd.read_csv(import_corpus_path)\n",
    "per_repo_imports = import_corpus_df.groupby('repo')['imports'].agg(sum).apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1402272, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375818, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_corpus_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      trangvu/ape-npi\n",
       "1                      trangvu/ape-npi\n",
       "2                      trangvu/ape-npi\n",
       "3                      trangvu/ape-npi\n",
       "4                      trangvu/ape-npi\n",
       "                      ...             \n",
       "1402267    wayne1204/NOAA-fish-finding\n",
       "1402268    wayne1204/NOAA-fish-finding\n",
       "1402269    wayne1204/NOAA-fish-finding\n",
       "1402270    wayne1204/NOAA-fish-finding\n",
       "1402271    wayne1204/NOAA-fish-finding\n",
       "Name: repo_name, Length: 1402272, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18933,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df['repo_name'].unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python_files_df['repo'] = python_files_df['repo_name'].str.split(\"/\").apply(itemgetter(1))  + '/' + python_files_df['repo_name']\n",
    "repo_names_tmp = python_files_df['repo_name']\n",
    "repo_names = repo_names_tmp.unique()\n",
    "python_files_df['repo_name'] = python_files_df['repo']\n",
    "python_files_df['repo'] = repo_names_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.9 ms, sys: 0 ns, total: 7.9 ms\n",
      "Wall time: 9.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import2vec = gensim.models.KeyedVectors.load(word_vectors_filename)\n",
    "import2vec_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(import2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = pd.read_csv('output/papers_with_imports.csv')\n",
    "paperswithcode_with_imports_df['tasks'] = paperswithcode_with_imports_df['tasks'].str.replace(\"2d \", \"\").str.replace(\"3d \", \"\").str.replace(\"4d \", \"\").str.replace(\"6d \", \"\").str.lower().apply(ast.literal_eval)\n",
    "paperswithcode_with_imports_df['imports'] = paperswithcode_with_imports_df['imports'].str.replace(\"set\\(\\)\", \"{}\").apply(ast.literal_eval)#str.replace(\"2d \", \"\").str.replace(\"3d \", \"\").str.replace(\"4d \", \"\").str.replace(\"6d \", \"\").str.lower().apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 23)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports'] = paperswithcode_with_imports_df['imports'].apply(len) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['n_imports_with_embeddings'] = paperswithcode_with_imports_df['imports'].apply(lambda imps: len([imp in import2vec.vocab.keys() for imp in imps]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 s, sys: 243 ms, total: 33 s\n",
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_embeddings = mlutil.feature_extraction.embeddings.load_gensim_embedding_model('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_word_embeddings = gensim.models.Word2Vec.load('output/abstract_w2v100.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class RepoTaskData:\n",
    "    \n",
    "    tasks = attr.ib()\n",
    "    repos = attr.ib()\n",
    "    X = attr.ib()\n",
    "    all_tasks = attr.ib()\n",
    "    y = attr.ib()\n",
    "    \n",
    "    def split_tasks(area_grouped_tasks, test_size=0.2):\n",
    "        tasks_train, tasks_test = model_selection.train_test_split(area_grouped_tasks['task'], stratify=area_grouped_tasks['area'], test_size=test_size, random_state=0)\n",
    "        return tasks_train, tasks_test\n",
    "    \n",
    "    def create_split(tasks_train, all_tasks, paperswithcode_with_features_df, X_repr):\n",
    "        train_indicator = paperswithcode_with_features_df['most_common_task'].isin(tasks_train)\n",
    "        print(train_indicator.shape)\n",
    "        repos_train = paperswithcode_with_features_df['repo'][train_indicator]\n",
    "        repos_test = paperswithcode_with_features_df['repo'][~train_indicator]\n",
    "        X_repr = X_repr.apply(lambda x: \" \".join(x))\n",
    "        X_train = X_repr[train_indicator]\n",
    "        X_test = X_repr[~train_indicator]\n",
    "        all_tasks_train = all_tasks[train_indicator]\n",
    "        all_tasks_test = all_tasks[~train_indicator]\n",
    "        y_train = paperswithcode_with_features_df[train_indicator]['most_common_task'].str.lower()\n",
    "        y_test = paperswithcode_with_features_df[~train_indicator]['most_common_task'].str.lower()\n",
    "        \n",
    "        return (\n",
    "            RepoTaskData(tasks_train, repos_train, X_train, all_tasks_train, y_train),\n",
    "            RepoTaskData(tasks_test, repos_test, X_test, all_tasks_test, y_test)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_first_vocab_entry(vocab):\n",
    "    return list(itertools.islice(vocab.items(), 1))[0][0] \n",
    "\n",
    "\n",
    "class PairedKeyedVectors:\n",
    "    \n",
    "    @attr.s\n",
    "    class wv:\n",
    "        vocab = attr.ib()\n",
    "    \n",
    "    def __init__(self, kv1, kv2):\n",
    "        self.kv1 = kv1\n",
    "        self.kv2 = kv2\n",
    "        self.vocab = {**kv1.vocab, **kv2.vocab} \n",
    "        self.dim1 = len(kv1[get_first_vocab_entry(kv1.vocab)])\n",
    "        self.dim2 = len(kv2[get_first_vocab_entry(kv2.vocab)])\n",
    "        self.wv= PairedKeyedVectors.wv(self.vocab)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        if not item in self.kv1.vocab.keys():\n",
    "            return np.concatenate([np.zeros(self.dim1), self.kv2[item]])\n",
    "        elif not item in self.kv2.vocab.keys():\n",
    "            return np.concatenate([self.kv1[item], np.zeros(self.dim2)])\n",
    "        else:\n",
    "            return np.concatenate([self.kv1[item], self.kv2[item]])\n",
    "    \n",
    "\n",
    "\n",
    "@attr.s\n",
    "class RetrieverLearner:\n",
    "    \n",
    "    zs_learner: zero_shot.ZeroShotClassifier = attr.ib()\n",
    "    input_embedder: embeddings.EmbeddingVectorizer = attr.ib() \n",
    "    y_embedder: embeddings.EmbeddingVectorizer = attr.ib()\n",
    "    input_embedder_kwargs = attr.ib(default=dict())\n",
    "        \n",
    "    @staticmethod\n",
    "    def create(\n",
    "        zs_learner: zero_shot.ZeroShotClassifier,\n",
    "        input_embeddings: gensim.models.KeyedVectors,\n",
    "        target_embeddings: gensim.models.KeyedVectors,\n",
    "        input_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        y_embedding_method: embeddings.EmbeddingVectorizer,\n",
    "        input_embedder_kwargs=dict()\n",
    "    ):\n",
    "        input_embedder = input_embedding_method(input_embeddings, **input_embedder_kwargs) \n",
    "        y_embedder = y_embedding_method(target_embeddings)\n",
    "        return RetrieverLearner(zs_learner, input_embedder, y_embedder)\n",
    "    \n",
    "    def get_target_embeddings(self, y):\n",
    "        unique_y = pd.Series(y.unique())\n",
    "        y_embeddings = self.y_embedder.transform(unique_y)\n",
    "        return unique_y, y_embeddings\n",
    "    \n",
    "    def fit_learner(self, data, **kwargs):\n",
    "        self.input_embedder.fit(data.X)\n",
    "        X_embeddings = self.input_embedder.transform(data.X)\n",
    "        self.y_embedder.fit(data.y)\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        self.zs_learner.fit(np.array(X_embeddings), np.array(input_y_idxs), np.array(y_embeddings), **kwargs)\n",
    "        \n",
    "    def predict_idxs(self, X, y_embeddings):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        return self.zs_learner.predict(X_embeddings, y_embeddings)\n",
    "    \n",
    "    def predict_topk(self, X, y_embeddings, target_names, k=5, similarity=metrics.pairwise.cosine_similarity):\n",
    "        X_embeddings = self.input_embedder.transform(X)\n",
    "        predictions = self.zs_learner.predict_raw(X_embeddings)\n",
    "        target_similarities = similarity(predictions, y_embeddings)\n",
    "        targets = [target_names[row[:k]] for row in (-target_similarities).argsort(axis=1)]\n",
    "        return targets\n",
    "        \n",
    "    def evaluate(self, data, metric):\n",
    "        unique_y, y_embeddings = self.get_target_embeddings(data.y)\n",
    "        input_y_idxs = data.y.apply(lambda t: unique_y[unique_y == t].index[0])\n",
    "        predicted_idxs = self.predict_idxs(data.X, y_embeddings)\n",
    "        return metric(input_y_idxs, predicted_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_accuracy(learner, X, y, y_names, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    input_embeddings = learner.input_embedder.transform(X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    target_similarities = similarity(predictions, y_embeddings)\n",
    "    target_idxs = (-target_similarities).argsort(axis=1)\n",
    "    targets = [y_names.iloc[row[:k]] for row in target_idxs]\n",
    "\n",
    "    accuracies = np.zeros(len(X))\n",
    "    for i in range(len(X)):\n",
    "        true_tasks = set(all_tasks_test.iloc[i])\n",
    "        accuracies[i] = len(true_tasks.intersection(set(targets[i].values))) / min(len(true_tasks), k)\n",
    "    return accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "graph = pickle.load(open('output/call_igraph.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-163-42a59506436d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-163-42a59506436d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "abstract_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "abstract_fasttext_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18934"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph.get_vertex_dataframe().iloc[graph.neighborhood(vertices=[\"<ROOT>\"])[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get repos that are in graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_nodes = graph.get_vertex_dataframe()['name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 527 ms, sys: 27.8 ms, total: 555 ms\n",
      "Wall time: 559 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "paperswithcode_with_features_df = paperswithcode_with_imports_df[\n",
    "    paperswithcode_with_imports_df['repo'].isin(graph.get_vertex_dataframe()['name']) |\n",
    "    paperswithcode_with_imports_df['repo'].apply(lambda s: s.split(\"/\")[1]).isin(graph.get_vertex_dataframe()['name'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(paperswithcode_with_features_df['repo'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_task_name(task_name):\n",
    "    return task_name.replace(\"2d \", \"\").replace(\"3d \", \"\").replace(\"4d \", \"\").replace(\"6d \", \"\").lower()\n",
    "\n",
    "paperswithcode_with_features_df['most_common_task'] = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = paperswithcode_with_features_df['most_common_task'].str.lower()\n",
    "tasks = tasks.apply(clean_task_name)\n",
    "all_tasks = paperswithcode_with_features_df['tasks'].apply(lambda s: [clean_task_name(t) for t in s])\n",
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "semantic segmentation             1066\n",
       "object detection                  1050\n",
       "image classification               946\n",
       "language modelling                 494\n",
       "representation learning            454\n",
       "                                  ... \n",
       "cell segmentation                   70\n",
       "nuclear segmentation                69\n",
       "multi-person pose estimation        69\n",
       "natural language understanding      69\n",
       "semantic parsing                    68\n",
       "Name: tasks, Length: 100, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks.explode().value_counts()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "def get_area_grouped_tasks(paperswithcode_tasks_path='data/paperswithcode_tasks.csv'):\n",
    "    area_grouped_tasks = pd.read_csv('data/paperswithcode_tasks.csv')\n",
    "    area_grouped_tasks['task'] = area_grouped_tasks['task'].str.replace(\"-\", ' ')\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['task'].isin(tasks)]\n",
    "    area_counts = area_grouped_tasks['area'].value_counts()\n",
    "    area_grouped_tasks = area_grouped_tasks[area_grouped_tasks['area'].isin(area_counts.index[area_counts > 1])]\n",
    "    return area_grouped_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_grouped_tasks = get_area_grouped_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_train, tasks_test = RepoTaskData.split_tasks(area_grouped_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "467                        object counting\n",
       "1253    conversational response generation\n",
       "854              probabilistic programming\n",
       "525          facial expression recognition\n",
       "1683                   montezuma's revenge\n",
       "                       ...                \n",
       "896                      data augmentation\n",
       "926                                    eeg\n",
       "1646            neural architecture search\n",
       "592                       graph regression\n",
       "1230               sentence classification\n",
       "Name: task, Length: 74, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tasks_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               dictionary learning\n",
       "1                   region proposal\n",
       "2                  image generation\n",
       "3        natural language inference\n",
       "4        natural language inference\n",
       "                    ...            \n",
       "12219             anomaly detection\n",
       "12220             anomaly detection\n",
       "12221             anomaly detection\n",
       "12222                style transfer\n",
       "12223       representation learning\n",
       "Name: most_common_task, Length: 12224, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2915"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df['most_common_task'].isin(tasks_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12224, 25)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import github_readmes\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_decode(s, codec=\"utf-8\"):\n",
    "    try:\n",
    "        return s.decode(codec)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_readme_summaries(upstream, product, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, paperswithcode_with_features_df['repo']))\n",
    "    readmes = pd.Series(raw_readmes).apply(try_decode)\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import python_call_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_readmes(df, keywords=True):\n",
    "    pool = concurrent.futures.ProcessPoolExecutor(max_workers=10)\n",
    "    raw_readmes = list(pool.map(github_readmes.get_readme, df['repo']))\n",
    "    readmes = list(map(try_decode, raw_readmes))\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'paper_url', 'arxiv_id', 'title', 'abstract', 'url_abs',\n",
       "       'url_pdf', 'proceeding', 'authors', 'tasks', 'date', 'methods',\n",
       "       'framework', 'mentioned_in_github', 'mentioned_in_paper',\n",
       "       'paper_arxiv_id', 'paper_title', 'paper_url_abs', 'paper_url_pdf',\n",
       "       'repo', 'repo_url', 'most_common_task', 'imports', 'n_imports',\n",
       "       'n_imports_with_embeddings'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_features_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-cab5e3031f02>\u001b[0m in \u001b[0;36mget_readmes\u001b[0;34m(df, keywords)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_readmes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mraw_readmes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgithub_readmes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_readme\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mreadmes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtry_decode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_readmes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreadmes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \"\"\"\n\u001b[0;32m--> 484\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    617\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readmes = get_readmes(paperswithcode_with_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "def try_keywords(text):\n",
    "    return python_call_graph.try_run(gensim.summarization.keywords)(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = concurrent.futures.ProcessPoolExecutor(max_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.91 s, sys: 1.52 s, total: 4.43 s\n",
      "Wall time: 5min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "readme_keywords = pd.Series(pool.map(try_keywords, readmes)).str.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_records_df = pd.read_csv('output/processed_dependency_records.csv').dropna()#.iloc[:1000000]\n",
    "non_root_dependency_records_df = dependency_records_df[\n",
    "    (dependency_records_df['source'] != \"<ROOT>\") &\n",
    "    (dependency_records_df['edge_type'] != 'repo-repo')\n",
    "]\n",
    "repo_descriptions = non_root_dependency_records_df[['source', 'repo_description']].groupby('source').apply(lambda df: df['repo_description'].iloc[0])\n",
    "\n",
    "describable_paperswithcode_with_features_df = paperswithcode_with_features_df[paperswithcode_with_features_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_repo_tasks = all_tasks[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]\n",
    "\n",
    "\n",
    "import_data_train, import_data_test = RepoTaskData.create_split(tasks_train, describable_repo_tasks, describable_paperswithcode_with_features_df, describable_paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "describable_paperswithcode_with_features_df = paperswithcode_with_features_df[paperswithcode_with_features_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_paperswithcode_with_imports_df = paperswithcode_with_imports_df[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]\n",
    "describable_repo_tasks = all_tasks[paperswithcode_with_imports_df['repo'].isin(repo_descriptions.index)]\n",
    "\n",
    "\n",
    "import_data_train, import_data_test = RepoTaskData.create_split(tasks_train, describable_repo_tasks, describable_paperswithcode_with_features_df, describable_paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11245, 25)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describable_paperswithcode_with_features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11245, 25)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describable_paperswithcode_with_imports_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    [dictionary learning]\n",
       "1        [region proposal, user constrained thumbnail g...\n",
       "2         [conditional image generation, image generation]\n",
       "3        [answer selection, natural language inference,...\n",
       "4        [answer selection, natural language inference,...\n",
       "                               ...                        \n",
       "12219    [anomaly detection, unsupervised anomaly detec...\n",
       "12220    [anomaly detection, unsupervised anomaly detec...\n",
       "12221    [anomaly detection, unsupervised anomaly detec...\n",
       "12222                                     [style transfer]\n",
       "12223    [denoising, domain adaptation, representation ...\n",
       "Name: tasks, Length: 12224, dtype: object"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11245,)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7647,), (3598,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_data_train.X.shape, import_data_test.X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_embedder = mlutil.feature_extraction.embeddings.AverageWordEmbeddingsVectorizer(word_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def get_outgoing_edges(graph, node):\n",
    "    #idx = pd.Index(graph.names).get_loc(node)\n",
    "    #outgoing_edges_idx = np.where(graph.mat[idx].todense())[1]\n",
    "    return graph.get_vertex_dataframe().iloc[graph.successors(node)]['name']\n",
    "    #return graph.names[outgoing_edges_idx]\n",
    "\n",
    "\n",
    "def get_repo_functions(graph, repo):\n",
    "    return ' '.join(get_outgoing_edges(graph, repo).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_records = pd.read_csv('output/dependency_records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 ms, sys: 37 µs, total: 16.9 ms\n",
      "Wall time: 92.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if os.path.exists(\"output/tmp_graph_data.pkl\"):\n",
    "    (graph_data_train, graph_data_test) = pickle.load(open(\"output/tmp_graph_data.pkl\", \"rb\"))\n",
    "else:\n",
    "    graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "    graph_data_train.X = graph_data_train.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    graph_data_test.X = graph_data_test.repos.apply(lambda x: get_repo_functions(graph, x))\n",
    "    pickle.dump((graph_data_train, graph_data_test), open(\"output/tmp_graph_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kinimod23/ATS_Project read_one_stop_english fasttext_to_file preprocess_dump preprocess BCNN utils train test'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_descriptions.loc[graph_data_train.repos[6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11245,)\n"
     ]
    }
   ],
   "source": [
    "graph_data_train, graph_data_test = RepoTaskData.create_split(tasks_train, describable_repo_tasks, describable_paperswithcode_with_features_df, describable_paperswithcode_with_imports_df['imports'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_train.X = pd.Series(repo_descriptions.loc[graph_data_train.repos].values, index=graph_data_train.repos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_data_test.X = pd.Series(repo_descriptions.loc[graph_data_test.repos].values, index=graph_data_test.repos.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'canbakiskan/neuro-inspired-defense'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_train.repos.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vertex ID\n",
       "3203          get_accuracy_score\n",
       "4890                         hvp\n",
       "16936      test_bitmap_mask_init\n",
       "17720                     matmul\n",
       "20276                        fix\n",
       "                   ...          \n",
       "1333883                write_wav\n",
       "1337476                   repeat\n",
       "1338246                    vgg19\n",
       "1341862                      max\n",
       "1344759              get_dataset\n",
       "Name: name, Length: 406, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_outgoing_edges(graph, get_outgoing_edges(graph, graph_data_train.repos.iloc[0]).iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7647"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_data_train.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def retrieve_query_results(learner, data, query, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform([query])\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "    return data.X.iloc[np.argsort(-input_target_similarities[:,0])[:k]]\n",
    "\n",
    "    \n",
    "def get_retrieval_results(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    input_embeddings = learner.input_embedder.transform(data.X)\n",
    "    y_embeddings = learner.y_embedder.transform(y_names)\n",
    "    predictions = learner.zs_learner.predict_raw(input_embeddings)\n",
    "    input_target_similarities = similarity(predictions, y_embeddings)\n",
    "\n",
    "    X_recalled = [\n",
    "        np.argsort(-input_target_similarities[:,y_idx])[:k]\n",
    "        for (y_idx, __) in enumerate(y_names)\n",
    "    ]\n",
    "    return X_recalled\n",
    "\n",
    "\n",
    "def get_retrieval_accuracies(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    recalled_X = get_retrieval_results(learner, data, k=k, similarity=similarity)\n",
    "    recalled_X_actual_y = [data.y.iloc[idxs_recalled].explode() for idxs_recalled in recalled_X]\n",
    "    accurately_recalled = [\n",
    "        y_name in recalled_X_actual_y[y_idx].values \n",
    "        for (y_idx, y_name) in enumerate(y_names)\n",
    "    ]\n",
    "    return pd.Series(data=accurately_recalled, index=y_names)\n",
    "\n",
    "\n",
    "def get_retrieval_accuracy(learner, data, k=10, similarity=metrics.pairwise.cosine_similarity):\n",
    "    y_names, __ = learner.get_target_embeddings(data.y)\n",
    "    return np.mean(get_retrieval_accuracies(learner, data, k, similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def run_learner_experiment(\n",
    "    retriever_learner,\n",
    "    data_train, data_test\n",
    "):\n",
    "    retriever_learner.fit_learner(data_train)\n",
    "    \n",
    "    accuracy_train = retriever_learner.evaluate(data_train, metrics.accuracy_score)\n",
    "    accuracy_test = retriever_learner.evaluate(data_test, metrics.accuracy_score)\n",
    "    top10_accuracy_train = get_retrieval_accuracy(retriever_learner, data_train, k=10)\n",
    "    top10_accuracy_test = get_retrieval_accuracy(retriever_learner, data_test, k=10)\n",
    "    \n",
    "    return dict(\n",
    "        accuracy_train=accuracy_train,\n",
    "        accuracy_test=accuracy_test,\n",
    "        top10_accuracy_train=top10_accuracy_train,\n",
    "        top10_accuracy_test=top10_accuracy_test\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Deep Neural Networks (DNNs) are vulnerable to ...\n",
       "1        Thumbnails are widely used all over the world ...\n",
       "2        Despite the recent success of face image gener...\n",
       "3        How to model a pair of sentences is a critical...\n",
       "4        How to model a pair of sentences is a critical...\n",
       "                               ...                        \n",
       "12219    Obtaining models that capture imaging markers ...\n",
       "12220    Obtaining models that capture imaging markers ...\n",
       "12221    Obtaining models that capture imaging markers ...\n",
       "12222    Gatys et al. recently introduced a neural algo...\n",
       "12223    We introduce a new representation learning alg...\n",
       "Name: abstract, Length: 12224, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_with_imports_df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_abstract = ~paperswithcode_with_imports_df['abstract'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url_abs</th>\n",
       "      <th>url_pdf</th>\n",
       "      <th>proceeding</th>\n",
       "      <th>authors</th>\n",
       "      <th>tasks</th>\n",
       "      <th>...</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>most_common_task</th>\n",
       "      <th>imports</th>\n",
       "      <th>n_imports</th>\n",
       "      <th>n_imports_with_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://paperswithcode.com/paper/a-neuro-inspi...</td>\n",
       "      <td>2011.10867</td>\n",
       "      <td>A Neuro-Inspired Autoencoding Defense Against ...</td>\n",
       "      <td>Deep Neural Networks (DNNs) are vulnerable to ...</td>\n",
       "      <td>https://arxiv.org/abs/2011.10867v2</td>\n",
       "      <td>https://arxiv.org/pdf/2011.10867v2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Can Bakiskan', 'Metehan Cekic', 'Ahmet Dunda...</td>\n",
       "      <td>[dictionary learning]</td>\n",
       "      <td>...</td>\n",
       "      <td>2011.10867</td>\n",
       "      <td>A Neuro-Inspired Autoencoding Defense Against ...</td>\n",
       "      <td>https://arxiv.org/abs/2011.10867v2</td>\n",
       "      <td>https://arxiv.org/pdf/2011.10867v2.pdf</td>\n",
       "      <td>canbakiskan/neuro-inspired-defense</td>\n",
       "      <td>https://github.com/canbakiskan/neuro-inspired-...</td>\n",
       "      <td>dictionary learning</td>\n",
       "      <td>{os, train_test_functions, matplotlib, namers,...</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>https://paperswithcode.com/paper/user-constrai...</td>\n",
       "      <td>1810.13054</td>\n",
       "      <td>User Constrained Thumbnail Generation using Ad...</td>\n",
       "      <td>Thumbnails are widely used all over the world ...</td>\n",
       "      <td>http://arxiv.org/abs/1810.13054v3</td>\n",
       "      <td>http://arxiv.org/pdf/1810.13054v3.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Perla Sai Raj Kishore', 'Ayan Kumar Bhunia',...</td>\n",
       "      <td>[region proposal, user constrained thumbnail g...</td>\n",
       "      <td>...</td>\n",
       "      <td>1810.13054</td>\n",
       "      <td>User Constrained Thumbnail Generation using Ad...</td>\n",
       "      <td>http://arxiv.org/abs/1810.13054v3</td>\n",
       "      <td>http://arxiv.org/pdf/1810.13054v3.pdf</td>\n",
       "      <td>Aiyoj/Thumbnail-Generation</td>\n",
       "      <td>https://github.com/Aiyoj/Thumbnail-Generation</td>\n",
       "      <td>region proposal</td>\n",
       "      <td>{re, custom_vgg19, os, pandas, sys, cv2, ops, ...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>https://paperswithcode.com/paper/michigan-mult...</td>\n",
       "      <td>2010.16417</td>\n",
       "      <td>MichiGAN: Multi-Input-Conditioned Hair Image G...</td>\n",
       "      <td>Despite the recent success of face image gener...</td>\n",
       "      <td>https://arxiv.org/abs/2010.16417v1</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16417v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Zhentao Tan', 'Menglei Chai', 'Dongdong Chen...</td>\n",
       "      <td>[conditional image generation, image generation]</td>\n",
       "      <td>...</td>\n",
       "      <td>2010.16417</td>\n",
       "      <td>MichiGAN: Multi-Input-Conditioned Hair Image G...</td>\n",
       "      <td>https://arxiv.org/abs/2010.16417v1</td>\n",
       "      <td>https://arxiv.org/pdf/2010.16417v1.pdf</td>\n",
       "      <td>tzt101/MichiGAN</td>\n",
       "      <td>https://github.com/tzt101/MichiGAN</td>\n",
       "      <td>image generation</td>\n",
       "      <td>{data, os, ui, matplotlib, dominate, scipy, ar...</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>https://paperswithcode.com/paper/abcnn-attenti...</td>\n",
       "      <td>1512.05193</td>\n",
       "      <td>ABCNN: Attention-Based Convolutional Neural Ne...</td>\n",
       "      <td>How to model a pair of sentences is a critical...</td>\n",
       "      <td>http://arxiv.org/abs/1512.05193v4</td>\n",
       "      <td>http://arxiv.org/pdf/1512.05193v4.pdf</td>\n",
       "      <td>TACL 2016 1</td>\n",
       "      <td>['Wenpeng Yin', 'Hinrich Schütze', 'Bing Xiang...</td>\n",
       "      <td>[answer selection, natural language inference,...</td>\n",
       "      <td>...</td>\n",
       "      <td>1512.05193</td>\n",
       "      <td>ABCNN: Attention-Based Convolutional Neural Ne...</td>\n",
       "      <td>http://arxiv.org/abs/1512.05193v4</td>\n",
       "      <td>http://arxiv.org/pdf/1512.05193v4.pdf</td>\n",
       "      <td>shamalwinchurkar/question-classification</td>\n",
       "      <td>https://github.com/shamalwinchurkar/question-c...</td>\n",
       "      <td>natural language inference</td>\n",
       "      <td>{os, matplotlib, qc_plot, qc_emb, argparse, nu...</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>https://paperswithcode.com/paper/abcnn-attenti...</td>\n",
       "      <td>1512.05193</td>\n",
       "      <td>ABCNN: Attention-Based Convolutional Neural Ne...</td>\n",
       "      <td>How to model a pair of sentences is a critical...</td>\n",
       "      <td>http://arxiv.org/abs/1512.05193v4</td>\n",
       "      <td>http://arxiv.org/pdf/1512.05193v4.pdf</td>\n",
       "      <td>TACL 2016 1</td>\n",
       "      <td>['Wenpeng Yin', 'Hinrich Schütze', 'Bing Xiang...</td>\n",
       "      <td>[answer selection, natural language inference,...</td>\n",
       "      <td>...</td>\n",
       "      <td>1512.05193</td>\n",
       "      <td>ABCNN: Attention-Based Convolutional Neural Ne...</td>\n",
       "      <td>http://arxiv.org/abs/1512.05193v4</td>\n",
       "      <td>http://arxiv.org/pdf/1512.05193v4.pdf</td>\n",
       "      <td>jastfkjg/semantic-matching</td>\n",
       "      <td>https://github.com/jastfkjg/semantic-matching</td>\n",
       "      <td>natural language inference</td>\n",
       "      <td>{os, random, sklearn, matchpyramid, mvlstm, ma...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12219</th>\n",
       "      <td>21737</td>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>Obtaining models that capture imaging markers ...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...</td>\n",
       "      <td>[anomaly detection, unsupervised anomaly detec...</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>YeongHyeon/f-AnoGAN-TF</td>\n",
       "      <td>https://github.com/YeongHyeon/f-AnoGAN-TF</td>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>{os, matplotlib, sklearn, math, argparse, nump...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12220</th>\n",
       "      <td>21738</td>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>Obtaining models that capture imaging markers ...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...</td>\n",
       "      <td>[anomaly detection, unsupervised anomaly detec...</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>LeeDoYup/AnoGAN</td>\n",
       "      <td>https://github.com/LeeDoYup/AnoGAN</td>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>{os, tqdm, zipfile, sys, subprocess, requests,...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12221</th>\n",
       "      <td>21739</td>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>Obtaining models that capture imaging markers ...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...</td>\n",
       "      <td>[anomaly detection, unsupervised anomaly detec...</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.05921</td>\n",
       "      <td>Unsupervised Anomaly Detection with Generative...</td>\n",
       "      <td>http://arxiv.org/abs/1703.05921v1</td>\n",
       "      <td>http://arxiv.org/pdf/1703.05921v1.pdf</td>\n",
       "      <td>tkwoo/anogan-keras</td>\n",
       "      <td>https://github.com/tkwoo/anogan-keras</td>\n",
       "      <td>anomaly detection</td>\n",
       "      <td>{anogan, os, matplotlib, tqdm, sklearn, cv2, m...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12222</th>\n",
       "      <td>21740</td>\n",
       "      <td>https://paperswithcode.com/paper/arbitrary-sty...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>Gatys et al. recently introduced a neural algo...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ICCV 2017 10</td>\n",
       "      <td>['Xun Huang', 'Serge Belongie']</td>\n",
       "      <td>[style transfer]</td>\n",
       "      <td>...</td>\n",
       "      <td>1703.06868</td>\n",
       "      <td>Arbitrary Style Transfer in Real-time with Ada...</td>\n",
       "      <td>http://arxiv.org/abs/1703.06868v2</td>\n",
       "      <td>http://arxiv.org/pdf/1703.06868v2.pdf</td>\n",
       "      <td>ptran1203/style_transfer</td>\n",
       "      <td>https://github.com/ptran1203/style_transfer</td>\n",
       "      <td>style transfer</td>\n",
       "      <td>{os, matplotlib, sklearn, cv2, keras, utils, p...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12223</th>\n",
       "      <td>21741</td>\n",
       "      <td>https://paperswithcode.com/paper/domain-advers...</td>\n",
       "      <td>1412.4446</td>\n",
       "      <td>Domain-Adversarial Neural Networks</td>\n",
       "      <td>We introduce a new representation learning alg...</td>\n",
       "      <td>http://arxiv.org/abs/1412.4446v2</td>\n",
       "      <td>http://arxiv.org/pdf/1412.4446v2.pdf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Hana Ajakan', 'Pascal Germain', 'Hugo Laroch...</td>\n",
       "      <td>[denoising, domain adaptation, representation ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1412.4446</td>\n",
       "      <td>Domain-Adversarial Neural Networks</td>\n",
       "      <td>http://arxiv.org/abs/1412.4446v2</td>\n",
       "      <td>http://arxiv.org/pdf/1412.4446v2.pdf</td>\n",
       "      <td>Kano-Wu/Domain-Adversarial-Neural-Networks</td>\n",
       "      <td>https://github.com/Kano-Wu/Domain-Adversarial-...</td>\n",
       "      <td>representation learning</td>\n",
       "      <td>{sklearn, time, sys, data_helper, utils, DANN,...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12179 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                          paper_url  \\\n",
       "0               0  https://paperswithcode.com/paper/a-neuro-inspi...   \n",
       "1               3  https://paperswithcode.com/paper/user-constrai...   \n",
       "2               4  https://paperswithcode.com/paper/michigan-mult...   \n",
       "3               7  https://paperswithcode.com/paper/abcnn-attenti...   \n",
       "4               8  https://paperswithcode.com/paper/abcnn-attenti...   \n",
       "...           ...                                                ...   \n",
       "12219       21737  https://paperswithcode.com/paper/unsupervised-...   \n",
       "12220       21738  https://paperswithcode.com/paper/unsupervised-...   \n",
       "12221       21739  https://paperswithcode.com/paper/unsupervised-...   \n",
       "12222       21740  https://paperswithcode.com/paper/arbitrary-sty...   \n",
       "12223       21741  https://paperswithcode.com/paper/domain-advers...   \n",
       "\n",
       "         arxiv_id                                              title  \\\n",
       "0      2011.10867  A Neuro-Inspired Autoencoding Defense Against ...   \n",
       "1      1810.13054  User Constrained Thumbnail Generation using Ad...   \n",
       "2      2010.16417  MichiGAN: Multi-Input-Conditioned Hair Image G...   \n",
       "3      1512.05193  ABCNN: Attention-Based Convolutional Neural Ne...   \n",
       "4      1512.05193  ABCNN: Attention-Based Convolutional Neural Ne...   \n",
       "...           ...                                                ...   \n",
       "12219  1703.05921  Unsupervised Anomaly Detection with Generative...   \n",
       "12220  1703.05921  Unsupervised Anomaly Detection with Generative...   \n",
       "12221  1703.05921  Unsupervised Anomaly Detection with Generative...   \n",
       "12222  1703.06868  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "12223   1412.4446                 Domain-Adversarial Neural Networks   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      Deep Neural Networks (DNNs) are vulnerable to ...   \n",
       "1      Thumbnails are widely used all over the world ...   \n",
       "2      Despite the recent success of face image gener...   \n",
       "3      How to model a pair of sentences is a critical...   \n",
       "4      How to model a pair of sentences is a critical...   \n",
       "...                                                  ...   \n",
       "12219  Obtaining models that capture imaging markers ...   \n",
       "12220  Obtaining models that capture imaging markers ...   \n",
       "12221  Obtaining models that capture imaging markers ...   \n",
       "12222  Gatys et al. recently introduced a neural algo...   \n",
       "12223  We introduce a new representation learning alg...   \n",
       "\n",
       "                                  url_abs  \\\n",
       "0      https://arxiv.org/abs/2011.10867v2   \n",
       "1       http://arxiv.org/abs/1810.13054v3   \n",
       "2      https://arxiv.org/abs/2010.16417v1   \n",
       "3       http://arxiv.org/abs/1512.05193v4   \n",
       "4       http://arxiv.org/abs/1512.05193v4   \n",
       "...                                   ...   \n",
       "12219   http://arxiv.org/abs/1703.05921v1   \n",
       "12220   http://arxiv.org/abs/1703.05921v1   \n",
       "12221   http://arxiv.org/abs/1703.05921v1   \n",
       "12222   http://arxiv.org/abs/1703.06868v2   \n",
       "12223    http://arxiv.org/abs/1412.4446v2   \n",
       "\n",
       "                                      url_pdf    proceeding  \\\n",
       "0      https://arxiv.org/pdf/2011.10867v2.pdf           NaN   \n",
       "1       http://arxiv.org/pdf/1810.13054v3.pdf           NaN   \n",
       "2      https://arxiv.org/pdf/2010.16417v1.pdf           NaN   \n",
       "3       http://arxiv.org/pdf/1512.05193v4.pdf   TACL 2016 1   \n",
       "4       http://arxiv.org/pdf/1512.05193v4.pdf   TACL 2016 1   \n",
       "...                                       ...           ...   \n",
       "12219   http://arxiv.org/pdf/1703.05921v1.pdf           NaN   \n",
       "12220   http://arxiv.org/pdf/1703.05921v1.pdf           NaN   \n",
       "12221   http://arxiv.org/pdf/1703.05921v1.pdf           NaN   \n",
       "12222   http://arxiv.org/pdf/1703.06868v2.pdf  ICCV 2017 10   \n",
       "12223    http://arxiv.org/pdf/1412.4446v2.pdf           NaN   \n",
       "\n",
       "                                                 authors  \\\n",
       "0      ['Can Bakiskan', 'Metehan Cekic', 'Ahmet Dunda...   \n",
       "1      ['Perla Sai Raj Kishore', 'Ayan Kumar Bhunia',...   \n",
       "2      ['Zhentao Tan', 'Menglei Chai', 'Dongdong Chen...   \n",
       "3      ['Wenpeng Yin', 'Hinrich Schütze', 'Bing Xiang...   \n",
       "4      ['Wenpeng Yin', 'Hinrich Schütze', 'Bing Xiang...   \n",
       "...                                                  ...   \n",
       "12219  ['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...   \n",
       "12220  ['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...   \n",
       "12221  ['Thomas Schlegl', 'Philipp Seeböck', 'Sebasti...   \n",
       "12222                    ['Xun Huang', 'Serge Belongie']   \n",
       "12223  ['Hana Ajakan', 'Pascal Germain', 'Hugo Laroch...   \n",
       "\n",
       "                                                   tasks  ... paper_arxiv_id  \\\n",
       "0                                  [dictionary learning]  ...     2011.10867   \n",
       "1      [region proposal, user constrained thumbnail g...  ...     1810.13054   \n",
       "2       [conditional image generation, image generation]  ...     2010.16417   \n",
       "3      [answer selection, natural language inference,...  ...     1512.05193   \n",
       "4      [answer selection, natural language inference,...  ...     1512.05193   \n",
       "...                                                  ...  ...            ...   \n",
       "12219  [anomaly detection, unsupervised anomaly detec...  ...     1703.05921   \n",
       "12220  [anomaly detection, unsupervised anomaly detec...  ...     1703.05921   \n",
       "12221  [anomaly detection, unsupervised anomaly detec...  ...     1703.05921   \n",
       "12222                                   [style transfer]  ...     1703.06868   \n",
       "12223  [denoising, domain adaptation, representation ...  ...      1412.4446   \n",
       "\n",
       "                                             paper_title  \\\n",
       "0      A Neuro-Inspired Autoencoding Defense Against ...   \n",
       "1      User Constrained Thumbnail Generation using Ad...   \n",
       "2      MichiGAN: Multi-Input-Conditioned Hair Image G...   \n",
       "3      ABCNN: Attention-Based Convolutional Neural Ne...   \n",
       "4      ABCNN: Attention-Based Convolutional Neural Ne...   \n",
       "...                                                  ...   \n",
       "12219  Unsupervised Anomaly Detection with Generative...   \n",
       "12220  Unsupervised Anomaly Detection with Generative...   \n",
       "12221  Unsupervised Anomaly Detection with Generative...   \n",
       "12222  Arbitrary Style Transfer in Real-time with Ada...   \n",
       "12223                 Domain-Adversarial Neural Networks   \n",
       "\n",
       "                            paper_url_abs  \\\n",
       "0      https://arxiv.org/abs/2011.10867v2   \n",
       "1       http://arxiv.org/abs/1810.13054v3   \n",
       "2      https://arxiv.org/abs/2010.16417v1   \n",
       "3       http://arxiv.org/abs/1512.05193v4   \n",
       "4       http://arxiv.org/abs/1512.05193v4   \n",
       "...                                   ...   \n",
       "12219   http://arxiv.org/abs/1703.05921v1   \n",
       "12220   http://arxiv.org/abs/1703.05921v1   \n",
       "12221   http://arxiv.org/abs/1703.05921v1   \n",
       "12222   http://arxiv.org/abs/1703.06868v2   \n",
       "12223    http://arxiv.org/abs/1412.4446v2   \n",
       "\n",
       "                                paper_url_pdf  \\\n",
       "0      https://arxiv.org/pdf/2011.10867v2.pdf   \n",
       "1       http://arxiv.org/pdf/1810.13054v3.pdf   \n",
       "2      https://arxiv.org/pdf/2010.16417v1.pdf   \n",
       "3       http://arxiv.org/pdf/1512.05193v4.pdf   \n",
       "4       http://arxiv.org/pdf/1512.05193v4.pdf   \n",
       "...                                       ...   \n",
       "12219   http://arxiv.org/pdf/1703.05921v1.pdf   \n",
       "12220   http://arxiv.org/pdf/1703.05921v1.pdf   \n",
       "12221   http://arxiv.org/pdf/1703.05921v1.pdf   \n",
       "12222   http://arxiv.org/pdf/1703.06868v2.pdf   \n",
       "12223    http://arxiv.org/pdf/1412.4446v2.pdf   \n",
       "\n",
       "                                             repo  \\\n",
       "0              canbakiskan/neuro-inspired-defense   \n",
       "1                      Aiyoj/Thumbnail-Generation   \n",
       "2                                 tzt101/MichiGAN   \n",
       "3        shamalwinchurkar/question-classification   \n",
       "4                      jastfkjg/semantic-matching   \n",
       "...                                           ...   \n",
       "12219                      YeongHyeon/f-AnoGAN-TF   \n",
       "12220                             LeeDoYup/AnoGAN   \n",
       "12221                          tkwoo/anogan-keras   \n",
       "12222                    ptran1203/style_transfer   \n",
       "12223  Kano-Wu/Domain-Adversarial-Neural-Networks   \n",
       "\n",
       "                                                repo_url  \\\n",
       "0      https://github.com/canbakiskan/neuro-inspired-...   \n",
       "1          https://github.com/Aiyoj/Thumbnail-Generation   \n",
       "2                     https://github.com/tzt101/MichiGAN   \n",
       "3      https://github.com/shamalwinchurkar/question-c...   \n",
       "4          https://github.com/jastfkjg/semantic-matching   \n",
       "...                                                  ...   \n",
       "12219          https://github.com/YeongHyeon/f-AnoGAN-TF   \n",
       "12220                 https://github.com/LeeDoYup/AnoGAN   \n",
       "12221              https://github.com/tkwoo/anogan-keras   \n",
       "12222        https://github.com/ptran1203/style_transfer   \n",
       "12223  https://github.com/Kano-Wu/Domain-Adversarial-...   \n",
       "\n",
       "                 most_common_task  \\\n",
       "0             dictionary learning   \n",
       "1                 region proposal   \n",
       "2                image generation   \n",
       "3      natural language inference   \n",
       "4      natural language inference   \n",
       "...                           ...   \n",
       "12219           anomaly detection   \n",
       "12220           anomaly detection   \n",
       "12221           anomaly detection   \n",
       "12222              style transfer   \n",
       "12223     representation learning   \n",
       "\n",
       "                                                 imports n_imports  \\\n",
       "0      {os, train_test_functions, matplotlib, namers,...        30   \n",
       "1      {re, custom_vgg19, os, pandas, sys, cv2, ops, ...        15   \n",
       "2      {data, os, ui, matplotlib, dominate, scipy, ar...        40   \n",
       "3      {os, matplotlib, qc_plot, qc_emb, argparse, nu...        29   \n",
       "4      {os, random, sklearn, matchpyramid, mvlstm, ma...         9   \n",
       "...                                                  ...       ...   \n",
       "12219  {os, matplotlib, sklearn, math, argparse, nump...         9   \n",
       "12220  {os, tqdm, zipfile, sys, subprocess, requests,...        16   \n",
       "12221  {anogan, os, matplotlib, tqdm, sklearn, cv2, m...        12   \n",
       "12222  {os, matplotlib, sklearn, cv2, keras, utils, p...        12   \n",
       "12223  {sklearn, time, sys, data_helper, utils, DANN,...         9   \n",
       "\n",
       "      n_imports_with_embeddings  \n",
       "0                            30  \n",
       "1                            15  \n",
       "2                            40  \n",
       "3                            29  \n",
       "4                             9  \n",
       "...                         ...  \n",
       "12219                         9  \n",
       "12220                        16  \n",
       "12221                        12  \n",
       "12222                        12  \n",
       "12223                         9  \n",
       "\n",
       "[12179 rows x 25 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks_train[has_abstract]\n",
    "paperswithcode_with_features_df[has_abstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12179,)\n"
     ]
    }
   ],
   "source": [
    "abstract_data_train, abstract_data_test = RepoTaskData.create_split(tasks_train[has_abstract], all_tasks[has_abstract], paperswithcode_with_features_df[has_abstract], paperswithcode_with_features_df[has_abstract]['abstract'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scarce_learn.zero_shot import devise_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "fasttext_model = fasttext.load_model(\"output/python_files_fasttext_dim200.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "abstract_learner.fit_learner(abstract_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4405755047757224,\n",
       " 'accuracy_test': 0.12461617195496417,\n",
       " 'top10_accuracy_train': 0.6903914590747331,\n",
       " 'top10_accuracy_test': 0.6147540983606558}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(abstract_learner, abstract_data_train, abstract_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4405755047757224"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_learner.evaluate(abstract_data_train, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12461617195496417"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_learner.evaluate(abstract_data_test, metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6903914590747331"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_retrieval_accuracy(abstract_learner, abstract_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6147540983606558"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_retrieval_accuracy(abstract_learner, abstract_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract model using fasttext trained on Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "abstract_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.4176036754926853,\n",
       " 'accuracy_test': 0.06704196519959059,\n",
       " 'top10_accuracy_train': 0.498220640569395,\n",
       " 'top10_accuracy_test': 0.38524590163934425}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(abstract_fasttext_learner, abstract_data_train, abstract_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fasttext model on READMEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_with_imports_df['readme'] = readmes\n",
    "paperswithcode_with_features_df['readme'] = readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11605,)\n"
     ]
    }
   ],
   "source": [
    "has_readme = ~paperswithcode_with_imports_df['readme'].isna()\n",
    "\n",
    "readme_data_train, readme_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], paperswithcode_with_features_df[has_readme]['readme'].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "readme_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 100),\n",
    "    python_word_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "readme_learner.fit_learner(readme_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.32076953278366704,\n",
       " 'accuracy_test': 0.04994954591321897,\n",
       " 'top10_accuracy_train': 0.6401515151515151,\n",
       " 'top10_accuracy_test': 0.45985401459854014}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(readme_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext on READMEs - worse than word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_fasttext_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    word_embeddings,\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.23216856432404134,\n",
       " 'accuracy_test': 0.020686175580221997,\n",
       " 'top10_accuracy_train': 0.4621212121212121,\n",
       " 'top10_accuracy_test': 0.291970802919708}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_learner_experiment(readme_fasttext_learner, readme_data_train, readme_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11605,)\n"
     ]
    }
   ],
   "source": [
    "readme_keywords_data_train, readme_keywords_data_test = RepoTaskData.create_split(tasks_train[has_readme], all_tasks[has_readme], paperswithcode_with_features_df[has_readme], readme_keywords[has_readme].str.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.292893600314095,\n",
       " 'accuracy_test': 0.03279515640766902,\n",
       " 'top10_accuracy_train': 0.7916666666666666,\n",
       " 'top10_accuracy_test': 0.24817518248175183}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "readme_keywords_keywords_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(10, 10),\n",
    "    word_embeddings,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(readme_keywords_learner, readme_keywords_data_train, readme_keywords_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.16856283509873152,\n",
       " 'accuracy_test': 0.008337965536409116,\n",
       " 'top10_accuracy_train': 0.34296028880866425,\n",
       " 'top10_accuracy_test': 0.1557377049180328}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "import2vec_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(lmbda=100.0, gamma=10.0),\n",
    "    import2vec,\n",
    "    word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(import2vec_learner, import_data_train, import_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRoNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "prone_embeddings = gensim.models.KeyedVectors.load(\"data/prone_embeddings.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using repo embedding from node embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.10932391787629135,\n",
       " 'accuracy_test': 0.0019455252918287938,\n",
       " 'top10_accuracy_train': 0.27075812274368233,\n",
       " 'top10_accuracy_test': 0.040983606557377046}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prone_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    prone_embeddings,\n",
    "    python_word_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(prone_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## aggregating vertex embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_embeddings = gensim.models.KeyedVectors.load(\"output/graphsage_embeddings_fasttext_dim200_epochs50_dim200_layers2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'coincidence'"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(graphsage_embeddings.vocab)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        canbakiskan/neuro-inspired-defense ensemble dr...\n",
       "1        Aiyoj/Thumbnail-Generation custom_vgg19 data_l...\n",
       "2        tzt101/MichiGAN ui_palette coco generator repl...\n",
       "3        shamalwinchurkar/question-classification qc_tf...\n",
       "4        jastfkjg/semantic-matching matcramid utils mvl...\n",
       "                               ...                        \n",
       "12219    YeongHyeon/f-AnoGAN-TF neuralnet tf_process la...\n",
       "12220        LeeDoYup/AnoGAN utils download ops main model\n",
       "12221                       tkwoo/anogan-keras main anogan\n",
       "12222      ptran1203/style_transfer utils dataloader model\n",
       "12223    Kano-Wu/Domain-Adversarial-Neural-Networks uti...\n",
       "Length: 7647, dtype: object"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy_train': 0.006276971361318164,\n",
       " 'accuracy_test': 0.02584769316286826,\n",
       " 'top10_accuracy_train': 0.18050541516245489,\n",
       " 'top10_accuracy_test': 0.1557377049180328}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ezslearner = zero_shot.ESZSLearner()\n",
    "graphsage_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    graphsage_embeddings,\n",
    "    graphsage_embeddings,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer\n",
    ")\n",
    "\n",
    "run_learner_experiment(graphsage_learner, graph_data_train, graph_data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## using GraphSAGE model for embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                canbakiskan/neuro-inspired-defense\n",
       "1                        Aiyoj/Thumbnail-Generation\n",
       "2                                   tzt101/MichiGAN\n",
       "3          shamalwinchurkar/question-classification\n",
       "4                        jastfkjg/semantic-matching\n",
       "                            ...                    \n",
       "12219                        YeongHyeon/f-AnoGAN-TF\n",
       "12220                               LeeDoYup/AnoGAN\n",
       "12221                            tkwoo/anogan-keras\n",
       "12222                      ptran1203/style_transfer\n",
       "12223    Kano-Wu/Domain-Adversarial-Neural-Networks\n",
       "Name: repo, Length: 8307, dtype: object"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphsage_data_train.repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaTransformer:\n",
    "    \n",
    "    def __init__(self, transform_fn):\n",
    "        self.transform = transform_fn\n",
    "        \n",
    "    def fit(self, X, **kwargs):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search.pytorch_geometric_data import PygGraphWrapper\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embedder = embeddings.FastTextVectorizer(fasttext_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "0492wzl/tensorflow_slim_densenet                  0492wzl/tensorflow_slim_densenet inception_v2 ...\n",
       "08173021/FCOS                                     08173021/FCOS deform_pool_func scale test_box_...\n",
       "09jvilla/CS234_gym                                09jvilla/CS234_gym walker2d spec_list play bip...\n",
       "0h-n0/cdn_molecule_pytorch                        0h-n0/cdn_molecule_pytorch __init__ data util ...\n",
       "0h-n0/tfdbonas                                    0h-n0/tfdbonas layers setup deep_surrogate_mod...\n",
       "                                                                        ...                        \n",
       "xzgz/faster-rcnn                                  xzgz/faster-rcnn compress_net pyloss resize_an...\n",
       "xzhangfox/ANALYSE-AND-CLASSIFY-MUSIC-BY-LYRICS    xzhangfox/ANALYSE-AND-CLASSIFY-MUSIC-BY-LYRICS...\n",
       "xzr12/PredCNN                                     xzr12/PredCNN ResidualMultiplicativeBlock pred...\n",
       "xzwlx/Difficulty-SR                               xzwlx/Difficulty-SR rcan vdsr general100 ddbpn...\n",
       "y-ouali/pytorch_segmentation                      y-ouali/pytorch_segmentation cityscapes coco r...\n",
       "Length: 17441, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repo_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 955 ms, total: 32.7 s\n",
      "Wall time: 31.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dependency_graph_wrapper = PygGraphWrapper(fasttext_embedder.transform, non_root_dependency_records_df, \"repo_description\", \"file_description\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphsage_model = torch.load(\"output/graphsage_model_11_dim200_layers2.pth\").cpu()#\"output/graphsage_model_60_dim200_layers3.pth\").cpu()\n",
    "graphsage_model.training = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_data_train.repos.isin(repo_descriptions.index).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12224,)\n"
     ]
    }
   ],
   "source": [
    "graphsage_data_train, graphsage_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "graphsage_data_train.X = repo_descriptions.loc[graph_data_train.repos]\n",
    "graphsage_data_test.X = repo_descriptions.loc[graph_data_test.repos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_records_df(sources, connected_vertices):\n",
    "    return pd.DataFrame.from_records(\n",
    "        [\n",
    "            {\"source\": src, \"destination\": dst, \"edge_type\": \"repo-file\"}\n",
    "            for (src, destinations) in zip(sources, connected_vertices)\n",
    "            for dst in destinations \n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records_df = make_records_df(graphsage_data_train.repos, graph_data_train.X.fillna(\"\").str.split()).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertex_embeddings(wrapper, vertex_subset, model):\n",
    "    features = (\n",
    "        model.full_forward(\n",
    "            wrapper.dataset.x, wrapper.dataset.edge_index\n",
    "        )\n",
    "        .cpu()\n",
    "        .detach()\n",
    "        .numpy()\n",
    "    )\n",
    "    return features[wrapper.vertex_mapping.loc[vertex_subset]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot mask with non-boolean array containing NA / NaN values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-203-04c188e77f4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mextended_dependency_graph_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPygGraphWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastTextVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasttext_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_root_dependency_records_df\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmake_records_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphsage_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_data_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/github_search/github_search/pytorch_geometric_data.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, featurizer, records_df, source_col, destination_col)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertex_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_vertex_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvertices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0medge_index_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertex_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrecords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         edge_index_destination = self.vertex_mapping.loc[\n\u001b[1;32m     31\u001b[0m             \u001b[0mrecords_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdestination_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1090\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mis_bool_indexer\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mna_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Cannot mask with non-boolean array containing NA / NaN values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mna_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot mask with non-boolean array containing NA / NaN values"
     ]
    }
   ],
   "source": [
    "extended_dependency_graph_wrapper = PygGraphWrapper(embeddings.FastTextVectorizer(fasttext_model).transform, non_root_dependency_records_df + make_records_df(graphsage_data_train.repos, graph_data_train.X.dropna().str.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependency_graph_wrapper.get_vertex_embeddings(graphsage_data_train.X.iloc[0].split(), graphsage_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search/github_search/pytorch_geometric_data.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.dataset = Data(torch.tensor(features), torch.tensor(edge_index))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SAGEConv' object has no attribute 'decomposed_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-ce9e8a74cbd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastTextVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasttext_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgraphsage_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphsage_data_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mgraphsage_learner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphsage_data_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-3b4cd466f6ad>\u001b[0m in \u001b[0;36mfit_learner\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mX_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_embedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0munique_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-ce9e8a74cbd6>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m graphsage_learner = RetrieverLearner(\n\u001b[1;32m      2\u001b[0m     \u001b[0mzero_shot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESZSLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mLambdaTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdependency_graph_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vertex_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphsage_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastTextVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfasttext_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/Projects/github_search/github_search/pytorch_geometric_data.py\u001b[0m in \u001b[0;36mget_vertex_embeddings\u001b[0;34m(self, vertex_subset, model)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0msub_dataset_wrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sub_dataset_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvertex_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         features = (\n\u001b[0;32m---> 49\u001b[0;31m             model.full_forward(\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0msub_dataset_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_dataset_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             )\n",
      "\u001b[0;32m~/Projects/github_search/github_search/pytorch_geometric_networks.py\u001b[0m in \u001b[0;36mfull_forward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfull_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0maggregate\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mto\u001b[0m \u001b[0mupdate\u001b[0m \u001b[0mnode\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mdecomposed_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__explain__\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposed_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_propagate_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m    948\u001b[0m             type(self).__name__, name))\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SAGEConv' object has no attribute 'decomposed_layers'"
     ]
    }
   ],
   "source": [
    "graphsage_learner = RetrieverLearner(\n",
    "    zero_shot.ESZSLearner(100,10),\n",
    "    LambdaTransformer(lambda x: dependency_graph_wrapper.get_vertex_embeddings(x, graphsage_model)),\n",
    "    embeddings.FastTextVectorizer(fasttext_model)\n",
    ")\n",
    "graphsage_learner.fit_learner(graphsage_data_train)\n",
    "graphsage_learner.evaluate(graphsage_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graphsage_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(graphsage_learner, graphsage_data_test, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenation of repo, import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train, paired_data_test = RepoTaskData.create_split(tasks_train, all_tasks, paperswithcode_with_features_df, paperswithcode_with_imports_df['imports'])\n",
    "paired_data_train.X = graph_data_train.X + \" \" + import_data_train.X\n",
    "paired_data_test.X = graph_data_test.X + \" \" + import_data_test.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_data_train.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner = RetrieverLearner.create(\n",
    "    zero_shot.ESZSLearner(100, 10),\n",
    "    PairedKeyedVectors(python_word_embeddings.wv, graphsage_embeddings),\n",
    "    fasttext_model,\n",
    "    embeddings.AverageWordEmbeddingsVectorizer,\n",
    "    embeddings.FastTextVectorizer\n",
    ")\n",
    "\n",
    "paired_learner.fit_learner(graph_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paired_learner.evaluate(graph_data_train, metric=metrics.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_train, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_retrieval_accuracy(paired_learner, paired_data_test, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for (learner, learner_name, test) in zip(\n",
    "    [import2vec_learner, prone_learner, paired_learner],\n",
    "    ['import2vec', 'prone', 'both'],\n",
    "    [X_test, repo_graph_terms_test, X_paired_test]\n",
    "):\n",
    "    accs = []\n",
    "    for k in [1, 3, 5, 10, 20]:\n",
    "        rec = get_retrieval_accuracy(learner, test, y_test, test_task_idxs, k=k)\n",
    "        accs.append(rec)\n",
    "    results.append(pd.Series(name=learner_name, data=accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.columns = [\"Accuracy@{}\".format(i) for i in [1, 3, 5, 10, 20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.round(3).to_markdown(open(\"metrics/zsl_results.md\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat metrics/zsl_results.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_distances = metrics.pairwise.cosine_distances(task_embeddings, task_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poincare_embeddings = gensim.models.KeyedVectors.load('data/poincare5.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models.wrappers.fasttext\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from github_search import typical_file_parts\n",
    "from mlutil import prototype_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lines_df = typical_file_parts.get_selected_lines_and_repos(python_files_df['repo_name'], python_files_df['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting prototypical lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_selector = prototype_selection.PrototypeSelector(fasttext_avg_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fasttext_prototypes = json.load(open('data/fasttext_prototypes.json', 'r'))\n",
    "except:\n",
    "    fasttext_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    fasttext_prototypes = fasttext_selector.prototypes\n",
    "    json.dump(fasttext_prototypes, open('data/fasttext_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_vectorizer = embeddings.TransformerVectorizer('microsoft/codebert-base', batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector = prototype_selection.PrototypeSelector(codebert_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    codebert_prototypes = json.load(open('data/codebert_prototypes.json', 'r'))\n",
    "except:\n",
    "    codebert_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])\n",
    "    codebert_prototypes = codebert_selector.prototypes\n",
    "    json.dump(codebert_prototypes, open('data/codebert_prototypes.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_prototypes(vectorizer, prototypes):\n",
    "    prototype_aggregated_embeddings = {}\n",
    "    for key in prototypes.keys():\n",
    "        prototype_aggregated_embeddings[key] = np.mean(vectorizer.transform(prototypes[key]), axis=0)\n",
    "    return list(prototype_aggregated_embeddings.keys()), np.row_stack(prototype_aggregated_embeddings.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in codebert_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes = {\n",
    "    repo: v\n",
    "    for (repo, v) in fasttext_prototypes.items()\n",
    "    if repo in paperswithcode_with_imports_df['repo_name'].values\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prototypes(repo_name):\n",
    "    return pd.DataFrame({\"codebert\": codebert_prototypes[repo_name], \"fasttext\": fasttext_prototypes[repo_name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"Recommenders-movielens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prototypes(\"mmdetection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_prototypes['mmdetection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_repos, codebert_prototype_embeddings = vectorize_prototypes(codebert_vectorizer, codebert_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_repos, fasttext_prototype_embeddings = vectorize_prototypes(fasttext_avg_embedder, fasttext_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fasttext_prototype_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_tasks_series = paperswithcode_with_imports_df['most_common_task']\n",
    "paperswithcode_tasks_series.index = paperswithcode_with_imports_df['repo_name']\n",
    "#paperswithcode_tasks_series = paperswithcode_tasks_series[paperswithcode_tasks_series.index.isin(fasttext_repos)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_tasks = paperswithcode_tasks_series.loc[fasttext_repos]\n",
    "fasttext_tasks_embeddings = task_embedder.transform(fasttext_tasks)\n",
    "codebert_tasks = paperswithcode_tasks_series.loc[codebert_repos]\n",
    "codebert_tasks_embeddings = task_embedder.transform(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner = zero_shot.ESZSLearner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_prototype_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(codebert_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(codebert_prototype_embeddings, codebert_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eszs_learner.fit(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])\n",
    "eszs_learner.score(fasttext_prototype_embeddings, fasttext_tasks, task_embeddings[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(selected_lines_df['repo']))[3007]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df = selected_lines_df[selected_lines_df['repo'] == 'auto_ml']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del codebert_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_lines_df['lines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector.prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings = fasttext_avg_embedder.transform(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_names = \n",
    "repo_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
