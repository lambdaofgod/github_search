{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export typical_file_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from github_search import python_tokens\n",
    "from mlutil.feature_extraction import embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "python_files_df = pd.read_csv('data/python_files.csv', nrows=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_file = python_files_df['content'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_class_names(lines):\n",
    "    return [line.strip() for line in lines if line.lstrip().startswith('class ') and line.rstrip().endswith(':')]\n",
    "\n",
    "\n",
    "def select_function_names(lines):\n",
    "    return [line.strip() for line in lines if line.lstrip().startswith('def ')]\n",
    "\n",
    "\n",
    "def select_lines(text):\n",
    "    lines = text.split('\\n')\n",
    "    return select_function_names(lines) + select_class_names(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import io\n",
    "import tokenize\n",
    "import keyword\n",
    "import re\n",
    "\n",
    "\n",
    "PYTHON_KEYWORDS = set(keyword.kwlist)\n",
    "\n",
    "\n",
    "def tokenize_snakecase(identifier):\n",
    "    return identifier.split('_')\n",
    "\n",
    "\n",
    "def tokenize_camelcase(identifier):\n",
    "    matches = re.finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return [m.group(0) for m in matches]\n",
    "\n",
    "\n",
    "def tokenize_python(identifier, lowercase=False):\n",
    "    if '_' in identifier:\n",
    "        tokens = tokenize_snakecase(identifier)\n",
    "    else:\n",
    "        tokens = tokenize_camelcase(identifier)\n",
    "    return [\n",
    "        t.lower()\n",
    "        for t in tokens\n",
    "    ]\n",
    "    \n",
    "\n",
    "def get_file_variable_token_set(file_text, min_token_length=2, lowercase=True):\n",
    "    token_infos = list(tokenize.generate_tokens(io.StringIO(file_text).readline))\n",
    "    raw_tokens = [t.string for t in token_infos if t.type == 1]\n",
    "    all_tokens = (\n",
    "        tokenize_python(t, lowercase) for t in raw_tokens\n",
    "    )\n",
    "    all_tokens = [\n",
    "        token\n",
    "        for tokens in all_tokens\n",
    "        for token in tokens\n",
    "        if len(token) > min_token_length and not token in PYTHON_KEYWORDS\n",
    "    ]\n",
    "    return set(all_tokens)\n",
    "\n",
    "\n",
    "def maybe_get_file_variable_token_string(file_text, min_token_length=2):\n",
    "    try:\n",
    "        tokens = get_file_variable_token_set(file_text)\n",
    "    except:\n",
    "        return None\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "models                           7634\n",
       "transformers                      744\n",
       "DeepPavlov                        407\n",
       "GIZMO-CMZ                         105\n",
       "faster-rcnn-fcn                    93\n",
       "                                 ... \n",
       "DeepPrivInf2017                     2\n",
       "BiSeNet-Implementation              1\n",
       "Machine-Learning-CS539              1\n",
       "stain-normalization-isbi-2017       1\n",
       "kNN_SWin                            1\n",
       "Name: repo_name, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_files_df.iloc[:10000]['repo_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selected_lines = select_lines(' '.join(python_files_df[python_files_df['repo_name'] == 'transformers']['content'].dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_selected_lines_and_repos(repos, file_contents):\n",
    "    \n",
    "    selected_lines_by_repo = {\n",
    "        repo: np.unique(select_lines(' '.join(file_contents[repos == repo].dropna())))\n",
    "        for repo in repos.unique()\n",
    "    }\n",
    "    selected_lines_by_repo = {\n",
    "        repo: lines\n",
    "        for (repo, lines) in selected_lines_by_repo.items()\n",
    "        if len(lines) > 0\n",
    "    }\n",
    "    line_repos = [k for k in selected_lines_by_repo.keys() for __ in selected_lines_by_repo[k]]\n",
    "    all_selected_lines = [line for lines in selected_lines_by_repo.values() for line in lines]\n",
    "    return pd.DataFrame({'repo': line_repos, 'line': all_selected_lines})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_lines_df = get_selected_lines_and_repos(python_files_df['repo_name'], python_files_df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlutil.feature_extraction import embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_vectorizer = embeddings.TransformerVectorizer('microsoft/codebert-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selected_lines = list(np.unique(example_selected_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:02<00:00, 22.76it/s]\n"
     ]
    }
   ],
   "source": [
    "example_line_embeddings = codebert_vectorizer.transform(example_selected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6708, 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_line_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from sklearn import cluster, metrics, mixture\n",
    "\n",
    "\n",
    "def select_centroid_prototype_indices(features, n_prototypes=10):\n",
    "    n_prototypes = min(len(features), n_prototypes)\n",
    "    clusterer = cluster.KMeans(n_prototypes)\n",
    "    clusterer.fit(features)\n",
    "    cluster_distances = metrics.pairwise.euclidean_distances(clusterer.cluster_centers_, features)\n",
    "    prototype_indices = np.unique(cluster_distances.argmin(axis=1))\n",
    "    return prototype_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_prototypes = 10 \n",
    "data = example_line_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prototype_lines_by_repo_types' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-822bb4d3a961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprototype_lines_by_repo_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'prototype_lines_by_repo_types' is not defined"
     ]
    }
   ],
   "source": [
    "frozenset(prototype_lines_by_repo_types.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototype_embeddings_by_repo['transformers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import attr\n",
    "from sklearn import cluster, metrics, mixture\n",
    "\n",
    "\n",
    "def select_centroid_prototype_indices(features, n_prototypes=10):\n",
    "    n_prototypes = min(len(features), n_prototypes)\n",
    "    clusterer = cluster.KMeans(n_prototypes)\n",
    "    clusterer.fit(features)\n",
    "    cluster_distances = metrics.pairwise.euclidean_distances(clusterer.cluster_centers_, features)\n",
    "    prototype_indices = np.unique(cluster_distances.argmin(axis=1))\n",
    "    return prototype_indices\n",
    "\n",
    "\n",
    "@attr.s\n",
    "class PrototypeSelector:\n",
    "    \n",
    "    vectorizer = attr.ib()\n",
    "    n_prototypes = attr.ib(default=10)\n",
    "    \n",
    "    def fit_prototypes(self, data, labels):\n",
    "        self.prototypes = {}\n",
    "        data = np.array(data)\n",
    "        labels = pd.Series(labels)\n",
    "        for label in tqdm.tqdm(set(labels)):\n",
    "            label_data = data[labels == label]\n",
    "            label_features = self.vectorizer.transform(list(label_data))\n",
    "            label_prototype_indices = select_centroid_prototype_indices(label_features, self.n_prototypes)\n",
    "            self.prototypes[label] = np.array(label_data)[label_prototype_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector = prototype_selection.PrototypeSelector(codebert_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector.fit_prototypes(selected_lines_df['line'], selected_lines_df['repo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codebert_selector.prototypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
