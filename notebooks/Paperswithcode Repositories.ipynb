{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defaul_texp paperswithcode_repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "from github_search import github_crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kuba/Projects/github_search\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘data/links-between-papers-and-code.json.gz’ already there; not retrieving.\n",
      "File ‘data/papers-with-abstracts.json.gz’ already there; not retrieving.\n"
     ]
    }
   ],
   "source": [
    "!wget -nc -O data/links-between-papers-and-code.json.gz https://paperswithcode.com/media/about/links-between-papers-and-code.json.gz\n",
    "!wget -nc -O data/papers-with-abstracts.json.gz https://paperswithcode.com/media/about/papers-with-abstracts.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ape_npi_main.py\r\n",
      "CodeSearchNet\r\n",
      "file.csv\r\n",
      "links-between-papers-and-code.json.gz\r\n",
      "lm_data.pkl\r\n",
      "nlp_github_repos.csv\r\n",
      "nlp_github_repos.json\r\n",
      "numpy_requirement_pairs.csv\r\n",
      "packages_with_numpy_requirements.csv\r\n",
      "papers-with-abstracts.json.gz\r\n",
      "python_pypi_projects.json\r\n",
      "python_pypi_projects_modules000000000000.json.gz\r\n",
      "python_pypi_projects_modules000000000001.json.gz\r\n",
      "python_pypi_projects_modules000000000002.json.gz\r\n",
      "python_pypi_projects_modules000000000003.json.gz\r\n",
      "python_pypi_projects_modules000000000004.json.gz\r\n",
      "python_pypi_projects_modules000000000005.json.gz\r\n",
      "python_pypi_projects_modules000000000006.json.gz\r\n",
      "python_pypi_projects_modules000000000007.json.gz\r\n",
      "python_pypi_projects_modules000000000008.json.gz\r\n",
      "python_pypi_projects_modules000000000009.json.gz\r\n",
      "repo_imports.csv\r\n",
      "repo_requirements.csv\r\n",
      "susi_setup.py\r\n",
      "tmp_df.csv\r\n",
      "token.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperswithcode_df = pd.read_json('data/links-between-papers-and-code.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/paper/searching-for...</td>\n",
       "      <td>Searching for Efficient Multi-Scale Architectu...</td>\n",
       "      <td>1809.04184</td>\n",
       "      <td>http://arxiv.org/abs/1809.04184v1</td>\n",
       "      <td>http://arxiv.org/pdf/1809.04184v1.pdf</td>\n",
       "      <td>https://github.com/tensorflow/models</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://paperswithcode.com/paper/automatic-pos...</td>\n",
       "      <td>Automatic Post-Editing of Machine Translation:...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.aclweb.org/anthology/D18-1341/</td>\n",
       "      <td>https://www.aclweb.org/anthology/D18-1341</td>\n",
       "      <td>https://github.com/trangvu/ape-npi</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paperswithcode.com/paper/predicting-th...</td>\n",
       "      <td>Predicting the Driver's Focus of Attention: th...</td>\n",
       "      <td>1705.03854</td>\n",
       "      <td>http://arxiv.org/abs/1705.03854v3</td>\n",
       "      <td>http://arxiv.org/pdf/1705.03854v3.pdf</td>\n",
       "      <td>https://github.com/ndrplz/dreyeve</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://paperswithcode.com/paper/asynchronous-...</td>\n",
       "      <td>Asynchronous Stochastic Gradient Descent with ...</td>\n",
       "      <td>1609.08326</td>\n",
       "      <td>https://arxiv.org/abs/1609.08326v6</td>\n",
       "      <td>https://arxiv.org/pdf/1609.08326v6.pdf</td>\n",
       "      <td>https://github.com/microsoft/dmtk</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://paperswithcode.com/paper/parser-showdo...</td>\n",
       "      <td>Parser Showdown at the Wall Street Corral: An ...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.aclweb.org/anthology/D12-1096/</td>\n",
       "      <td>https://www.aclweb.org/anthology/D12-1096</td>\n",
       "      <td>https://github.com/jkkummerfeld/berkeley-parse...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47129</th>\n",
       "      <td>https://paperswithcode.com/paper/coco-gan-gene...</td>\n",
       "      <td>COCO-GAN: Generation by Parts via Conditional ...</td>\n",
       "      <td>1904.00284</td>\n",
       "      <td>https://arxiv.org/abs/1904.00284v4</td>\n",
       "      <td>https://arxiv.org/pdf/1904.00284v4.pdf</td>\n",
       "      <td>https://github.com/hubert0527/COCO-GAN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47130</th>\n",
       "      <td>https://paperswithcode.com/paper/collabonet-co...</td>\n",
       "      <td>CollaboNet: collaboration of deep neural netwo...</td>\n",
       "      <td>1809.07950</td>\n",
       "      <td>https://arxiv.org/abs/1809.07950v2</td>\n",
       "      <td>https://arxiv.org/pdf/1809.07950v2.pdf</td>\n",
       "      <td>https://github.com/wonjininfo/CollaboNet</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47131</th>\n",
       "      <td>https://paperswithcode.com/paper/visnet-deep-c...</td>\n",
       "      <td>VisNet: Deep Convolutional Neural Networks for...</td>\n",
       "      <td>None</td>\n",
       "      <td>https://www.mdpi.com/1424-8220/19/6/1343</td>\n",
       "      <td>https://www.mdpi.com/1424-8220/19/6/1343</td>\n",
       "      <td>https://github.com/JaniceLC/PyTorch-VisNet</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47132</th>\n",
       "      <td>https://paperswithcode.com/paper/network-learn...</td>\n",
       "      <td>Network learning via multi-agent inverse trans...</td>\n",
       "      <td>1609.04117</td>\n",
       "      <td>http://arxiv.org/abs/1609.04117v4</td>\n",
       "      <td>http://arxiv.org/pdf/1609.04117v4.pdf</td>\n",
       "      <td>https://github.com/BUILTNYU/Network-learning-v...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47133</th>\n",
       "      <td>https://paperswithcode.com/paper/unsupervised-...</td>\n",
       "      <td>Unsupervised Part-based Weighting Aggregation ...</td>\n",
       "      <td>1705.01247</td>\n",
       "      <td>http://arxiv.org/abs/1705.01247v3</td>\n",
       "      <td>http://arxiv.org/pdf/1705.01247v3.pdf</td>\n",
       "      <td>https://github.com/XJhaoren/PWA</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47134 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper_url  \\\n",
       "0      https://paperswithcode.com/paper/searching-for...   \n",
       "1      https://paperswithcode.com/paper/automatic-pos...   \n",
       "2      https://paperswithcode.com/paper/predicting-th...   \n",
       "3      https://paperswithcode.com/paper/asynchronous-...   \n",
       "4      https://paperswithcode.com/paper/parser-showdo...   \n",
       "...                                                  ...   \n",
       "47129  https://paperswithcode.com/paper/coco-gan-gene...   \n",
       "47130  https://paperswithcode.com/paper/collabonet-co...   \n",
       "47131  https://paperswithcode.com/paper/visnet-deep-c...   \n",
       "47132  https://paperswithcode.com/paper/network-learn...   \n",
       "47133  https://paperswithcode.com/paper/unsupervised-...   \n",
       "\n",
       "                                             paper_title paper_arxiv_id  \\\n",
       "0      Searching for Efficient Multi-Scale Architectu...     1809.04184   \n",
       "1      Automatic Post-Editing of Machine Translation:...           None   \n",
       "2      Predicting the Driver's Focus of Attention: th...     1705.03854   \n",
       "3      Asynchronous Stochastic Gradient Descent with ...     1609.08326   \n",
       "4      Parser Showdown at the Wall Street Corral: An ...           None   \n",
       "...                                                  ...            ...   \n",
       "47129  COCO-GAN: Generation by Parts via Conditional ...     1904.00284   \n",
       "47130  CollaboNet: collaboration of deep neural netwo...     1809.07950   \n",
       "47131  VisNet: Deep Convolutional Neural Networks for...           None   \n",
       "47132  Network learning via multi-agent inverse trans...     1609.04117   \n",
       "47133  Unsupervised Part-based Weighting Aggregation ...     1705.01247   \n",
       "\n",
       "                                    paper_url_abs  \\\n",
       "0               http://arxiv.org/abs/1809.04184v1   \n",
       "1      https://www.aclweb.org/anthology/D18-1341/   \n",
       "2               http://arxiv.org/abs/1705.03854v3   \n",
       "3              https://arxiv.org/abs/1609.08326v6   \n",
       "4      https://www.aclweb.org/anthology/D12-1096/   \n",
       "...                                           ...   \n",
       "47129          https://arxiv.org/abs/1904.00284v4   \n",
       "47130          https://arxiv.org/abs/1809.07950v2   \n",
       "47131    https://www.mdpi.com/1424-8220/19/6/1343   \n",
       "47132           http://arxiv.org/abs/1609.04117v4   \n",
       "47133           http://arxiv.org/abs/1705.01247v3   \n",
       "\n",
       "                                   paper_url_pdf  \\\n",
       "0          http://arxiv.org/pdf/1809.04184v1.pdf   \n",
       "1      https://www.aclweb.org/anthology/D18-1341   \n",
       "2          http://arxiv.org/pdf/1705.03854v3.pdf   \n",
       "3         https://arxiv.org/pdf/1609.08326v6.pdf   \n",
       "4      https://www.aclweb.org/anthology/D12-1096   \n",
       "...                                          ...   \n",
       "47129     https://arxiv.org/pdf/1904.00284v4.pdf   \n",
       "47130     https://arxiv.org/pdf/1809.07950v2.pdf   \n",
       "47131   https://www.mdpi.com/1424-8220/19/6/1343   \n",
       "47132      http://arxiv.org/pdf/1609.04117v4.pdf   \n",
       "47133      http://arxiv.org/pdf/1705.01247v3.pdf   \n",
       "\n",
       "                                                repo_url  mentioned_in_paper  \\\n",
       "0                   https://github.com/tensorflow/models               False   \n",
       "1                     https://github.com/trangvu/ape-npi               False   \n",
       "2                      https://github.com/ndrplz/dreyeve                True   \n",
       "3                      https://github.com/microsoft/dmtk               False   \n",
       "4      https://github.com/jkkummerfeld/berkeley-parse...               False   \n",
       "...                                                  ...                 ...   \n",
       "47129             https://github.com/hubert0527/COCO-GAN               False   \n",
       "47130           https://github.com/wonjininfo/CollaboNet                True   \n",
       "47131         https://github.com/JaniceLC/PyTorch-VisNet               False   \n",
       "47132  https://github.com/BUILTNYU/Network-learning-v...                True   \n",
       "47133                    https://github.com/XJhaoren/PWA                True   \n",
       "\n",
       "       mentioned_in_github framework  \n",
       "0                    False        tf  \n",
       "1                    False        tf  \n",
       "2                     True      none  \n",
       "3                     True     torch  \n",
       "4                    False      none  \n",
       "...                    ...       ...  \n",
       "47129                False        tf  \n",
       "47130                 True        tf  \n",
       "47131                False   pytorch  \n",
       "47132                False      none  \n",
       "47133                False      none  \n",
       "\n",
       "[47134 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_df = pd.read_json('data/papers-with-abstracts.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158127 entries, 0 to 158126\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   paper_url   158127 non-null  object        \n",
      " 1   arxiv_id    121567 non-null  object        \n",
      " 2   title       157975 non-null  object        \n",
      " 3   abstract    157608 non-null  object        \n",
      " 4   url_abs     158127 non-null  object        \n",
      " 5   url_pdf     157975 non-null  object        \n",
      " 6   proceeding  53304 non-null   object        \n",
      " 7   authors     158127 non-null  object        \n",
      " 8   tasks       158127 non-null  object        \n",
      " 9   date        157975 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), object(9)\n",
      "memory usage: 12.1+ MB\n"
     ]
    }
   ],
   "source": [
    "all_papers_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_df['date_string'] = all_papers_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_papers_df['date'] = pd.to_datetime(all_papers_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_df = all_papers_df[all_papers_df['date'].dt.year == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_url</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url_abs</th>\n",
       "      <th>url_pdf</th>\n",
       "      <th>proceeding</th>\n",
       "      <th>authors</th>\n",
       "      <th>tasks</th>\n",
       "      <th>date</th>\n",
       "      <th>date_string</th>\n",
       "      <th>paper_title</th>\n",
       "      <th>paper_arxiv_id</th>\n",
       "      <th>paper_url_abs</th>\n",
       "      <th>paper_url_pdf</th>\n",
       "      <th>repo_url</th>\n",
       "      <th>mentioned_in_paper</th>\n",
       "      <th>mentioned_in_github</th>\n",
       "      <th>framework</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://paperswithcode.com/paper/neural-conver...</td>\n",
       "      <td>1909.03759</td>\n",
       "      <td>Neural Conversational QA: Learning to Reason v...</td>\n",
       "      <td>In this paper we work on the recently introduc...</td>\n",
       "      <td>https://arxiv.org/abs/1909.03759v1</td>\n",
       "      <td>https://arxiv.org/pdf/1909.03759v1.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Abhishek Sharma, Danish Contractor, Harshit K...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>2019-09-09</td>\n",
       "      <td>Neural Conversational QA: Learning to Reason v...</td>\n",
       "      <td>1909.03759</td>\n",
       "      <td>https://arxiv.org/abs/1909.03759v1</td>\n",
       "      <td>https://arxiv.org/pdf/1909.03759v1.pdf</td>\n",
       "      <td>https://github.com/IBM/UrcaNet</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://paperswithcode.com/paper/neurocore-gui...</td>\n",
       "      <td>1903.04671</td>\n",
       "      <td>Guiding High-Performance SAT Solvers with Unsa...</td>\n",
       "      <td>The NeuroSAT neural network architecture was r...</td>\n",
       "      <td>https://arxiv.org/abs/1903.04671v7</td>\n",
       "      <td>https://arxiv.org/pdf/1903.04671v7.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Daniel Selsam, Nikolaj Bjørner]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>2019-03-12</td>\n",
       "      <td>Guiding High-Performance SAT Solvers with Unsa...</td>\n",
       "      <td>1903.04671</td>\n",
       "      <td>https://arxiv.org/abs/1903.04671v7</td>\n",
       "      <td>https://arxiv.org/pdf/1903.04671v7.pdf</td>\n",
       "      <td>https://github.com/dselsam/neurocore-public</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://paperswithcode.com/paper/contextual-re...</td>\n",
       "      <td>1902.03455</td>\n",
       "      <td>Contextual Recurrent Neural Networks</td>\n",
       "      <td>There is an implicit assumption that by unfold...</td>\n",
       "      <td>http://arxiv.org/abs/1902.03455v1</td>\n",
       "      <td>http://arxiv.org/pdf/1902.03455v1.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Sam Wenke, Jim Fleming]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>2019-02-09</td>\n",
       "      <td>Contextual Recurrent Neural Networks</td>\n",
       "      <td>1902.03455</td>\n",
       "      <td>http://arxiv.org/abs/1902.03455v1</td>\n",
       "      <td>http://arxiv.org/pdf/1902.03455v1.pdf</td>\n",
       "      <td>https://github.com/fomorians/contextual_rnn</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://paperswithcode.com/paper/190510752</td>\n",
       "      <td>1905.10752</td>\n",
       "      <td>TIGS: An Inference Algorithm for Text Infillin...</td>\n",
       "      <td>Text infilling is defined as a task for fillin...</td>\n",
       "      <td>https://arxiv.org/abs/1905.10752v1</td>\n",
       "      <td>https://arxiv.org/pdf/1905.10752v1.pdf</td>\n",
       "      <td>ACL 2019 7</td>\n",
       "      <td>[Dayiheng Liu, Jie Fu, Pengfei Liu, Jiancheng Lv]</td>\n",
       "      <td>[Text Generation, Text Infilling]</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>2019-05-26</td>\n",
       "      <td>TIGS: An Inference Algorithm for Text Infillin...</td>\n",
       "      <td>1905.10752</td>\n",
       "      <td>https://arxiv.org/abs/1905.10752v1</td>\n",
       "      <td>https://arxiv.org/pdf/1905.10752v1.pdf</td>\n",
       "      <td>https://github.com/dayihengliu/Text-Infilling-...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>tf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://paperswithcode.com/paper/are-we-consis...</td>\n",
       "      <td>1904.11783</td>\n",
       "      <td>Are We Consistently Biased? Multidimensional A...</td>\n",
       "      <td>Word embeddings have recently been shown to re...</td>\n",
       "      <td>http://arxiv.org/abs/1904.11783v2</td>\n",
       "      <td>http://arxiv.org/pdf/1904.11783v2.pdf</td>\n",
       "      <td>SEMEVAL 2019 6</td>\n",
       "      <td>[Anne Lauscher, Goran Glavaš]</td>\n",
       "      <td>[Cross-Lingual Transfer, Word Embeddings]</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>2019-04-26</td>\n",
       "      <td>Are We Consistently Biased? Multidimensional A...</td>\n",
       "      <td>1904.11783</td>\n",
       "      <td>http://arxiv.org/abs/1904.11783v2</td>\n",
       "      <td>http://arxiv.org/pdf/1904.11783v2.pdf</td>\n",
       "      <td>https://github.com/umanlp/XWEAT</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11221</th>\n",
       "      <td>https://paperswithcode.com/paper/fixup-initial...</td>\n",
       "      <td>1901.09321</td>\n",
       "      <td>Fixup Initialization: Residual Learning Withou...</td>\n",
       "      <td>Normalization layers are a staple in state-of-...</td>\n",
       "      <td>http://arxiv.org/abs/1901.09321v2</td>\n",
       "      <td>http://arxiv.org/pdf/1901.09321v2.pdf</td>\n",
       "      <td>ICLR 2019 5</td>\n",
       "      <td>[Hongyi Zhang, Yann N. Dauphin, Tengyu Ma]</td>\n",
       "      <td>[Image Classification, Machine Translation]</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>Fixup Initialization: Residual Learning Withou...</td>\n",
       "      <td>1901.09321</td>\n",
       "      <td>http://arxiv.org/abs/1901.09321v2</td>\n",
       "      <td>http://arxiv.org/pdf/1901.09321v2.pdf</td>\n",
       "      <td>https://github.com/AngusG/bn-advex-zhang-fixup</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11222</th>\n",
       "      <td>https://paperswithcode.com/paper/fixup-initial...</td>\n",
       "      <td>1901.09321</td>\n",
       "      <td>Fixup Initialization: Residual Learning Withou...</td>\n",
       "      <td>Normalization layers are a staple in state-of-...</td>\n",
       "      <td>http://arxiv.org/abs/1901.09321v2</td>\n",
       "      <td>http://arxiv.org/pdf/1901.09321v2.pdf</td>\n",
       "      <td>ICLR 2019 5</td>\n",
       "      <td>[Hongyi Zhang, Yann N. Dauphin, Tengyu Ma]</td>\n",
       "      <td>[Image Classification, Machine Translation]</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>2019-01-27</td>\n",
       "      <td>Fixup Initialization: Residual Learning Withou...</td>\n",
       "      <td>1901.09321</td>\n",
       "      <td>http://arxiv.org/abs/1901.09321v2</td>\n",
       "      <td>http://arxiv.org/pdf/1901.09321v2.pdf</td>\n",
       "      <td>https://github.com/Abhimanyu08/Fixup_Initializ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11223</th>\n",
       "      <td>https://paperswithcode.com/paper/harmonic-netw...</td>\n",
       "      <td>1905.00135</td>\n",
       "      <td>Harmonic Networks with Limited Training Samples</td>\n",
       "      <td>Convolutional neural networks (CNNs) are very ...</td>\n",
       "      <td>http://arxiv.org/abs/1905.00135v1</td>\n",
       "      <td>http://arxiv.org/pdf/1905.00135v1.pdf</td>\n",
       "      <td>None</td>\n",
       "      <td>[Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot]</td>\n",
       "      <td>[Image Classification]</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>2019-04-30</td>\n",
       "      <td>Harmonic Networks with Limited Training Samples</td>\n",
       "      <td>1905.00135</td>\n",
       "      <td>http://arxiv.org/abs/1905.00135v1</td>\n",
       "      <td>http://arxiv.org/pdf/1905.00135v1.pdf</td>\n",
       "      <td>https://github.com/matej-ulicny/harmonic-networks</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11224</th>\n",
       "      <td>https://paperswithcode.com/paper/a-discrete-ha...</td>\n",
       "      <td>1909.04849</td>\n",
       "      <td>A Discrete Hard EM Approach for Weakly Supervi...</td>\n",
       "      <td>Many question answering (QA) tasks only provid...</td>\n",
       "      <td>https://arxiv.org/abs/1909.04849v1</td>\n",
       "      <td>https://arxiv.org/pdf/1909.04849v1.pdf</td>\n",
       "      <td>IJCNLP 2019 11</td>\n",
       "      <td>[Sewon Min, Danqi Chen, Hannaneh Hajishirzi, L...</td>\n",
       "      <td>[Question Answering]</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>2019-09-11</td>\n",
       "      <td>A Discrete Hard EM Approach for Weakly Supervi...</td>\n",
       "      <td>1909.04849</td>\n",
       "      <td>https://arxiv.org/abs/1909.04849v1</td>\n",
       "      <td>https://arxiv.org/pdf/1909.04849v1.pdf</td>\n",
       "      <td>https://github.com/shmsw25/qa-hard-em</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11225</th>\n",
       "      <td>https://paperswithcode.com/paper/partially-shu...</td>\n",
       "      <td>1903.04167</td>\n",
       "      <td>Partially Shuffling the Training Data to Impro...</td>\n",
       "      <td>Although SGD requires shuffling the training d...</td>\n",
       "      <td>http://arxiv.org/abs/1903.04167v2</td>\n",
       "      <td>http://arxiv.org/pdf/1903.04167v2.pdf</td>\n",
       "      <td>arXiv 2019 3</td>\n",
       "      <td>[Ofir Press]</td>\n",
       "      <td>[Language Modelling, Sentence Ordering]</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>2019-03-11</td>\n",
       "      <td>Partially Shuffling the Training Data to Impro...</td>\n",
       "      <td>1903.04167</td>\n",
       "      <td>http://arxiv.org/abs/1903.04167v2</td>\n",
       "      <td>http://arxiv.org/pdf/1903.04167v2.pdf</td>\n",
       "      <td>https://github.com/ofirpress/PartialShuffle</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11226 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paper_url    arxiv_id  \\\n",
       "0      https://paperswithcode.com/paper/neural-conver...  1909.03759   \n",
       "1      https://paperswithcode.com/paper/neurocore-gui...  1903.04671   \n",
       "2      https://paperswithcode.com/paper/contextual-re...  1902.03455   \n",
       "3             https://paperswithcode.com/paper/190510752  1905.10752   \n",
       "4      https://paperswithcode.com/paper/are-we-consis...  1904.11783   \n",
       "...                                                  ...         ...   \n",
       "11221  https://paperswithcode.com/paper/fixup-initial...  1901.09321   \n",
       "11222  https://paperswithcode.com/paper/fixup-initial...  1901.09321   \n",
       "11223  https://paperswithcode.com/paper/harmonic-netw...  1905.00135   \n",
       "11224  https://paperswithcode.com/paper/a-discrete-ha...  1909.04849   \n",
       "11225  https://paperswithcode.com/paper/partially-shu...  1903.04167   \n",
       "\n",
       "                                                   title  \\\n",
       "0      Neural Conversational QA: Learning to Reason v...   \n",
       "1      Guiding High-Performance SAT Solvers with Unsa...   \n",
       "2                   Contextual Recurrent Neural Networks   \n",
       "3      TIGS: An Inference Algorithm for Text Infillin...   \n",
       "4      Are We Consistently Biased? Multidimensional A...   \n",
       "...                                                  ...   \n",
       "11221  Fixup Initialization: Residual Learning Withou...   \n",
       "11222  Fixup Initialization: Residual Learning Withou...   \n",
       "11223    Harmonic Networks with Limited Training Samples   \n",
       "11224  A Discrete Hard EM Approach for Weakly Supervi...   \n",
       "11225  Partially Shuffling the Training Data to Impro...   \n",
       "\n",
       "                                                abstract  \\\n",
       "0      In this paper we work on the recently introduc...   \n",
       "1      The NeuroSAT neural network architecture was r...   \n",
       "2      There is an implicit assumption that by unfold...   \n",
       "3      Text infilling is defined as a task for fillin...   \n",
       "4      Word embeddings have recently been shown to re...   \n",
       "...                                                  ...   \n",
       "11221  Normalization layers are a staple in state-of-...   \n",
       "11222  Normalization layers are a staple in state-of-...   \n",
       "11223  Convolutional neural networks (CNNs) are very ...   \n",
       "11224  Many question answering (QA) tasks only provid...   \n",
       "11225  Although SGD requires shuffling the training d...   \n",
       "\n",
       "                                  url_abs  \\\n",
       "0      https://arxiv.org/abs/1909.03759v1   \n",
       "1      https://arxiv.org/abs/1903.04671v7   \n",
       "2       http://arxiv.org/abs/1902.03455v1   \n",
       "3      https://arxiv.org/abs/1905.10752v1   \n",
       "4       http://arxiv.org/abs/1904.11783v2   \n",
       "...                                   ...   \n",
       "11221   http://arxiv.org/abs/1901.09321v2   \n",
       "11222   http://arxiv.org/abs/1901.09321v2   \n",
       "11223   http://arxiv.org/abs/1905.00135v1   \n",
       "11224  https://arxiv.org/abs/1909.04849v1   \n",
       "11225   http://arxiv.org/abs/1903.04167v2   \n",
       "\n",
       "                                      url_pdf      proceeding  \\\n",
       "0      https://arxiv.org/pdf/1909.03759v1.pdf            None   \n",
       "1      https://arxiv.org/pdf/1903.04671v7.pdf            None   \n",
       "2       http://arxiv.org/pdf/1902.03455v1.pdf            None   \n",
       "3      https://arxiv.org/pdf/1905.10752v1.pdf      ACL 2019 7   \n",
       "4       http://arxiv.org/pdf/1904.11783v2.pdf  SEMEVAL 2019 6   \n",
       "...                                       ...             ...   \n",
       "11221   http://arxiv.org/pdf/1901.09321v2.pdf     ICLR 2019 5   \n",
       "11222   http://arxiv.org/pdf/1901.09321v2.pdf     ICLR 2019 5   \n",
       "11223   http://arxiv.org/pdf/1905.00135v1.pdf            None   \n",
       "11224  https://arxiv.org/pdf/1909.04849v1.pdf  IJCNLP 2019 11   \n",
       "11225   http://arxiv.org/pdf/1903.04167v2.pdf    arXiv 2019 3   \n",
       "\n",
       "                                                 authors  \\\n",
       "0      [Abhishek Sharma, Danish Contractor, Harshit K...   \n",
       "1                       [Daniel Selsam, Nikolaj Bjørner]   \n",
       "2                               [Sam Wenke, Jim Fleming]   \n",
       "3      [Dayiheng Liu, Jie Fu, Pengfei Liu, Jiancheng Lv]   \n",
       "4                          [Anne Lauscher, Goran Glavaš]   \n",
       "...                                                  ...   \n",
       "11221         [Hongyi Zhang, Yann N. Dauphin, Tengyu Ma]   \n",
       "11222         [Hongyi Zhang, Yann N. Dauphin, Tengyu Ma]   \n",
       "11223  [Matej Ulicny, Vladimir A. Krylov, Rozenn Dahyot]   \n",
       "11224  [Sewon Min, Danqi Chen, Hannaneh Hajishirzi, L...   \n",
       "11225                                       [Ofir Press]   \n",
       "\n",
       "                                             tasks       date date_string  \\\n",
       "0                                               [] 2019-09-09  2019-09-09   \n",
       "1                                               [] 2019-03-12  2019-03-12   \n",
       "2                                               [] 2019-02-09  2019-02-09   \n",
       "3                [Text Generation, Text Infilling] 2019-05-26  2019-05-26   \n",
       "4        [Cross-Lingual Transfer, Word Embeddings] 2019-04-26  2019-04-26   \n",
       "...                                            ...        ...         ...   \n",
       "11221  [Image Classification, Machine Translation] 2019-01-27  2019-01-27   \n",
       "11222  [Image Classification, Machine Translation] 2019-01-27  2019-01-27   \n",
       "11223                       [Image Classification] 2019-04-30  2019-04-30   \n",
       "11224                         [Question Answering] 2019-09-11  2019-09-11   \n",
       "11225      [Language Modelling, Sentence Ordering] 2019-03-11  2019-03-11   \n",
       "\n",
       "                                             paper_title paper_arxiv_id  \\\n",
       "0      Neural Conversational QA: Learning to Reason v...     1909.03759   \n",
       "1      Guiding High-Performance SAT Solvers with Unsa...     1903.04671   \n",
       "2                   Contextual Recurrent Neural Networks     1902.03455   \n",
       "3      TIGS: An Inference Algorithm for Text Infillin...     1905.10752   \n",
       "4      Are We Consistently Biased? Multidimensional A...     1904.11783   \n",
       "...                                                  ...            ...   \n",
       "11221  Fixup Initialization: Residual Learning Withou...     1901.09321   \n",
       "11222  Fixup Initialization: Residual Learning Withou...     1901.09321   \n",
       "11223    Harmonic Networks with Limited Training Samples     1905.00135   \n",
       "11224  A Discrete Hard EM Approach for Weakly Supervi...     1909.04849   \n",
       "11225  Partially Shuffling the Training Data to Impro...     1903.04167   \n",
       "\n",
       "                            paper_url_abs  \\\n",
       "0      https://arxiv.org/abs/1909.03759v1   \n",
       "1      https://arxiv.org/abs/1903.04671v7   \n",
       "2       http://arxiv.org/abs/1902.03455v1   \n",
       "3      https://arxiv.org/abs/1905.10752v1   \n",
       "4       http://arxiv.org/abs/1904.11783v2   \n",
       "...                                   ...   \n",
       "11221   http://arxiv.org/abs/1901.09321v2   \n",
       "11222   http://arxiv.org/abs/1901.09321v2   \n",
       "11223   http://arxiv.org/abs/1905.00135v1   \n",
       "11224  https://arxiv.org/abs/1909.04849v1   \n",
       "11225   http://arxiv.org/abs/1903.04167v2   \n",
       "\n",
       "                                paper_url_pdf  \\\n",
       "0      https://arxiv.org/pdf/1909.03759v1.pdf   \n",
       "1      https://arxiv.org/pdf/1903.04671v7.pdf   \n",
       "2       http://arxiv.org/pdf/1902.03455v1.pdf   \n",
       "3      https://arxiv.org/pdf/1905.10752v1.pdf   \n",
       "4       http://arxiv.org/pdf/1904.11783v2.pdf   \n",
       "...                                       ...   \n",
       "11221   http://arxiv.org/pdf/1901.09321v2.pdf   \n",
       "11222   http://arxiv.org/pdf/1901.09321v2.pdf   \n",
       "11223   http://arxiv.org/pdf/1905.00135v1.pdf   \n",
       "11224  https://arxiv.org/pdf/1909.04849v1.pdf   \n",
       "11225   http://arxiv.org/pdf/1903.04167v2.pdf   \n",
       "\n",
       "                                                repo_url  mentioned_in_paper  \\\n",
       "0                         https://github.com/IBM/UrcaNet               False   \n",
       "1            https://github.com/dselsam/neurocore-public                True   \n",
       "2            https://github.com/fomorians/contextual_rnn                True   \n",
       "3      https://github.com/dayihengliu/Text-Infilling-...               False   \n",
       "4                        https://github.com/umanlp/XWEAT                True   \n",
       "...                                                  ...                 ...   \n",
       "11221     https://github.com/AngusG/bn-advex-zhang-fixup               False   \n",
       "11222  https://github.com/Abhimanyu08/Fixup_Initializ...               False   \n",
       "11223  https://github.com/matej-ulicny/harmonic-networks               False   \n",
       "11224              https://github.com/shmsw25/qa-hard-em               False   \n",
       "11225        https://github.com/ofirpress/PartialShuffle                True   \n",
       "\n",
       "       mentioned_in_github framework  \n",
       "0                     True   pytorch  \n",
       "1                     True        tf  \n",
       "2                     True        tf  \n",
       "3                     True        tf  \n",
       "4                    False      none  \n",
       "...                    ...       ...  \n",
       "11221                 True   pytorch  \n",
       "11222                 True   pytorch  \n",
       "11223                 True   pytorch  \n",
       "11224                 True   pytorch  \n",
       "11225                 True   pytorch  \n",
       "\n",
       "[11226 rows x 19 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df.merge(paperswithcode_df, on='paper_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 140 ms, sys: 5.2 ms, total: 145 ms\n",
      "Wall time: 145 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Semantic Segmentation      1151\n",
       "Image Classification        952\n",
       "Machine Translation         893\n",
       "Transfer Learning           846\n",
       "Object Detection            831\n",
       "Language Modelling          726\n",
       "Decision Making             695\n",
       "Time Series                 687\n",
       "Representation Learning     660\n",
       "Question Answering          646\n",
       "Word Embeddings             573\n",
       "Data Augmentation           525\n",
       "Domain Adaptation           498\n",
       "Speech Recognition          438\n",
       "Recommendation Systems      430\n",
       "adversarial training        408\n",
       "Sentiment Analysis          394\n",
       "Pose Estimation             383\n",
       "Denoising                   350\n",
       "Multi-Task Learning         342\n",
       "Name: tasks, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "papers_df.explode('tasks')['tasks'].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://github.com/jkkummerfeld/berkeley-parser-analyser'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paperswithcode_df.iloc[4]['repo_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "owner = 'jkkummerfeld'\n",
    "repo_name = 'berkeley-parser-analyser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"sha\":\"e35934cbc1679c77e17e6e135c54cd653df3ac21\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/e35934cbc1679c77e17e6e135c54cd653df3ac21\",\"tree\":[{\"path\":\"LICENSE.txt\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"3731b589d240aba930a64c0a949bd7639f8e9e3b\",\"size\":760,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/3731b589d240aba930a64c0a949bd7639f8e9e3b\"},{\"path\":\"LICENSE_notes.txt\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"0eefd8fb790c8d362a8da4eab9411f2817163cb0\",\"size\":307,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/0eefd8fb790c8d362a8da4eab9411f2817163cb0\"},{\"path\":\"README.md\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"958a5a258877fe91bf97734e0c375961d02c106c\",\"size\":5676,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/958a5a258877fe91bf97734e0c375961d02c106c\"},{\"path\":\"_config.yml\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"5061c961378c0368e3aa289e21eb1d0f73804631\",\"size\":191,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/5061c961378c0368e3aa289e21eb1d0f73804631\"},{\"path\":\"archival_versions\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"981954ea219f7714070eb203af47d7d396589fef\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/981954ea219f7714070eb203af47d7d396589fef\"},{\"path\":\"archival_versions/acl2013\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"778c3826345fbdcf29e9eaabee5e5f1dcd57329d\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/778c3826345fbdcf29e9eaabee5e5f1dcd57329d\"},{\"path\":\"archival_versions/acl2013/error_set.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"841b18977f6c8d80d7b369ab2e4f01f09a970607\",\"size\":935,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/841b18977f6c8d80d7b369ab2e4f01f09a970607\"},{\"path\":\"archival_versions/acl2013/head_finder.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"ee62e482288fe4676a3ba24b04baddd275599bcc\",\"size\":10715,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/ee62e482288fe4676a3ba24b04baddd275599bcc\"},{\"path\":\"archival_versions/acl2013/init.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"eb578eb078ec8a62e00e71b5122f75c39cd969d1\",\"size\":969,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/eb578eb078ec8a62e00e71b5122f75c39cd969d1\"},{\"path\":\"archival_versions/acl2013/nlp_eval.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"4d9bb918c24503d6da39fba8c561599e4fba21b5\",\"size\":2174,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/4d9bb918c24503d6da39fba8c561599e4fba21b5\"},{\"path\":\"archival_versions/acl2013/ptb.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"4e5d94ea2be16ced9ba76bdfec3f7252589d4da8\",\"size\":22301,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/4e5d94ea2be16ced9ba76bdfec3f7252589d4da8\"},{\"path\":\"archival_versions/acl2013/render_tree.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"43e94f1b8391e36c9c7ab6cf628c63fd5cf3fda5\",\"size\":10352,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/43e94f1b8391e36c9c7ab6cf628c63fd5cf3fda5\"},{\"path\":\"archival_versions/acl2013/transform_search.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"13e216b076dd1a083dfa2756e563dc078c92b83f\",\"size\":37649,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/13e216b076dd1a083dfa2756e563dc078c92b83f\"},{\"path\":\"archival_versions/emnlp2012\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"dfd94381135ceff056329fcbc9f66069ca01f687\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/dfd94381135ceff056329fcbc9f66069ca01f687\"},{\"path\":\"archival_versions/emnlp2012/bracket_errors.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"17d42b4ed3886596c9d67435d3a50bcf345c55b9\",\"size\":7793,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/17d42b4ed3886596c9d67435d3a50bcf345c55b9\"},{\"path\":\"archival_versions/emnlp2012/classify.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"222a3d11bb61ad59a951279c7a54d8adeec4101a\",\"size\":6402,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/222a3d11bb61ad59a951279c7a54d8adeec4101a\"},{\"path\":\"archival_versions/emnlp2012/error_group.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"337b92ff617fa1fea6413a19be40a0d653fc7ffa\",\"size\":9593,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/337b92ff617fa1fea6413a19be40a0d653fc7ffa\"},{\"path\":\"archival_versions/emnlp2012/error_tree.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"df630f356632d62279d0eb7b6d6d4e153a66e5f4\",\"size\":11073,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/df630f356632d62279d0eb7b6d6d4e153a66e5f4\"},{\"path\":\"archival_versions/emnlp2012/ptb.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"6ce7deea8c41fd81345d7a3bf5a3cb9bd3c15893\",\"size\":7403,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/6ce7deea8c41fd81345d7a3bf5a3cb9bd3c15893\"},{\"path\":\"archival_versions/emnlp2012/repair_tree.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"ebc21157bc18a0864735c532a08ef949d3bddba8\",\"size\":11760,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/ebc21157bc18a0864735c532a08ef949d3bddba8\"},{\"path\":\"archival_versions/emnlp2012/s_attachment.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"2783f7d1b06eaab8848f5fe6c1c33c50243d7c6e\",\"size\":34634,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/2783f7d1b06eaab8848f5fe6c1c33c50243d7c6e\"},{\"path\":\"archival_versions/emnlp2012/s_single_word.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"b1e8798dc4b6d823ab0f88ff3d6af9e29824ef32\",\"size\":2114,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/b1e8798dc4b6d823ab0f88ff3d6af9e29824ef32\"},{\"path\":\"archival_versions/emnlp2012/s_unary.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"59aab043416f5f5643a59378023242e5a17c9b67\",\"size\":4602,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/59aab043416f5f5643a59378023242e5a17c9b67\"},{\"path\":\"archival_versions/emnlp2012/util.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"19582da5967213b8a22fe9f67fab6ade273c0d37\",\"size\":1799,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/19582da5967213b8a22fe9f67fab6ade273c0d37\"},{\"path\":\"berkeley_parse_analyser\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"4b16bbbdbcd8345a88fddb51114c4909061216fd\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/4b16bbbdbcd8345a88fddb51114c4909061216fd\"},{\"path\":\"berkeley_parse_analyser/__init__.py\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"e69de29bb2d1d6434b8b29ae775ad8c2e48c5391\",\"size\":0,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/e69de29bb2d1d6434b8b29ae775ad8c2e48c5391\"},{\"path\":\"berkeley_parse_analyser/classify_chinese.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"193752292c0a4d8661d6c15c6b9a51d7a3d25637\",\"size\":11667,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/193752292c0a4d8661d6c15c6b9a51d7a3d25637\"},{\"path\":\"berkeley_parse_analyser/classify_english.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"f640e316d24a883990a1b8a92fb700df6ba25dca\",\"size\":5063,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/f640e316d24a883990a1b8a92fb700df6ba25dca\"},{\"path\":\"berkeley_parse_analyser/nlp_util\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"240fbce0b72c032a35961ef7cc1c077586d5698d\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/240fbce0b72c032a35961ef7cc1c077586d5698d\"},{\"path\":\"berkeley_parse_analyser/nlp_util/__init__.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"fdb8de639b6aac9e937885d2d428cf3d72fb5b5d\",\"size\":51,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/fdb8de639b6aac9e937885d2d428cf3d72fb5b5d\"},{\"path\":\"berkeley_parse_analyser/nlp_util/head_finder.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"fdd5cba98b9a41f5cfd3348a5ff33d4e6ac4b55d\",\"size\":12402,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/fdd5cba98b9a41f5cfd3348a5ff33d4e6ac4b55d\"},{\"path\":\"berkeley_parse_analyser/nlp_util/init.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"01ace6aecfc761db04d38c10e8f87c25b7b88780\",\"size\":1244,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/01ace6aecfc761db04d38c10e8f87c25b7b88780\"},{\"path\":\"berkeley_parse_analyser/nlp_util/nlp_eval.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"4a397daf39b880e9cb72de3793f3a5d1732effc3\",\"size\":1066,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/4a397daf39b880e9cb72de3793f3a5d1732effc3\"},{\"path\":\"berkeley_parse_analyser/nlp_util/parse_errors.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"eb9b331945d4821f34abec10672c4b4b8435f1ed\",\"size\":4600,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/eb9b331945d4821f34abec10672c4b4b8435f1ed\"},{\"path\":\"berkeley_parse_analyser/nlp_util/pstree.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"a733ceca50341835d61d2aa9358e91d04b5a7a86\",\"size\":12753,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/a733ceca50341835d61d2aa9358e91d04b5a7a86\"},{\"path\":\"berkeley_parse_analyser/nlp_util/render_tree.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"50f152838ac3417d5a92d36fa75c455ecf905f5e\",\"size\":12588,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/50f152838ac3417d5a92d36fa75c455ecf905f5e\"},{\"path\":\"berkeley_parse_analyser/nlp_util/tree_transform.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"2b39c3426e6f10f1a05f79c51b12890a3dc9eead\",\"size\":6060,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/2b39c3426e6f10f1a05f79c51b12890a3dc9eead\"},{\"path\":\"berkeley_parse_analyser/nlp_util/treebanks.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"f8ff7985fa40c0f44040eeb95f89afbff900829b\",\"size\":16993,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/f8ff7985fa40c0f44040eeb95f89afbff900829b\"},{\"path\":\"berkeley_parse_analyser/print_coloured_errors.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"8c34539e22cc5835d736d7f4b5ffa1c7501a3377\",\"size\":4970,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/8c34539e22cc5835d736d7f4b5ffa1c7501a3377\"},{\"path\":\"berkeley_parse_analyser/reprint_trees.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"7522fdef32c37788478d6704e28ec760e9dad1ee\",\"size\":3756,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/7522fdef32c37788478d6704e28ec760e9dad1ee\"},{\"path\":\"berkeley_parse_analyser/transform_search.py\",\"mode\":\"100755\",\"type\":\"blob\",\"sha\":\"3756e1933398ebcd6babac939575c35dc2c68d51\",\"size\":15034,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/3756e1933398ebcd6babac939575c35dc2c68d51\"},{\"path\":\"example-terminal.png\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"dd1894b21018cd280cf3aababad5d7d1657cb144\",\"size\":754745,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/dd1894b21018cd280cf3aababad5d7d1657cb144\"},{\"path\":\"sample_data\",\"mode\":\"040000\",\"type\":\"tree\",\"sha\":\"79474af573bdd02f49ee314cb97dfb7ee5529091\",\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/trees/79474af573bdd02f49ee314cb97dfb7ee5529091\"},{\"path\":\"sample_data/berkeley.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"c3b5dbc27d432ac445f6e4fb6ebef9af918eb4f4\",\"size\":3756,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/c3b5dbc27d432ac445f6e4fb6ebef9af918eb4f4\"},{\"path\":\"sample_data/bikel.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"0c9a002a1fc17b59f243acf44e89afb615d3517a\",\"size\":3712,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/0c9a002a1fc17b59f243acf44e89afb615d3517a\"},{\"path\":\"sample_data/bubs.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"d01efbdcefec49d2099a0bd89b41d555e42b4d5c\",\"size\":3755,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/d01efbdcefec49d2099a0bd89b41d555e42b4d5c\"},{\"path\":\"sample_data/charniak_basic.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"a8e599d773e7c0c02229b9c4559590947cc9245a\",\"size\":3747,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/a8e599d773e7c0c02229b9c4559590947cc9245a\"},{\"path\":\"sample_data/charniak_reranking.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"da7b113b161919f2df16fe1a07558244ef1c3a7b\",\"size\":3731,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/da7b113b161919f2df16fe1a07558244ef1c3a7b\"},{\"path\":\"sample_data/charniak_selftrained_basic.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"b365410978c35c20a10080f3b91d854a85c74a99\",\"size\":3733,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/b365410978c35c20a10080f3b91d854a85c74a99\"},{\"path\":\"sample_data/charniak_selftrained_reranking.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"aa99120a9f0836a5cc8a7b4a6bd00f4c809d9bc3\",\"size\":3746,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/aa99120a9f0836a5cc8a7b4a6bd00f4c809d9bc3\"},{\"path\":\"sample_data/collins.1.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"3a6a3ec066ef2146b87e9bcb3cdec0346f3c72c8\",\"size\":3713,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/3a6a3ec066ef2146b87e9bcb3cdec0346f3c72c8\"},{\"path\":\"sample_data/collins.2.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"d628273e7dc7b57175cf97c95a3939fb56ff8e98\",\"size\":3720,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/d628273e7dc7b57175cf97c95a3939fb56ff8e98\"},{\"path\":\"sample_data/collins.3.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"999f893e33deea4c761dae6d6806c0f3bad6b410\",\"size\":3725,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/999f893e33deea4c761dae6d6806c0f3bad6b410\"},{\"path\":\"sample_data/henderson.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"4920ae7f860138b61a04f24032b5948dba4a3ceb\",\"size\":3720,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/4920ae7f860138b61a04f24032b5948dba4a3ceb\"},{\"path\":\"sample_data/stanford.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"b7e96743ecdd41734735ed4345a7f4b63ffbc2fc\",\"size\":3739,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/b7e96743ecdd41734735ed4345a7f4b63ffbc2fc\"},{\"path\":\"sample_data/stanford_factored.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"38733560348dd9fb737ceab4a4b115d2d1da82be\",\"size\":3758,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/38733560348dd9fb737ceab4a4b115d2d1da82be\"},{\"path\":\"sample_data/wsj01.mrg\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"592c35518b87b8491db3ec82b5019042ff63b588\",\"size\":4411,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/592c35518b87b8491db3ec82b5019042ff63b588\"},{\"path\":\"sample_data/wsj01.tok\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"b54a49b23f0be8ddc0157884198608fbdfd889bb\",\"size\":1355,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/b54a49b23f0be8ddc0157884198608fbdfd889bb\"},{\"path\":\"setup.py\",\"mode\":\"100644\",\"type\":\"blob\",\"sha\":\"0acaccd82bb6cc8f27f95795e9f9f18ab2fae6d4\",\"size\":392,\"url\":\"https://api.github.com/repos/jkkummerfeld/berkeley-parser-analyser/git/blobs/0acaccd82bb6cc8f27f95795e9f9f18ab2fae6d4\"}],\"truncated\":false}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_crawling._get_tree(owner, repo_name).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 550 ms, sys: 16.3 ms, total: 567 ms\n",
      "Wall time: 11.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>owner</th>\n",
       "      <th>repo_name</th>\n",
       "      <th>file_path</th>\n",
       "      <th>content</th>\n",
       "      <th>sha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/error_set.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nclass Error_Set:\\n\\td...</td>\n",
       "      <td>841b18977f6c8d80d7b369ab2e4f01f09a970607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/head_finder.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport pt...</td>\n",
       "      <td>ee62e482288fe4676a3ba24b04baddd275599bcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/init.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\n'''A collection of us...</td>\n",
       "      <td>eb578eb078ec8a62e00e71b5122f75c39cd969d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/nlp_eval.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\ndef get_errors(self, ...</td>\n",
       "      <td>4d9bb918c24503d6da39fba8c561599e4fba21b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/ptb.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nfrom coll...</td>\n",
       "      <td>4e5d94ea2be16ced9ba76bdfec3f7252589d4da8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/render_tree.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport ptb\\n\\ndef tex...</td>\n",
       "      <td>43e94f1b8391e36c9c7ab6cf628c63fd5cf3fda5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/acl2013/transform_search.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>13e216b076dd1a083dfa2756e563dc078c92b83f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/bracket_errors.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport er...</td>\n",
       "      <td>17d42b4ed3886596c9d67435d3a50bcf345c55b9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/classify.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport pt...</td>\n",
       "      <td>222a3d11bb61ad59a951279c7a54d8adeec4101a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/error_group.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\n\\n#######...</td>\n",
       "      <td>337b92ff617fa1fea6413a19be40a0d653fc7ffa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/error_tree.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport pt...</td>\n",
       "      <td>df630f356632d62279d0eb7b6d6d4e153a66e5f4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/ptb.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\n\\nword_to...</td>\n",
       "      <td>6ce7deea8c41fd81345d7a3bf5a3cb9bd3c15893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/repair_tree.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport er...</td>\n",
       "      <td>ebc21157bc18a0864735c532a08ef949d3bddba8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/s_attachment.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport pt...</td>\n",
       "      <td>2783f7d1b06eaab8848f5fe6c1c33c50243d7c6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/s_single_word.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport re...</td>\n",
       "      <td>b1e8798dc4b6d823ab0f88ff3d6af9e29824ef32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/s_unary.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\nimport pt...</td>\n",
       "      <td>59aab043416f5f5643a59378023242e5a17c9b67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>archival_versions/emnlp2012/util.py</td>\n",
       "      <td>#!/usr/bin/env python\\n\\nimport sys\\n\\ndef cut...</td>\n",
       "      <td>19582da5967213b8a22fe9f67fab6ade273c0d37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/__init__.py</td>\n",
       "      <td></td>\n",
       "      <td>e69de29bb2d1d6434b8b29ae775ad8c2e48c5391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/classify_chinese.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>193752292c0a4d8661d6c15c6b9a51d7a3d25637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/classify_english.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>f640e316d24a883990a1b8a92fb700df6ba25dca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/__init__.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n# vim: set ts=2 sw=2 ...</td>\n",
       "      <td>fdb8de639b6aac9e937885d2d428cf3d72fb5b5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/head_finder.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>fdd5cba98b9a41f5cfd3348a5ff33d4e6ac4b55d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/init.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>01ace6aecfc761db04d38c10e8f87c25b7b88780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/nlp_eval.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>4a397daf39b880e9cb72de3793f3a5d1732effc3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/parse_errors.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>eb9b331945d4821f34abec10672c4b4b8435f1ed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/pstree.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>a733ceca50341835d61d2aa9358e91d04b5a7a86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/render_tree.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>50f152838ac3417d5a92d36fa75c455ecf905f5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/tree_transfor...</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>2b39c3426e6f10f1a05f79c51b12890a3dc9eead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/nlp_util/treebanks.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>f8ff7985fa40c0f44040eeb95f89afbff900829b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/print_coloured_errors.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>8c34539e22cc5835d736d7f4b5ffa1c7501a3377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/reprint_trees.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>7522fdef32c37788478d6704e28ec760e9dad1ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>berkeley_parse_analyser/transform_search.py</td>\n",
       "      <td>#!/usr/bin/env python\\n# -*- coding: utf-8 -*-...</td>\n",
       "      <td>3756e1933398ebcd6babac939575c35dc2c68d51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>jkkummerfeld</td>\n",
       "      <td>berkeley-parser-analyser</td>\n",
       "      <td>setup.py</td>\n",
       "      <td>from setuptools import setup\\n\\nsetup(name='be...</td>\n",
       "      <td>0acaccd82bb6cc8f27f95795e9f9f18ab2fae6d4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           owner                 repo_name  \\\n",
       "0   jkkummerfeld  berkeley-parser-analyser   \n",
       "1   jkkummerfeld  berkeley-parser-analyser   \n",
       "2   jkkummerfeld  berkeley-parser-analyser   \n",
       "3   jkkummerfeld  berkeley-parser-analyser   \n",
       "4   jkkummerfeld  berkeley-parser-analyser   \n",
       "5   jkkummerfeld  berkeley-parser-analyser   \n",
       "6   jkkummerfeld  berkeley-parser-analyser   \n",
       "7   jkkummerfeld  berkeley-parser-analyser   \n",
       "8   jkkummerfeld  berkeley-parser-analyser   \n",
       "9   jkkummerfeld  berkeley-parser-analyser   \n",
       "10  jkkummerfeld  berkeley-parser-analyser   \n",
       "11  jkkummerfeld  berkeley-parser-analyser   \n",
       "12  jkkummerfeld  berkeley-parser-analyser   \n",
       "13  jkkummerfeld  berkeley-parser-analyser   \n",
       "14  jkkummerfeld  berkeley-parser-analyser   \n",
       "15  jkkummerfeld  berkeley-parser-analyser   \n",
       "16  jkkummerfeld  berkeley-parser-analyser   \n",
       "17  jkkummerfeld  berkeley-parser-analyser   \n",
       "18  jkkummerfeld  berkeley-parser-analyser   \n",
       "19  jkkummerfeld  berkeley-parser-analyser   \n",
       "20  jkkummerfeld  berkeley-parser-analyser   \n",
       "21  jkkummerfeld  berkeley-parser-analyser   \n",
       "22  jkkummerfeld  berkeley-parser-analyser   \n",
       "23  jkkummerfeld  berkeley-parser-analyser   \n",
       "24  jkkummerfeld  berkeley-parser-analyser   \n",
       "25  jkkummerfeld  berkeley-parser-analyser   \n",
       "26  jkkummerfeld  berkeley-parser-analyser   \n",
       "27  jkkummerfeld  berkeley-parser-analyser   \n",
       "28  jkkummerfeld  berkeley-parser-analyser   \n",
       "29  jkkummerfeld  berkeley-parser-analyser   \n",
       "30  jkkummerfeld  berkeley-parser-analyser   \n",
       "31  jkkummerfeld  berkeley-parser-analyser   \n",
       "32  jkkummerfeld  berkeley-parser-analyser   \n",
       "\n",
       "                                            file_path  \\\n",
       "0              archival_versions/acl2013/error_set.py   \n",
       "1            archival_versions/acl2013/head_finder.py   \n",
       "2                   archival_versions/acl2013/init.py   \n",
       "3               archival_versions/acl2013/nlp_eval.py   \n",
       "4                    archival_versions/acl2013/ptb.py   \n",
       "5            archival_versions/acl2013/render_tree.py   \n",
       "6       archival_versions/acl2013/transform_search.py   \n",
       "7       archival_versions/emnlp2012/bracket_errors.py   \n",
       "8             archival_versions/emnlp2012/classify.py   \n",
       "9          archival_versions/emnlp2012/error_group.py   \n",
       "10          archival_versions/emnlp2012/error_tree.py   \n",
       "11                 archival_versions/emnlp2012/ptb.py   \n",
       "12         archival_versions/emnlp2012/repair_tree.py   \n",
       "13        archival_versions/emnlp2012/s_attachment.py   \n",
       "14       archival_versions/emnlp2012/s_single_word.py   \n",
       "15             archival_versions/emnlp2012/s_unary.py   \n",
       "16                archival_versions/emnlp2012/util.py   \n",
       "17                berkeley_parse_analyser/__init__.py   \n",
       "18        berkeley_parse_analyser/classify_chinese.py   \n",
       "19        berkeley_parse_analyser/classify_english.py   \n",
       "20       berkeley_parse_analyser/nlp_util/__init__.py   \n",
       "21    berkeley_parse_analyser/nlp_util/head_finder.py   \n",
       "22           berkeley_parse_analyser/nlp_util/init.py   \n",
       "23       berkeley_parse_analyser/nlp_util/nlp_eval.py   \n",
       "24   berkeley_parse_analyser/nlp_util/parse_errors.py   \n",
       "25         berkeley_parse_analyser/nlp_util/pstree.py   \n",
       "26    berkeley_parse_analyser/nlp_util/render_tree.py   \n",
       "27  berkeley_parse_analyser/nlp_util/tree_transfor...   \n",
       "28      berkeley_parse_analyser/nlp_util/treebanks.py   \n",
       "29   berkeley_parse_analyser/print_coloured_errors.py   \n",
       "30           berkeley_parse_analyser/reprint_trees.py   \n",
       "31        berkeley_parse_analyser/transform_search.py   \n",
       "32                                           setup.py   \n",
       "\n",
       "                                              content  \\\n",
       "0   #!/usr/bin/env python\\n\\nclass Error_Set:\\n\\td...   \n",
       "1   #!/usr/bin/env python\\n\\nimport sys\\nimport pt...   \n",
       "2   #!/usr/bin/env python\\n\\n'''A collection of us...   \n",
       "3   #!/usr/bin/env python\\n\\ndef get_errors(self, ...   \n",
       "4   #!/usr/bin/env python\\n\\nimport sys\\nfrom coll...   \n",
       "5   #!/usr/bin/env python\\n\\nimport ptb\\n\\ndef tex...   \n",
       "6   #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "7   #!/usr/bin/env python\\n\\nimport sys\\nimport er...   \n",
       "8   #!/usr/bin/env python\\n\\nimport sys\\nimport pt...   \n",
       "9   #!/usr/bin/env python\\n\\nimport sys\\n\\n#######...   \n",
       "10  #!/usr/bin/env python\\n\\nimport sys\\nimport pt...   \n",
       "11  #!/usr/bin/env python\\n\\nimport sys\\n\\nword_to...   \n",
       "12  #!/usr/bin/env python\\n\\nimport sys\\nimport er...   \n",
       "13  #!/usr/bin/env python\\n\\nimport sys\\nimport pt...   \n",
       "14  #!/usr/bin/env python\\n\\nimport sys\\nimport re...   \n",
       "15  #!/usr/bin/env python\\n\\nimport sys\\nimport pt...   \n",
       "16  #!/usr/bin/env python\\n\\nimport sys\\n\\ndef cut...   \n",
       "17                                                      \n",
       "18  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "19  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "20  # -*- coding: utf-8 -*-\\n# vim: set ts=2 sw=2 ...   \n",
       "21  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "22  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "23  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "24  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "25  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "26  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "27  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "28  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "29  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "30  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "31  #!/usr/bin/env python\\n# -*- coding: utf-8 -*-...   \n",
       "32  from setuptools import setup\\n\\nsetup(name='be...   \n",
       "\n",
       "                                         sha  \n",
       "0   841b18977f6c8d80d7b369ab2e4f01f09a970607  \n",
       "1   ee62e482288fe4676a3ba24b04baddd275599bcc  \n",
       "2   eb578eb078ec8a62e00e71b5122f75c39cd969d1  \n",
       "3   4d9bb918c24503d6da39fba8c561599e4fba21b5  \n",
       "4   4e5d94ea2be16ced9ba76bdfec3f7252589d4da8  \n",
       "5   43e94f1b8391e36c9c7ab6cf628c63fd5cf3fda5  \n",
       "6   13e216b076dd1a083dfa2756e563dc078c92b83f  \n",
       "7   17d42b4ed3886596c9d67435d3a50bcf345c55b9  \n",
       "8   222a3d11bb61ad59a951279c7a54d8adeec4101a  \n",
       "9   337b92ff617fa1fea6413a19be40a0d653fc7ffa  \n",
       "10  df630f356632d62279d0eb7b6d6d4e153a66e5f4  \n",
       "11  6ce7deea8c41fd81345d7a3bf5a3cb9bd3c15893  \n",
       "12  ebc21157bc18a0864735c532a08ef949d3bddba8  \n",
       "13  2783f7d1b06eaab8848f5fe6c1c33c50243d7c6e  \n",
       "14  b1e8798dc4b6d823ab0f88ff3d6af9e29824ef32  \n",
       "15  59aab043416f5f5643a59378023242e5a17c9b67  \n",
       "16  19582da5967213b8a22fe9f67fab6ade273c0d37  \n",
       "17  e69de29bb2d1d6434b8b29ae775ad8c2e48c5391  \n",
       "18  193752292c0a4d8661d6c15c6b9a51d7a3d25637  \n",
       "19  f640e316d24a883990a1b8a92fb700df6ba25dca  \n",
       "20  fdb8de639b6aac9e937885d2d428cf3d72fb5b5d  \n",
       "21  fdd5cba98b9a41f5cfd3348a5ff33d4e6ac4b55d  \n",
       "22  01ace6aecfc761db04d38c10e8f87c25b7b88780  \n",
       "23  4a397daf39b880e9cb72de3793f3a5d1732effc3  \n",
       "24  eb9b331945d4821f34abec10672c4b4b8435f1ed  \n",
       "25  a733ceca50341835d61d2aa9358e91d04b5a7a86  \n",
       "26  50f152838ac3417d5a92d36fa75c455ecf905f5e  \n",
       "27  2b39c3426e6f10f1a05f79c51b12890a3dc9eead  \n",
       "28  f8ff7985fa40c0f44040eeb95f89afbff900829b  \n",
       "29  8c34539e22cc5835d736d7f4b5ffa1c7501a3377  \n",
       "30  7522fdef32c37788478d6704e28ec760e9dad1ee  \n",
       "31  3756e1933398ebcd6babac939575c35dc2c68d51  \n",
       "32  0acaccd82bb6cc8f27f95795e9f9f18ab2fae6d4  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "github_crawling.get_python_files_df(owner, repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r",
      "\r\n",
      "\u001b[1mdate\u001b[0m: Mon, 14 Sep 2020 08:54:54 GMT\r",
      "\r\n",
      "\u001b[1mcontent-type\u001b[0m: application/json; charset=utf-8\r",
      "\r\n",
      "\u001b[1mserver\u001b[0m: GitHub.com\r",
      "\r\n",
      "\u001b[1mstatus\u001b[0m: 200 OK\r",
      "\r\n",
      "\u001b[1mcache-control\u001b[0m: public, max-age=60, s-maxage=60\r",
      "\r\n",
      "\u001b[1mvary\u001b[0m: Accept, Accept-Encoding, Accept, X-Requested-With, Accept-Encoding\r",
      "\r\n",
      "\u001b[1metag\u001b[0m: W/\"ec0c7d7cfcf8dcb3f97a490edd7c7d08\"\r",
      "\r\n",
      "\u001b[1mlast-modified\u001b[0m: Sun, 23 Aug 2020 14:28:27 GMT\r",
      "\r\n",
      "\u001b[1mx-github-media-type\u001b[0m: github.v3; format=json\r",
      "\r\n",
      "\u001b[1maccess-control-expose-headers\u001b[0m: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, Deprecation, Sunset\r",
      "\r\n",
      "\u001b[1maccess-control-allow-origin\u001b[0m: *\r",
      "\r\n",
      "\u001b[1mstrict-transport-security\u001b[0m: max-age=31536000; includeSubdomains; preload\r",
      "\r\n",
      "\u001b[1mx-frame-options\u001b[0m: deny\r",
      "\r\n",
      "\u001b[1mx-content-type-options\u001b[0m: nosniff\r",
      "\r\n",
      "\u001b[1mx-xss-protection\u001b[0m: 1; mode=block\r",
      "\r\n",
      "\u001b[1mreferrer-policy\u001b[0m: origin-when-cross-origin, strict-origin-when-cross-origin\r",
      "\r\n",
      "\u001b[1mcontent-security-policy\u001b[0m: default-src 'none'\r",
      "\r\n",
      "\u001b[1mX-Ratelimit-Limit\u001b[0m: 60\r",
      "\r\n",
      "\u001b[1mX-Ratelimit-Remaining\u001b[0m: 59\r",
      "\r\n",
      "\u001b[1mX-Ratelimit-Reset\u001b[0m: 1600077298\r",
      "\r\n",
      "\u001b[1mX-Ratelimit-Used\u001b[0m: 1\r",
      "\r\n",
      "\u001b[1mAccept-Ranges\u001b[0m: bytes\r",
      "\r\n",
      "\u001b[1mContent-Length\u001b[0m: 1320\r",
      "\r\n",
      "\u001b[1mX-GitHub-Request-Id\u001b[0m: 8D1A:CDE3:7F380F2:97E4A2F:5F5F2FE2\r",
      "\r\n",
      "\r",
      "\r\n",
      "{\r\n",
      "  \"login\": \"octocat\",\r\n",
      "  \"id\": 583231,\r\n",
      "  \"node_id\": \"MDQ6VXNlcjU4MzIzMQ==\",\r\n",
      "  \"avatar_url\": \"https://avatars3.githubusercontent.com/u/583231?v=4\",\r\n",
      "  \"gravatar_id\": \"\",\r\n",
      "  \"url\": \"https://api.github.com/users/octocat\",\r\n",
      "  \"html_url\": \"https://github.com/octocat\",\r\n",
      "  \"followers_url\": \"https://api.github.com/users/octocat/followers\",\r\n",
      "  \"following_url\": \"https://api.github.com/users/octocat/following{/other_user}\",\r\n",
      "  \"gists_url\": \"https://api.github.com/users/octocat/gists{/gist_id}\",\r\n",
      "  \"starred_url\": \"https://api.github.com/users/octocat/starred{/owner}{/repo}\",\r\n",
      "  \"subscriptions_url\": \"https://api.github.com/users/octocat/subscriptions\",\r\n",
      "  \"organizations_url\": \"https://api.github.com/users/octocat/orgs\",\r\n",
      "  \"repos_url\": \"https://api.github.com/users/octocat/repos\",\r\n",
      "  \"events_url\": \"https://api.github.com/users/octocat/events{/privacy}\",\r\n",
      "  \"received_events_url\": \"https://api.github.com/users/octocat/received_events\",\r\n",
      "  \"type\": \"User\",\r\n",
      "  \"site_admin\": false,\r\n",
      "  \"name\": \"The Octocat\",\r\n",
      "  \"company\": \"@github\",\r\n",
      "  \"blog\": \"https://github.blog\",\r\n",
      "  \"location\": \"San Francisco\",\r\n",
      "  \"email\": null,\r\n",
      "  \"hireable\": null,\r\n",
      "  \"bio\": null,\r\n",
      "  \"twitter_username\": null,\r\n",
      "  \"public_repos\": 8,\r\n",
      "  \"public_gists\": 8,\r\n",
      "  \"followers\": 3227,\r\n",
      "  \"following\": 9,\r\n",
      "  \"created_at\": \"2011-01-25T18:44:36Z\",\r\n",
      "  \"updated_at\": \"2020-08-23T14:28:27Z\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl -i https://api.github.com/users/octocat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = open('data/token.txt', 'r').read()[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"resources\": {\r\n",
      "    \"core\": {\r\n",
      "      \"limit\": 5000,\r\n",
      "      \"used\": 2,\r\n",
      "      \"remaining\": 4998,\r\n",
      "      \"reset\": 1600077286\r\n",
      "    },\r\n",
      "    \"search\": {\r\n",
      "      \"limit\": 30,\r\n",
      "      \"used\": 0,\r\n",
      "      \"remaining\": 30,\r\n",
      "      \"reset\": 1600073759\r\n",
      "    },\r\n",
      "    \"graphql\": {\r\n",
      "      \"limit\": 5000,\r\n",
      "      \"used\": 0,\r\n",
      "      \"remaining\": 5000,\r\n",
      "      \"reset\": 1600077299\r\n",
      "    },\r\n",
      "    \"integration_manifest\": {\r\n",
      "      \"limit\": 5000,\r\n",
      "      \"used\": 0,\r\n",
      "      \"remaining\": 5000,\r\n",
      "      \"reset\": 1600077299\r\n",
      "    },\r\n",
      "    \"source_import\": {\r\n",
      "      \"limit\": 100,\r\n",
      "      \"used\": 0,\r\n",
      "      \"remaining\": 100,\r\n",
      "      \"reset\": 1600073759\r\n",
      "    },\r\n",
      "    \"code_scanning_upload\": {\r\n",
      "      \"limit\": 500,\r\n",
      "      \"used\": 0,\r\n",
      "      \"remaining\": 500,\r\n",
      "      \"reset\": 1600077299\r\n",
      "    }\r\n",
      "  },\r\n",
      "  \"rate\": {\r\n",
      "    \"limit\": 5000,\r\n",
      "    \"used\": 2,\r\n",
      "    \"remaining\": 4998,\r\n",
      "    \"reset\": 1600077286\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!curl -H \"Authorization: token $token\" https://api.github.com/rate_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sample_repo_urls = paperswithcode_df['repo_url'].sample(sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_repo_urls.to_csv('sample_repo_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7604              https://github.com/DRCKnowledgeTeam/DRCD\n",
       "9883          https://github.com/BoiseState/bookdata-tools\n",
       "32857    https://github.com/niuxiaozhang/mxnet-retinafa...\n",
       "27239                 https://github.com/corticph/MSTmodel\n",
       "9839     https://github.com/paidamoyo/survival_cluster_...\n",
       "                               ...                        \n",
       "24245                 https://github.com/zhuxinqimac/B-CNN\n",
       "13781       https://github.com/chaofanwang123/DA-RNN_Model\n",
       "9527                      https://github.com/lucfra/FAR-HO\n",
       "526              https://github.com/MatthiasNickles/DelSAT\n",
       "25619    https://github.com/nvshrao/Bidirectional-Trans...\n",
       "Name: repo_url, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_repo_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlutil import parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_python_df_from_repo_url(repo_url):\n",
    "    owner, repo_name = repo_url.split('/')[-2:]\n",
    "    return github_crawling.get_python_files_df(owner, repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/DRCKnowledgeTeam/DRCD\n"
     ]
    }
   ],
   "source": [
    "print(sample_repo_urls.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed for Tony607/mmdetection 'tree'\n",
      "failed for akikaaa/transformers 'tree'\n",
      "failed for M-Usman10/DenseSqueeze-RCNN 'tree'\n",
      "failed for master/vae_lightning.py 'tree'\n",
      "failed for modeling/layers 'tree'\n",
      "failed for itcabb/facebookresearch-ReAgent 'tree'\n",
      "failed for research/adv_imagenet_models 'tree'\n",
      "failed for cjohnchen/sai 'tree'\n",
      "failed for gjy3035/C-3-Framework 'tree'\n",
      "CPU times: user 1.72 s, sys: 569 ms, total: 2.29 s\n",
      "Wall time: 39min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dfs = list(parallel.mapp(get_python_df_from_repo_url, sample_repo_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 65.9 ms, sys: 517 µs, total: 66.5 ms\n",
      "Wall time: 64.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_file_contents_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36534, 5)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_file_contents_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file_contents_df.to_csv('data/sample_python_files.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
