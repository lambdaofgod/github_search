\section{Document expansion}
\label{approach_document_expansion}
Dependency graphs have rich structure, but the most important fact is that they encode project's hierarchical structure. We found that LLMs were able to provide useful summaries only given short snippets extracted from toplevel nodes that usually correspond to file names. We will call the outputs of document expansion \textbf{repository signatures}.

Document expansion is the responsibility of the \textbf{librarian model} -- for each repository it generates potential queries given a short snippet. This approach was inspired by Generative Pseudo-Labeling \cite{gpl}. Intuitively we use few-shot prompting: the context contains $n=2$ repositories with their dependency signatures and tasks, and the target repository name with signature (thus the language model will generate the tasks). We omit prompting details here, they can be found in Appendix \ref{prompts}.

\begin{samepage}
\begin{lstlisting}[caption=Few-shot prompt format]
## repository
<CONTEXT REPOSITORY NAME>
## files
<CONTEXT DEPENDENCY RECORDS>
## tags
<TASKS>
...
## repository
<REPOSITORY NAME>
## files
<DEPENDENCY RECORDS>
## tags
\end{lstlisting}
\end{samepage}

\begin{samepage}
\begin{lstlisting}[caption=Input repository]
<OMITTED CONTEXT>
## repository
AWehenkel/UMNN

files:
UCIExperiments.py, models/__init__.py, models/vae_lib/utils/plotting.py, lib/dataloader.py, lib/visualize_flow.py, lib/utils.py, lib/toy_data.py, lib/__init__.py, lib/transform.py, datasets/hepmass.py

defined classes:
Data, VAE, AmortizedCNFVAE, MADE, UMNNMAFFlow, ConditionnalMADE, UMNNMAF, GatedConvTranspose2d, GatedConv2d, EmbeddingNetwork

defined functions:
load_data, log_normal_diag, log_normal_standard, calculate_likelihood, calculate_loss, plot_reconstructions, log_bernoulli, logsumexp, integrate, load_data_normalised

imported modules:
numpy, torch, os.path.join, torch.nn, __future__.print_function, math, os, datasets, matplotlib.pyplot, matplotlib

## repository
Ahsanr312/Object-Detection-and-Tracking-using-YOLOv3-and-DeepSort

files:
yolov3_tf2/dataset.py, yolov3_tf2/models.py, yolov3_tf2/batch_norm.py, tools/generate_detections.py, tools/freeze_model.py, object_tracker.py, deep_sort/tracker.py, load_weights.py, yolov3_tf2/utils.py, deep_sort/iou_matching.py

defined classes:
BatchNormalization, Track, Detection, Tracker, ImageEncoder, TrackState, KalmanFilter, NearestNeighborDistanceMetric

defined functions:
DarknetConv, load_darknet_weights, YoloV3, YoloV3Tiny, transform_images, broadcast_iou, convert_boxes, create_inner_block, freeze_all, _cosine_distance

imported modules:
numpy, tensorflow, tensorflow.keras.Model, cv2, __future__.absolute_import, linear_assignment, scipy.linalg, absl.flags.FLAGS, kalman_filter, absl.logging

## repository
rajammanabrolu/Q-BERT

files:
qbert/goexplore_py/goexplore_main.py, qbert/goexplore_py/goexplore.py, qbert/goexplore_py/__init__.py, qbert/goexplore_py/basics.py, qbert/goexplore_py/randselectors.py, qbert/extraction/wsgi.py, qbert/extraction/utils_squad_evaluate.py, qbert/extraction/kg_extraction.py, qbert/extraction/run_squad.py, qbert/extraction/router.py

defined classes:
StateAction, AlbertQA, QBERTTrainer, QBERT, EVAL_OPTS, KVWriter, DirWeights, Weight, SquadExample, ProfileKV

defined functions:
log, normalize_answer, configure, find_best_thresh_v2, to_list, read_squad_example, convert_examples_to_features, convert_example_to_features, get_predictions, get_all_predictions

imported modules:
glob, router.app, collections.namedtuple, numpy, time, collections.defaultdict, os, collections.Counter, import_ai.*, random
\end{lstlisting}
\end{samepage}


\begin{samepage}
\begin{lstlisting}[caption=Generated text]

\end{lstlisting}
\end{samepage}
