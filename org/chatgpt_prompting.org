#+title: Chatgpt_prompting
#+PROPERTY: header-args

* Training data generation


* Initialize OpenAI API

#+BEGIN_SRC python :session chatgpt_prompting.org :results both drawer :exports both :tangle chatgpt_prompting.py
from dataclasses import dataclass, asdict
from mlutil import chatgpt_api
import numpy as np
import pandas as pd
#+END_SRC

#+RESULTS:
:results:
:end:
#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py
api_key_path = '~/Projects/org/openai_key.txt' # specify file path if OPENAI_API_KEY is not in env
chatgpt_client = chatgpt_api.ChatGPTClient(api_key_path)
"initialized api"
#+END_SRC

#+RESULTS:
:results:
initialized api
:end:


* Prepare GPT-2 tokenizer

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py
from transformers import AutoTokenizer, AutoModelForTokenClassification
from transformers import pipeline

tokenizer = AutoTokenizer.from_pretrained("gpt2")
tokenizer

def get_n_tokens(text):
    ids = tokenizer(text)["input_ids"]
    return len(ids)
#+END_SRC

#+RESULTS:
:results:
:end:

* Load data


#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py
import pandas as pd

train_nbow_df = pd.read_parquet("../output/nbow_data_train.parquet").drop(["count"], axis=1)
train_nbow_df.head()
#+END_SRC

#+RESULTS:
:results:
                       repo  ...                                 function_signature
0  000Justin000/torchdiffeq  ...      def test_adams_adjoint_against_dopri5(self...
1     008karan/SincNet_demo  ...  def read_conf_inp(cfg_file):\npass\nclass sinc...
2  00marco/pydnet-duplicate  ...  def mapFunction(value, min_orig, max_orig, min...
3            011235813/SEPT  ...  class DDQN(object):\npass\n    def run_actor_p...
4             011235813/cm3  ...      def create_local_critic_train_op(self):\np...

[5 rows x 10 columns]
:end:



train_nbow_df["dependencies"]
#+END_SRC

#+RESULTS:
:results:
0        torchdiffeq/_impl/misc.py torchdiffeq/_impl/rk...
1        speaker_id.py dnn_models.py TIMIT_preparation....
2        training_code/layers.py training_code/monodept...
3        alg/__init__.py hip-mdp-public/HiPMDP.py hip-m...
4        alg/alg_credit.py env/multiagent-particle-envs...
                               ...
33316    main.py core/model.py core/wing.py core/finetu...
33317    arch/Inpainting/GAN_Inpainting.py exp/mnist-co...
33318    simulated_database/evaluate_policy_dummy_seque...
33319    scripts/mingjie_create_in_hospital_mortality.p...
33320    nets/cifar_resnet.py utils/preprocessing.py ne...
Name: dependencies, Length: 33321, dtype: object
:end:

* Prompting

** Preparing records - using first n dependencies basically means using file names
#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py

def preprocess_dep(dep):
    return P(dep).name

def select_deps(deps, n_deps):
    return [preprocess_dep(dep) for dep in deps if not "__init__" in dep][:n_deps]

def get_repo_records_by_index(data_df, indices, fields=["repo", "dependencies", "tasks"], n_deps=10):
    records_df = data_df.iloc[indices].copy()
    raw_deps = records_df["dependencies"].str.split()
    records_df["dependencies"] = raw_deps.apply(lambda dep:  select_deps(dep, n_deps))
    return records_df[fields].to_dict(orient="records")

#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
get_repo_records_by_index(train_nbow_df, [0,1])[0].keys()
#+END_SRC

#+RESULTS:
:results:
dict_keys(['repo', 'dependencies', 'tasks'])
:end:

** Vanilla prompting

** Vanilla prompt preparation

#+BEGIN_SRC python :session chatgpt_prompting.org :tangle chatgpt_prompting.py
from typing import List
from pathlib import Path as P

base_prompt = """
repository {}
contains files {}
its tags are {}
"""

@dataclass
class PromptInfo:
    """
    information about sample repositories passed to prompt
    """
    repo_records: List[dict]
    predicted_repo_record: dict


    def get_single_prompt(self, record):
        repo = record["repo"]
        dependencies = ", ".join(record["dependencies"])
        tasks  = record["tasks"]
        return base_prompt.format(repo, dependencies, tasks)

    def get_prompt(self):
        prefix_prompt = "\n".join(
            self.get_single_prompt(record)
            for record in self.repo_records
        )
        other_repo_name, other_repo_filenames, other_repo_tasks = self.predicted_repo_record.values()
        other_repo_filenames = [P(fname).name for fname in other_repo_filenames]
        return (prefix_prompt +
            f"\nrepository {other_repo_name}\n" +
            f"contains files: {', '.join(other_repo_filenames)}\n" +
            "tags: "
        )

    @classmethod
    def from_df(cls, data_df, pos_indices, pred_index, n_deps=10):
        return PromptInfo(
            get_repo_records_by_index(data_df, pos_indices, n_deps=n_deps),
            get_repo_records_by_index(data_df, [pred_index], n_deps=n_deps)[0],
        )

repo_records = get_repo_records_by_index(train_nbow_df, [5,10])
other_repo_record = get_repo_records_by_index(train_nbow_df, [1])[0]

prompt_info = PromptInfo(repo_records, other_repo_record)
prompt = prompt_info.get_prompt()
prompt
#+END_SRC

#+RESULTS:
#+begin_example

repository 011235813/hierarchical-marl
contains files alg_iql.py, env_wrapper.py, train_hsd_scripted.py, alg_qmix.py, train_multiprocess.py, replay_buffer.py, test_env_wrapper.py, networks.py, evaluate.py, alg_hsd_scripted.py
its tags are ['multi agent reinforcement learning', 'q learning', 'reinforcement learning']


repository 08173021/FCOS
contains files inference.py, retinanet.py, imports.py, roi_mask_predictors.py, test_detectors.py, registry.py, inference.py, detectors.py, roi_pool.py, backbone.py
its tags are ['object detection', 'pedestrian detection', 'semantic segmentation']

repository 008karan/SincNet_demo
contains files: speaker_id.py, dnn_models.py, TIMIT_preparation.py, similarity.py, inference.py, data_io.py, compute_d_vector.py, ReadList, str_to_bool, read_conf
tags:
#+end_example


#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
prompt_info.predicted_repo_record["tasks"]
#+END_SRC

#+RESULTS:
:results:
['speech denoising', 'denoising', 'speech enhancement', 'audio tagging']
:end:

*** Running experiment
#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py

def get_sample_prompt_info(data_df, n_labeled):
    sample_labeled_indices = np.random.randint(2)
    repo_records = get_repo_records_by_index(train_nbow_df, [100,101])
    other_repo_record = get_repo_records_by_index(train_nbow_df, [20])[0]

    prompt_info = promptinfo(repo_records, other_repo_record)
    return prompt_info
#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :exports both

from pathlib import Path
from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer

# from GPTQ_loader import load_quantized

text_webui_path = "/home/kuba/Projects/forks/text-generation-webui"

model_name = "llama-13b-hf"
model_path = Path(f"{text_webui_path}/models/{model_name}")
tokenizer = AutoTokenizer.from_pretrained(model_path)
llama = AutoModelForCausalLM.from_pretrained(
    model_path, device_map="auto", load_in_8bit=True
)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session chatgpt_prompting.org  :exports both
import sys

sys.executable

#+END_SRC

#+RESULTS:
: /home/kuba/miniconda3/envs/llama/bin/python

*** Get some repo pairs

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py

pos_idxs = list(zip(range(0, 1000, 10), range(1000, 2000, 10)))
pred_idxs = list(range(2000, 3000, 10))


#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
PromptInfo.from_df(train_nbow_df, list(pos_idxs[0]), pred_idxs[0]).get_prompt()
#+END_SRC

#+RESULTS:
:results:

repository: 000Justin000/torchdiffeq
files: ['torchdiffeq/_impl/misc.py', 'torchdiffeq/_impl/rk_common.py', 'torchdiffeq/_impl/fixed_adams.py', 'tests/api_tests.py', 'tests/gradient_tests.py', 'torchdiffeq/_impl/fixed_grid.py', 'torchdiffeq/_impl/interp.py', 'torchdiffeq/_impl/solvers.py', 'torchdiffeq/__init__.py', 'torchdiffeq/_impl/dopri5.py']
tags: ['multivariate time series forecasting', 'multivariate time series imputation', 'point processes', 'time series']

repository: Baichenjia/DCGAN-eager
files: ['create_gif.py', 'train.py', 'generator_loss', 'generate_and_save_images', 'discriminator_loss', 'train', 'Discriminator', 'Generator', 'train_step', 'sigmoid_cross_entropy_with_logits']
tags: ['image clustering', 'representation learning', 'conditional image generation']
repository: DeepMindv2/DeepDetection
files: ['Visualization.py', 'Jupyter_Notebooks/discovery.py', 'Models/Pretrained.py', 'Keras_Tuner.py', 'DataAug.py', 'configs.py', 'DenseNet.py', 'ResNet.py', 'VGG.py', 'Utils.py']
tags:
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both

#PromptInfo.from_df(train_nbow_df, pos_idxs[0], pred_idxs[0])
#+END_SRC

#+RESULTS:
:results:
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both :tangle chatgpt_prompting.py

prompt_infos = [
    PromptInfo.from_df(train_nbow_df, list(pos), i)
    for (pos, i) in zip(pos_idxs, pred_idxs)
]

true_tasks = [pinfo.predicted_repo_record["tasks"] for pinfo in prompt_infos]
true_tasks[0]
#+END_SRC

#+RESULTS:
:results:
['object categorization', 'data augmentation']
:end:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
prompt_infos[2]
#+END_SRC

#+RESULTS:
:results:
PromptInfo(repo_records=[{'repo': '0three/Speech-Denoise-With-Feature-Loss', 'dependencies': ['helper.py', 'senet_train.py', 'lossnet_train.py', 'model.py', 'data_import.py', 'data/extract.py', 'data/noise.py', 'dataset/seg.py', 'senet_infer.py', 'data/sox.py'], 'tasks': "['speech denoising', 'denoising', 'speech enhancement', 'audio tagging']"}, {'repo': 'BangLiu/ArticlePairMatching', 'dependencies': ['src/models/CCIG/util/ml_utils.py', 'src/models/CCIG/util/str_utils.py', 'src/models/CCIG/main.py', 'src/models/CCIG/util/file_utils.py', 'src/models/CCIG/data/girvan_newman.py', 'src/models/CCIG/util/exp_utils.py', 'src/models/CCIG/models/layers.py', 'src/models/CCIG/data/sentence_score.py', 'src/models/CCIG/util/visualize.py', 'src/models/CCIG/data/ccig.py'], 'tasks': "['question answering', 'text matching']"}], predicted_repo_record={'repo': 'Deepest-Project/WorldModels-A3C', 'dependencies': ['hparams.py', 'test.py', 'train-a3c.py', 'train-vae.py', 'replay.py', 'train-rnn.py', 'rollout.py', 'models/vision.py', 'rollout-a3c.py', 'models/memory.py'], 'tasks': "['car racing', 'reinforcement learning']"})
:end:

*** Run experiment

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
#impo rt tqdm

# predicted_tasks = [
#     chatgpt_client.get_chatgpt_response_from_text(pinfo.get_prompt())
#     for pinfo in tqdm.tqdm(prompt_infos)
# ]
#+END_SRC

#+RESULTS:
:results:
:end:


*** Vanilla experiment results

#+BEGIN_SRC python :session chatgpt_prompting.org  :results output :exports both
import ast

def get_sanitized_tasks(task_list_str):
    if type(task_list_str) is list:
        return " ; ".join(task_list_str)
    else:
        return " ; ".join(task_list_str.replace("[", "").replace("]", "").split(", "))

def get_pred_records(prompt_infos, true_tasks, predicted_tasks):
    return [
        {"repo": pinfo.predicted_repo_record["repo"], "true_tasks": get_sanitized_tasks(t), "predicted_tasks": get_sanitized_tasks(p_t)}
        for (pinfo, t, p_t) in zip(prompt_infos, true_tasks, predicted_tasks)
    ]

#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports botht
get_sanitized_tasks(true_tasks[0])
#+END_SRC

#+RESULTS:
:results:
'object categorization' | 'data augmentation'
:end:


#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
pred_records = get_pred_records(prompt_infos, true_tasks, predicted_tasks)
pd.DataFrame.from_records(pred_records).to_csv("chatgpt_file_tasks_results.csv", index=False)
pred_records[4]
#+END_SRC

#+RESULTS:
:results:
{'repo': 'DengPingFan/BBS-Net', 'true_tasks': "'object detection' ; 'rgb salient object detection' ; 'salient object detection' ; 'rgb d salient object detection'", 'predicted_tasks': "'image segmentation' ; 'boundary-based segmentation' ; 'deep learning' ; 'computer vision'"}
:end:

#+BEGIN_SRC latex
\begin{tabular}{llll}
\toprule
{} &                                             repo &                                         true\_tasks &                                    predicted\_tasks \\
\midrule
0  &                              AlexOlsen/DeepWeeds &  ['classification', 'robust classification', 'g... &  ['weed detection', 'agriculture', 'deep learni... \\
1  &            AlexanderBogatko/TensorFlow\_Keras\_GAN &  ['time series few shot learning with heterogen... &  ['generative adversarial networks', 'image syn... \\
2  &                  AlexeiKaplenko/FaceShifter\_mine &               ['face generation', 'face swapping'] &  ['face swapping', 'face recognition', 'face de... \\
3  &                        AlextheEngineer/Ego2Hands &                              ['domain adaptation'] &  ['computer vision', 'deep learning', 'hand pos... \\
4  &                            AliLotfi92/InfoMaxVAE &                        ['representation learning'] &  ['variational autoencoder', 'information maxim... \\
5  &                                 Alibaba-MIIL/ASL &  ['multi label classification', 'image classifi... &  'image recognition', 'classification', 'data a... \\
6  &                   Alina-Samokhina/guided\_cost\_RL &                            ['feature engineering'] &  ['reinforcement learning', 'cost-guided reinfo... \\
7  &                         AllenPeng0209/SaccadeNet &  ['object detection', 'instance segmentation', ... &            ['object detection', 'computer vision'] \\
8  &                    AlphaJia/keras\_unet\_plus\_plus &  ['medical image segmentation', 'thermal image ... &  'image segmentation', 'deep learning', 'comput... \\
9  &                                 AmIAttribute/AmI &     ['face recognition', 'general classification'] &  ['ambient intelligence', 'machine learning', '... \\
10 &                                Amgao/RLS-RTMDNet &  ['continual learning', 'meta learning', 'visua... &             ['tracking', 'reinforcement learning'] \\
11 &                            AmirsSaad/UWPhysDepth &  ['depth estimation', 'monocular depth estimati... &  'computer vision', 'depth estimation', 'AI in ... \\
12 &                            Amrou7/Sin-GAN-master &  ['image manipulation', 'image generation', 'im... &  \textbackslash n\textbackslash n['image synthesis', 'machine learning', 'c... \\
13 &                    Anaststam/Adversarial-Attacks &                           ['image classification'] &  ['adversarial attacks', 'convolutional neural ... \\
14 &                      Andreas-Pfeuffer/LSTM-ICNet &  ['video segmentation', 'self driving cars', 'v... &  ['LSTM', 'ICNet', 'image segmentation', 'video... \\
15 &                              Andrew-booler/W-Net &  ['unsupervised image segmentation', 'semantic ... &    ['image segmentation', 'semantic segmentation'] \\
16 &            Andrey885/Machine\_translation\_PyTorch &  ['machine translation', 'text summarization', ... &  ['machine translation', 'deep learning', 'PyTo... \\
17 &                                 Andyeyeye/MTANet &  ['multi task learning', 'emotion classification'] &         ['multi-task learning', 'neural networks'] \\
18 &                    AniSkywalker/SarcasmDetection &                              ['sarcasm detection'] &  ['sarcasm detection', 'NLP', 'text classificat... \\
19 &                              AnjanDutta/sem-pcyc &  ['sketch based image retrieval', 'feature sele... &  ['semantic parsing', 'cyclic generation', 'ima... \\
20 &                             AnnaAraslanova/FBNet &  ['image classification', 'neural architecture ... &  ['neural architecture search', 'supernet', 'mo... \\
21 &                            Anou9531/Bayesian-CNN &  ['variational inference', 'reinforcement learn... &  ['Bayesian CNN', 'machine learning', 'neural n... \\
22 &                   AntixK/Spectral-Stein-Gradient &                          ['variational inference'] &  ['gradient estimation', 'spectral stein gradie... \\
23 &                 AntreasAntoniou/MatchingNetworks &  ['language modelling', 'metric learning', 'few... &         ['one shot learning', 'matching networks'] \\
24 &  AnzorGozalishvili/sentence\_transformers\_serving &  ['transfer learning', 'semantic textual simila... &  ['sentence embeddings', 'natural language proc... \\
\bottomrule
\end{tabular}
#+END_SRC

#+RESULTS:
#+begin_export latex
\begin{tabular}{llll}
\toprule
{} &                                             repo &                                         true\_tasks &                                    predicted\_tasks \\
\midrule
0  &                              AlexOlsen/DeepWeeds &  ['classification', 'robust classification', 'g... &  ['weed detection', 'agriculture', 'deep learni... \\
1  &            AlexanderBogatko/TensorFlow\_Keras\_GAN &  ['time series few shot learning with heterogen... &  ['generative adversarial networks', 'image syn... \\
2  &                  AlexeiKaplenko/FaceShifter\_mine &               ['face generation', 'face swapping'] &  ['face swapping', 'face recognition', 'face de... \\
3  &                        AlextheEngineer/Ego2Hands &                              ['domain adaptation'] &  ['computer vision', 'deep learning', 'hand pos... \\
4  &                            AliLotfi92/InfoMaxVAE &                        ['representation learning'] &  ['variational autoencoder', 'information maxim... \\
5  &                                 Alibaba-MIIL/ASL &  ['multi label classification', 'image classifi... &  'image recognition', 'classification', 'data a... \\
6  &                   Alina-Samokhina/guided\_cost\_RL &                            ['feature engineering'] &  ['reinforcement learning', 'cost-guided reinfo... \\
7  &                         AllenPeng0209/SaccadeNet &  ['object detection', 'instance segmentation', ... &            ['object detection', 'computer vision'] \\
8  &                    AlphaJia/keras\_unet\_plus\_plus &  ['medical image segmentation', 'thermal image ... &  'image segmentation', 'deep learning', 'comput... \\
9  &                                 AmIAttribute/AmI &     ['face recognition', 'general classification'] &  ['ambient intelligence', 'machine learning', '... \\
10 &                                Amgao/RLS-RTMDNet &  ['continual learning', 'meta learning', 'visua... &             ['tracking', 'reinforcement learning'] \\
11 &                            AmirsSaad/UWPhysDepth &  ['depth estimation', 'monocular depth estimati... &  'computer vision', 'depth estimation', 'AI in ... \\
12 &                            Amrou7/Sin-GAN-master &  ['image manipulation', 'image generation', 'im... &  \textbackslash n\textbackslash n['image synthesis', 'machine learning', 'c... \\
13 &                    Anaststam/Adversarial-Attacks &                           ['image classification'] &  ['adversarial attacks', 'convolutional neural ... \\
14 &                      Andreas-Pfeuffer/LSTM-ICNet &  ['video segmentation', 'self driving cars', 'v... &  ['LSTM', 'ICNet', 'image segmentation', 'video... \\
15 &                              Andrew-booler/W-Net &  ['unsupervised image segmentation', 'semantic ... &    ['image segmentation', 'semantic segmentation'] \\
16 &            Andrey885/Machine\_translation\_PyTorch &  ['machine translation', 'text summarization', ... &  ['machine translation', 'deep learning', 'PyTo... \\
17 &                                 Andyeyeye/MTANet &  ['multi task learning', 'emotion classification'] &         ['multi-task learning', 'neural networks'] \\
18 &                    AniSkywalker/SarcasmDetection &                              ['sarcasm detection'] &  ['sarcasm detection', 'NLP', 'text classificat... \\
19 &                              AnjanDutta/sem-pcyc &  ['sketch based image retrieval', 'feature sele... &  ['semantic parsing', 'cyclic generation', 'ima... \\
20 &                             AnnaAraslanova/FBNet &  ['image classification', 'neural architecture ... &  ['neural architecture search', 'supernet', 'mo... \\
21 &                            Anou9531/Bayesian-CNN &  ['variational inference', 'reinforcement learn... &  ['Bayesian CNN', 'machine learning', 'neural n... \\
22 &                   AntixK/Spectral-Stein-Gradient &                          ['variational inference'] &  ['gradient estimation', 'spectral stein gradie... \\
23 &                 AntreasAntoniou/MatchingNetworks &  ['language modelling', 'metric learning', 'few... &         ['one shot learning', 'matching networks'] \\
24 &  AnzorGozalishvili/sentence\_transformers\_serving &  ['transfer learning', 'semantic textual simila... &  ['sentence embeddings', 'natural language proc... \\
\bottomrule
\end{tabular}
#+end_export
***

*** Vanilla cost

#+BEGIN_SRC python :session chatgpt_prompting.org  :results both drawer :exports both
prompts_with_responses = [pinfo.get_prompt() + response for (pinfo, response) in zip(prompt_infos, predicted_tasks)]

billed_token_lengths = pd.Series([get_n_tokens(t) for t in prompts_with_responses])
billed_token_lengths.describe()
#+END_SRC

#+RESULTS:
:results:
:end:


**** Vanilla cost estimate

#+BEGIN_SRC python :session chatgpt_prompting.org  :results output :exports both
billed_prompt_tokens = billed_token_lengths.mean()
estimated_billed_tokens = billed_token_lengths.mean() * train_nbow_df.shape[0]
token_cost = 2e-6

print("estimaded billed tokens per prompt:", billed_prompt_tokens)
print("train dataset prompts:", train_nbow_df.shape[0])
print("estimated cost:", round(estimated_billed_tokens * token_cost, 2), "USD")
#+END_SRC

#+RESULTS:
