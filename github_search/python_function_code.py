# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Code_Prototypes.ipynb (unless otherwise specified).

__all__ = [
    "select_class_names",
    "select_function_names",
    "select_lines",
    "select_functions",
    "tokenize_snakecase",
    "tokenize_camelcase",
    "tokenize_python",
    "get_file_variable_token_set",
    "maybe_get_file_variable_token_string",
    "PYTHON_KEYWORDS",
    "get_functions",
    "get_function_tuples",
    "get_function_data_df",
]

import ast
import multiprocessing.pool

import astunparse

# Cell
import pandas as pd


# Cell


def select_class_names(lines):
    return [
        line.strip()
        for line in lines
        if line.lstrip().startswith("class ") and line.rstrip().endswith(":")
    ]


def select_function_names(lines):
    return [line.strip() for line in lines if line.lstrip().startswith("def ")]


def select_lines(text, use_function_names=True, use_class_names=False):
    lines = text.split("\n")
    selected_lines = []
    if use_class_names:
        selected_lines = selected_lines + select_class_names(lines)
    if use_function_names:
        selected_lines = selected_lines + select_function_names(lines)

    return selected_lines


def select_functions(file_contents):
    return [
        elem
        for elem in ast.parse(file_contents).body
        if elem.__class__ is ast.FunctionDef
    ]


# Cell
import io
import keyword
import re
import tokenize

PYTHON_KEYWORDS = set(keyword.kwlist)


def tokenize_snakecase(identifier):
    return identifier.split("_")


def tokenize_camelcase(identifier):
    matches = re.finditer(
        ".+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)", identifier
    )
    return [m.group(0) for m in matches]


def tokenize_python(identifier, lowercase=False):
    if "_" in identifier:
        tokens = tokenize_snakecase(identifier)
    else:
        tokens = tokenize_camelcase(identifier)
    return [t.lower() for t in tokens]


def get_file_variable_token_set(file_text, min_token_length=2, lowercase=True):
    token_infos = list(tokenize.generate_tokens(io.StringIO(file_text).readline))
    raw_tokens = [t.string for t in token_infos if t.type == 1]
    all_tokens = (tokenize_python(t, lowercase) for t in raw_tokens)
    all_tokens = [
        token
        for tokens in all_tokens
        for token in tokens
        if len(token) > min_token_length and not token in PYTHON_KEYWORDS
    ]
    return set(all_tokens)


def maybe_get_file_variable_token_string(file_text, min_token_length=2):
    try:
        tokens = get_file_variable_token_set(file_text)
    except:
        return None
    return " ".join(tokens)


# Cell


def get_functions(code_ast, depth):
    if depth == 0:
        return None
    if type(code_ast) is ast.FunctionDef:
        return (code_ast.name, astunparse.unparse(code_ast).strip())
    elif type(code_ast) is ast.ClassDef:
        return (code_ast.name, astunparse.unparse(code_ast).strip())
    elif hasattr(code_ast, "body"):
        maybe_functions = [get_functions(item, depth - 1) for item in code_ast.body]
        return [fn for fn in maybe_functions if not fn is None]
    else:
        return None


def get_function_tuples(code, max_depth):
    try:
        code_ast = ast.parse(code)
        return [
            fn_data
            for fn_data in get_functions(code_ast, max_depth)
            if type(fn_data) is tuple
        ]
    except (SyntaxError, multiprocessing.pool.MaybeEncodingError, RecursionError) as e:
        return []


# Cell
import pandas_parallel_apply
from github_search.python_code import signatures


def get_functions_from_file_row(row):
    return [
        (row["repo_name"], row["path"]) + tp
        for tp in get_function_tuples(row["content"], max_depth=4)
    ]


def get_function_data_df(files_df, max_depth=4, n_cores=4):
    file_info = pandas_parallel_apply.DataFrameParallel(
        files_df, n_cores=n_cores
    ).apply(get_functions_from_file_row, axis=1)
    return pd.DataFrame(
        list(file_info.explode().dropna().values),
        columns=["repo_name", "path", "function_name", "function_code"],
    )


def get_bytes(s):
    return bytes(s, "utf-8")


def get_function_signatures_df(
    files_df,
    n_cores=4,
    get_signatures: signatures.SignatureExtractor = signatures.get_signatures,
):
    def get_function_signatures_from_file_row(row):
        return [
            (row["repo_name"], row["path"])
            + (get_bytes(signatures.get_name_from_signature(sig)), get_bytes(sig))
            for sig in get_signatures(row["content"].split("\n"))
        ]

    file_info = pandas_parallel_apply.DataFrameParallel(
        files_df, n_cores=n_cores
    ).apply(get_function_signatures_from_file_row, axis=1)
    df = pd.DataFrame(
        list(file_info.explode().dropna().values),
        columns=["repo_name", "path", "function_name", "function_signature"],
    )
    for col in ["function_name", "function_signature"]:
        df[col] = df[col].apply(lambda s: s.decode("utf-8"))
    return df
