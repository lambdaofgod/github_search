# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Token_Exploration.ipynb (unless otherwise specified).

__all__ = ['store_word_vectors']

# Cell

import json
import pandas as pd
import tqdm
import numpy as np
import gensim

from github_search import parsing_imports, repository_descriptions, python_tokens
from sklearn import feature_extraction, decomposition

# Cell


def _word_vectors_to_word2vec_format_generator(vocabulary, word_vectors):
    for (word, vector) in zip(vocabulary, word_vectors):
        yield word + ' ' + ' '.join([str('{:.5f}'.format(f)) for f in vector])


def store_word_vectors(words, word_vectors, file_name):
    with open(file_name, 'w') as f:
        f.write(str(len(words)) + ' ' + str(word_vectors.shape[1]) + '\n')
        for line in _word_vectors_to_word2vec_format_generator(words, module_vectors):
            f.write(line + '\n')