# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Import Exploration.ipynb (unless otherwise specified).

__all__ = [
    "get_modules_string",
    "get_module_corpus",
    "prepare_module_corpus",
    "store_word_vectors",
]

# Cell

import ast
import json

import gensim
import numpy as np
import pandas as pd
import tqdm
from sklearn import decomposition, feature_extraction

from github_search import paperswithcode_tasks, parsing_imports, repository_descriptions

# Cell


def get_modules_string(modules):
    public_modules = [mod for mod in modules if not mod[0] == "_"]
    return " ".join(public_modules)


def get_module_corpus(files_df):
    module_lists = []
    repos = []

    for __, row in tqdm.tqdm(files_df.iterrows(), total=len(files_df)):
        try:
            maybe_imports = parsing_imports.get_modules(row["content"])
            module_lists.append(list(set(maybe_imports)))
            repos.append(row["repo_name"])
        except SyntaxError as e:
            print(row["repo_name"], e)
    df = pd.DataFrame({"repo": repos, "imports": module_lists})
    return df


def get_paperswithcode_with_imports_df(papers_with_repo_df, per_repo_imports):
    return papers_with_repo_df.merge(
        per_repo_imports, left_on="repo", right_index=True
    ).drop_duplicates("repo")


def prepare_paperswithcode_with_imports_df(product, upstream, python_files_path):
    python_files_df = pd.read_csv(python_files_path)  # )
    repo_names = python_files_df["repo_name"]
    paperswithcode_df, all_papers_df = paperswithcode_tasks.get_paperswithcode_dfs()
    papers_with_repo_df = paperswithcode_tasks.get_papers_with_repo_df(
        all_papers_df, paperswithcode_df, repo_names
    )
    papers_with_repo_df = paperswithcode_tasks.get_papers_with_biggest_tasks(
        papers_with_repo_df, 500
    )
    import_corpus_df = pd.read_csv(upstream["prepare_module_corpus"])
    import_corpus_df["imports"] = import_corpus_df["imports"].apply(ast.literal_eval)
    per_repo_imports = import_corpus_df.groupby("repo")["imports"].agg(sum).apply(set)
    paperswithcode_with_imports_df = get_paperswithcode_with_imports_df(
        papers_with_repo_df, per_repo_imports
    )
    paperswithcode_with_imports_df.to_csv(str(product))


# Cell


def prepare_module_corpus(python_files_csv_path, product):
    files_df = pd.read_csv(python_files_csv_path)
    get_module_corpus(files_df.dropna()).to_csv(str(product))


# Cell


# Cell


def _word_vectors_to_word2vec_format_generator(vocabulary, word_vectors):
    for (word, vector) in zip(vocabulary, word_vectors):
        yield word + " " + " ".join([str("{:.5f}".format(f)) for f in vector])


def store_word_vectors(words, word_vectors, file_name):
    with open(file_name, "w") as f:
        f.write(str(len(words)) + " " + str(word_vectors.shape[1]) + "\n")
        for line in _word_vectors_to_word2vec_format_generator(words, module_vectors):
            f.write(line + "\n")
