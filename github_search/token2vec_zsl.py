# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Matching_ZSL.ipynb (unless otherwise specified).

__all__ = ['import_corpus_df', 'python_files_df', 'repo_names', 'get_paperswithcode_with_imports_df',
           'prepare_paperswithcode_with_imports_df', 'RetrieverLearner']

# Cell
import os
import ast
import tqdm
import json
from operator import itemgetter

import pandas as pd
import numpy as np
from sklearn import feature_extraction, metrics, model_selection

import matplotlib.pyplot as plt
import gensim

from github_search import paperswithcode_tasks

import mlutil
from functools import partial

# Cell

# Cell


def get_paperswithcode_with_imports_df(papers_with_repo_df, per_repo_imports):
    return papers_with_repo_df.merge(
        per_repo_imports,
        left_on='repo',
        right_index=True
    ).drop_duplicates('repo')


def prepare_paperswithcode_with_imports_df(product, upstream):
    paperswithcode_df, all_papers_df = paperswithcode_tasks.get_paperswithcode_dfs()
    papers_with_repo_df = paperswithcode_tasks.get_papers_with_repo_df(all_papers_df, paperswithcode_df, repo_names)
    papers_with_repo_df = paperswithcode_tasks.get_papers_with_biggest_tasks(papers_with_repo_df, 500)
    paperswithcode_with_imports_df = get_paperswithcode_with_imports_df(papers_with_repo_df, per_repo_imports)
    paperswithcode_with_imports_df.to_csv(str(product))

# Cell
import attr
from scarce_learn import zero_shot
from mlutil.feature_extraction import embeddings


@attr.s
class RetrieverLearner:

    zs_learner: zero_shot.ZeroShotClassifier = attr.ib()
    input_embedder: embeddings.EmbeddingVectorizer = attr.ib()
    y_embedder: embeddings.EmbeddingVectorizer = attr.ib()

    @staticmethod
    def create(
        zs_learner: zero_shot.ZeroShotClassifier,
        input_embeddings: gensim.models.KeyedVectors,
        y_embeddings: gensim.models.KeyedVectors,
        input_embedding_method: embeddings.EmbeddingVectorizer,
        y_embedding_method: embeddings.EmbeddingVectorizer
    ):
        input_embedder = input_embedding_method(input_embeddings)
        y_embedder = y_embedding_method(y_embeddings)
        return RetrieverLearner(zs_learner, input_embedder, y_embedder)

    def get_target_embeddings(self, y):
        unique_y = pd.Series(y.unique())
        y_embeddings = self.y_embedder.transform(unique_y)
        return unique_y, y_embeddings

    def fit_learner(self, X, y):
        self.input_embedder.fit(X)
        input_embeddings = self.input_embedder.transform(X)
        self.y_embedder.fit(y)
        unique_y, y_embeddings = self.get_target_embeddings(y)
        input_y_idxs = y.apply(lambda t: unique_y[unique_y == t].index[0])
        self.zs_learner.fit(input_embeddings, input_y_idxs, y_embeddings)

    def predict_idxs(self, X, y_embeddings):
        input_embeddings = self.input_embedder.transform(X)
        return self.zs_learner.predict(input_embeddings, y_embeddings)

    def predict_topk(self, X, y_embeddings, target_names, k=5, similarity=metrics.pairwise.cosine_similarity):
        input_embeddings = self.input_embedder.transform(X)
        predictions = self.zs_learner.predict_raw(input_embeddings)
        target_similarities = similarity(predictions, y_embeddings)
        targets = [target_names[row[:k]] for row in (-target_similarities).argsort(axis=1)]
        return targets

    def evaluate(self, X, y, metric):
        unique_y, y_embeddings = self.get_target_embeddings(y)
        input_y_idxs = y.apply(lambda t: unique_y[unique_y == t].index[0])
        predicted_idxs = self.predict_idxs(X, y_embeddings)
        return metric(input_y_idxs, predicted_idxs)
