#+title: Pipeline_steps
#+PROPERTY: header-args :tangle tangle/pipeline_steps.py

Conda env github_search

* Running pipeline step by step

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link
import pandas as pd
from github_search.pipelines.steps import sample_data_step, expand_documents_step, evaluate_generated_texts_step 
from tgutil.configs import PipelineConfig, ConfigPaths, APIConfig, TextGenerationConfig, SamplingConfig, PromptConfig
import logging
import yaml
from pathlib import Path
from github_search.utils import load_config_yaml_key
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both
output_path = Path("../../output")
pipeline_output_path = output_path / "pipelines"
#+END_SRC

#+RESULTS:

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link
logging.basicConfig(level="INFO")

sampling = "micro"
generation_method = "api_rwkv"

cfg_path = "conf/text_generation/config.yaml"
generation_config = load_config_yaml_key(APIConfig, "conf/generation.yaml", generation_method)
sampling_config = load_config_yaml_key(SamplingConfig, "conf/sampling.yaml", sampling)
prompt_config = load_config_yaml_key(PromptConfig, "conf/prompts.yaml", "few_shot_markdown")
#cfg = PipelineConfig.load(cfg_path)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
model_type = generation_config.model_name
model_type
#+END_SRC

#+RESULTS:
: rwkv-4-raven-7b

** Sample
#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
prompt_infos = sample_data_step(prompt_config.dict(), sampling_config.dict())
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
type(prompt_infos[0])
#+END_SRC

#+RESULTS:
: <class 'tgutil.prompting.ContextPromptInfo'>

#+BEGIN_SRC python :session pipeline_steps.org  :exports both
len(prompt_infos)
#+END_SRC

#+RESULTS:
: 10

** Expand documents (generate texts)

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
generated_records, _ = expand_documents_step({**generation_config.dict(), "n_generations":2}, prompt_config.dict(), prompt_infos)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
generated_records.iloc[0]["generated_text"]
#+END_SRC

#+RESULTS:
| \n[Dataset]\n\n## repository\npydigeru/PyData-for-Dentistry\n## files\nbionic-data bonic-models bionic-config bionic-tools bionic-config-ui b |

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
generated_records.to_json(pipeline_output_path / f"{model_type}_generated_records_{sampling}.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:
: None


** Evaluate text generation

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
generated_records = pd.read_json(pipeline_output_path / f"{model_type}_generated_records_{sampling}.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:


#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
from operator import itemgetter

def process_generated_records(generated_records):
    return pd.DataFrame(
        repo=generated_records["prompt_info"].apply(itemgetter("name")),
        tasks=generated_records["generated_text"],
        true_tasks=generated_records["tasks"],
        generated_text=generated_records["generated_text"].apply(itemgetter(0)),
        prompt_info=generated_records["prompt_info"].apply(dict)
    )
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
evaluated_df = evaluate_generated_texts_step(
    process_generated_records(generated_records),
    "../../data/paperswithcode_with_tasks.csv"
)
#+END_SRC

#+RESULTS:
: /tmp/babel-bSJdAX/python-R7a7N5

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
evaluated_df.to_json(pipeline_output_path / f"{model_type}_evaluated_records_{sampling}.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:
: /tmp/babel-bSJdAX/python-TDytPr

*** Results
#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
evaluated_df.describe()
#+END_SRC

#+RESULTS:
: /tmp/babel-bSJdAX/python-HpqqX0

** Evaluate information retrieval

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
evaluated_df = pd.read_json(pipeline_output_path / f"{model_type}_evaluated_records.json", orient="records", lines=True)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
evaluated_df["reference_text"]
#+END_SRC

#+RESULTS:
#+begin_example
0            depth estimation, monocular depth estimation
1                      few shot learning, active learning
2       sentiment analysis, aspect based sentiment ana...
3       medical image segmentation, edge detection, se...
4                               visual question answering
                              ...
4296                        semantic parsing, time series
4297                                   mri reconstruction
4298                                 scene text detection
4299    optical character recognition, scene text reco...
4300                                          time series
Name: reference_text, Length: 4301, dtype: object
#+end_example

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
def replace_list_chars(text):
    return text.replace("[", "").replace("]", "").replace(",", "").replace("'", "")

def process_generated_text(text):
    return replace_list_chars(text.strip().split("\n")[0])
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
from ir_generation_metric_comparison_pipeline import make_ir_df

max_len = 100
ir_df = make_ir_df(pd.read_parquet(output_path / "nbow_data_test.parquet"), evaluated_df)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both
ir_df
#+END_SRC

#+RESULTS:
#+begin_example
                                        repo  ...                             truncated_dependencies
0     0bserver07/One-Hundred-Layers-Tiramisu  ...  helper.py model-tiramasu-103.py model-tiramasu...
1           101vinayak/Neural-Style-Transfer  ...  images2gif.py get_cKDTree writeGif NeuQuant Gi...
2        12kleingordon34/NLP_masters_project  ...  process_winogender_data.py process_occ_stats p...
3        131250208/TPlinker-joint-extraction  ...  setup.py tplinker/tplinker.py tplinker/config....
4                     15saurabh16/Multipoles  ...  COMET_fMRI.py CLIQUE_multipoles_algorithm.py q...
...                                      ...  ...                                                ...
4296                         zyf12389/GC-Net  ...  main.py read_sceneflow.py read_data.py gc_net....
4297                zyf12389/LayoutGAN-Alpha  ...  layoutgan.py model.py dataset.py Dataset Gener...
4298           zykls/performative-prediction  ...  experiments/neurips2020/data_prep.py experimen...
4299     zzwells/jdd2018-population-forecast  ...  data_process.py attention.py model.py features...
4300      zzzace2000/dropout-feature-ranking  ...  exp/DFRdatasets/models/ProblemType.py exp/DFRd...

[4301 rows x 18 columns]
#+end_example

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
processed_text = ir_df["generated_text"].apply(process_generated_text).iloc[0]
processed_text
#+END_SRC

#+RESULTS:
: unlabeled

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
from github_search.ir.evaluator import InformationRetrievalEvaluatorConfig, EmbedderPairConfig, InformationRetrievalColumnConfig
from github_search.ir import evaluator, models
import yaml


with open("conf/ir_config_nbow.yaml") as f:
    ir_config = InformationRetrievalEvaluatorConfig(**yaml.safe_load(f))
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :async
ir_evaluator = evaluator.InformationRetrievalEvaluator.setup_from_df(ir_df, ir_config)
ir_results = ir_evaluator.evaluate()
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both
def write_dataclass_with_dataframes(dc, write_dir):
    p = Path(write_dir).expanduser()
    p.mkdir(exist_ok=True, parents=True)
    for (k, v) in dict(dc).items():
        print(k)
        if type(v) is pd.DataFrame:
            out_path = str(p / k) + ".csv"
            print(out_path)
            v.to_csv(out_path)
#+END_SRC

#+RESULTS:

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :results output
write_dataclass_with_dataframes(ir_results, f"results/{model_type}_{sampling}")
#+END_SRC

#+RESULTS:
: per_query_metrics
: results/rwkv-4-raven-7b_micro/per_query_metrics.csv
: aggregate_metrics
: results/rwkv-4-raven-7b_micro/aggregate_metrics.csv

#+BEGIN_SRC python :session pipeline_steps.org  :exports both
evaluated_df.to_csv(f"results/{model_type}_{sampling}/generation_metrics")
#+END_SRC

#+RESULTS:
: None

#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link :results output
import pprint

pprint.pprint(ir_results)
#+END_SRC

#+RESULTS:
#+begin_example
InformationRetrievalMetricsResult(per_query_metrics=                                    hit@1  hit@3  hit@5  hit@10  ...  recall@10  MRR@10  ndcg@10  AveP@50
query                                                            ...
semantic segmentation                   0      0      1       1  ...      0.016    0.25    0.531    0.321
style transfer                          1      1      1       1  ...      0.047    1.00    1.000    0.951
word embeddings                         1      1      1       1  ...      0.049    1.00    0.936    0.367
relation extraction                     0      1      1       1  ...      0.027    0.50    0.249    0.047
time series                             1      1      1       1  ...      0.042    1.00    0.915    0.368
...                                   ...    ...    ...     ...  ...        ...     ...      ...      ...
robust speech recognition               0      0      0       0  ...      0.000    0.00    0.000    0.000
deformable object manipulation          0      0      0       0  ...      0.000    0.00    0.000    0.000
unsupervised semantic segmentation      0      0      0       0  ...      0.000    0.00    0.000    0.032
graph reconstruction                    0      0      0       0  ...      0.000    0.00    0.000    0.000
sentence compression                    0      0      0       0  ...      0.000    0.00    0.000    0.000

[306 rows x 15 columns], aggregate_metrics=         hit@1    hit@3    hit@5   hit@10  precisions@1  ...  recall@5  recall@10   MRR@10  ndcg@10  AveP@50
count  306.000  306.000  306.000  306.000       306.000  ...   306.000    306.000  306.000  306.000  306.000
mean     0.101    0.196    0.248    0.278         0.101  ...     0.028      0.038    0.159    0.085    0.036
std      0.302    0.398    0.433    0.449         0.302  ...     0.086      0.101    0.315    0.177    0.091
min      0.000    0.000    0.000    0.000         0.000  ...     0.000      0.000    0.000    0.000    0.000
25%      0.000    0.000    0.000    0.000         0.000  ...     0.000      0.000    0.000    0.000    0.000
50%      0.000    0.000    0.000    0.000         0.000  ...     0.000      0.000    0.000    0.000    0.000
75%      0.000    0.000    0.000    1.000         0.000  ...     0.000      0.023    0.156    0.085    0.024
max      1.000    1.000    1.000    1.000         1.000  ...     1.000      1.000    1.000    1.000    0.951

[8 rows x 15 columns])
#+end_example
**
**

** Comparing IR to text generation metrics
#+BEGIN_SRC python :session pipeline_steps.org  :exports both :comments link
(ir_df["generated_text"] + ir_df["dependencies"]).iloc[0]
#+END_SRC

#+RESULTS:
#+begin_example

unlabeled

## repository
pytext-nlp/spynner
#!/bin/sh -ex

cd "~/Downloads/spynner"
echo "Patching..."
git -c diff.mnhelper.py model-tiramasu-103.py model-tiramasu-67-func-api.py fc-densenet-model.py train-tiramisu.py model-dynamic.py model-tiramasu-56.py model-tiramasu-67.py camvid_data_loader.py load_data Tiramisu normalized one_hot_it Tiramisu Tiramisu Tiramisu Tiramisu Tiramisu step_decay one_hot_it len print append normalized range rollaxis zeros equalizeHist float32 zeros range pow floor
#+end_example


#+BEGIN_SRC python :session pipeline_steps.org  :exports both
pd.DataFrame(ir_results["cos_sim"])
#+END_SRC

#+RESULTS:
