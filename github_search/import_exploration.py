# AUTOGENERATED! DO NOT EDIT! File to edit: notebooks/Import Exploration.ipynb (unless otherwise specified).

__all__ = ['get_modules_string', 'get_module_corpus', 'store_word_vectors']

# Cell

import json
import pandas as pd
import tqdm
import numpy as np
import gensim

from github_search import parsing_imports, repository_descriptions
from sklearn import feature_extraction, decomposition

# Cell


def get_modules_string(modules):
    public_modules = [mod for mod in modules if not mod[0] == '_']
    return ' '.join(public_modules)


def get_module_corpus(files_df):
    module_lists = []
    repos = []

    for __, row in tqdm.tqdm(files_df.iterrows(), total=len(files_df)):
        try:
            maybe_imports = parsing_imports.get_modules(row['content'])
            module_lists.append(list(set(maybe_imports)))
            repos.append(row['repo_name'])
        except SyntaxError:
            pass
    df = pd.DataFrame({'repo': repos, 'imports': module_lists})
    return df

# Cell


def _word_vectors_to_word2vec_format_generator(vocabulary, word_vectors):
    for (word, vector) in zip(vocabulary, word_vectors):
        yield word + ' ' + ' '.join([str('{:.5f}'.format(f)) for f in vector])


def store_word_vectors(words, word_vectors, file_name):
    with open(file_name, 'w') as f:
        f.write(str(len(words)) + ' ' + str(word_vectors.shape[1]) + '\n')
        for line in _word_vectors_to_word2vec_format_generator(words, module_vectors):
            f.write(line + '\n')